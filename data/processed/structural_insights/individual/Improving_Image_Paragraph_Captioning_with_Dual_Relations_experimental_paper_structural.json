{
  "document_metadata": {
    "document_type": "experimental_paper",
    "title": "IMPROVING IMAGE PARAGRAPH CAPTIONING WITH DUAL RELATIONS",
    "authors": [
      "Yun Liu",
      "Yihui Shi",
      "Fangxiang Feng",
      "Ruifan Li",
      "Zhanyu Ma",
      "Xiaojie Wang"
    ],
    "institutions": [
      "School of Artificial Intelligence, Beijing University of Posts and Telecommunications, China",
      "Beijing Academy of Artificial Intelligence, Beijing, China"
    ],
    "publication_venue": "原文无此信息"
  },
  "technical_relationships": {
    "base_methods": [
      {
        "method_name": "Faster R-CNN",
        "relationship_type": "基于",
        "evidence_text": "We employ Faster R-CNN [19] to detect N objects in an image, represented as C={c1, · · · , cN}."
      }
    ],
    "compared_methods": [
      {
        "method_name": "Regions-Hierarchical",
        "comparison_result": "DualRel outperforms SCST on all metrics (except for a tie in METEOR) and the recent IMAP method.",
        "evidence_text": "Baselines: We compare DualRel with baselines including Regions-Hierarchical [1], RTT-GAN [5], DAM [7], SCST [8], DCPG-VAE [6], TMOS [27], CAE-LSTM [11], DHPV [9], CVAP [10], CRL [12], Dual-CNN [15], VREN [17], IMAP [14], S2TD [16], and OR-ATT [18]."
      },
      {
        "method_name": "SCST",
        "comparison_result": "DualRel outperforms SCST on all metrics (except for a tie in METEOR)",
        "evidence_text": "Results: Table 1 shows our DualRel method achieves the best scores in B@{1-4} and CIDEr. DualRel outperforms SCST on all metrics (except for a tie in METEOR) and the recent IMAP method."
      }
    ]
  },
  "experimental_setup": {
    "datasets_used": [
      {
        "dataset_name": "Stanford benchmark dataset",
        "dataset_description": "includes 14575/2487/2489 pairs for training/validation/test. The dataset comprises an average of 67.5 words per paragraph and 5.7 sentences.",
        "evidence_text": "Dataset and Metrics: We utilize the Stanford benchmark dataset [1], which includes 14575/2487/2489 pairs for training/validation/test."
      }
    ],
    "evaluation_metrics": [
      "BLEU@{1, 2, 3, 4}",
      "METEOR",
      "CIDEr",
      "BERTScore F metrics"
    ],
    "baseline_methods": [
      "Regions-Hierarchical",
      "RTT-GAN",
      "DAM",
      "SCST",
      "DCPG-VAE",
      "TMOS",
      "CAE-LSTM",
      "DHPV",
      "CVAP",
      "CRL",
      "Dual-CNN",
      "VREN",
      "IMAP",
      "S2TD",
      "OR-ATT"
    ]
  },
  "performance_results": {
    "quantitative_results": [
      {
        "metric_name": "BLEU@{1-4}",
        "our_result": "原文中我们方法的数值或'原文无此信息'",
        "baseline_result": "原文中基准的数值或'原文无此信息'",
        "dataset": "Stanford benchmark dataset",
        "evidence_text": "Table 1 shows our DualRel method achieves the best scores in B@{1-4} and CIDEr."
      },
      {
        "metric_name": "CIDEr",
        "our_result": "原文中我们方法的数值或'原文无此信息'",
        "baseline_result": "原文中基准的数值或'原文无此信息'",
        "dataset": "Stanford benchmark dataset",
        "evidence_text": "Table 1 shows our DualRel method achieves the best scores in B@{1-4} and CIDEr."
      }
    ]
  },
  "innovation_analysis": {
    "stated_contributions": [
      "提出DualRel模型，明确捕捉空间和语义关系以改进图像段落字幕生成"
    ],
    "stated_novelty": [
      "DualRel模型考虑了特定的语义和空间关系，并使用关系感知交互"
    ],
    "stated_advantages": [
      "在Stanford基准数据集上优于现有方法"
    ]
  },
  "limitations": {
    "acknowledged_limitations": [
      "原文无此信息"
    ],
    "failure_cases": [
      "原文无此信息"
    ]
  },
  "extraction_metadata": {
    "file_id": "Improving_Image_Paragraph_Captioning_with_Dual_Relations",
    "detected_doc_type": "experimental_paper",
    "extraction_time": "2025-08-02 13:22:51",
    "validation": {
      "warnings": [
        "可疑document_type: experimental_paper",
        "可疑性能数据our_result: 原文中我们方法的数值或'原文无此信息'",
        "可疑性能数据baseline_result: 原文中基准的数值或'原文无此信息'",
        "可疑性能数据our_result: 原文中我们方法的数值或'原文无此信息'",
        "可疑性能数据baseline_result: 原文中基准的数值或'原文无此信息'"
      ],
      "suspicious_count": 5,
      "validation_score": 0,
      "quality_level": "low"
    },
    "text_length": 11060,
    "processed_text_length": 11060
  }
}