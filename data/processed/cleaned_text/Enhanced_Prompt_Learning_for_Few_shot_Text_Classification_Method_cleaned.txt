增强提示学习的少样本文本分类方法

李睿凡1,2,3,† 魏志宇1 范元涛1 叶书勤1 张光卫2,4

1. 北京邮电大学人工智能学院, 北京 100876; 2. 教育部信息网络工程研究中心, 北京 100876; 3. 交互技术与体验系统文化和旅游部重点实验室, 北京 100876; 4. 北京邮电大学计算机学院, 北京 100876; † E-mail: rfli@bupt.edu.cn

摘要：针对少样本文本分类任务，提出提示学习增强的分类算法(EPL4FTC)。该算法将文本分类任务转换为基于自然语言推理的提示学习形式，通过两种粒度的损失进行优化。为捕获下游任务中含有的类别信息，采用三元组损失联合优化方法，并引入掩码语言模型任务作为正则项，提升模型的泛化能力。实验评估表明EPL4FTC方法的准确度明显优于对比基线方法。

关键词：预训练语言模型; 少样本学习; 文本分类; 提示学习; 三元组损失

1. 相关工作

本文提出的方法与基于度量学习的方法和基于提示学习的方法密切相关。基于度量学习的方法通过传统度量或深度度量实现对类别的表征。基于提示学习的方法通过将下游任务形式调整为与预训练任务一致，减小上下游任务训练方式不一致带来的差异。

2. EPL4FTC算法

EPL4FTC模型由基于自然语言推理的提示学习模块和度量优化模块组成，共享编码层的参数。基于自然语言推理的提示学习模块通过掩码语言模型头层计算输入句子中推理词的概率，并使用单句级和句群级两种粒度损失方法进行优化。度量优化模块使用三元组损失计算锚点与正负例之间的损失。

2.1 基于自然语言推理的提示学习模块

该模块负责将文本分类任务转换为基于自然语言推理形式的完型填空任务。对于给定的输入文本x，通过模板映射将真实标签转化为自然语言推理形式。定义模板的一般形式为[x'] = “[x], [z][d]”。在推理阶段，通过计算[z]处的自然语言推理词概率，选取预测为蕴含关系最大概率的标签描述d对应的真实标签作为最终预测结果。

针对单样本输入形式以及通过数据增强形式扩增负样本形成的样例集合形式，设计两种粒度的损失函数来优化建模效果。

2.2 度量优化模块

通过三元组损失函数进行有监督的度量学习，使模型可以更好地学习不同类别间的距离关系信息。使用带间隔的损失函数。

在文本分类任务中，EPL4FTC算法通过将任务转化为自然语言推理任务，并采用三元组损失优化模型泛化性能。实验结果显示，该算法在中文和英文数据集上均优于基线方法，特别是在少样本场景下。此外，通过消融实验验证了度量优化模块和句群级损失的有效性。提示模板分析表明，非自然语言形式的推理词在复杂任务中表现更优。

---

表6 中文数据集和英文数据集上推理词形式性能比较

中文数据集 英文数据集
EPRSTMT CSLDCP TNEWS IFLYTEK 平均值 AG News TREC Yelp Review 平均值
自然语言推理词 86.0 54.3 53.5 45.4 59.8 77.3 59.0 26.1 54.1
非自然语言推理词 85.3 55.1 54.6 46.4 60.4 79.5 55.8 26.1 53.8

3.6.2 提示模板的性能

手工设计的提示模板会使模型的效果产生一定的波动。实验结果表明，模型性能受提示模板的影响较大。在中文TNEWS和英文TREC任务中对模板采用前缀式与后缀式的形式进行评测，中文数据集上性能差异相对较小，准确率的最大值与最小值相差1.1%，而英文数据上性能差异较大，准确率最大值与最小值相差6.4%。这表明提示模板对模型准确率的影响与下游任务的具体形式有关。

3.7 可视化分析

采用t-SNE方法对中文TNEWS数据集进行可视化分析，评估引入度量优化模块后模型获得任务类别信息的有效性。结果表明，编码层CLS位的输出作为实例的向量化表示，已学习到一定的实例类别信息。度量优化模块通过三元组损失优化类别间的距离，使同一类别的实例间紧密聚集，不同类别的实例间存在明显间隔。

本文提出基于提示学习和三元组损失优化的少样本文本分类EPL4FTC算法，实验结果表明，该算法能有效提升文本分类的准确性。

未来的工作中，我们将尝试将EPL4FTC算法应用于其他少样本任务场景，并对其他语种的少样本文本分类进行研究。

---

[参考文献列表省略]