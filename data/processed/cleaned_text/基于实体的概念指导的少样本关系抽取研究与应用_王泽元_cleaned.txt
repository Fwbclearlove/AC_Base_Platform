关系抽取任务是指根据语义信息判断文本中两个实体的关系，从而将非结构化文本转化成结构化知识。传统的关系抽取模型需要较多的标注数据，并且很难实现新型关系的建模。为了降低标注成本且满足新型关系的建模需求，少样本关系抽取任务逐渐成为研究热点。少样本关系抽取任务通过少量标注数据建模，保证模型的泛化能力是该任务的一大挑战。近期的研宄通过将知识库融入少样本关系抽取模型，在该任务取得了较大的进展。但在现实应用中，特别是存在领域迁移的情况下，知识库的来源和类型可能存在较大的差异，知识库和融入模块的泛化能力很难得到保证。

在上述任务背景下，本文针对少样本关系抽取任务下的知识融入和领域迁移问题上进行研究，具体研究工作如下：

1. 利用实体概念作为融入知识，寻找不同类型和来源的知识库的有效融入方式。针对图类型的知识库，设计了结合语义门控机制和距离打分器的知识融合模块，该知识融合方式能在不同领域间的知识库上实现有效迁移。针对文本类型的知识库，将文本知识以模板的形式输入语言学模型，提高了模型对于知识的感知。此外，针对已知目标领域的情况，设计了领域导向的元训练方法，从训练数据中获取与领域更为相关的知识，并在训练过程中利用样本对维度的正则项来约束样本的特征表示，提高训练的稳定性。

2. 基于上述模型，设计并实现了少样本关系抽取系统。该系统支持用户定义关系，包括用户管理、数据管理、图谱管理等模块；通过上述模块完成训练数据和测试数据的上传，经过离线训练实现少样本关系抽取的自动化流程。系统测试结果表明设计的系统能够高效完成新型关系的快速抽取工作。

关键词：关系抽取少样本学习领域迁移知识库

知识图谱的构建包括实体抽取和关系抽取两部分。实体抽取方法包括基于Pipeline的方法和联合抽取方法。基于Pipeline的方法通过依次抽取实体和关系来完成知识图谱的构建，而基于联合抽取的方法则是直接抽取知识三元组。早期的实体抽取方法依赖人工抽取或构建规则，而近年来，基于统计学习和深度学习的方法逐渐应用于实体抽取，并取得了显著的性能提升。

关系抽取是指根据文本描述判断文本中两个实体之间的关系。传统的关系抽取任务利用高质量的标注数据来训练关系抽取模型。根据模型特点，传统的关系抽取模型分为基于特征、基于核、深度学习和联合抽取等方法。基于特征的关系抽取模型通过特征编码器和分类器进行建模，而基于核函数的关系抽取模型利用核函数计算文本间的实体关系相似度。基于深度学习的关系抽取模型通过词向量技术和深度学习模型进行结合，通过大量数据训练实现关系抽取任务性能的显著提升。

少样本关系抽取方法的发展现状可分为三类：基于元学习的少样本关系抽取方法、基于预训练模型的少样本关系抽取方法和基于知识增强的少样本关系抽取方法。基于元学习的少样本关系抽取方法会利用较多的关系类别数据进行元训练，然后在少样本任务上进行微调。基于预训练模型的少样本关系抽取方法通过语言模型学习到的知识来解决样本不足的问题。基于知识增强的少样本关系抽取方法将现有的知识库融入模型，提升少样本任务性能。

本文旨在通过融入知识库信息来提升模型在少量标注数据下的关系抽取能力。选择实体概念作为融入知识，设计泛化能力较强的知识融合模块，实现不同领域知识库的有效融入。同时，基于少样本关系抽取模型构建关系抽取系统，在领域图谱构建和新型关系抽取任务上进行实际应用。

清洗后的内容如下：

CBOW模型通过输入词矩阵V和输出词矩阵U构建上下文词与中心词的关系，最后得到矩阵U和矩阵V。ELMO模型采用双向LSTM结构，对词的表示能够抓住上下文的语义。BERT模型采用Transformer的编码器结构，采用两阶段的训练方式来获得语言模型。少样本学习是机器学习的一种类型，主要针对数据量不足的问题。元学习是少样本学习的一种训练策略，通过训练集进行元训练，通过将训练过程中的经验以先验知识的形式存储进模型，在少样本任务上能够实现快速的迁移。度量学习利用度量公式直接计算样本相似度，避免了参数优化的过程。孪生网络和原型网络是两种常见的度量学习方法。Prompt方法通过重新修改下游任务形式，使下游任务与预训练任务更为相似，希望利用预训练期间的模型结构就能完成下游任务。PET方法通过设置模版，将下游任务转化为MASK词预测预训练任务。

如图2-8所示，模版函数为“这是[情感]的情感”，映射函数v为“积极—正向，消极—负向”。PET方法构建多个(p,v)映射来解决模版敏感问题，然后通过多个模板的集成提升模型性能，并选取置信度高的标签作为伪标签。具体而言，PET有三个步骤：(1)对于每个模版(p,v)使用小的训练集进行预训练模型的训练；(2)对于未标注的数据集，通过集成上述多个预训练模型得到未标注数据的伪标签；(3)利用数据集的伪标签训练一般的模型。此外，集成的时候可以根据不同的模版映射，设置相应的权重，对集成的分数进行加权。模型的加权分数是采用语言模型计算得到。

2021年Facebook提出EFLL(eatment few-shot learner)，将少样本文本分类任务转换为文本对关系预测的预训练任务。针对每个类别设定相应的模板，通过计算所有类别模版与句子的逻辑关系来计算句子的类别概率。输入文本X，每个类别标签/通过模版函数p构成标签模板p(X)。EFLL利用语言模型M来计算输入文本x和每个模版的逻辑关系。句子对的逻辑关系集合S为{entailment, not_entailment}。通过计算输入句子x与每个标签的p()的逻辑关系，选择逻辑关系为entailment概率最大的标签作为预测值。

在少样本任务的训练中，EFLL将所有的标签模版和文本进行拼接，然后根据句子的真实标签标签，得到句子对的逻辑关系标签。当句子与模版的标签一致时，两者的逻辑关系是entailment；当句子与模版的标签不一致时，两者的逻辑关系是not_entailment。通过句子对的逻辑标签和模型的预测值使用交叉熵损失来训练逻辑关系判断模型。如图2-9所示，在新闻分类任务中对每个标签构建了模版，通过计算输入文本与各个模版的关系来进行训练和预测。

EFLL方法通过将文本分类任务转化为句子对的逻辑关系预测任务，由于句子对的逻辑关系集合是较为固定的，因此可以利用公开的句子关系逻辑判断数据集进行中间训练。在EFLL训练模式中，首先通过逻辑关系判断数据集对模型进行中间训练，然后利用少样本数据和标签模板构建句子对的逻辑关系判断任务，最后利用模型和标签模版对文本类别进行预测。

在实际应用层面，利用实体的本体作为概念是一种高效的概念获取方式。本文也采用这种方式获取实体概念信息，其简洁高效，获取成本较低。此外，还有其他渠道可以获取概念知识，包括Microsoft Concept Graph、CN-Phrase等多个大规模实体概念知识库。实体概念知识具有以下特点：概念和实体通常是“多”的映射关系，概念的表示形式不同，概念粒度不固定，这些都是概念知识作为知识库时需要关注的问题。

在概念映射部分，已经有很多工作完成了该部分的数据收集，但由于实体的不断出现，维护实体和概念的映射是较为困难的工作。本文参考了相关工作，利用实体和“isa”关系构建查询语句，将查询得到的节点作为实体的伪映射概念。具体而言，本文利用公有知识图谱Wikidata和医学知识图谱UMLS作为知识库，利用Wikidata的SPARQL查询服务来完成实体和概念的映射。通过上述方式，本文能对FewRel中的绝大多数实体查询到对应的概念。

在概念编码部分，本文使用的知识库Wikidata和UMLS均为开源的知识图谱。在知识融入时，本文选择两种知识表示形式，包括概念的文本标签和概念节点的图编码向量。在对概念图谱进行图嵌入编码时，由于公开知识图谱Wikidata的规模巨大，本文将其划分为概念层级和实体层级，在知识图谱Wikidata上仅用概念层级的图谱进行图嵌入编码。在UMLS知识库中，由于图谱的数量较少，本文直接使用整个图谱进行编码。本文使用到的知识图谱UMLS和Wikidata的规模如表3-2所示，该规模的图谱能够利用图嵌入算法快速得到对应的图编码结果。编码方式本文选择了DistMult技术。

通过概念映射和概念表示模块，能够将文本中的头实体ehead和尾实体etail映射成概念chead和ctail。提取概念节点的文本标签和图嵌入表征得到知识表示，概念知识的链接和表示为知识融入模块的提供了知识输入。

在文本形式的概念融入部分，当概念知识以文本标签形式融入基础模型时，本文直接将实体概念的文本标签拼接到实体后面，通过文本序列位置上的关联让模型关注到实体和概念的联系。此外，实体与概念的映射关系通常是一对多的，当某个实体存在多个概念时，本文直接将所有概念的文本标签拼接起来，将整体的拼接结果放在文本序列中实体后方，并用BERT的特殊字来标记概念知识的开始和结束位置。

在图谱形式的概念融入部分，当概念以图谱编码的形式融入基模型时，由于文本与概念的表示存在较大的模态差异，概念不能直接以输入的形式输入基础模型。针对模态差异，需要设计知识融入模块来实现文本和概念知识的融合。知识融入模块需要考虑文本和知识的模态差异，以及不同来源知识库在的领域差异。模态差异是由于文本语义和概念知识的数据来源和编码方式不一致产生的，文本语义是输入的非结构化文本经过BERT编码器得到的语义向量，概念知识则是概念图谱中的节点通过图编码技术得到的编码向量，数据来源不同和编码方式不同导致两者在模态维度上差异巨大。领域差异是指训练领域上用的知识库和测试用的知识库是不一致的，这会导致图嵌入编码的向量差异巨大，因此如何保证知识融入方式在不同领域间具有一定的泛化能力也是知识融合模块的挑战。

在元学习增强模块部分，本文构建了句子对级别的对比学习优化目标作为正则项，来减小过拟合的风险和训练时的过大波动问题。在领域导向性训练部分，本文构建了两阶段的元学习训练模式，首先通过训练集和验证集进行元学习训练，然后利用打分模型在第二次训练中计算每个样本的真实标签的置信度作为权重，以损失加权的方式进行领域导向性训练。

在实验结果分析部分，本文采用公开数据集FewRel作为实验数据集，利用训练集进行元学习训练，在验证集和测试集上，通过构建Episode来实现少样本任务的测试，通过构建大量Episode并使用其平均准确率作为评判指标。

本文主要探讨了实体概念指导下的少样本关系抽取模型。首先介绍了数据集FewRel 1.0和FewRel 2.0，其中FewRel 2.0包含领域迁移和不包含类别两个任务。接着，利用知识图谱Wikidata和医学领域图谱UMLS构建了训练集和验证集的知识库。在模型方面，采用了BERT-BASE对文本进行编码，并设计了不同的知识融入模块。实验结果显示，文本形式的概念知识融入可以显著提升性能，而图谱形式的概念融入也取得了不错的效果。最后，通过对比实验验证了所设计的模型的有效性。

清洗后的内容如下：

---

本文详细介绍了少样本关系抽取模型的各模块，包括概念知识增强模块和元学习增强模块。在概念知识增强模块中，针对不同形式的概念知识，设计了相应的概念表示和概念融合机制。在元学习增强模块，通过设计对比学习正则项来对模型的语义表征进行限制，针对目标领域已知的情况设计了领域导向性元训练来获取更好的领域迁移性能。在公开数据集FewRel上对上述模型进行实验，验证了实体概念知识在少样本关系抽取上的有效性，并对比了不同知识融入方法的性能，并对融合结果进行可视化等多维度的分析。此外，本章还验证了元学习增强模块的有效性，实验表明对比学习正则项和领域导向性元学习均能取得不错的结果。

---

以上内容已去除页眉、页脚、页码、重复信息和乱码等噪音，保留了核心学术内容。

第8部分内容：

4.2.2 数据库设计

少样本关系抽取系统的存储内容主要包括上传的数据和抽取的图谱。存储的数据和图谱主要是以Json文件格式进行存储。上传文件和图谱的具体格式如表-2所示。

表-2 系统上传数据和抽取图谱格式

数据类型    Key    Value
上传数据    annotation_data    category    数组
category    [[sl^e^UsI^e^], ...]
testdata

图谱    kg    [[el, e2, rl, score], ...]

在文件描述中，上传文件包括少样本标注数据annotation_data和推理数据testdata，每条数据包括句子si和句子中对应的头实体4和尾实体es；在图谱设置的格式中，el、e2表示头实体和尾实体，rl表示关系，score表示实体关系的模型置信度。

系统利用MySQL来存储用户的相关信息，角色信息，图谱数据的路径等信息。本系统共设定了5张表，具体包括：用户基本信息表(user_info表)，角色权限映射表(role_permission表)，用户权限表(permission表)，数据管理表(upload_data表)，图谱管理表(kg_data表)，具体的功能如表4-3所示。

表4-3 数据表描述信息

数据表    功能
用户基本信息表    存储用户的基本信息和注册信息
角色权限映射表    角色对应的权限等级
用户权限表    用户和权限的映射
数据管理表    数据的描述信息和存储地址
图谱管理表    图谱的描述信息和存储地址

通过上述表，能够实现系统功能的实现，并对信息进行管理，具体的数据表字段如图4-6所示。

4.3 功能模块设计

4.3.1 前端展示模块

前端展示模块是用户与系统的交互模块，设计系统时，需要考虑到用户操作的便利性。前端展示模块包括两个功能栏，包括菜单栏和功能栏，菜单栏和功能栏一一对应，功能栏会随着菜单栏的点击而改变。菜单栏主要包括三部分：用户管理、数据列表和图谱列表。如上述描述，具体的前端模式页面布局如图-7所示。

4.3.2 后端模块

后端模块是前端展示模块通过界面和系统的数据进行交互，前端模块通过http请求完成对应的数据传输。在数据层面，通过将http请求将对应的功能转换成SQL语句，将查询结果转换成Json文件格式，然后展示给用户。后端模块的部分接口如表4-4和表4-5所示。

4.3.3 数据上传模块

数据上传模块是指用户通过该模块将本地文件上传至服务器，用户可以对服务器中上传的文件进行操作，包括删除，使用关系抽取模块构建抽取模型等功能。数据上传模块的部分接口如下表所示。

4.3.4 关系抽取模型构建模块

关系抽取模块会利用上文少样本关系抽取模型实现少样本关系抽取分类，为了避免模型在多个少样本任务生成过多模型，导致系统的存储风险。该系统要求用户在上传训练数据的同时上传测试数据，方便测试后即可删除训练后的模型。在上传数据模块需要上传满足如上述表4-4的数据，然后选择对应的数据建模并对图谱进行管理。该模块的接口如下表4-8所示。

4.3.5 用户管理模块

用户管理模块可以对系统用户的信息进行管理，通过对用户的权限进行判断，来限制用户的部分操作。

4.4 系统测试

4.4.1 测试环境

系统开发结束后，会对系统进行功能性测试和非功能性测试，功能性测试是指对系统的各个模块是否能够正常运行，非功能性测试是指对系统的响应时间，运行流畅度进行测试。在测试过程中，系统的运行环境如表4-10所示，并记录测试结果。

4.4.2 功能性测试

本系统的目的是构建少样本关系抽取模型的落地应用。用户通过上传某类型关系的少量标注数据和测试数据，系统利用少样本关系抽取系统和少量标注数据完成模型的快速训练。在测试数据上进行快速推理，得到对应的三元组知识图谱。此外，需要满足系统的登陆功能、用户管理功能等。如图4-8和图4-9所示是对应的用户登陆界面和用户管理界面。用户管理界面可以对用户的权限进行限制、密码进行重置、以及用户删除等操作。

4.5 系统测试

4.5.1 测试环境

系统开发结束后，会对系统进行功能性测试和非功能性测试，功能性测试是指对系统的各个模块是否能够正常运行，非功能性测试是指对系统的响应时间，运行流畅度进行测试。在测试过程中，系统的运行环境如表4-10所示，并记录测试结果。

4.5.2 功能性测试

本系统的目的是构建少样本关系抽取模型的落地应用。用户通过上传某类型关系的少量标注数据和测试数据，系统利用少样本关系抽取系统和少量标注数据完成模型的快速训练。在测试数据上进行快速推理，得到对应的三元组知识图谱。此外，需要满足系统的登陆功能、用户管理功能等。如图4-8和图4-9所示是对应的用户登陆界面和用户管理界面。用户管理界面可以对用户的权限进行限制、密码进行重置、以及用户删除等操作。

第9部分内容：

4.4.3 非功能性测试

本节主要对系统的兼容性和流畅性进行测试，以及少样本学习算法的时间消耗进行测试。在流畅性测试中，本文进行了登录界面速度、页面切换速度、接口响应速度的测试。在兼容性中，本文进行了浏览器兼容性的测试，以验证该系统的运行情况。具体测试结果如表4-11所示，可以看到测试结果满足系统需求分析中的要求。

表4-11 系统非功能性测试结果

| 测试用例 | 测试结果 |
| --- | --- |
| 登录页面速度 | 通过登录界面提交登录信息到系统后台，并在2秒以内返回结果 |
| 页面切换速度 | 点击不同的菜单栏切换右侧的不同功能页面，加载时间在2秒以内 |
| 接口响应速度 | 页面提交请求到后端响应，服务器响应时间在5秒之间 |
| 浏览器兼容性 | 在Chrome和Safari浏览器登录系统界面，页面展示正常，系统运行正常 |

系统在保证稳定流畅运行的基础上，需要利用少样本数据进行关系抽取任务。由于少样本关系抽取系统是基于文本对的形式，即将测试文本与标注数据进行拼接，所以标注数据量的增多，会增加模型推理时间的损耗。在不同少样本设置下，单条样本推理时耗情况如表4-12所示，可见该少样本关系抽取系统在大多数情况下的推理时间在接受范围内。

表4-12 模型推理时耗情况

| 少样本设置 | 平均时耗 | 时耗方差 |
| --- | --- | --- |
| 5-way 1-shot | 40ms | 2ms |
| 5-way 5-shot | 182ms | 31ms |
| 10-way 1-shot | 174ms | 42ms |
| 10-way 5-shot | 398ms | 134ms |

4.5 本章小结

本章介绍了少样本关系抽取系统的设计与实现的具体细节，包括需求分析、系统概要设计、系统的各个功能模块的详细实现方案。整个系统的功能模块包括数据管理模块，用户管理模块，关系抽取模块三个部分，通过这三部分的有效组合，能够完成少样本关系抽取系统的基本功能。在测试阶段对系统的各个功能模块的功能性和非功能性进行了测试，以验证系统的运行流畅度和兼容性，并且对少样本关系抽取模型的性能时耗进行了测试。通过该系统，少样本关系抽取模型能够应对新关系或是特殊领域上的关系建模问题，提升了关系抽取任务的效率。

Connecting language and knowledge bases with embedding models for relation extraction

Extracting relations between entities in text is a crucial step for many natural language processing tasks. Recent years have seen a growing interest in using embedding models to connect language and knowledge bases for relation extraction. These models can capture semantic information and improve the accuracy of relation extraction.

Several studies have explored the use of feature-rich compositional embedding models for relation extraction. These models can represent the meaning of phrases and sentences by combining the embeddings of their constituent words. For example, Gormley et al. (2015) proposed a model that uses a feature-rich compositional embedding to improve relation extraction.

Other studies have used neural networks for relation extraction. For instance, Liu et al. (2013) proposed a convolutional neural network model for relation extraction. Similarly, Zhang et al. (2015) used a bidirectional long short-term memory network for relation classification.

More recent approaches have explored the use of pre-trained language models like BERT for relation extraction. For example, Devlin et al. (2018) used BERT for relation extraction by fine-tuning the model on a relation extraction task.

In summary, embedding models and neural networks have shown promise for improving relation extraction by connecting language and knowledge bases. These approaches can capture semantic information and improve the accuracy of relation extraction.