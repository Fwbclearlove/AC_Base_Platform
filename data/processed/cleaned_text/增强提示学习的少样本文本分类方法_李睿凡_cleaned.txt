针对少样本文本分类任务，提出了一种名为EPL4FTC的提示学习增强分类算法。该算法首先将文本分类任务转换为基于自然语言推理的提示学习形式，以利用预训练语言模型的先验知识，实现隐式数据增强。通过两种不同粒度的损失优化，并引入三元组损失联合优化，以捕获下游任务中的类别信息。同时，掩码语言模型任务作为正则项，提升模型泛化能力。在多个中英文文本分类数据集上进行了实验评估，结果表明EPL4FTC方法在准确度性能上明显优于对比的基线方法。

其中，Ie表示在当前样例组中真实标签为蕴含关系的位置索引，g(s(z|x))表示语言模型对位置处的推理词在蕴含关系上的预测得分。最后，基于自然语言推理的提示学习模块的损失函数定义如下：

Lp= (1 −α) ∙Ls+ α∙Lq (6)

其中，α为可调节的超参数。

图2 单句级与句群级的优化图

度量优化模块的目标是使在语义空间中属于同一类别的实例的距离更接近，而不同类别的实例的距离远离。通过三元组损失函数进行有监督的度量学习，使模型可以更好学习不同类别间的距离关系信息。此外，使用带间隔的损失函数可以提升模型的泛化性能。具体地，构造三元组数据时，在某个类别中选定一个实例作为锚点，同类别的实例作为正例，其他类别的实例作为负例。

Ltm= ∑ max(0, d(Am, Pm) −d(Am, Nm) + ∆) M m=1 (7)

其中，d(Am, Pm)表示锚点与正例间的距离，d(Am, Nm)表示锚点与负例间的距离，∆表示设定的间隔值。

此外，少样本学习场景中用于训练的数据量通常十分有限。为了缓解灾难性遗忘的问题，使用掩码语言模型优化目标作为正则项进行建模。所以度量优化模型的损失函数表示为：

Lax= (1 −β)Ltm+ βLmlm (8)

其中，Lmlm表示语言模型损失，β表示相应的权重参数。

最后，整体的损失函数由提示学习损失Lp和度量优化损失Lax的加权构成，具体如下：

Ltotal= (1 −γ)Lp+ γLax (9)

其中，Lp表示基于自然语言推理的提示学习模块的损失，Lax表示度量优化模块的损失，γ表示权重参数。

2.3 模型训练与推理

EPL4FTC算法将文本分类任务转化成自然语言推理任务，即转化后的任务是一个二分类任务。因此，当一个原始分类任务包括N个类别时，该算法需要进行N次推理，最后选择推理概率最大所对应的标签类别作为最终预测结果。所以，1) 在模型训练过程中，为提升模型的泛化性能同时降低模型训练的成本，通过负采样的方式对下游任务进行训练。对于一个包含多个类别的分类任务，将每一个实例与之对应的类别作为正例，同时随机选择K个其他类别与当前实例构成负例。以上数据构造方式不但能够提升模型的性能，而且相比使用全部类别作为负例进一步缩短了训练模型所需的时间。2) 在模型推理阶段，EPL4FTC算法仅使用基于自然语言推理的提示学习模块。具体地，对于包含N个标签的文本分类任务，对每一个实例生成包含自然语言推理提示模板的N条新的输入实例。通过模型预测出每一个实例中位置处所蕴含推理词的概率，在N个预测结果中选择预测最大概率所对应的标签作为当前原始输入实例的预测结果。

3 实验与结果 3.1 实验数据集

1) 中文数据集。中文数据集使用少样本评测数据集FewCLUE中的文本分类任务对应的数据集。本文在4个不同领域的评测数据集上进行实验。其中，EPRSTMT为电商评论情感分析任务，是典型的包含正负向情感的二分类任务。CSLDCP是科学文献学科领域的长文本多分类任务，包含了67个类别。TNEWS是新闻标题的短文本分类任务，包含了教育、娱乐和文化等15个类别。最后，IFLYTEK是根据APP应用的长文本主题描述信息对超过100多个应用类别进行分类的任务。2) 英文数据集。本文采用3个英文文本分类数据集AG News、TREC以及Yelp Review进行评测。其中，AG News是学术新闻搜索引擎从多个新闻来源中搜集超过了100万篇新闻文章构成的数据集。它包含4类新闻主题，分别是世界、体育、商业和科技。TREC数据集包含6个一级标签和47个二级标签。Yelp Review数据集来自Yelp的用户评论。它的标签是用户对商品的星级打分，共分为5级。用于评测的英文数据集将从以上数据集中抽样获得。将每一个原始英文数据集中随机抽取8个、16个和32个实例形成对多个不同规模的数据集用于训练，测试集为默认。

3.2 基线方法

采用的基线方法包括：1)基于微调方法：在预训练语言模型的基础上，通过为模型添加任务相关的分类器，达到使模型可以处理具体的下游任务的目的。2)Zero-shot方法：基于Roberta等自编码预训练语言模型，通过MLM进行推理评测。3)Zero-shot(GPT)方法：基于GPT自回归预训练语言模型，通过从左至右的语言模型进行推理评测。4)PET方法：通过添加人工自定义模板，将下游任务转化成完成填空形式的任务，然后在候选标签列表中选择合适的标签。5)ADAPET方法：对模板搜索正确答案时从有限候选词变成整个词表，扩大了模型的搜索空间。此外，对正确标签反向预测原文中的词，实现模型性能的提升。6)LM-BFF方法：通过自动化生成的离散化自然语言作为提示模板，同时通过采样的形式将实例以上下文的方式添加到每一个输入中。7)P-tuningR方法：区别于自然语言形式的提示模板，采用Roberta作为预训练语言模型，实现让模型自动学习到最佳的连续式的非自然语言提示模板。8)EFL方法：通过添加人工自定义模板，将下游任务转化成蕴含任务形式，并添加额外的二分类器，实现对下游任务的微调。

3.3 实现细节与评测指标

实验在配有CUDA环境的Linux操作系统下进行，并配置了两块GTX 1080Ti显卡。代码使用基于PyTorch框架的HuggingFace工具包实现。对于中文数据集的评测，采用12层网络结构的中文RoBERTa-wwm-ext预训练模型。对于英文数据集的评测，采用12层结构的BERT-BASE预训练模型。模型参数设置如下：学习率为10−5，超参α设置为0.7，β为0.01，γ为0.02，三元损失间隔∆为0.15，并且使用AdamW优化器进行模型参数的优化。依据之前的研究，在少样本学习问题中通常使用准确率(Accuracy)作为评测指标。它表示模型预测正确的样本数量占所有的样本数量的比例。

3.4 实验结果

1) 中文数据集的实验结果。实验结果如表1所示。可以看到，对于基于微调的方法，在小样本学习场景中模型性能通过表现不佳。而对于采用基于提示学习的方法，通过使用PET、LM-BFF、EFL、P-tuningR方法以及EPL4FTC算法，在小样本学习场景中模型的准确率都有大幅提高，显示出提示学习方法具有强大的潜能。通过对比EPL4FTC算法与其他基于提示学习的方法(PET、ADAPET、LM-BFF、EFL和P-tuning等)，可以看出EPL4FTC算法在EPRSTMT、CSLDCP和TNEWS等数据集上取得了优异的成绩。此外，在IFLYTEK数据集上也取得了与其他现有方法同等效果的性能。而且，EPL4FTC算法在中文文本分类任务的平均准确率性能上取得了最高的成绩。与转换为完形填空任务形式的PET和ADAPET等方法相比，EPL4FTC算法在利用预训练模型中已经学习到的通用知识基础上，引入下游任务的类别信息实现更好的建模效果，并在任务的平均准确率上高出3.9%。与转化为文本蕴含任务的EFL方法相比，EPL4FTC算法没有引入额外需要学习的大规模参数，并且与预训练语言模型任务保持一致，有效减小上下游任务间的差异性，最终在任务的平均准确率上高出4.2%。与使用自动构建模板或是非自然语言形式模板的LM-BFF和P-tuning方法相比，EPL4FTC算法无需繁琐的模板构建形式，并且在任务的平均准确率上高出1.6%。

表1 中文少样本数据集实验结果

2) 英文数据集的实验结果。本文英文数据集的训练集中每一类别包含不同规模的实例数量(K=8, 16和32)。实验结果如表2所示。从结果可以看出，对于不同的实例数量，基于微调的方法、PET、ADAPET、EFL、P-tuning以及EPL4FTC算法，都表现出随着实例数量的不断增多，模型的准确率都有着明显的提升。这表明在基于深度模型的少样本学习场景中，训练数据的规模对模型性能有着较大影响。其次，在实例数K=8时，虽然PET、ADAPET、EFL和P-tuning等基于提示学习的方法比基于微调的方法模型的准确率有很大提升，但EPL4FTC算法却表现出更加出众的性能，其模型准确率远高于其他方法。这表明在给定较少实例的情况下，EPL4FTC算法能够有效地对下游任务进行建模，也进一步说明了该算法的有效性。进一步，随着实例数的增加(K=16, 32)，虽然其他基于提示学习方法

---

1) 推理词形式性能分析。EPL4FTC算法将文本分类任务转换为自然语言推理形式的完型填空任务，同时受P-tuning方法启发，比较了自然语言形式与非自然语言形式推理词的性能。实验结果表明，在中文和英文数据集上，非自然语言形式推理词表现出更稳定性能。对于简单、数据区分度高的任务，如EPRSTMT和TREC，自然语言形式推理词表现更佳；而对于类别多、复杂的任务，如TNEWS、IFLYTEK和CSLDCP，非自然语言形式推理词性能更优。

2) 提示模板性能分析。本文评估了手工设计的提示模板对模型性能的影响。实验发现，模型性能受提示模板影响显著，尤其在英文TREC任务上，模板形式的不同导致性能差异较大。优化模板形式可显著提升模型性能。

3) 可视化分析。通过t-SNE方法对中文TNEWS数据集进行可视化分析，验证了模型编码层学习到的类别信息。结果显示，CLS作为句子编码表示已学习到一定的类别信息，且度量优化模块为模型提供了额外的类别知识。

提出的EPL4FTC算法利用三元组损失增强提示学习，通过句子和句群粒度的三元组损失优化，捕获下游任务的类别信息。实验证明了算法的有效性，未来将扩展至其他少样本任务场景及多语种文本分类研究。

---

[注：参考文献列表和其他非结构化内容在此次清洗中已被省略。]