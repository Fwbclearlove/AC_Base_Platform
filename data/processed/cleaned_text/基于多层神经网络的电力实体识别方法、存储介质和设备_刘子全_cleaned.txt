本发明公开了一种基于多层神经网络的电力实体识别方法、存储介质和设备。该方法包括将待识别的电力语料输入至预先构建的BERT电力实体识别模型中，得到电力实体标签的哈夫曼编码，通过哈夫曼编码映射得到实体标签，进而得到识别出的实体。通过语言模型训练语料对BERT语言模型进行预训练；对电力语料数据标注电力实体标签，构建电力实体识别语料；根据电力实体标签在电力实体识别语料中的数量构建电力实体标签的哈夫曼编码；在预训练得到的BERT语言模型后增加分类层构成BERT电力实体识别模型，通过电力实体识别语料对BERT电力实体识别模型进行再次训练，得到训练好的BERT电力实体识别模型。提高了电力领域中文命名实体识别的精度。

---

[0068] 采用BMEO标记形式构建伪标注语料，以减少人力成本。字符单元若是实体词开始则标记为B‑实体类别，结束则标记为E‑实体类别，非开始非结束字符标记为M‑实体类别，非实体词字符标注为O。

[0069] 步骤4：根据电力实体标签数量构建哈夫曼编码；

[0070] 采用哈夫曼树编码表示实体标签类型，包括“B‑0”到“B‑8”，“M‑0”到“M‑8”，“E‑0”到“E‑8”和“O”，共28个实体标签。根据这些实体标签在电力实体识别语料中的数量构建哈夫曼树。

[0071] 实体标签哈夫曼编码可缓解类别不平衡问题，通过模型预测标签的哈夫曼编码路径，使用前向最大匹配进行标签映射。

[0072] 步骤5：在预训练BERT语言模型后增加分类层构成BERT电力实体识别模型，通过电力实体识别语料进行再次训练；

[0073] BERT电力实体识别模型输入文本经过嵌入层、多层编码器，分类层包括全连接层和Sigmoid激活函数，输出为预测的电力实体标签的哈夫曼编码。

[0074] 步骤6：待识别语料输入BERT电力实体识别模型，通过哈夫曼编码映射得到实体标签，识别出预先定义的9个类别的实体。

[0075] 待识别语料逐句输入模型，通过哈夫曼编码和实体标签映射关系，识别实体。

[0076] 实施例2：计算机可读存储介质包含程序，用于执行基于多层神经网络的电力实体识别方法。

[0079] 计算设备包括处理器、存储器及程序，用于执行基于多层神经网络的电力实体识别方法。

[0084] 本发明可做出若干改进和变形，这些改进和变形也应视为保护范围。

---