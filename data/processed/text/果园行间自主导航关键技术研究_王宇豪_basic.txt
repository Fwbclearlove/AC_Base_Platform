Research on Key Technologies of Autonomous

Navigation Between Rows in Orchard

Wang Yuhao

A Dissertation Submitted to

North China University of Technology

In partial fulfillment of the requirement

For the professional degree of

Master of Engineering

North China University of Technology

May, 2021

果园行间自主导航关键技术研究

自1990年至2019年，我国水果产量均位于世界首位，果品及其相关产业已逐

渐成为农村经济的重要支柱。为进一步提高生产效率和水果品质，农业机械装备

的智能化是未来发展的必然趋势。智能农业装备可利用传感器感知环境信息和自

身状态，在果园环境中完成预定任务。果园行间自主导航作为农业智能化的关键

技术，实现行间自主运行，有效降低劳动强度，提高作业效率。水果种植园为复

杂多变的非结构未知环境，实现自主运行的关键是环境感知、位姿估计和自主定

位。本文围绕单目视觉导航和激光雷达导航展开研究，其中(1)、(2)属于激光雷

达导航，(3)-(5)属于单目视觉导航，主要工作和创新点如下：

(1)为抑制激光点云密度对滤波器的影响，提出自适应半径滤波方法。该方

法根据目标距离动态计算滤波半径，实现多尺度噪声去除。实验结果表明：与原

始数据相比，DBSCAN聚类精确率提升0.40，召回率提升0.34，计算时间为43ms。

(2)针对可通行区域提取与位姿估计的需求，提出基于交叉像素的可通行区

域提取方法。实验结果表明：在密集种植和非密集种植条件下，该方法均能较准

确地提取可通行区域、偏航角和横向位移，具有较高的适应性和稳定性。

(3)研究场景语义信息提取方法，基于改进的Mask R-CNN网络分割道路与树

干，基于霍夫变换计算边界方程和消失点坐标。实验结果表明：该方法提取复杂

光照条件中的多尺度目标信息，为单目位姿估计和视觉导航提供有效参考。

(4)针对高精度位姿估计的需求，建立果园行间的道路几何成像模型，实现

偏航角、横向偏移与道路宽度的定量计算。实验结果表明：道路宽度测量精度

0.989，偏航角平均误差0.042，横向位移平均误差0.048，平均计算时间56ms。

(5)针对果树定位需求，利用树行共线性和边界平行性，基于单目相机实现

果树相对位置计算。实验结果表明：横向定位平均误差0.038，纵向定位平均误

差0.027，株距估计平均误差0.081，平均计算时间1.1ms。

关键词：自主导航，位姿测量，相机模型，深度神经网络，自适应半径滤波

Research on Key Technologies of Autonomous Navigation

Between Rows in Orchard

Abstract

From 1990 to 2019, Chinese fruit production ranked first in the world, and fruit

industry has gradually become an important pillar of the rural economy. In order to

further improve production efficiency and fruit quality, intelligent agricultural

equipment is an inevitable trend of future development. The equipment can use

sensors to perceive environment and its own state, and complete predetermined tasks

in the orchard environment. As the key technology of agricultural intelligence,

autonomous navigation between rows of orchards can realize autonomous operation

between rows, reducing labor intensity and improving work efficiency. Orchard is a

complex non-structural unknown environment. The key to achieving autonomous

operation is environment perception, pose estimation and autonomous positioning.

This paper focuses on monocular vision navigation and lidar navigation, (1) and (2)

belong to lidar navigation, and (3)-(5) belong to monocular vision navigation. The

main work and innovations are as follows:

(1) For the problem of filter sensitivity to LiDAR point cloud density, an

adaptive radius filtering method is proposed. This method dynamically calculates the

filter radius according to the target distance to realize multi-scale noise removal. The

experimental results show that compared with the raw data, the DBSCAN precision

rate is increased by 0.40, the recall rate is increased by 0.34, and the average

calculation time is 43ms.

(2) For the problem of road extraction and pose estimation based on LiDAR, a

passable area extraction method based on intersecting pixels is proposed. The

experimental results show that the method can accurately extract the passable area,

yaw angle and lateral displacement in both dense planting mode and non-dense

planting mode, and has high adaptability and stability.

(3) Scene semantic information extraction technique is studied, based on the

improved Mask R-CNN network, realize the segmentation of roads and tree trunks,

and calculate the boundary equation and vanishing point coordinates based on the

Hough transform. Experimental results show that this method extracts multi-scale

target information in complex lighting conditions, and provides an effective reference

for monocular pose estimation and visual navigation.

(4) For the problem of high-precision pose estimation, a geometric imaging

model of roads between rows of orchards is established. Based on this model, the

calculation methods of yaw angle, lateral offset and road width are realized. The

experimental results show that the measurement accuracy of road width is 0.989, the

average error of yaw angle is 0.042, the average error of lateral displacement is 0.048,

and the average calculation time is 56ms.

(5) For the problem of fruit tree positioning, the relative position of fruit trees is

calculated based on the monocular camera by using the collinearity of the tree rows

and the parallelism of the boundaries. The experimental results show that the average

error of horizontal positioning is 0.038, the average error of longitudinal positioning is

0.027, the average error of plant spacing estimation is 0.081, and the average

calculation time is 1.1ms.

Key words: autonomous navigation, pose measurement, camera model, deep neural network, adaptive radius filter

摘 要 .................................................. I ABSTRACT ............................................... II 第一章 绪论 ............................................ 1

1.1 研究背景和意义 ................................................................................................. 1

1.2 国内外研究现状及存在的问题 ......................................................................... 2

1.2.1 基于激光雷达的行间自主导航技术 ........................................................... 2

1.2.2 基于视觉的行间自主导航技术 ................................................................... 3

1.3 研究内容 ............................................................................................................. 5

1.4 组织结构 ............................................................................................................. 5 第二章 行间自主导航理论基础 ............................. 7

2.1 惯性导航理论 ..................................................................................................... 7

2.2 激光雷达导航理论 ............................................................................................. 8

2.2.1 点云滤波方法 ............................................................................................... 8

2.2.2 点云密度聚类方法 ....................................................................................... 9

2.3 单目视觉导航理论 ........................................................................................... 11

2.3.1 单目相机成像原理 ..................................................................................... 11

2.3.2 目标信息提取方法 ..................................................................................... 13

2.4 本章总结 ........................................................................................................... 17 第三章 基于自适应半径滤波的激光点云去噪方法 ............ 18

3.1 激光点云噪声来源及特点 ............................................................................... 18

3.1.1 激光雷达噪声产生原因 ............................................................................. 18

3.1.2 激光点云密度特性 ..................................................................................... 18

3.2 自适应半径滤波原理 ....................................................................................... 22

3.2.1 种植模式判定器 ......................................................................................... 23

3.2.2 动态半径滤波 ............................................................................................. 25

3.3 实验与分析 ....................................................................................................... 26

3.3.1 种植模式判定器性能与分析 ..................................................................... 27

3.3.2 去噪结果分析 ............................................................................................. 29

3.4 本章总结 ........................................................................................................... 35 第四章 基于激光雷达的行间自主导航方法 .................. 37

4.1 算法原理及步骤 ............................................................................................... 37

4.2 实验与分析 ....................................................................................................... 40

4.2.1 误差计算方法 ............................................................................................. 40

4.2.2 非密集种植场景实验与分析 ..................................................................... 40

4.2.3 密集种植场景实验与分析 ......................................................................... 42

4.2.4 误差来源分析 ............................................................................................. 43

4.3 本章总结 ........................................................................................................... 43 第五章 基于单目视觉的行间自主导航方法 .................. 44

5.1 道路与消失点信息提取 ................................................................................... 45

5.1.1 果园场景实例分割 ..................................................................................... 45

5.1.2 消失点和边界方程提取 ............................................................................. 46

5.1.3 实验与分析 ................................................................................................. 47

5.2 位姿估计方法 ................................................................................................... 52

5.2.1 道路几何成像模型 ..................................................................................... 52

5.2.3 偏航角与横向偏移估计 ............................................................................. 56

5.2.4 实验与分析 ................................................................................................. 57

5.3 果树定位方法 ................................................................................................... 58

5.3.1 果树相对位置估计 ..................................................................................... 59

5.3.2 实验与分析 ................................................................................................. 59

5.5 本章总结 ........................................................................................................... 62 第六章 结论与展望 ..................................... 63

6.1 主要结论 ........................................................................................................... 63

6.2 研究展望 ........................................................................................................... 63 参考文献 ............................................... 64 在学期间的研究成果 ..................................... 68

第一章 绪论

第一章 绪论

1.1 研究背景和意义

从人力成本角度分析，随着我国城镇化的快速发展，农业从业人口大幅度下

降。跟据国家统计局数据[1]，截止至2019，我国从事第一产业人员从2015 年21919

万人减少至19445 万人，五年内减少2474 万人，减少11.3%，人工成本快速上

升，现已经成为制约水果生产快速发展的主要因素之一。

从国情和政策角度分析，我国农业机械智能化水平亟待提升，农业科技领域

的发展得到国家的高度重视。党的十九大指出，实施乡村振兴战略，是新时代中

国特色社会主义伟大事业的重要内容，要加快农业现代化步伐。因此，从我国农

业生产机械的长远发展考虑，必须加快农业机器人的研究，全面提高我国农业机

械的智能化水平。

从水果生产的角度分析，我国是全球最大的水果生产国。2019 年全国水果

总产量达到27400.8 万吨，十年内增长7305.4 万吨，增长率为36.4%[1]，果品产

业在农村经济中有举足轻重的地位。但是，我国果园机械化程度仍处于起步阶段，

目前果园管理作业主要还是靠人工来执行，其中，育苗栽种、施肥打药、采摘等

工作都在果园行间完成，占总人力需求的50%以上。

在人力成本快速上升、水果需求量显著增加的背景下，农业科技引起国家的

高度重视。与传统人工作业模式相比，农业机械化设备能够显著降低劳动强度、

提高作业效率、提升生产品质，有利于缓解劳动力短缺问题，因此，农业机器人

技术逐渐成为学者研究的重点和热点。农业机器人作业场景通常为非结构化或半

结构化的未知环境，不仅需要较高的自主运行能力，估计当前的位置和姿态，而

且需要实时感知周围环境，准确识别目标信息。行间自主导航技术是实现农业机

器人自主运行的关键技术，伴随着导航传感器的发展和人工智能技术的完善，使

机器人在行间自主导航逐渐成为现实。本课题在该背景下，展开对果园行间自主

导航关键技术的探索研究。

农业果园具有以下特点：1、遮挡严重，在树冠的遮蔽条件下，卫星信号准

确度受到较大影响；2、复杂多变，场景光线容易受到晨昏更替与四季变换的影

响，图像特征的差异性较大；3、自由度高，与工业产品不同，植物生长具有较

高程度的随机性和自由度，为视觉识别带来较大的挑战。本文基于以上特点，展

开对单目视觉导航和激光雷达导航的研究，分别采用单目相机和激光雷达实现位

姿估计和果树定位，具有重要的理论意义和实际应用价值。

第一章 绪论

1.2 国内外研究现状及存在的问题

本文主要研究了基于视觉的行间自主导航技术和基于激光雷达的行间自主

导航技术，针对农业果园场景的导航特点和要求，分析了国内外研究的优势和挑

战，并指出本文的研究点。

1.2.1 基于激光雷达的行间自主导航技术

激光雷达工作原理为发射装置发出探测激光束，目标回波被接收装置收集

后，通过测量激光束飞行时间进而确定目标距离。具有测距准确、分辨率高、抗

干扰能力强等诸多优点，由于激光雷达可直接获取周围环境的几何信息，较准确

地完成目标识别、定位等任务，在果园行间自主导航技术中逐渐得以应用。

但是，由于无目标处无回波返回，或者回波飞行时间异常，导致失落信息产

生，果园行间纵深较大，在距离道路尽头较远的位置，激光雷达可能无法扫描至

行间尽头，导致失落信息的产生，从而使激光点云中存在影响行间自主导航的噪

声数据。由于点云噪声将降低特征提取和特征匹配的精度，从而降低目标感知和

导航路径的可靠性。因此，对点云去噪是保证后续处理的关键步骤，去噪效果也

直接影响了点云数据分析的准确性。基于以上分析，本文分别研究了激光点云去

噪方法和激光雷达行间自主导航方法。

点云去噪受到国内外学者关注，提出了基于点云数据特征、基于图像分析以

及基于邻域分析等去噪方法。针对基于特征的去噪方法，曹爽[2]利用基于特征选

择的双边滤波算法对工业结构件点云进行去噪；Gu[3]使用改进的中值滤波和双边

滤波实现平滑效果；吴禄慎[4]采用基于特征信息分类的方法对Bunny 模型进行去

噪；崔鑫[5]采用特征加权模糊C 均值聚类算法对特征区域和非特征区域去噪。针

对基于图像的去噪方法，Rosman[6]将图像中的邻域匹配方法应用于三维空间，但

降低了点云数据精度；Fleishman[7]将双边滤波扩展到三维网格模型，但存在过光

顺问题。针对基于邻域分析的去噪方法，曾妮红[8]提出一种改进的TIN 迭代加密

滤波算法，但此类算法耗时相对较长；夏春华[9]采用改进密度分析和双边滤波的

方法，对植株数据中的噪声进行检测和去除；陈世超[10]提出了一种基于距离变化

并融合点云强度与密度信息的去噪方法；Arvanitis[11]基于离群点的稀疏性采用鲁

棒主成分分析算法去除城市环境中的明显异常点。

已有研究成果对特定环境或模型具有较好的适应性，但基于数据特征的滤波

器需要提取不同层次的点云特征，算法复杂度较高，需要较高的计算成本，但是

农业机器人通常搭载嵌入式计算平台，计算能力有限，且自主导航需要较高的实

第一章 绪论

时性，此类方法有不适应之处。基于图像分析的点云去噪算法依赖有序点云，难

以应用于无序点云数据，而激光数据以无序点云为主，此类方法具有一定的局限

性。基于领域分析的去噪方法依据球半径内的点云数据特征实现滤波，由于此类

方法的球半径固定，且果园的激光点云密度差异较大，此类算法在果园场景中适

应性较低。由以上分析可知，现有方法的局限性集中体现在三个方面：1、算法

时间复杂度较高，实时性难以满足要求；2、适用性较低，例如依赖反射率或有

序点云；3、对点云密度较敏感，不适用密度差异大的点云数据。

针对目前点云去噪方法的局限性，本文提出自适应半径滤波的激光点云去噪

方法，该方法主要由种植模式判定器和动态半径滤波器组成。种植模式判定器用

于识别种植方式，并将场景类别信息传递至动态半径滤波器，滤波器根据目标点

到原点的欧式距离设计该点的搜索半径，以此实现抑制多尺度点云噪声。

基于激光雷达的导航技术是通过感知、分析周围环境，获取当前农业机械装

备状态和导航信息，使其能够沿特定轨迹行驶。国内外学者就相关技术展开深入

研究：薛金林[12]基于近距离区域树干的检测方法，实现拟合树行直线，但未计算

偏航信息。Lemos[13]基于离群点鲁棒的随机采样一致方法提取树墙直线，通过扩

展卡尔曼滤波优化拟合路径，但未在非密集种植场景中实验。艾长胜[14]基于距离

阈值提取感兴趣区域并利用卡尔曼滤波器校正离群点，采用支持向量机拟合导航

路径，但仅在密集种植的葡萄园完成实验。周俊[15]基于聚类分割提取树干圆弧，

并利用其中心点建图和实时定位，但该方法未计算偏航信息。

以上基于激光雷达的行间导航方法适用于较特殊的种植场景，其局限性集中

在以下两点：1、适应性较低，对种植模式不鲁棒，难以同时适应密集种植和非

密集种植条件；2、导航信息不完整，难以同时计算横向偏移和偏航角，当农业

机械装备偏离航向时，无法及时且准确地矫正姿态。

针对目前激光雷达导航方法的局限性，本文提出直线簇交叉像素的导航方

法，统计直线簇与感兴趣区域的交叉像素数量，选取交叉像素最多的直线进行斜

率和截距匹配，符合阈值条件的直线作为可通行区域边界，并基于边界方程逆解

偏航信息和横向位移。

1.2.2 基于视觉的行间自主导航技术

在果园环境中，行间道路容易受到树冠遮挡，精细化种植的果园覆盖尼龙防

护网，与一般道路环境相比，果园道路显著的特点是遮挡严重。因此，基于卫星

定位的导航方式在果园中存在较大局限性。基于惯性导航单元可实现姿态、运动

状态测量，但由于缺少语义信息，无法准确识别和定位果树位置，难以实现精细

第一章 绪论

化作业。相机系统可采集语义信息，基于成像模型和标定方法，可一定程度上获

取几何信息，具有成本可控、信息丰富的优势，适合完成果园行间自主导航任务，

实现提取场景语义信息、估计位姿、定位果树等目标，国内外学者就相关问题和

技术展开深入的研究。

针对场景语义信息提取问题，关卓怀[16]基于综合阈值法和B 样条曲线进行

水稻待收获区域的边缘拟合；张成涛[17]提出基于改进平滑度纹理特征的路径识别

算法，并在田间环境完成导航实验；Radcliffe[18]根据天空和树冠的差异，从树冠

背景中分割天空并拟合导航路径；Choi[19]根据形态学特征识别植株的中心区域，

并根据回归算法和霍夫变换进行导航线的生成；Montalvoa[20]采用图像分割和

Otsu 方法的双阈值处理以及最小二乘线性回归进行作物行检测；Sharifi[21]基于图

分割理论将聚类后的图像进行分割，应用霍夫变换提取路径特征；杨洋[22]建立了

基于卷积神经网络的玉米根茎识别算法，实现了机器人在玉米行间行走；韩振浩

[23]基于U-Net 语义分割网络实现果园路径识别。上述方法利用边界点拟合导航

线，根据导航线定性提取航向信息，在特定环境中实现自主导航，但难以准确地

定量分析位姿，导航准确性、位姿可控性可一步提升。

针对基于视觉的位姿估计问题，刘军[24]提出了一种基于变参数逆透视变换和

道路消失点检测的单目视觉测距模型，实现车辆纵向距离和横向距离测量；颜松

[25]基于道路左右边缘特征估计相对位置，并引入误差校正模型进行修正；Chen[26]

基于车道参数标定相机的变换矩阵，实现单目测距。上述方法基于单目相机模型

实现距离测量，但果园自主导航不仅需要测量道路宽度，也需要估计横向偏移和

偏航角，以上方法应用于果园自主导航仍具有一定的局限性。

针对树干识别与定位问题，Cheein[27]通过提取树干的HOG 特征，利用SVM

分类器进行树干识别；Shalal[28]在ROI 区域内，采用颜色信息和边缘特征识别树

干；Chen[29]利用通过轮廓提取、训练多特征分类器识别树木；刘慧[30]采用融合

深度和纹理特征的树干分割算法对彩色图像进行分割，通过色调和宽度特征对树

干进行识别。上述方法对果树识别方法展开探索，取得了较理想的实验结果。然

而，上述研究停留在果树检测层面，并未深入研究果树定位方法。智能农业装备

不仅需要自主行进、识别作物，更需要根据植株位置完成采摘、喷药、施肥等作

上述研究的思路、成熟度和稳定性不尽相同，根据以上对果园自主导航研究

成果的分析，目前视觉导航的局限性体现在以下两点：1、导航信息不完整，以

定性视觉自主导航为主，基于视觉的位姿估计方法难以有效提取偏航角和横向位

移；2、果树定位方法不完善，以果树检测研究为主，难以确定果树的相对位置。

第一章 绪论

针对现有方法的局限性，本文提出基于实例分割模型的位姿估计与果树定位

方法。在改进并训练深度神经网络的基础上，完成道路掩码和果树掩码的提取，

并进一步计算消失点和边界方程。利用树行平行性，建立位姿-道路几何成像模

型，确定了不同位姿条件下，世界坐标与像素坐标的映射关系，定量分析了位姿

对图像关键点的影响，基于消失点和边界方程估计偏航信息和横向位移。

1.3 研究内容

根据本文的主要研究内容，本文主要分为六章，每章概述如下：

第1 章为绪论。依据统计数据和国家政策方针，论述了本文的研究背景、目

的和意义，指出了论文的研究点。总结并分析了国内外学者的研究进展和待改进

第2 章为自主导航理论基础。介绍了惯性导航基础理论并分析了该方法在果

园场景中的局限性，从点云滤波、点云聚类两部分阐述了激光雷达导航中常用的

数据处理方法，从单目相机成像模型、目标信息提取方法两部分阐述了视觉导航

的理论基础。

第3 章为自适应半径滤波方法。在研究激光雷达成像原理的基础上，分析其

噪声的来源和种类，提出自适应半径滤波方法，该方法由种植模式判定器和动态

半径滤波器组成，可自适应确定去噪参数，并有效抑制不同尺度的点云噪声。

第4 章为基于激光雷达的导航方法。本章提出基于感兴趣区域交叉像素的导

航方法，基于点云二值图的形态学特征提取感兴趣区域，通过计算直线簇交叉像

素数量，提取可通行路径、位姿信息和果树相对位置，对于不同的种植模式均具

有较高的鲁棒性。

第5 章为基于单目视觉的导航方法。为解决果园场景中的道路识别、位姿估

计和果树定位问题，此章节对道路几何成像过程进行建模，结合消失点坐标、边

界线方程和果树掩码，估计当前偏航角、横向偏移、道路宽度和果树相对位置。

第6 章为总结与展望。本章节就目前研究的不足展开分析，并结合前沿技术，

展望智慧农业的发展方向。

1.4 组织结构

全文方法部分共分为五个章节，主要研究内容的组织结构如图1.1 所示。

第一章 绪论

图1-1 论文主要研究内容和组织结构

第二章 行间自主导航理论基础

第二章 行间自主导航理论基础

自主导航是一种具有强自适应能力、高度自规划能力的导航方式，适合在复

杂的种植园环境中完成导航任务。该方法的目标是在低人工干预、不改变环境的

条件下，有目的地移动和完成相应任务，目前，常见的导航方式有惯性导航、激

光导航和视觉导航等。

惯性导航以不依赖外部信息、高度自主性的特点得到广泛使用，在导航系统

中具有重要作用，本文在第一节阐述了相关原理和局限性。

激光雷达可精确探测物体距离和几何信息，在复杂多变的光线条件中具有较

高的稳定性，在自主导航的研究中得到广泛应用，激光雷达的距离像为三维点云，

点云滤波和聚类是激光雷达导航的关键技术，本文在第二节展开相关论述。

视觉导航是实现农业装备自主运行的关键技术之一，该技术具有语义信息丰

富、自主性强和纠错鲁棒性强的特点，在果园导航中具有良好的适应性，单目相

机成像模型和目标提取是实现视觉导航的基础，本文在第三节展开相关论述。

2.1 惯性导航理论

惯性测量单元可实现测量惯性空间的加速度与角速率信息，基于牛顿运动定

律估计载体的姿态与速度信息，在不依赖外界信息的条件下，能连续地估计载体

的导航参数(线速度、角速度、姿态角等)，在自主导航技术中占据重要地位。

捷联式惯导是以数字计算平台代替机电式导航平台的导航技术，通过将惯性

测量单元直接安装在载体上，显著提高结构的可靠性与易用性，是惯性导航技术

的重要发展方向，其姿态估计方法如图2-1 所示。

图2-1 捷联式惯性导航方法

第二章 行间自主导航理论基础

由图2-1 可知，基于捷联式惯性导航单元的姿态估计方法如下：首先，将加

速度计和陀螺仪刚性连接至载体；其次，陀螺仪测量的角速度与导航坐标系角速

度做差，得到载体坐标系下的角速度，并利用该信息计算姿态矩阵；再次，基于

姿态矩阵元素，提取姿态和航向信息。

加速度计通过计算三轴加速度与重力加速度的偏差估计当前姿态角，但机械

装备由运动产生的加速度与重力加速度耦合，导致动态性能较低；虽然陀螺仪动

态性能较好，但无法避免累计误差。

目前，基于概率滤波器的融合导航方法可在一定程度抑制该现象，但长时间

工作仍存在累计误差，此外，基于惯性测量单元的导航方法，无法利用场景信息

估计当前位置，在果园条件中，难以独立完成导航。基于以上分析，本文重点研

究了激光雷达导航方法和单目视觉导航方法，并以道路提取、位姿估计、果树定

位为研究目标。

2.2 激光雷达导航理论

本节分析了激光雷达导航中的数据处理方法，研究了基于统计滤波和半径滤

波的点云噪声抑制原理，分析了K-Means 聚类和密度聚类方法的优势和局限性。

2.2.1 点云滤波方法

1.统计滤波

统计滤波的点云去噪方法基本原理是抑制与均值偏差较大的信息点，计算所

有点云到N 个近邻的均值μ 与标准差σ，则距离阈值为dmax=μ+ασ，α 为比例系

数，若信息点与N 个近邻的平均距离大于dmax，则推测为噪声点，具体算法步骤

首先，统计点云总数量n，并计算每个点到N 个近邻的平均距离；其次，计

算距离集合{d1,d2,...,dn}的均值与标准差，其计算方法如公式(2-1)和公式(2-2)所

示；最后，比较每个数据点对应的平均距离值与dmax 的大小，若结果为大于，则

定义该点为噪声点并去除。

 (2-1)

d n  

    (2-2)

第二章 行间自主导航理论基础

2.半径滤波

半径滤波的基本原理是考察点云中以某个点为中心的指定半径空间范围内

相邻点的数量作为判断该点是否为孤立点的依据[31-32]。若相邻点数量大于等于指

定阈值，则该点为非孤立点并予以保留，反之为孤立点予以去除。半径滤波示意

图如图2-2 所示，图中点云密度相对一致，设定近邻数量为N，数据点Ai 为中心，

r 为半径的邻域内的实际近邻数目为ni。当ni≥N 时，保留数据点Ai；反之，则

图2-2 半径滤波示意图

图2-2 中，当指定至少有2 个近邻，即N=2 时，只有A1 点被删除；如果指

定N=3 时，则A1 和A3 都被删除。

基于半径滤波和统计滤波的点云去噪方法具有处理速度快、通用性强、去噪

效果稳定的优点而得到广泛应用[33]，但该类方法对于密度差异较大的点云数据，

存在去噪不完全或者细节损失较严重的缺点。

2.2.2 点云密度聚类方法

1.基于K-Means 的聚类方法

K-Means 算法是基于样本间相似性度量的非监督机器学习方法，具有较高的

实时性，通过把点云数据帧n 个数据点划分为k 个子集，使子集内的数据具有较

高的相似度，而子集之间的相似度较低，通常用质心到数据点间的距离评判相似

度。K-Means 聚类实现方法如下：

给定类别数k 和迭代数R，在数据帧中随机选取k 个元素作为初始聚类中心

Cj(r)，j=1,2,3,...,k，r=1,2,3,...,R。

②计算相似度

计算数据帧中每个数据点与聚类中心的相似度D(Xi,Cj(r))，i=1,2,3,...,n，若

数据点满足公式(2-3)，则数据点Xi 属于子集Wj。

第二章 行间自主导航理论基础

      1 1 1 , , n

i j i j i D X C r D X C r        (2-3)

式中 ε——相似度阈值

③更新聚类中心

根据公式(2-4)计算k 个新聚类中心，并由公式(2-5)计算聚类准则函数值E。

nj j j i n i C r X    (2-4)

   

1 1 1 j

j i w W E r w C r        (2-5)

④合理性判断

若满足公式(2-6)中的条件，则聚类中心合理并停止迭代；否则，返回2、3 步继续执行。

   1 E r E r     (2-6)

由于果园通常为非结构或半结构环境，聚类数量需要根据场景动态变化，因

此，k 值难以确定，在果园条件中具有较大的局限性，基于以上原因，本文对基

于密度聚类的方法展开研究。

2.基于密度的聚类方法

为解决聚类数量动态变化的问题，本文对基于密度聚类的方法展开研究，

DBSCAN(Density-Based Spatial Clustering of Application with Noise, DBSCAN)算

法在实现密度聚类的基础上，可有效抑制点云噪声的干扰，就该算法的专有概念

核心对象：若数据点在以ε 为球半径的球面内，至少有M 个数据点，则该

点被定义为核心对象。

直接密度可达：若数据点O2 在核心对象O1 的邻域范围内，则O2 是从O1

直接密度可达。

密度可达：若存在对象链{O1,O2,...,On},Oi+1 是从Oi 直接密度可达，则On 是

从O1 密度可达。

密度相连：若存在数据点p，使p 到O1、O2 都是密度可达，则O1 与O2 是

算法具体工作原理和流程如下：

①给所有数据点增加状态属性，并赋初值“未标记”；

②判断是否为核心对象，若为核心对象，则状态属性设为“标记”，创建点

云簇Ci 并执行步骤③；若为非核心对象，则状态属性设为“噪声”；

第二章 行间自主导航理论基础

③遍历以Ci 为中心τ为半径领域内的所有数据点并加入Ci；若存在某数据

点为核心对象，则将其邻域内的数据点加入类Ci，重复执行步骤③；

④将点云簇Ci 从数据帧中移除，重复执行步骤①-④，直至所有数据点都被

2.3 单目视觉导航理论

本节分析了单目相机成像原理，研究从三维世界坐标点到二维像平面的映射

关系，研究了目标信息提取方法，对比分析了目标检测与实例分割方法的优势和

局限性，对Mask R-CNN 实例分割模型展开较详细的分析。

2.3.1 单目相机成像原理

三维世界中的坐标点映射至二维像平面的过程常用几何模型描述，其中广泛

应用的几何模型为针孔相机模型，该模型也是单目相机成像的基本模型，其成像

原理如图2-3 所示。

图2-3 针孔相机成像示意图

图2-3 为针孔相机基本成像原理，为清晰地表述其几何关系与成像模型，建

立相机坐标系yczc 与图像坐标系ocxcyczc，其中，Oc 为相机焦点，即投影中心，

该点垂直于像平面I 的距离为焦距f。焦点Oc 与空间点p 构成的射线与像平面I

的交于p’点(称为像点)。空间点p 的欧式坐标记为  , ,

c c c x y z ,在像平面中的映射

p’记为  ,

T x y ，由空间相似三角关系，可得：

第二章 行间自主导航理论基础

x f x z

y f y z

    

进一步可得公式(2-7)矩阵形式：

0 0 0 0 0 1 0

z y f f z

                      

I c c p p Tp

  , ,1

T x y  Ip (2-9)

   3 3 3 1 , ,1 , diag f f    T I 0 (2-10)

  , , ,1

T xc yc zc  cP (2-11)

式中 T——投影变换矩阵（中心原点）

f——镜头焦距

P——图像坐标系中三维点坐标

在实际应用中，由于坐标原点未知，也避免出现负坐标值，常以左上角作为

坐标原点建立坐标系，则相机投影关系变换为公式(2-12)：

0 0 0 0 1 0

f v          

C T (2-12)

式中 TC——投影变换矩阵（左上角原点）

u0——感光元件u 轴尺寸

v0——感光元件v 轴尺寸

农业机械装备自主导航过程中，通常需要建立基本坐标系（世界坐标系）描

述自身和目标的相对位置关系，基本坐标系与相机坐标系的关系可通过刚体六自

由度变换矩阵描述，令空间三维点在基本坐标系中的坐标为Pw，则该点在基本

坐标系与相机坐标系下的变换关系为公式(2-13)所示：

      

W c w 1 3

R RO p p 0

(2-13)

式中 R——三维旋转矩阵

OW——基本坐标系中相机焦点坐标

第二章 行间自主导航理论基础

pw——基本坐标系中三维点坐标

由公式(2-8)、公式(2-12)与公式(2-13)可得相机矩阵的一般形式，如公式(2-14)

    3 3 3 1

1 3 , , 1 cz  

       

C I C w C C w R -RO p T I 0 p T R -RO p 0 (2-14)

公式(2-14)为基本坐标系中三维点到像点的映射关系，其中  , C R -RO 为相机

外参矩阵，令平移向量   = , C t R -RO ，相机矩阵可表示为   = , C A T R t 。

2.3.2 目标信息提取方法

1.基于特征分类器的目标检测方法

基于特征分类器的目标检测方法主要由生成候选框、提取区域特征、特征分

类器构成，通过提取感兴趣区域的人工特征，训练特征分类器，实现检测目标的

目的，该方法的一般检测流程如图2-4 所示。

图2-4 基于特征分类的目标检测方法

由图2-4 可知基于特征分类的目标检测方法流程如下：首先，给定待检测图

像数据，并生成若干尺寸和比例的候选框，候选框的提取通产采用滑动窗口方式

进行。其次，针对每个候选框进行特征提取，模式识别中的特征包含两类：1、

底层特征：纹理、梯度、颜色、形状等基本特征；2、中高层次特征：利用机器

学习方法挖掘底层特征得到的更抽象的特征。最后，通过训练的特征分类器确定

所属类别，并通过非极大值抑制机制去除交并比较低的预测框，输出目标类别及

边界框位置。

与结构化场景不同，果园场景更加复杂多变，需要大量的实验确定特征类型

和参数，而深度神经网络可通过自学习方式获得适应性更高的特征，因此，基于

深度神经网络的目标检测方法逐渐成为主流。

第二章 行间自主导航理论基础

2.基于深度神经网络的目标检测方法

基于深度学习的目标检测方法由主干网络与检测网络两大部分组成，其中，

主干网络用于提取图像多层次特征，检测网络用于确定目标所属类别及其位置，

该方法的检测流程如图2-5 所示。

图2-5 基于深度神经网络的目标检测方法

图2-5 为基于深度学习目标检测方法的一般流程，该方法可分为单阶段模型

和双阶段模型，二者的主要区别在于是否通过区域建议网络生成预测框，通常双

阶段模型具有更高的精确率，单阶段模型的计算量较低，具有更高的计算效率。

基于深度神经网络的目标检测流程如下：首先，通过主干网络提取多层次信

息并得到特征图；其次，对于双阶段网络，区域建议网络生成特定比例和大小的

预测框，确定所属前景和背景的概率，去除类别为背景的预测框；单阶段网络则

直接在特定尺寸的特征图上生成预测框；最后，回归边界框位置，并确定每个预

测框所属类别的概率。

目标检测方法可较准确地提取目标的边界框，满足一般检测需求，但无法提

取对物体的轮廓及掩码，而自主导航技术需要准确获得可通行区域轮廓，果树定

位也依赖较高精度树干轮廓信息，基于以上因素，本文对实例分割网络展开研究

3.基于深度学习的实例分割模型

与目标检测模型不同，实例分割网络可实现对目标的像素级分割，即针对矩

形框内的物体提取掩码，较高精确度的轮廓信息有利于提升位姿估计和果树定位

精度，Mask R-CNN[34]模型可同时完成目标识别与实例分割任务，且具有较高的

算法效率，而准确地提取可通行区域与果树树干掩码是实现农业装备自主导航的

Mask R-CNN 模型分为五大主要部分：主干网络、区域建议网络、ROI

Align[34]、分类、检测和分割分支。其中，主干网络用于提取图像特征图；区域

建议网络的作用为调整锚框位置并去除无效锚框；ROI Align 通过建立锚框、特

征图和原始图像的映射关系，使预测框和掩码准确回归至图像数据；分类和检测

分支为全连接网络，分别输出类别概率和位置信息；分割分支为全卷积上采样网

第二章 行间自主导航理论基础

络，输出分割掩码。其示意图如图2-5 所示。

图2-5 Mask R-CNN 网络结构示意图

由图2-5 可知，基于Mask R-CNN 实例分割方法的流程如下：首先，图像数

据经过主干网络提取特征图；其次，针对特征图中的关键像素点，生成锚框组合，

由区域建议网络判断锚框属于前后景的概率，并调整锚框位置，去除无效预测框；

再次，有效锚框进行ROI Align 操作，即建立锚框、特征图和原始图像的映射关

系；最后，对预测框进行分类、边界回归，经全卷积上采样网络生成掩码。本文

主要优化了该模型的主干网络，以下展开介绍。

本文基于该模型实现场景语义信息的提取，由于三维信息在单目相机中的成

像过程为射影变换，目标尺度在图像中表现为近大远小，其尺度存在较大差异性。

为了获得多尺寸表示能力，要求特征提取能够以较大范围的感受野来描述不同尺

基于以上原因，本文主干网络采用Res2Net[35]和特征金字塔网络提取特征，

与ResNet[36]网络相比，该模型将特征图分成4 组，除第一组特征X1 外，每组特

征图经3x3 卷积后，以残差的方式与下一组进行连接，Res2Net 模块结构如图2-6

图2-6 Res2Net 模块结构示意图

第二章 行间自主导航理论基础

由图2-6 可知，除X1 特征组外，每个3x3 的卷积核可以接受来自前层所有

特征，其输出的特征图具有更大的感受野。基于该组网方式，Res2Net 的输出包

含不同大小及数量的感受野，同时，特征图输出前经过1x1 卷积核，可有效融合

不同尺度信息。

此外，为增强对不同尺寸物体的识别能力，本文在Res2Net 网络的下一级增

加特征金字塔网络，该模型通过提取多尺度的特征信息，并进行深度融合，从而

提高检测的精确度。Res2Net 网络和特征金字塔网络结构如图2-7 所示。

图2-7 主干网络结构示意图

由图2-7 可知，主干网络提取特征的流程如下：首先，原始图像经卷积层和

Res2Net 模块提取不同层次的图像特征；其次，将C4-C1 阶段的特征图进行1×1

卷积运算得到特征图T4-T1，通过卷积上采样并与下一阶段的特征图叠加得到特

征金字塔M4-M1；最后，将M4-M1 的特征图进行3×3 卷积运算后，输出特征

图P4-P1 至区域建议网络。

区域建议网络基于卷积神经网络结构输出二分类信息和边框位置信息，特征

图经卷积变换后，输入两个全连接分支，生成类别概率和位置信息，并去除超出

边界和无效的预测框。为保证检测和分割的准确性，保证原图中的像素和特征图

中的像素准确对齐，模型使用双线性内插值的方法对预选框的位置进行调整，并

对这些特征采用最大或平均池化，经全连接网络回归至原始图像，避免了对候选

框回归和预测框回归量化操作带来的误差，具有更高的检测和分割精度。

第二章 行间自主导航理论基础

4.对比分析

本文分析了目标检测模型和实例分割模型的优势和局限性，如表2-1 所示。

表2-1 目标检测模型与实例分割模型的对比分析

目标信息提取方法 返回类型 提取精度 适应性 需求数据量

基于特征分类的目标检测 最小外接矩形框 较低 较弱 较少

基于深度学习的目标检测 最小外接矩形框 较低 较强 较多

基于深度学习的实例分割 目标掩码 较高 较强 较多

由表2-1 可知，基于深度学习的实例分割模型可较高精度提取目标信息，农

业果园场景受光照、季节、降雨等因素的影响，具有较高复杂性，图像明暗、色

温差异较大，而基于深度学习的方法具有较强的适应性，在此类场景中鲁棒性更

强。针对深度学习方法数据需求量大的问题，目前可采用迁移学习、数据增强等

手段显著减少数据样本。综上所述，由于基于深度学习的实例分割模型具有高精

度和高适应性，更适合在果园自主导航技术中应用。

2.4 本章总结

本章首先分析了惯性导航的基本理论，由于该方法存在累积误差，且难以估

计横向偏移和果树的相对位置，在果园导航中具有较明显的局限性。其次，阐述

了激光雷达导航技术中常用的数据处理方法，统计滤波和半径滤波具有处理速度

快、通用性强、去噪效果稳定的优点而得到广泛应用，但是其去噪效果容易受到

点云密度的影响，基于密度的点云聚类方法对噪声具有较高的鲁棒性，可对任意

数量的点云簇聚类，在激光雷达导航中广泛应用。最后，论述了单目视觉导航理

论，建立单目视觉成像模型，确定了从三维坐标点到二维像素点的映射关系，对

比分析了目标检测和实例分割方法的原理及特点，由于实例分割网络可实现目标

检测和像素级分割，在视觉导航技术中具有更广泛的适应性。

第三章 基于自适应半径滤波的激光点云去噪方法

第三章 基于自适应半径滤波的激光点云去噪方法

激光雷达可较准确地采集目标几何信息和环境结构信息，在目标识别、导航

信息提取等任务中具有重要的作用。但激光雷达工作过程中，由于光线较强、距

离较远、目标较小等因素，不可避免地受到噪声干扰，影响聚类、识别、特征提

取等算法的效果。因此，有效抑制点云噪声具有较高的必要性，本章分析了噪声

产生原因和激光点云密度特性，并提出自适应半径滤波方法。

3.1 激光点云噪声来源及特点

激光雷达在智能机器人、自主导航、动态避障等方面具有广阔的应用前景，

其噪声抑制方法日益成为国内外学者研究的热点。激光雷达具有探测视角广、集

成度高的优势，逐渐成为自主导航技术的关键传感器。但包含噪声的点云数据对

识别与特征提取有较大影响，为有效抑制激光点云噪声，本文分析了噪声产生的

原因，并研究了点云密度特性。

3.1.1 激光雷达噪声产生原因

激光雷达主要基于飞行时间测距，具体原理如下：主振激光器发射激光脉冲，

通过测量其反射的飞行时间，计算激光雷达与物体之间的距离，进而得到三维距

激光雷达主要受到失落信息和距离反常两类噪声的干扰。发射脉冲无回波和

回波时间超出接收窗口期是产生失落信息的主要原因，例如，激光脉冲发射至无

反射的表面或者探测超出量程的目标，失落信息存在于无目标处或目标距离较远

处。距离反常主要存在于目标边缘，枝叶相对密集和细小，激光点存在发射至枝

叶边缘的可能，进而导致距离反常。

3.1.2 激光点云密度特性

单位矩形内的点云平均间距是衡量点云密度的重要指标，平均距离越大，

点云密度越低；点云间的平均间距越小，点云密度越高。单位矩形中，点云数

量为激光雷达光束与单位平面交点的数量，计算方法如公式(3-1)所示，数据点间

距为面积的几何平均数，即单位面积除以点云总数的几何平均数，计算方法如公

第三章 基于自适应半径滤波的激光点云去噪方法

式(3-2)所示，点云密度与点云平均间距的关系呈负线性相关，计算方法如公式

(3-3)所示，计算方法对应示意图如图3-1 所示。

图3-1 点云平均间距计算方法示意图

1 1 2 2 2arctan 2arctan

l l m r r  

h w s m   (3-2)

s c  (3-3)

式中 m——单位矩形的点云数量

s——点云的几何平均间距

ρ——点云密度

h——单位矩形高

w——单位矩形宽

l——激光雷达到单位矩形的距离

rh——水平方向激光雷达的角分辨率

rv——垂直方向激光雷达的角分辨率

c——点云单位间距，几何意义为单位面积内仅有单个点云时的平均间距

基于以上公式推导，研究变量rh、rv、l 和点云间距s、点云密度ρ之间的关

系，文中采用等边单位矩形，即h、w 相同。单位矩形垂直于激光雷达中心o 与

y 轴的延长线上，且矩形中心o’与oy 共线，四者关系如图3-2、图3-3 和图3-4

第三章 基于自适应半径滤波的激光点云去噪方法

图3-2 s-l 关系曲线

图3-3 ρ-l 关系曲线

0 0.5 1 1.5 激光雷达与单位矩形的距离

水平角分辨率0.1度，垂直角分辨率0.1度 水平角分辨率0.1度，垂直角分辨率0.2度 水平角分辨率0.1度，垂直角分辨率0.3度 水平角分辨率0.2度，垂直角分辨率0.2度 水平角分辨率0.2度，垂直角分辨率0.3度 水平角分辨率0.3度，垂直角分辨率0.3度

图3-4 ρ-l 关系曲线(近距离区域)

由图3-2、图3-3 和图3-3 可知，平均间距s 随距离l 增加而增加，点云密度

ρ随之降低，在近距离区域，点云密度ρ加速降低。其他区域的点云密度ρ与距

离l 呈近似线性负相关，表明此范围中的点云密度随探测距离的增加而线性减小。

第三章 基于自适应半径滤波的激光点云去噪方法

经理论分析可知：理想条件下，当单位矩形与激光雷达的距离为0 时，点云

密度达到最大值，即ρ=1；当点云密度等于0 时，单位矩形内的点云处于消失的

距离l 相同的条件下，激光线越密集，分辨率越高，角分辨率rv、rh 数值越

小，平均间距s 越小，表明具有更高的点云密度ρ。由于等边矩形的h、w 相同，

根据公式(3-1)、公式(3-2)可知，此条件下的rv、rh 具有对称性，例如，rv=0.1，

rh=0.2 与rv=0.2，rh=0.1 两种条件下的点云密度ρ一致。为进一步研究点云密度

与距离的关系，本文对公式(3-3)进行求导，以点云密度的变化率，如公式(3-4)

和图3-5 所示。

2 2 2 2 2 1 1 2 1 1

8 tan tan 1 8 tan t

an 1 2 2 4 2 2 4 '

4tan tan 2 2

h v h v

w w w l l l l l l l l

h r r hw r r

h r r 

   

                                   

           

点云密度的导数

图3-5 ρ’(l)-l 关系曲线

经分析图3-4 和图3-5 可知，在激光雷达附近区域（1.5 米内）的点云密度

变化率ρ’(l)逐渐减小，点云密度平缓加速降低(如图3-4 所示)；在1.5 米以外区

域，点云密度变化率ρ’(l)无明显变化，近似为常数，点云密度ρ(l)与距离l 可近

似为线性负相关。

综合以上分析，除激光雷达附近的点云外，其他区域的点云密度近似线性减

小。激光雷达常用于较远距离点云信息的获取，点云密度非线性变化的区域集中

在激光雷达附近，所占比重较低，而且本文所用激光雷达的探测范围为

0.4m-28m，在此区域点云密度近似线性变化。激光雷达输出点云密度具有随目

第三章 基于自适应半径滤波的激光点云去噪方法

标点距离增大而减小的特性，其点云密度分布示意图如图3-7 所示。

图3-7 激光雷达点云密度分布示意图

由图3-7 可知，近距离区域和远距离区域的点云密度差异较大，点云密度与

探测距离近似线性负相关，点云噪声密度分布同样符合以上特性，A1、A2、A3

以r 为半径的邻域内分别具有1、4、15 个近邻，其数量差异明显，由于半径滤

波参数固定，在场景中，容易出现过度去噪或噪声残留问题，实际效果并不理想。

3.2 自适应半径滤波原理

含有噪声的激光点云果园机器人工作场景可分为密集种植环境和非密集种

植环境，水果种植园行间纵深较大、光线复杂多变，导致激光点云密度具有较大

的差异性，噪声具有较高的随机性。

在密集种植场景中，激光点云呈连续立面状；在非密集种植场景中，激光数

据表现为若干点云簇。由于不同种植模式中的点云簇形状和大小均存在差异性，

为更有效地抑制噪声，需要根据种植模式调整滤波器参数。为使滤波器参数对种

植模式有更高的适应性，也为避免在运行过程中整定方法参数，本文构建了基于

卷积神经网络的种植模式判定器，并支持预置滤波器参数，实现了根据点云数据

特征自动选取相应的去噪参数。

为使滤波器参数与点云密度匹配，适应密度差异大且随机性强[37-38]的激光点

云噪声，提出动态半径滤波器，该方法的滤波半径可根据点云密度动态调整，适

应不同密度的点云噪声，从而实现对多尺度激光点云噪声的有效抑制。

本文提出的自适应半径滤波器由点云图像转换器、种植模式判定器和动态半

径滤波器组成。由于激光点云通常呈无序排列，其处理速度相对较慢，而图像数

据通常为多维矩阵，处理方法更加多样且高效，更适合用于场景分类。滤波器结

构如图3-8 所示。

第三章 基于自适应半径滤波的激光点云去噪方法

图3-8 自适应半径滤波器结构图

由图3-8 所示，自适应半径滤波器首先利用点云图像转换器将从激光雷达中

获取原始点云数据转换为二值图像。其次，场景判定层根据二值图像判断当前种

植模式，并将场景类别信息传递至下一层。最后，点云去噪层将根据点云密度去

噪，当处理完所有信息点，输出去噪结果。自适应半径滤波器周期运行，从而使

该模型具有对种植模式变化的场景具有良好的适应性。

3.2.1 种植模式判定器

果园机器人运行过程中，数据采集角度和位置均具有较大的不确定性，且各

果园的株距行距不尽相同，导致激光雷达可探测的范围不同。机器人在上述条件

作业时，激光点云及其二值图的特征变化明显，难以用单一特征判别种植模式。

目前，大部分传统的特征提取方法提取的特征相对较浅，如HOG 特征、SIFT

特征、颜色特征、局部二值特征等，基于传统特征的分类器适用于某些特定场景。

在复杂多变的场景中，表现并不尽如人意，难以满足种植模式的分类需求。

深度卷积神经网络具有模型层次深、特征表达能力强的特点，能自适应地从

大规模数据集中学习当前任务所需要的特征表达，广泛应用于图像分类问题。因

此，本文采用深度卷积神经网络作为种植模式判别器。卷积神经网络以转换后的

二值图像为输入，判断并输出其种植模式。

第三章 基于自适应半径滤波的激光点云去噪方法

由于该方法应用于实时性较高的场景，所以，在轻量化模型MobileNetV2[39]

的基础上，本文重新调整并精简了瓶颈层（Bottleneck）结构和卷积核数量，网

络结构如图3-9 所示。

图3-9 网络模型示意图

图3-9 中，Conv3BN 为3×3 卷积正则化层，Conv1BN 为1×1 卷积正则化

层，DWConv3BN 为3×3 深度可分离卷积正则化层，深度可分离卷积能显著降

低参数量和运算量，在轻量化网络中广泛使用[40]。首先，二值图经过卷积正则化

层提取3 张112×112 特征图，之后经过瓶颈层和瓶颈残差层[39]提取更高维特征。

为使网络更加高效，在网络中主要使用深度可分离卷积提取特征。此外，在网络

第三章 基于自适应半径滤波的激光点云去噪方法

中加入残差模块，此方法可有效抑制梯度消失和梯度爆炸问题。在网络末端，将

64 张7×7 特征图进行全局池化，转换为特征向量，由于共有密集种植和非密集

种植两个类别，因此，经全连接层变换为含有两个元素的一维向量。

本文在训练阶段利用Softmax 分类器将预测类别与标签类别比较得到其交

叉熵损失，进而使用Adam 算法[41]（Adaptive moment estimation algorithm，Adam）

优化损失函数使其收敛。在推理阶段，神经网络输出当前图像所属标签，即当前

种植模式，读取预置的去噪参数后，将两类信息传递至动态半径滤波算法，从而

有针对性地抑制不同种植模式下的点云噪声。

3.2.2 动态半径滤波

半径滤波方法的效果与选取的半径参数相关，而半径参数与区域点云密度相

关。若探测范围内点云密度相对均匀，则根据点云密度可选取适当的半径参数；

若点云密度差异较大，则应根据点云密度动态改变去噪操作的半径。

降低点云密度变化的影响是提高去噪准确性的关键方法之一。点云距离激光

雷达越远，其密度越稀疏，滤波半径应增大。本文根据目标点到原点的欧式距离

设计该点的滤波半径，从而有效地避免了密度对滤波过程的影响，为降低算法时

间和空间复杂度，将滤波半径与探测距离视作线性相关，如公式(3-7)所示。

i i r K d   (3-7)

2 2 2 i i i i d y x z   

式中 ri——滤波半径

di——目标点与原点的欧式距离，本文中激光雷达所在位置为原点

K——滤波半径相关系数

xi, yi, zi——目标点的欧式坐标

动态半径滤波的具体方法如下：

①根据场景类别初始化滤波参数：滤波半径相关系数K 和近邻数量N，其中，

K 为目标点欧式距离的缩小比例，K 值越大，则滤波半径越大，K 值越小，则滤

波随之减小；N 为近邻数量，当邻域内的点云数目小于N 时，删除该点；反之，

则保留数据点。

②依据公式(3-7)、公式(3-8)计算某目标点去噪参数：欧式距离di 和滤波半径

③统计其滤波半径ri 内的近邻点ni，若ni 小于近邻数量N，则该点为离群点，

第三章 基于自适应半径滤波的激光点云去噪方法

删除该点；否则予以保留。当按上述步骤遍历所有目标点后，完成当前数据帧处

本文提出的噪声去除方法的伪代码3-1 如下：

伪代码3-1 自是半径滤波伪代码

Algorithm 自适应半径滤波方法 Input: 原始点云 Output: 去噪后的点云

while 接收到完整点云数据帧 do

转换 原始点云 为 二值图; 场景类别  改进MobileNetV2 (二值图); if 场景类别 == “密集种植” then

动态半径滤波器(K1, N1, 原始点云); else

动态半径滤波器(K2, N2, 原始点云); End function 动态半径滤波器(K, N, 原始点云)

for i  1 to 点云数量 do

2 2 2 i i i i d y x z   

ri  K di if 以pi 为中心,ri 为半径的邻域内的点云数量小于N then

删除该点; else

保留该点; end end

3.3 实验与分析

为保证数据集能够较好地反映自然条件下树林的真实特点，分别在苹果种植

园、白杨树林和旱柳树林进行实验，点云采集设备为北醒光子CE30-D 固态面阵

激光雷达，其固有参数为探测范围0.4m-28m，视场角60°×4°，分辨率320×20。

此类场景中，激光雷达主要受到两类噪声的干扰，一是天空、树行尽头等无目标

处产生的失落信息，二是树干、树枝等目标边缘产生的逸出值。实验场景及其噪

声来源具有较强的代表性，且包含的信息复杂程度与农业自动导航机器人的一般

工作环境相似。

同时，为验证算法有效性，将本文去噪方法与点云库PCL 中的统计滤波、

半径滤波进行对比测试，实验平台为Intel(R) Core(TM) i7-6850K CPU@3.60

GHz，NVIDIA 1080Ti×4 GPU，32GB RAM，500GB SSD。

第三章 基于自适应半径滤波的激光点云去噪方法

3.3.1 种植模式判定器性能与分析

本文共收集1083 张点云数据，其中，477 来自采用密集矮化种植的苹果园，

在胸高位置，密集种植的植株间不存在明显间隙；285 张来自非密集种植的白杨

树林，321 张来自非密集种植的旱柳树林，在此种植条件下，植株间在胸高位置

存在明显间隙。

训练神经网络时，先将点云数据转换成俯视视角的二值图像，点云转二值图

平均耗时为每张0.312 ms。数据集的60%作为训练集，20%作为验证集，20%作

配置网络超参数如下：批处理大小为128 张，学习率为0.05，Adam 优化器，

同时，模型训练过程中，使用随机旋转的方法增强数据。采用边训练边评估的方

式，共训练1000 周期，过程的平均损失值、训练精度和验证集精度如图3-10、

图3-11、图3-12 所示。

0 200 400 600 800 1000 0.0

图3-10 训练过程的损失值

0 200 400 600 800 1000 0.7

训练集精确度

图3-11 训练集精确度

第三章 基于自适应半径滤波的激光点云去噪方法

0 200 400 600 800 1000 0.0

验证集精确率

图3-12 验证集精度

由于训练集和验证集存在差异性，且训练初期的模型参数变化明显，因此，

验证集精度呈波动上升趋势，如图3-12 所示。本文为抑制模型过拟合现象，在

训练时随机旋转数据集角度，增加了训练数据的复杂性和多样性，加剧了训练集

和验证集的差异，导致验证集精度曲线波动更加明显。随着训练周期的增加，模

型参数逐渐收敛，分类能力趋于稳定。

训练至702 周期时，分类器在训练集的精确率为0.99，验证集的精确率为

0.98，综合效果较好，仅使用CPU 的条件下，推理速度平均为每帧7.51ms；如

果使用GPU，推理速度为每帧7.04ms。测试结果如图3-13 所示。

(a)密集种植 (b)非密集种植

图3-13 模型测试结果

第三章 基于自适应半径滤波的激光点云去噪方法

由图3-13 可知，该模型可准确分类不同拍摄角度和位置的场景类别，数据

中包含失落信息、逸出值等类型噪声，模型仍可准确分类，且计算时间较低，具

有强的鲁棒性和高效性。

3.3.2 去噪结果分析

点云去噪不仅应准确去除远处、近处和物体边缘的噪声，而且目标点云簇的

细节和特征应被充分保留，为聚类、识别和融合等操作奠定基础。由于点云去噪

为不可逆操作，因此本文在整定去噪参数时，以保留充足的信息量为原则，兼顾

去噪效果和目标细节。经过实验分析，三种方法去噪的参数如表3-1 所示：

表3-1 去噪参数

滤波方法 密集种植场景 非密集种植场景

半径滤波 近邻数量 6 30 滤波半径 0.3 0.8

统计滤波 近邻数量 30 30 标准差倍数 2 0.5

本文方法 近邻数量 11 30 滤波半径相关系数 0.072 0.066

1.苹果果园实验结果

实验地点为北京市昌平区苹果果园，该果园采用矮化密植的种植模式，株行

距为1×3 米，如图3-14 所示。

图3-14 苹果果园实验场景

在图3-14 所示的场景中，点云噪声主要来自两个方面：一是枝叶边缘带来

的逸出值，如图3-15(a)的虚线框所示；二是部分激光束穿过枝叶间隙到达无目

标处，带来失落信息，表现为近距离密集噪声，如图3-15(a)的实线框所示。去

第三章 基于自适应半径滤波的激光点云去噪方法

噪方法应有效抑制目标边缘的逸出值和近距离密集噪声，且保留丰富的点云信

图3-15 苹果果园实验结果

图3-15(b)为统计滤波结果，近距离区域存在大量密集噪声；在远距离区域

内，行两侧的点云细节有所丢失。图3-15(c)为半径滤波结果，稀疏离群点被有

效去除，但近距离区域存在较多密集噪声，而且两侧的点云信息损失严重。图

3-15(d)为本文提出的自适应半径滤波实验结果，稀疏离群点、密集噪声被有效去

除，激光雷达前方几乎不存在密集噪声，两侧点云细节保留完整。

综合比较以上去噪结果，本文提出的自适应半径滤波不仅去除更多的密集噪

声，而且细节更丰富。

2.白杨树林实验结果

实验地点为山西省太原市尖草坪区的白杨树林，株行距为3×3 米，如图3-16

图3-16 白杨树林实验场景

第三章 基于自适应半径滤波的激光点云去噪方法

在图3-16 所示的场景中，噪声主要来自两个方面：一是分布在树干边缘的

逸出值；二林间无目标处的失落信息，表现为近距离密集噪声，两种噪声均应被

算法明显抑制。逸出值和密集噪声原始点云数据如图3-17(a)所示。

图3-17 白杨树林实验结果

图3-17(b)和图3-17(c)为统计滤波和半径滤波实验结果，两种方法均可有效

抑制离群噪声和拖点，但近距离区域内存在大量密集噪声。图3-17 为本文提出

的自适应半径滤波实验结果，稀疏离群点、密集噪声和目标周围的拖点被有效去

除，在远距离区域，目标细节和数量保留较完整。

综合比较以上去噪结果，半径滤波和统计滤波能有效去除明显离群点和少量

密集噪点，但对于密度差异较大的长距离激光点云，噪声去除率较低。本文方法

可有效抑制不同密度中的噪声，且目标特征保留较完好。

3.旱柳树林实验结果

实验地点为山西省太原市尖草坪区旱柳树林，株行距为3.5×3.5 米，如图

3-18 所示。

图3-18 旱柳树林实验场景

第三章 基于自适应半径滤波的激光点云去噪方法

图3-18 所示的场景中均匀种植着旱柳树，与白杨树相比，此树种的胸径较

细，更容易损失目标信息，去噪难度相对更大。图3-19(a)为原始点云，噪声来

源与白杨树林点一致，但由于树木分布更加稀疏，林间无目标处的失落信息更多，

算法应有效去除散布在树木周边的逸出值和近距离的密集噪声。

图3-19 旱柳树林实验结果

图3-19(b)和图3-19(c)为统计滤波和半径滤波实验结果，两种方法均可有效

抑制离群噪声和拖点，但近距离区域内存在大量密集噪声，半径滤波在远距离区

域目标数量和细节相对更少。图3-19(d)为本文提出的自适应半径滤波实验结果，

稀疏离群点、密集噪声和目标周围的拖点被有效抑制，目标数量和细节损失更少。

4.计算效率分析

综合比较三种去噪方法，由于半径滤波和统计滤波参数固定，容易出现细节

损失和噪声残留的问题，本文方法根据点云密度动态调整去噪参数，可有效抑制

不同点云密度中的噪声，且目标特征保留相对完整。为比较方法计算效率，本文

统计了三种滤波器的去噪时间，如表3-2 所示。

表3-2 去噪计算时间分析

统计滤波 半径滤波 本文方法

去噪耗时/ms

苹果果园 36.1 35.4 43.1 白杨树林 52.1 51.9 45.6 旱柳树林 48.5 47.4 40.8 平均值 45.6 44.9 43.2

由表3-2 可知，与半径滤波和统计滤波相比，本文方法的去噪时间(已包含

神经网络分类时间)并未明显增加。一方面，由于以上算法均基于领域分析，去

除邻域中点云的数量越多，算法迭代次数越少，耗时越短，本文方法的噪声去除

率更高，因此，去噪耗时更短。另一方面，本文优化了神经网络模型，使网络模

型更加符合使用条件，通过合理地裁剪卷积层、广泛使用深度可分离卷积、减少

池化层等方式，不仅取得了较高的算法效率，而且保证了网络的分类精度。

第三章 基于自适应半径滤波的激光点云去噪方法

5.密度聚类相关分析

本文聚类精确率、聚类召回率和F1 分数四个维度评价算法性能。本文将原

始点云、去噪后的点云进行DBSCAN 聚类，聚类结果包含3 类信息：噪声点云

簇、目标点云簇和未被聚类点云。本文把聚类结果的精确率(Precision)、召回率

(Recall)和F1 分数的计算方法为：

T P A  (3-9)

T R G  (3-10)

1 2 P R F P R    (3-11)

式中 P——聚类精确率

R——聚类召回率

F1——F1 分数

T——聚类结果中，目标点云簇数量

A——聚类结果中，目标点云簇和噪声点云簇数量之和

G——实际目标点云簇数量

点云的噪声数量直接影响聚类或识别的精度，经过去噪的点云有利于提升聚

类的精确率和召回率。首先，对原始数据依次用统计滤波、半径滤波和本文提出

的自适应半径滤波进行去噪，并统计去噪时间，本文方法的去噪时间由三部分组

成：点云转换图像、神经网络推理和自适应半径滤波；其次，针对白杨树林和旱

柳树林原始数据和滤波结果，依次进行DBSCAN 聚类，计算其精确率、召回率

和F1 分数。由于苹果种植园采用密集种植方法，点云呈连续的立面状，不适合

做聚类分析。白杨树林和旱柳树林的聚类真值如图3-20(b)和图3-21(b)所示。

(a)采集场景 (b)聚类真值

图3-20 白杨树林采集场景及聚类结果

第三章 基于自适应半径滤波的激光点云去噪方法

(a)采集场景 (b)聚类真值

图3-21 旱柳树林采集场景及聚类结果

图3-20(b)与图3-21(b)中的矩形框中为目标点云簇，白杨树林和旱柳树林的

聚类真值分别为20 和22，其余部分为点云噪声或信息量很少的点云。由图3-17、

图3-19 可知，DBSCAN 算法能够在含有较多噪声的激光点云数据中，较准确地

完成聚类分割，对明显的离群噪声有较强的抑制效果。但由于果园场景较大且复

杂多变，点云数据包含较多的失落信息和逸出值，基于原始数据的聚类结果精确

度较低，而基于去噪点云的聚类效果有较明显的提升。结合图3-17 与图3-19 中

的聚类信息，计算精确率、召回率和F1 分数，结果如表3-3 所示。

表3-3 DBSCAN 聚类结果

去噪方法 原始数据 统计滤波 半径滤波 本文方法

白杨树林 0.500 0.875 0.933 0.944

旱柳树林 0.579 0.938 0.923 0.941

平均值 0.539 0.906 0.928 0.943

白杨树林 0.400 0.700 0.700 0.850

旱柳树林 0.500 0.682 0.545 0.727

平均值 0.450 0.691 0.623 0.789

白杨树林 0.444 0.778 0.800 0.895

旱柳树林 0.537 0.789 0.686 0.821

平均值 0.491 0.784 0.743 0.858

根据表3-3 可知，聚类原始数据的平均F1 分数为0.491，而统计滤波、半径

滤波和自适应半径滤波的平均F1 分数分别为0.784、0.743、0.858，相比提升

29.3%，25.2%、36.7%。经本文提出的自适应半径滤波方法去噪后，DBSCAN 聚

类的平均精确率和平均召回率的提升40.4%和33.9%，高于统计滤波和半径滤波，

第三章 基于自适应半径滤波的激光点云去噪方法

也表明该方法的有效性。综上所述，基于自适应半径滤波方法和DBSCAN 聚类

方法，能够实现准确、稳定地聚类分割激光点云数据，为点云后续处理提供更可

6.综合分析

在诸如苹果果园、白杨树林和旱柳树林等大场景中，点云密度相差较大，本

文中的数据点间平均距离相差约70 倍，而半径滤波、统计滤波的参数固定，不

能根据点云密度动态调整，去噪效果容易受到点云密度、数据点间距的影响，实

际效果并不理想。

经分析，在密集种植和非密集种植场景中，激光点云的形态特点差异较大，

通常需要采用多组去噪参数，本文通过提前预置参数并使用神经网络分类器的方

式，有效地提升了方法的适应性。

本文提出动态半径滤波器，利用点云密度与探测距离近似负相关的特性，根

据目标点到原点的欧式距离，有针对性地设计该点的滤波半径，从而有效地避免

了点云密度差异对去噪的影响，实现有效抑制噪声的同时，保留更加丰富的场景

该方法共有和两个参数：近邻数量和滤波半径相关系数。近邻数量相同时，

增大滤波半径相关系数，噪声去除能力有所减弱；在滤波半径相关系数一定时，

适当增大最小近邻数可提升滤波效果。经实验：在密集种植场景，点云呈连续里

面状，选择较多的近邻数量和较大的滤波半径相关系数有利于保持点云特征并提

高去噪效果；而在非密集种植场景，激光数据表现为若干点云簇，近邻数量较多

且滤波半径相关系数较大时，目标信息损失较少，噪声抑制效果更加显著。

综上所述，本文提出的自适应半径滤波不仅能有效去除稀疏离群噪声，而且

对密集噪声、目标周围的噪声同样有较明显的抑制效果。此外，与半径滤波和统

计滤波相比，耗时基本一致，具有较高的实时性，可适用于密集种植、非密集种

植场景。自适应半径滤波保留了更加丰富的目标信息，较明显地提升了聚类精确

率和召回率，有利于提升后续点云处理的效果。

3.4 本章总结

本章主要研究内容由两部分组成：一是激光雷达噪声来源及密度特性，二是

激光点云去噪方法。在果园条件中，激光雷达噪声主要来源无目标处的失落信息

和微小目标处的逸出值，激光点云密度差异较大，在工作范围内，点云密度对探

第三章 基于自适应半径滤波的激光点云去噪方法

测距离的导数值约为常数，表明点云密度呈线性减小。基于点云密度特性，提出

自适应半径滤波方法，该方法由种植模式判定器和动态半径滤波组成，判定器用

于识别当前种植模式并确定去噪参数，动态半径滤波器基于数据点的欧式距离设

计滤波半径，实现与点云密度相适应。

实验结果表明：本文提出的自适应半径滤波方法可明显抑制多尺度噪声，对

密集噪声和稀疏离群点均可有效去除，基于优化设计的卷积神经网络和较高的噪

声去除率，该方法的去噪时间未明显增加，具有较高的效率，为后续点云处理提

供可靠的点云数据。

第四章 基于激光雷达的行间自主导航方法

第四章 基于激光雷达的行间自主导航方法

从激光雷达获取的数据通常为无序点云，即由数据点位置构成的列表，与矩

阵排列的数据相比，此类数据处理方法相对复杂且计算量大，而自主导航技术需

要算法具有高效性、稳定性和鲁棒性，农业机械装备自主运行需要感知周围目标

类别和方位，因此，本文将点云转化为距离二值图后，进行形态学处理提取感兴

趣区域，提出交叉像素的可通行区域提取与位姿估计方法，在密集种植和非密集

种植条件下，具有良好的鲁棒性和稳定性。

4.1 算法原理及步骤

准确提取农业机械装备的可通行区域并估计其位姿是实现自主导航的关键

技术，果园场景中，可通行区域一般由左右两行植株构成的空间组成，左右两行

植株在激光雷达数据中表现为高密度、大数量的点云簇，而其他区域中的点云密

度和数量均较低，激光雷达数据通常为无序点云，且处理三维数据的时间和难度

均大于二值图。基于以上分析，本文提出基于交叉像素的激光雷达导航方法，其

流程如图4-1 所示。

连通域分析 椭圆离心率分析

直线簇与ROI 交叉像素数量

图4-1 基于激光雷达的导航方法流程图

第四章 基于激光雷达的行间自主导航方法

由图4-1 可知，本文方法由两部分构成：由数据转化、图像预处理、感兴趣

区域提取等方法构成图像处理模块，由直线簇生成、交叉像素统计、位姿估计等

方法构成导航信息提取模块，具体流程与原理如下：

1.参数初始化

由于激光雷达探测范围和导航精度需求不尽相同，本文通过细腻度参数调整

二值图分辨率。细腻度RW、RH 越高，二值图尺寸W、H 越大，点云转换至二值

图的量化误差越低，有利于提升导航信息的准确性，但也增加了数据计算量。图

像尺寸由公式(4-1)和公式(4-2)确定。

L W R  (4-1)

L H R  (4-2)

式中 LW——激光雷达探测宽度

LH——激光雷达探测长度

RW——宽度细腻度，物理意义为单个像素代表距离值

RH——高度细腻度，物理意义为单个像素代表距离值

2.转换点云为二值图

为最大程度地保留信息，本文二值图包含距离信息，细腻度参数为单颗像素

大小，以原点为基准，可进一步确定每颗像素对应的距离和位置。根据初始化中

的图像尺寸生成矩阵I(1)，遍历所有点云数据pi(xi,yi,zi)，i=1,2,...,n，根据信息点

坐标判断所属像素，根据公式(4-3)转换为二值图，并对图像I(1)依次采用孔洞填

充、腐蚀、膨胀处理方法完成离群点去除与预处理。

; 1 y x i i R R H W

 I (4-3)

3.感兴趣区域提取

针对非密集种植场景的二值图数据，树干区域呈椭圆状，可根据其形态特点

确定树干感兴趣区域。本文分析了图像连通域并标记每个独立区域，计算每个区

域的离心率ξ 与面积σ。若同时满足离心率阈值和面积阈值，则标记为感兴趣区

域，生成对应图像I(2)，通过计算I(2)中感兴趣区域质心像素坐标可进一步估计相

第四章 基于激光雷达的行间自主导航方法

4.计算交叉像素

根据搜索角度和横向偏移确定斜率集合K={k1,k2,...,kp} 与截距集合

C={c1,c2,...,cq}，并计算直线矩阵Di,j，该矩阵由为横轴向量a 和纵轴向量b 组成，

相应计算方法如公式(4-4)所示。创建用于存放直线像素点的图像矩阵I(3)，统计

I(2)、I(3)交叉像素数量，即I(2)、I(3)矩阵点积运算后所有元素的和，计算方法如公

式(4-5)所示。

    , 2 2 2 ; | ; 1; ; 1 , , , W W W i j i j i j k c k K c C              D a b a b a (4-4)

      2 3 , , 1 1

sum I I =1

i j i j i j      D S (4-5)

式中 sum——矩阵元素求和方法

5.提取可通行区域

将max(Si,j)对应直线方程作为第一条边界，其中，max 为矩阵最大元素提取

方法。假设其对应的斜率为K1，截距为C1，则在感兴趣直线簇集合L(公式(4-6))

搜索交叉像素最多的直线作为配对直线，对应的斜率与截距表示为K2 与C2。其

中，μ、λ 为斜率阈值和截距阈值。

     

1 1 1 1

; 1; ; 1 , , ; | - ,

W W W k c

k K K K c C C C    

                        

a b a L a b   ， ， (4-6)

式中 μ——斜率调整量

λ——截距调整量

6.导航信息估计

根据两条边界线参数可计算道路宽度D、横向偏移δ 与航向角φ，具体计算

方法如公式(4-7)、公式(4-8)和公式(4-9)所示。

  1 2 W D R C C   (4-7)

  1 2 2

W R C C    (4-8)

1 1 2 = tan 2 K K         

综上所述，本文提出的基于交叉像素的激光雷达导航方法由图像转换处理模

块和导航信息提取模块组成，图像处理转换模块主要完成点云二值图生成、图像

预处理和感兴趣区域，导航信息提取模块主要完成可通行区域分析、偏航角计算、

第四章 基于激光雷达的行间自主导航方法

横向偏移计算，为农业机械装备提供导航信息。

4.2 实验与分析

为验证本文所提方法的有效性，分别在密集种植和非密集种植条件下完成实

验，由于密集种植条件下，植株之间不存在明显的间隙，激光雷达数据呈连续的

点云簇，难以定位单棵植株。

实验数据采集设备为北醒光子CE30-D 固态面阵激光雷达，其固有参数为探

测范围0.4m-28m，视场角60°×4°，分辨率320×20，宽度细腻度与高度细腻

度均设为0.1m，生成二值图的尺寸为300×300 像素。分别在密集种植和非密集

种植条件中，采集不同偏航角的点云数据。

4.2.1 误差计算方法

位姿估计是农业装备在半结构场景下自主导航的前提和基础，利用建立的道

路成像几何模型，仅用单目相机即可实现偏航角与横向偏移的估计。基于消失点

像素坐标、相机感光元件和镜头焦距可得当前航向信息，再由图像中的边界线方

程和偏航角，估计距左右树行的距离，并估计行距与横向偏移。其中，偏航角、

横向偏移与道路宽度的误差计算方法如公式(4-10)、公式(4-11)和公式(4-12)所示，

其中水平视场角Ah 为60°。

h E A 

    (4-10)

ˆ E W 

    (4-11)

W W E W

  (4-12)

式中 Eφ——偏航角估计误差

Eλ——横向偏移估计误差

EW——道路宽度估计误差

4.2.2 非密集种植场景实验与分析

本文在非密集种植场景完成实验，该实验地点位于山西省太原市尖草坪区的

白杨树林，株行距为3×3 米，如图4-3 所示。

第四章 基于激光雷达的行间自主导航方法

图4-3 非密集种植实验场景

在图4-3 的实验场景中，激光雷达位于道路中线，行距为3m，采集视角偏

左、偏右和无偏三种类型的数据，实验结果如表4-1 所示。

表4-1 非密集种植条件实验结果

距离二值图 形态学分析 道路提取 位姿估计

真实值 估计值 估计误差

φ/° λ/m W/m ˆ/° ˆ/m ˆW /m E E EW

0 0 3 1 0.35 2.9 1.67% 11.67% 3.33%

-11 0 3 -13 0.15 3.1 3.33% 5.00% 3.33%

11 0 3 10 0.1 2.9 1.67% 3.33% 3.33%

由表4-1 可知，本文所用的图像预处理方法能够抑制离群噪声干扰，较准确

地提取感兴趣区域，估计果树的相对位置。在不同偏航角和横向偏移条件中，能

够稳定地提取可通行区域，并估计当前偏航信息和横向偏移信息，由章节4.2.1

误差计算方法可计算得：偏航角平均误差为2.22%，横向偏移平均误差为6.67%，

道路宽度平均误差为3.33%。

实验结果表明：在非密集种植场景中，本文提出的基于交叉像素的激光雷达

导航方法，能够较准确地提取道路区域、估计当前位姿、测量道路宽度，且对离

第四章 基于激光雷达的行间自主导航方法

群点具有较强的鲁棒性。

4.2.3 密集种植场景实验与分析

本文在密集种植场景完成实验，该实验地点位于北京市昌平区苹果果园，

株行距为1×3 米，如图4-4 所示。

图4-4 密集种植实验场景

在图4-4 的实验场景中，激光雷达位于道路中线，行距为3m，采集视角偏

左、偏右和无偏三种类型的数据，实验结果如表4-2 所示。

表4-2 密集种植条件实验结果

距离二值图 形态学分析 道路提取 位姿估计

真实值 估计值 估计误差

φ/° λ/m W/m ˆ/° ˆ/m ˆW /m E E EW

0 0 3 -3 -0.20 2.6 5.00% 6.67% 13.33%

-20 0 3 -22 0.2 3.0 3.33% 6.67% 0.00%

10 0 3 11 0.15 2.9 1.67% 5.00% 3.33%

由表4-2 可知，与非密集种植场景不同，密集种植条件下的点云呈连续立面

状，距离二值图连通性更强，在此场景中，难以估计每棵植株的位置，也难以利

第四章 基于激光雷达的行间自主导航方法

用果树辅助导航，因此，基于树行点云簇，准确道路区域并估计位姿尤为重要。

实验结果表明：本文所提出的方法能够在此场景中抑制离群点干扰，较准确

且稳定地提取可通行区域，并估计当前位姿信息，偏航角平均误差为3.33%，横

向偏移平均误差为6.11%，道路宽度平均误差为5.56%。此外，该方法具有较强

的鲁棒性：首先，对种植模式鲁棒，在密集种植和非密集种植条件中，均可有效

提取导航信息；其次，对点云噪声鲁棒，通过形态学预处理与感兴趣区域提取，

即使在包含较多噪声的点云数据中，仍然能够估计航向、偏移等关键信息。

4.2.4 误差来源分析

激光导航的误差主要来源于量化误差和测量误差。首先，量化误差是指将点

云数据转换为距离二值图时精度的下降，由于距离二值图利用像素表示位置，单

个像素代表边长为10 厘米的等边矩形，落在此区域的点云将被量化为同一像素，

从而引入量化误差。其次，测量真值与真实值存在误差，实验基于惯性导航单元

测量偏航角，该传感器存在累计误差，伴随测量时间的增加，传感器累计误差也

针对果园自主导航问题，系统高效性和稳定性尤为重要，虽然将点云转化为

二值图的过程存在量化误差，但是图像矩阵处理效率更加高效，有利于提升系统

实时性，实验结果表明该方法具有较高的准确性和稳定性。

4.3 本章总结

本章研究了基于激光雷达的导航技术，提出基于交叉像素的激光雷达导航方

法，该方法通过转化点云为距离二值图，并采用直线簇交叉像素的方法，实现可

通行区域的提取、导航信息的计算。实验结果表明：本文提出的基于交叉像素的

激光雷达导航方法，在密集种植和非密集种植条件中均可有效提取导航信息，对

种植模式具有较高的鲁棒性，偏航角、横向偏移、道路宽度等导航信息的误差均

小于10%，为实现农业机器人自主导航提供良好基础。

第五章 基于单目视觉的行间自主导航方法

第五章 基于单目视觉的行间自主导航方法

与城市道路条件相比，农业果园存在密集的遮挡现象，通常也不具备可用于

导航的地图，因此，自主导航逐渐成为果园机器人自主运行的关键技术。以较低

的成本，高效准确地获取当前位姿并确定果树的相对位置是实现农业机械装备自

主运行的基本保证。本文提出单目视觉的位姿估计和果树定位方法，方法流程如

图5-1 所示。

深度神经 网络模型

道路掩码 树干掩码

道路边界 消失点坐标 树干坐标

道路几何 成像模型

偏航角 横向位移 可通行区域宽度

植株相对位置

左边界 右边界 消失点

图5-1 基于单目视觉的导航方法

由图5-1 可知该方法的流程如下：首先，基于Mask R-CNN 深度神经网络提

取道路和果树掩码；其次，根据掩码信息进一步提取消失点坐标和道路边界方程；

最后，基于建立的道路成像几何模型，估计当前的位置和姿态，并计算果树的相

对位置。此外，本文基于三次B 样条曲线，选取起始点、消失点和中心关键点

拟合导航基准线。

第五章 基于单目视觉的行间自主导航方法

5.1 道路与消失点信息提取

提取关键的场景语义信息是实现机械装备智能化的基础，农业机器人完成喷

药、采摘、施肥、自主导航等任务均依赖丰富且准确的语义信息，智能化采摘任

务需要确定果树相对位置，自主导航任务需要识别可通行区域确定导航信息。农

业果园场景受光照、季节、降雨等因素的影响，具有较高复杂性，图像明暗、色

温差异较大，难以用单一特征完成识别与分割任务。

深度神经网络具有强大的特征拟合和学习能力，可在较复杂的场景中完成目

标检测、图像分割等任务，基于以上分析，本文采用神经网络结合图像处理方式，

提取果树、可通行区域等场景信息。

5.1.1 果园场景实例分割

道路掩码为果园可通行道路在像平面的映射，构成道路的边界具有较高的平

行性，由于各果园道路差异显著，且季节、光线、降水等因素对道路特征具有较

明显的影响，基于深度学习的特征提取方法适应性更强，在此场景中分割的精确

度和稳定性更佳。果树掩码为果树树干在平面的投影，在图像中常表现为垂直或

相交于地面的矩形，深度神经网络不仅可对纹理、形状、轮廓、颜色等低层次特

征进行提取，而且可进一步提取高层次抽象特征，稳定地提取目标掩码。

本文采用Mask R-CNN 深度神经网络模型完成实例分割任务，该模型主要由

特征提取主干网络、区域建议网络、RoI Align、检测和分割分支组成，方法流程

如图5-2 所示。

图5-2 Mask R-CNN 网络结构示意图

由图5-2 可知，基于Mask R-CNN 实例分割方法的流程如下：首先，主干网

络提取果园图像的多层次特征；其次，针对特征图中的关键像素点，生成锚框组

合，由区域建议网络判断锚框属于前后景的概率，并调整锚框位置，去除无效预

测框；再次，有效锚框进行ROI Align 操作，即建立锚框、特征图和原始图像的

映射关系；最后，对预测框进行分类、边界回归，经全卷积上采样网络生成掩码。

第五章 基于单目视觉的行间自主导航方法

5.1.2 消失点和边界方程提取

针对Mask R-CNN 分割的道路掩码，本节研究了道路边界和消失点[42-45]的提

取方法。受到栽培精度、植株生长不确定性和行间平整度等因素的影响，可通行

区域边界较不平滑，掩码区域的边界通常呈不规则锯齿线，如图5-3 所示。

(a)原始图像数据 (b)可通行掩码 (c)寻找凸包 (d)霍夫变换 提取边界与消失点

图5-3 消失点与边界线提取

由图5-3(b)可知，道路掩码属于非规则多边形，其左右边界呈波浪或锯齿曲

线，增加了提取边界线方程和消失点的难度和复杂度。因此，本文首先寻找道路

掩码的凸包，如图5-3(c)所示，掩码Q 的凸包是一个最小的凸多边形P，满足Q

中的每个点都在P 的边界或者其内部。其次，基于霍夫变换和角度阈值计算左右

边界方程，如图5-3(d)中绿色线所示，联合边界方程所得的交点坐标为道路消失

点，如图5-3(d)中红色圆点所示。基于以上分析，本节方法由消失点提取、边界

方程提取和果树坐标提取组成，具体方法如以下伪代码5-1 和伪代码5-2 所示：

伪代码5-1 边界方程和消失点计算伪代码

Algorithm 边界方程和消失点提取方法 Input: 可通行区域掩码 Output: 左边界方程, 右边界方程, 消失点 function 提取边界方程和消失点(可通行区域掩码)

凸包轮廓 ← 寻找凸包(可通行区域掩码) 直线簇 ← 霍夫直线变换(凸包轮廓) for i ← 1 to length(直线簇) do

if 长度阈值1 < 直线簇[i].长度 < 长度阈值2 then

if 角度阈值1 < 直线簇[i].角度 < 角度阈值2 then

左直线簇 ← 左直线簇 + 直线簇[i] elseif 角度阈值1 < 直线簇[i].角度 < 角度阈值2 then

右直线簇 ← 右直线簇 + 直线簇[i] else end end end 左边界索引 ← 最大值索引(左直线簇.长度) 右边界索引 ← 最大值索引(右直线簇.长度) 左边界方程 ← 左直线簇[左边界索引] 右边界方程 ← 右边界簇[右边界索引] 消失点坐标 ← 计算交点(左边界, 右边界) return 左边界方程, 右边界方程, 消失点 end

右边界线 左边界线

第五章 基于单目视觉的行间自主导航方法

伪代码5-2 果树像素坐标计算伪代码

Algorithm 果树坐标提取方法 Input: 树干掩码, 消失点, 左边界方程, 右边界方程 Output: 左侧果树坐标，右侧果树坐标 function 提取树干坐标(树干掩码, 消失点, 左边界方程, 右边界方程)

for i ← 1 to length(树干掩码) do

if 果树掩码[i].中心横坐标 < 消失点.横坐标 then

if 点到直线的距离(果树掩码[i].下方中点, 左边界方程) < 距离阈值 then

左侧果树坐标 ← 左侧果树坐标 + 果树掩码[i].右下坐标 end end if 果树掩码[i].中心横坐标 > 消失点.横坐标 then

if 点到直线的距离(果树掩码[i].下方中点, 右边界方程) < 距离阈值 then

右侧果树坐标 ← 右侧果树坐标 + 果树掩码[i].左下坐标 end end end return 左侧果树坐标，右侧果树坐标 end

本节所提方法的具体流程如下：首先，对道路和果树掩码进行轮廓提取、寻

找凸包和霍夫变换操作，获取描述边缘轮廓的直线簇；其次，提取倾斜程度、长

度符合阈值条件的线条方程，联立两边界线方程提取消失点坐标；最后，提取果

树掩码贴近道路边缘的坐标，位于消失左侧的果树掩码，提取右下方坐标；位于

消失右侧的果树掩码，提取左下方坐标；之后再计算距离边界线的距离，若该值

大于阈值，则推断为邻行果树，不进行位置估计。

5.1.3 实验与分析

从相机中随机选取1200 幅图像进行数据集制作（正常曝光、过曝光和曝光

不足各400 张），其中720 张用于训练，240 张用于验证，240 用于测试，数据

样例如图5-4所示。为提升训练和预测速度，图像预处理时，将图像长边的分辨

率统一转换1280 像素。为提高模型鲁棒性，抑制过拟合现象，本文训练时加入

随机扰动扩充数据量，例如随机调整对比度、饱和度、亮度等。训练平台为

Intel i7-6870K CPU，Nvidia Geforce GTX1080Ti×4 GPU，32GB RAM。

第五章 基于单目视觉的行间自主导航方法

图5-4 果园典型图像数据

图5-4为冬季苹果果园的典型数据，由于果树树干与地面的颜色相似度较高，

且可通行区域界线相对模糊，增加了道路与树干信息的提取难度，数据集包含多

角度与多位置的拍摄数据，具有较强的代表性。

为使区域建议网络生成的锚框与实际预测框的交并比更大，使用K-Means

对标注框进行聚类，预测框数量越多，与标注框的交并比越大，但计算量也相应

增加；预测框较少时，数据处理量随之减少，预测框精度较低。不同数量的预测

框对应交并比的曲线如图5-5 所示。

0.6600.673 0.684

1 2 3 4 5 6 7 8 9 10 11 0.40

图5-5 平均交并比随聚类数量变化曲线

由图5-5 可知，锚点数量从2 种增加为3 种时，交并比提升显著，而计算量

随锚点比例数量的增加而显著增加，因此，锚点比例数量为3 时的综合性能较高，

此时锚框的比例为0.7，3 和8。在训练过程中，优化方法选择Adam 自适应学习

率优化器，初始学习率为0.005，学习率衰减系数为0.1，最小学习率为1×10-6，

第五章 基于单目视觉的行间自主导航方法

总计训练100 周期，训练时的损失函数值和验证集的平均精度曲线如图5-6 所示。

0 20 40 60 80 100 0.0

0 20 40 60 80 100 0.0

(a)Mask R-CNN(Res2Net50)损失函数曲线 (b)Mask R-CNN(Res2Net50)平均精确度曲线

0 20 40 60 80 100 0.0

0 20 40 60 80 100 0.0

(c)Mask R-CNN(ResNet50)损失函数曲线 (d)Mask R-CNN(ResNet50)平均精确度曲线

图5-6 训练过程曲线

由图5-6(a)(b)可知，训练至76 回合时，边框回归平均精度为0.564，分割平

均精度为0.559，且损失函数值较低，模型具有较强的分割和识别能力。此外，

本文对比了以ResNet50 为主干网络的Mask R-CNN 模型，其损失函数曲线与平

均精度曲线如图5-6 (c)(d)所示，从图中可知其损失函数收敛速度、模型性能均弱

于Res2Net，详细数据如表5-1 所示。

表5-1 两种主干网络的Mask R-CNN 模型性能对比

网络结构 box mAP

mask mAP

boxAP boxAR maskAP maskAR 计算

时间/ms 大目标 中等

目标 小目标 大目标 中等

目标 小目标 大目标 中等

目标 小目标 大目标 中等

目标 小目标

MaskRCNN

(ResNet50)

0.519 0.519 0.668 0.290 0.095 0.719 0.383 0.139 0.699 0.295 0.065 0.728 0.382 0.112 138

MaskRCNN

(Res2Net50)

0.564 0.559 0.689 0.368 0.124 0.743 0.438 0.165 0.716 0.397 0.113 0.742 0.437 0.156 110

注：boxmAP：边界框回归平均精确率均值；maskmAP：掩码平均精确率均值；boxAP：边界框回归平均精确率；boxAR：边界 框回归平均召回率；maskAP：掩码平均精确率；boxAP：掩码平均召回率；

第五章 基于单目视觉的行间自主导航方法

由表5-1 可知，Mask R-CNN(Res2Net50)的边框回归与分割具有更高精确率

和召回率，分别提升4.5%和4%，推理速度提升20%；此外，基于该主干网络的

Mask R-CNN 对中小目标的检测和分割效果提升显著，受成像原理、拍摄角度、

拍摄距离与单目成像原理等因素的影响，图像中的目标尺度具有较大差异，而

Res2Net 模型采用分组卷积方法，可有效提取多尺度目标的特征，在本文实验条

件中表现出更高的适应性。

基于神经网络分割的可通行区域与树干掩码，提取消失点、边界方程、果树

坐标等更深层次的信息：对于果树掩码，分类其所属位置：左行、右行和邻行，

并对左右行的树干掩码提取贴近道路边界的坐标；对于可通行区域掩码，依次完

成寻找凸包、霍夫变换、计算边界和消失点坐标操作，其中红色圆点表示消失点，

绿色直线表示可通行区域的左右边界，实验结果如表5-2 所示，其中，左上角为

坐标原点，水平轴为u 轴，竖直轴为v 轴。

表5-2 场景分割与关键信息提取(1)

采集点1 采集点2 采集点3

道路掩码提取

消失点与边界线提取

消失点坐标 [642,495] [646,247] [612,361]

左边界方程 u=-2.2v+1755.7 u=-1.8v+1085.2 u=-2.9v+1661.4

右边界方程 u=2.5v-613.2 u=3.1v-115.9 u=1.5v+76.6

第五章 基于单目视觉的行间自主导航方法

表5-2 场景分割与关键信息提取(2)

采集点4 采集点5 采集点6

道路掩码提取

消失点与边界线提取

消失点坐标 [423,509] [804,426] [1107,461]

左边界方程 u=-2.2v+1543.3 u=-1.9v+1606.8 u=-2.9v+2446.1

右边界方程 u=2.6v-901.1 u=2.5v-255.3 u=1.4v+482.8

表5-2 场景分割与关键信息提取(3)

采集点7 采集点8 采集点9

道路掩码提取

消失点与边界线提取

消失点坐标 [361,444] [772,212] [339,437]

左边界方程 u=-1.8v+1447.4 u=-1.9v+1172.2 u=-2.7v+1506.7

右边界方程 u=3.5v-1191.3 u=2.7v+205.5 u=2.1v-557.1

由表5-2 可知，在不同拍摄位置和拍摄视角条件下，本文采用的网络模型可

较稳定且准确地提取语义信息，采用的消失点和边界线提取方法，具有较高的鲁

棒性。存在偏航角和横向偏移时，本文所用方法仍能在不同位置提取消失点、边

第五章 基于单目视觉的行间自主导航方法

界线和果树掩码，为估计位姿与计算果树相对位置提供可靠基础。

5.2 位姿估计方法

目前，获取位姿的方法主要有：全球导航卫星系统(Global navigation satellite

system, GNSS)、惯性导航INS(Inertia navigation system, INS)、激光雷达、人工标

志和视觉导航等。但是，GNSS 容易受到遮挡的影响，在不具备地图的场景难以

运用；INS 存在累积误差，不具有测量相对位置的条件。激光雷达语义信息量较

少，对环境感知能力弱于相机；人工标志需要特定安装环境，前期需要较高的人

工投入。由于以上问题，限制了此类传感器在农业场景中的应用。视觉导航主要

依赖单目相机、双目相机和RGB-D 相机，但双目相机在大场景中获取的深度信

息有限，RGB-D 相机在高照度条件中的距离信息存在较大漂移。

单目相机具有成像稳定、成本可控的优点，在视觉自主导航中广泛应用。现

有方法对定性单目视觉展开深入研究，为进一步提高导航的准确度，本文利用果

园边界的平行性，建立道路几何成像模型，可通过消失点坐标与边界线方程实现

偏航角、横向偏移与果树位置的定量计算。

5.2.1 道路几何成像模型

偏航角、横向偏移和植株相对位置是实现自主导航的关键信息。本文基于单

目相机成像原理，利用果园的结构特性，间接测量以上信息。现就存在偏航角和

横向位移的情况，对单目相机成像过程进行几何建模，其示意图如图5-7 所示。

图5-7 道路几何成像模型示意图

图5-7 果园一般场景示意图，左右树行S1、S2 相互平行，由两树行所构成的

空间为可通行区域，基于基本坐标系oxyz 建立成像模型，光心f 距地面高度为h，

第五章 基于单目视觉的行间自主导航方法

与左右边界的距离分别为xl 和xr，偏航角为φ，图像坐标系为ocxcyc,像素坐标系

为oixiyi。建模过程分为以下四部分：一，求解相机像平面方程；二，基于针孔

相机成像原理，计算边界线在像平面中的映射方程；三，分析方程斜率和消失点

表达式，逆解航向信息和横向位移；四，基于地面点和像平面的映射关系，逆解

果树的相对位置。

1.求解像平面方程

首先，计算无偏航信息时的像平面方程：在相平面选取三个关键点p1,2,3（本

文坐标统一表示为列向量，如公式(5-1)所示），用于描述相机像平面在oxyz 坐标

系下的平面方程。

C C C H C H H

          

式中 p1,2,3——像平面关键点

CF——镜头焦距

CW——像平面宽度(感光元件宽度)

CH——像平面高度(感光元件高度)

H——相机安装高度(焦点距地面距离)

其次，当存在偏航角φ 时，关键点p1,2,3经旋转矩阵t(公式(5-2))变换为p’1,2,3(公

式(5-3))。

   

cos sin 0

sin cos 0 0 0 1

          

        ' 1,2,3 1,2,3

sin sin cos sin

cos cos cos sin

F F W F

F F F W

C C C C

C C C C H C H H

   

   

                

式中 t——偏航角旋转矩阵

p’1,2,3——旋转变换的关键点

φ——偏航角

最后，由关键点p’1,2,3 可确定像平面法向量n(公式(5-4))，再与任一关键点（本

文选取p’1 点）构成平面点法式方程，如公式(5-5)所示。

第五章 基于单目视觉的行间自主导航方法

' ' ' ' 2 1 3 1

sin( )

= cos( )

            

n p p p p

            ' ' ' 1 1 1 1 1 2 2 3 3 0

sin( ) - cos( ) 0 F

x y C  

     

n p n p n p

式中 n——像平面法向量

2.计算边界线在像平面中的映射方程

首先，任取可通行区域边界S1 两点r1,2(边界S2 同理)，r1,2(公式(5-7))与焦点

f(公式(5-6))构成的空间直线方程l1 和l2，如公式(5-8)所示。

式中 f——相机焦点坐标

r1,2——边界关键点

xl——r 点x 轴坐标

y1,2——r 点y 轴坐标

l1,2——边界关键点与焦点构成的直线参数方程

β1,2——直线参数方程的参数

其次，联立像平面方程(公式(5-5))与直线方程l1 和l2，解得交点坐标，如公

式(5-9)所示。

         

f (5-6)

1,2 1 2 0 0

l l y y

x x          

r (5-7)

        

      

第五章 基于单目视觉的行间自主导航方法

cos sin cos sin

cos sin cos sin

cos sin cos sin

l C C y x y x C y C y x y x

C H C H H x

   

   

   

                            

式中 a1,2——直线参数方程与像平面的交点坐标

再次，将交点的世界坐标转换至图像坐标系，即计算a1,2 在向量p’2p’1 和向

量p’3p’1 上的投影a’1,2，如公式(5-10)所示。

     

     

   

' ' ' ' ' ' 2 1 1 1 2 1 1 2 1 2 ' ' ' ' 2 1 2 1 1 2 ' 1,2 ' ' ' ' ' ' 3 1 1 1 3 1 1 2 ' ' ' '

2 3 1 3 1 1

sin cos sin cos

cos sin cos sin

cos sin cos sin

F l F l

C y x C y x

y x y x

C H C H

y x y x

   

   

   

       

                         

p p p a p p p a

p p p p a

p p p a p p p a

p p p p

(5-10)

式中 a’1,2——与像平面的交点坐标(图像坐标系)

最后，确定l1 在ocxcyc 坐标系内的斜率k1、截距b1 和S1 在图像坐标系ocxcyc

的方程S’1，如公式(5-13)所示，S’2 的计算方法同理，如公式(5-14)所示。

    

' ' 2 1 ' ' 2 1

1 1 2 2 cos

l lk x H      a a a a

(5-11)

   ' ' 1 1 1 2 an = t l l F b k C     a a (5-12)

  ' 1 cos : tan c F l c l c l

x S H x k y b y C       (5-13)

  ' 2 t co : an s

c F r c

x S y C H x     (5-14)

式中 kl——左边界直线方程斜率(图像坐标系)

bl——左边界直线方程截距(图像坐标系)

S’1——左边界直线方程(图像坐标系)

S’2——右边界直线方程(图像坐标系)

根据透视投影原理，所有平行的直线经过透视投影后都会相交于一点，该点

称为消失点，可通行区域的消失点是行间环境的重要信息，其总是指向道路的尽

头，可以为农业机械装备提供重要的方向信息和道路边界信息，同时可用来估计

当前运动的姿态角[42-45]。在理想相机成像模型中，相机的横向偏移不影响消失点

在图像中的位置，但影响可通行区域边界在成像平面中的倾斜程度。因此，可利

用消失点坐标先估计偏航角，再由像平面中的边界线方程估计横向偏移。

第五章 基于单目视觉的行间自主导航方法

5.2.2 偏航角与横向偏移估计

首先，计算消失点坐标。联立图像坐标系下的边界方程S’1 和S’2，解得消失

点(两直线交点)坐标，即联立公式(5-13)、公式(5-14)求解交点坐标，消失点坐标

Xc 和Yc 如公式(5-15)所示。

式中 Xc，Yc——消失点坐标(图像坐标系)

其次，推导偏航角计算方法。由公式(5-15)可知，消失点xc 轴坐标XC 为偏航

角φ 的一元函数，因此，可通过逆解消失点坐标XC 求得偏航角φ。在图像坐标

系中，消失点的坐标无法直接获取，可通过图像-像素坐标系的相互映射关系间

接计算，如公式(5-16)所示。基于以上分析可知，通过消失点的像素坐标可计算

偏航角，计算方法如公式(5-17)所示。

式中 Xi——消失点xi 轴坐标(像素坐标系)

Ix——图像横轴分辨率

ˆ——偏航角估计值

再次，计算与边界S1 和S2 的距离。以左边界线为例，由S’1 表达式可知，在

图像坐标系和像素坐标系中，边界线斜率是关于偏航角φ 和边界距离xl 的二元函

数，偏航角φ 可由公式(5-17)解出，因此，基于图像坐标系中边界线斜率可计算

距离xl 和xr。基于以上分析，与边界S1、S2 的距离xl、xr 的计算方法如公式(5-18)

和公式(5-19)所示。

ˆ ˆ cos

k x H   (5-18)

ˆ ˆ cos

k x H   (5-19)

式中 ˆlx ——左边界距离估计值

ˆrx ——右边界距离估计值

 tan

    

(5-15)

2 i x c W x

X I X C I

  (5-16)

  t ˆ a = 2 arc n i x W

I C    (5-17)

第五章 基于单目视觉的行间自主导航方法

最后，计算道路宽度和横向偏移。由于xl、xr 为距离左右边界的距离，二者

绝对值之和为道路宽度W，二者绝对值之差的一半为横向偏移λ，计算方法如公

式(5-20)、公式(5-21)所示。

ˆ ˆ ˆ l r W x x   (5-20)

l r x x    (5-21)

式中 ˆW ——道路宽度

ˆ——横向位移

基于以上方法，可由公式(5-17)估计当前偏航角信息，由公式(5-20)计算道路

宽度，由公式(5-21)估计横向偏移。若将单目相机固定安装于在农业机械装备，

即可通过相机估计当前偏航角、道路宽度和横向位移。

5.2.3 实验与分析

位姿估计是农业装备在半结构场景下自主导航的前提和基础，利用建立的道

路成像几何模型，仅用单目相机即可实现偏航角与横向偏移的估计。基于消失点

像素坐标、相机感光元件和镜头焦距可得当前航向信息，再由图像中的边界线方

程和偏航角，估计距左右树行的距离，并估计行距与横向偏移。其中，偏航角、

横向偏移与道路宽度的误差计算方法如公式(5-22)、公式(5-23)和公式(5-24)所示，

其中水平视场角Ah 为37.2°。

h E A 

    (5-22)

ˆ E W 

    (5-23)

W W E W

  (5-24)

式中 Eφ——偏航角估计误差

Eλ——横向偏移估计误差

EW——道路宽度估计误差

一般工况下，农业装备既可能处于道路中线，也可能偏左或偏右，同理，偏

航角也存在相似的三种情况，分别为航向角与y 轴平行、左旋转或右旋转。为验

证模型的鲁棒性与可靠性，本文分析了农业装备工作时的九种位姿，即三种横向

位移和偏航角的交叉组合。实验结果如表5-3 所示。

第五章 基于单目视觉的行间自主导航方法

表5-3 位姿估计及其误差

真实值 估计值 估计误差

计算时间/s φ/° λ/mm W/mm ˆ/° ˆ/mm ˆW /mm E

1 0 0 5000 0.060 152 5037 0.16% 3.05% 0.75% 0.059

2 0 860 5000 0.181 687 5102 0.49% 3.47% 2.03% 0.058

3 0 -1054 5000 -0.845 -747 4615 2.27% 6.15% 7.71% 0.057

4 -6.0 0 5000 -6.521 214 5087 1.40% 4.28% 1.74% 0.063

5 5.0 0 5000 4.938 318 4612 0.17% 6.37% 7.75% 0.065

6 13.7 -613 5000 13.821 -840 4615 0.32% 4.54% 7.71% 0.053

7 -14.5 677 5000 -8.361 916 5593 16.50% 4.78% 11.87% 0.068

8 4.0 500 5000 3.978 418 4808 0.06% 1.63% 3.84% 0.060

9 -10.8 -785 5000 -9.010 -330 5031 4.81% 9.10% 0.61% 0.050

由表5-3 中数据可知，本文所提出的方法在存在偏航角和横向偏移值均能较

准确地计算位姿，其中，偏航角平均误差为2.91%，横向偏移平均误差为4.82%，

道路宽度平均误差为4.89%，其精度可满足农业装备导航需求。误差主要来源于

测量误差和相机系统误差，首先，用于测量航向角的惯性导航单元存在零点漂移

问题和累计误差；其次，本文采用相机并未经过标定，存在轻微畸变现象，因此，

道路掩码也存在一定程度地形变，影响位姿估计的精度。

在此基础上，研究所处位姿对算法精度的影响，将偏航角与横向偏移取的绝

对值进行Min-Max 归一化，对于偏航角误差，与当前偏航角、横向位移的协方

差分别为0.069 和0.035，对于横向偏移误差，相应的协方差分别为0.032 和0.026，

表明本文所提方法的精度受所处位姿的影响较小，具有较高的鲁棒性和适应性。

5.3 果树定位方法

智能机械装备进行喷药、采摘、施肥等工作时，需要估计果树的相对位置，

建立地图、特殊标志、射频识别虽能够实现定位要求，但果园图像帧间相似度高，

基于图像特征的建图方法效果并不理想，重定位也具有较大困难；特殊标志需要

消耗大量人力资源，且在自然环境中存在被破坏的可能；射频识别技术安装与维

护成本较高，不利于大规模推广。树行与可通行区域左右边界具有较高的重合度，

基于建立的道路几何成像模型，可获得像素坐标系与基本坐标系的映射关系，通

过树干的像素坐标可估计果树相对位置。基于以上分析，本文提出基于单目视觉

的果树定位方法，可利用树干掩码的像素坐标估计其相对位置

第五章 基于单目视觉的行间自主导航方法

5.3.1 果树相对位置估计

由5.2.1 节的图5-2 可知，在基本坐标系中，S1 和S2 为树行和可通行区域的

交界，因此位于边界S1 和S2 的果树x 轴坐标分别为xl 和xr，只需求解y 轴坐标

即可估计果树的相对位置，因为果树的像素坐标可以从图像中获得，可利用公式

(5-10)所示的映射关系求解y 轴坐标。因为安装高度h 由测量得出，一般带有测

量误差，未避免引入二次误差，采用yc 轴坐标求解y，将a’1,2 的yc 轴坐标(公式

(5-10))一般化，如公式(5-25)所示，由公式(5-16)和公式(5-25)可得果树的yc 轴与

y 轴坐标的映射关系，即y 轴坐标的计算方法，如公式(5-26)所示。

     

sin cos

cos sin

C y x x y x

  

(5-25)

     

     

ˆ ˆ tan , ˆ tan ˆ

ˆ ˆ tan , ˆ tan

l i x W F x

i i i x W F x

r i x W F x

i i i x W F x

x x I C C I x X x I C C I y

x x I C C I x X x I C C I

                

(5-26)

5.3.2 实验与分析

农业自主导航任务不仅需要准确估计当前位姿，为轨迹规划和自主运行提供

基础，更重要的是，在获取当前位姿的基础上，确定果树的相对位置，为智能化

采摘、喷药和施肥等精细化操作提供保障。本文根据边界线像素-基本坐标系的

相互映射关系，即根据公式(5-18)、公式(5-19)、公式(5-26)推理左右两行各四棵

果树的相对位置，并其误差计算方法如式所示。

ˆl l xl

x x E x

  (5-27)

y y E y   (5-28)

d d E d

  (5-29)

式中 Exl——横向位置(x 轴)估计误差

Ey——纵向位置(y 轴)估计误差

Ed——株距估计误差

d——株距真实值

第五章 基于单目视觉的行间自主导航方法

ˆd ——株距估计值

由于相机成像模型为射影变换，成像过程为三维信息向二维平面的映射，无

法直接表示深度信息，当存在偏航角和横向位移时，加剧了果树的层叠现象，存

在层叠现象的实验场景如图5-8 所示。

图5-8 存在层叠现象的实验场景

图5-8 拍摄位置为道路中线偏左，针对左侧树行，除近距离的三颗果树层次

结构较明显外，其余果树层叠现象明显，增加了果树识别与定位难度。因此，本

文在道路中线选取三处航向角为正前的实验点进行测试，分别测量每棵距离相机

的横向相对位置、纵向相对位置与株距，并与估计值对比，计算其误差，实验场

景如图5-9 所示。

(a)实验点1 (b)实验点2 实验点3

图5-9 实验点场景

图5-9 中的三处实验点位于同一行间的不同纵向位置，实验点1 距离道路尽

头最远，实验点2 次之，实验点3 距离道路尽头最近，三处实验点的位置示意图

如图5-10 所示。

第五章 基于单目视觉的行间自主导航方法

3 实验点2

图5-10 实验位置示意图

本文在三处实验点测量20m 以内果树的相对位置和距前株的株距，由图5-10

所示，实验点1 拍摄编号为1-7 的果树，实验点2 可拍摄编号为2-7 的果树，实

验点3 可拍摄编号为4-7 的果树，相应的实验数据如表5-4、表5-5 与表5-6 所示。

表5-4 实验点1 果树位置估计

横向位置（左行）纵向位置（左行） 左行株距（前株） 果树

横向位置（右行）纵向位置（右行） 右行株距（前株）

xl/m ˆlx /m Exl y/m ˆy /m Ey d/m ˆd /m Ed xl/m ˆlx /m Exl y/m ˆy /m Ey d/m ˆd /m Ed

2.5 2.68 7.20%

20.78 20.92 0.67% 2.95 2.9 1.69% 4

2.5 2.54 1.60%

17.33 16.69 3.69% 1.87 1.76 5.88%

3 17.83 18.02 1.07% 4.58 5.21 13.76% 3 15.46 14.93 3.43% 2.73 2.5 8.42%

2 13.25 12.81 3.32% 2.75 2.28 17.09% 2 12.73 12.43 2.36% 3.93 3.33 15.27%

1 10.5 10.53 0.29% 1 8.8 9.1 3.41%

表5-5 实验点2 果树位置估计

横向位置（左行） 纵向位置（左行） 左行株距（前株）果树

横向位置（右行） 纵向位置（右行） 右行株距（前株）

xl/m ˆlx /m Exl y/m ˆy /m Ey d/m ˆd /m Ed xl/m ˆlx /m Exl y/m ˆy /m Ey d/m ˆd /m Ed

2.5 2.37 5.20%

18.64 18.26 2.04% 2.71 2.82 4.06% 5

2.5 2.67 6.80%

16.81 17.48 3.99% 3.61 3.89 7.76%

4 15.93 15.44 3.08% 2.95 2.53 14.24% 4 13.2 13.59 2.95% 1.87 1.83 2.14%

3 12.98 12.91 0.54% 4.58 4.6 0.44% 3 11.33 11.76 3.80% 2.73 2.46 9.89%

2 8.4 8.31 1.07% 2.75 2 8.6 9.3 8.14% 3.93

表5-6 实验点3 果树位置估计

横向位置（左行） 纵向位置（左行） 左行株距（前株）果树

横向位置（右行） 纵向位置（右行） 右行株距（前株）

xl/m ˆlx /m Exl y/m ˆy /m Ey d/m ˆd /m Ed xl/m ˆlx /m Exl y/m ˆy /m Ey d/m ˆd /m Ed

2.5 2.51 0.40%

17.04 16.51 3.11% 3.98 3.88 2.51% 7

2.5 2.46 1.60%

16.41 16.05 2.19% 1.51 1.37 9.27%

6 13.06 12.63 3.29% 2.71 2.62 3.32% 6 14.9 14.68 1.48% 3.69 3.56 3.52%

5 10.35 10.01 3.29% 2.95 2.41 18.31% 5 11.21 11.12 0.80% 3.61 3.3 8.59%

4 7.4 7.6 2.70% 4.58 4 7.6 7.82 2.89% 1.87

第五章 基于单目视觉的行间自主导航方法

由表5-4、表5-5、表5-6 可知，本文提出的果树相对位置估计方法，仅用单

目相机即可较准确地估计果树位置，对最近探测距离到20m 以内的果树均能有

效推测其位置，横向位置的平均误差为3.80%，纵向位置的平均误差为2.65%；

此外，利用果树的相对位置可进一步估计株距，其平均误差为8.12%。

实验结果表明：本文所提方法可用单目相机实现对周围果树的位置估计，横

向与纵向平均误差均小于5%，株距测量误差小于10%，具有较高的准确性和稳

定性，为进一步提高农业装备智能化提供扎实基础。

5.4 本章总结

本章主要内容为基于单目视觉的位姿估计与果树定位，就场景语义信息提取

问题，提出深度学习与图像处理融合的方法，基于Mask R-CNN（Res2Net50）

实例分割模型，提取可通行区域与果树树干掩码，基于寻找凸包和霍夫变换等图

像处理方法，确定消失点坐标与边界线方程，采用边界直线方程匹配的方法抑制

邻行果树坐标对导航的影响。通过利用果园半结构化特性，建立道路几何成像模

型，研究了偏航角、横向位移与图像关键的关系，由场景语义信息，可实现估计

偏航角、横向偏移、果树定位等。

实验结果表明：训练后模型的边框回归精确率与分割精确率分别为0.564 和

0.559。模型具有较强的抗干扰能力和较高的识别精度，能够稳定实现果树树干

与可通行区域的识别和像素级分割。在不同拍摄位置与拍摄角度下，所提方法可

稳定准确地计算消失点与边界线方程，具有较高的鲁棒性和适应性。本文所提方

法的偏航角误差为2.91%，横向偏移误差为4.82%，道路宽度误差为4.89%，果

树横向位置误差为3.80%，果树纵向位置误差为2.65%，在不同拍摄角度和位置，

仅用单目相机即可实现较准确地提取导航信息，具有较高的实用性、稳定性和准

第六章 结论与展望

第六章 结论与展望

6.1 主要结论

本文主要研究了基于激光雷达的导航方法和基于单目视觉的导航方法。

针对激光雷达导航方法，本文提出自适应半径滤波方法，基于深度神经网络

判定器和动态半径滤波实现多尺度噪声抑制；提出基于交叉像素的导航方法，利

用图像形态学处理和直线簇交叉像素数量，实现可通行区域提取与位姿估计。

实验结果表明：经自适应半径滤波去噪，DBSCAN 聚类的平均精确率和平

均召回率的提升40.4%和33.9%，表明该方法具有较强的噪声抑制能力。提出的

基于交叉像素的导航方法，对种植模式具有较高的鲁棒性，偏航角、横向偏移、

道路宽度等导航信息的误差均小于10%，为实现装备自主导航提供良好基础。

针对单目视觉导航方法，本文提出基于Mask R-CNN 的场景语义信息提取方

法，可准确提取不同位姿条件的消失点与道路边界；提出基于道路几何成像模型

的位姿估算方法，利用单目相机完成偏航角估计、横向偏移计算与果树定位。

实验结果表明：偏航角误差为2.91%，横向偏移误差为4.82%，道路宽度误

差为4.89%，果树横向位置误差为3.80%，果树纵向位置误差为2.65%，具有较

高的实用性、稳定性和准确性。

综上所述，本文所提出的方法可准确且稳定地提取导航信息，为自主导航技

术提供扎实的基础，也为实现农业装备智能化提供有效的理论支持。

6.2 研究展望

本研究利用图像处理、神经网络、相机成像等技术，一定程度实现了果园自

主导航技术，但仍存在诸多问题需进一步研究：

1、果园地图建立：地图是导航的基础，但果园图像数据相似性较高，基于特征

的视觉里程计局限性较大，如何有效提取果园特征是下一步研究方向。

2、场景语义信息挖掘：图像语义信息丰富，但缺乏三维信息，如何有效融合并

提取激光点云与图像的语义信息是下一步研究的重点。

3、高精度位姿估计方法：相机、陀螺仪、加速度计均可用于导航，如何高效且

高精度融合传感器是下一步研究的基础。

[1] 国家统计局. 中国统计年鉴[EB/OL]. 2020. http://www.stats.gov.cn/tjsj/ndsj/2

020/indexch.htm

[2] 曹爽, 岳建平, 马文. 基于特征选择的双边滤波点云去噪算法[J]. 东南大学

学报(自然科学版), 2013, 43(S2): 351-354.

[3] Gu X Y, Liu Y S, Wu Q. A filtering algorithm for scattered point cloud based on

curvature features classification[J]. Journal of Information and Computational

Science, 2015, 12(2): 525-532.

[4] 吴禄慎, 史皓良, 陈华伟. 基于特征信息分类的三维点数据去噪[J]. 光学精

密工程, 2016, 24(6): 1465-1473.

[5] 崔鑫, 闫秀天, 李世鹏. 保持特征的散乱点云数据去噪[J]. 光学精密工程, 20

17, 25(12): 3169-3178.

[6] Rosman G, Dubrovina A, Kimmel R. Patch-collaborative spectral surface

denoising[J]. Computer Graphics Forum, 2013, 32(8): 1-12.

[7] Fleishman S, Drori I, Cohen-or D. Bilateral mesh denoising[J]. ACM

Transactionson Graphics, 2003, 22(3): 950-953.

[8] 曾妮红, 岳迎春, 魏占营等. 车载LiDAR 点云滤波的改进不规则三角网加密

方法[J]. 测绘科学, 2016, 41(09): 136-139.

[9] 夏春华, 施滢, 尹文庆. 基于TOF 深度传感的植物三维点云数据获取与去噪

方法[J]. 农业工程学报, 2018, 34(6): 168-174.

[10] 陈世超, 戴华阳, 王成等. 激光扫描数据的密集噪声剔除方法[J]. 激光与电

子学进展, 2019, 56(6): 62801.

[11] Arvanitis G, Lalos A S, Moustakas K, et al. Outliers removal of highly dense and

unorganized point clouds acquired by laser scanners in urban environments[C].

2018 International Conference on Cyberworlds. 2018: 415-418.

[12] 薛金林, 张顺顺. 基于激光雷达的农业机器人导航控制研究[J/OL]. 农业机

械学报, 2014, 45(9): 55-60.

[13] Lemos R, Nogueira L, Ribeiro A M, et al. Unisensory intra-row navigation

strategy for orchards environments based on sensor laser[C]. Congresso

Brasileiro de Automática, Brazil, 2018.

[14] 艾长胜, 林洪川, 武德林, 等. 葡萄园植保机器人路径规划算法[J]. 农业工程

学报, 2018, 34(13): 77-85.

[15] 周俊, 胡晨. 密植果园作业机器人行间定位方法[J/OL]. 农业机械学报, 2015,

46(11): 22-28

[16] 关卓怀, 陈科尹, 丁幼春, 吴崇友, 廖庆喜. 水稻收获作业视觉导航路径提取

方法[J]. 农业机械学报, 2020, 51(01): 19-28.

[17] 张成涛, 谭彧, 吴刚, 等. 基于达芬奇平台的联合收获机视觉导航系统路径

识别[J/OL]. 农业机械学报, 2012, 43(增刊): 271-276.

[18] Radcliffe J, Cox J, Bulanon D M. Machine vision for orchard navigation[J].

Computers in Industry, 2018, 98: 165-171.

[19] Choi K H, Han S K, Han S H, et al. Morphology-based guidance line extraction

for an autonomous weeding robot in paddy fields[J]. Computers and Electronics

in Agriculture, 2015, 113: 266-274.

[20] Montalvo M, Pajares G, Guerrero J M, et al. Automatic detection of crop rows in

maize fields with high weeds pressure[J]. Expert Systems with Applications,

2012, 39(15): p.11889-11897.

[21] Sharifi M, Chen X Q. A novel vision based row guidance approach for navigation

of agricultural mobile robots in orchards[C]. 2015 6th International Conference

on Automation, Robotics and Applications (ICARA). IEEE, 2015: 251-255.

[22] 杨洋, 张亚兰, 苗伟, 等. 基于卷积神经网络的玉米根茎精确识别与定位研

究[J/OL]. 农业机械学报, 2018, 49(10): 46-53.

[23] 韩振浩, 李佳 ,苑严伟, 方宪法, 赵博, 朱立成. 基于U-Net 网络的果园视觉

导航路径识别方法[J/OL]. 农业机械学报: 1-12.

[24] 刘军, 后士浩, 张凯, 等. 基于单目视觉车辆姿态角估计和逆透视变换的车

距测量[J]. 农业工程学报, 2018,34(13): 70-76.

[25] 颜松, 姚立健, 曾松伟, 王露露, 柴善鹏. 基于位姿状态的林区道路视觉导航

[J]. 林业工程学报, 2021, 6(01): 163-170.

[26] Chen Y C, Su T F, Lai S H. Integrated vehicle and lane detection with distance

estimation[C]. Asian Conference on Computer Vision. Springer, Cham, 2014:

473-485.

[27] Cheein F A, Steiner G, Paina G P, et al. Optimized EIF-SLAM algorithm for

precision agriculture mapping based on stems detection[J]. Computers and

electronics in agriculture, 2011, 78(2): 195-207.

[28] Shalal N, Low T, Mccarthy C, et al. Orchard mapping and mobile robot

localisation using on-board camera and laser scanner data fusion–Part A: Tree

detection[J]. Computers and Electronics in Agriculture, 2015, 119: 254-266.

[29] Chen X, Zhang B, Luo L. Multi-feature fusion tree trunk detection and orchard

mobile robot localization using camera/ultrasonic sensors[J]. Computers and

Electronics in Agriculture, 2018, 147: 91-108.

[30] 刘慧, 朱晟辉, 沈跃, 汤金华. 基于多特征融合的树干快速分割算法[J]. 农业

机械学报, 2020, 51(01): 221-229.

[31] 李仁忠, 杨曼, 冉媛, 张缓缓, 景军锋, 李鹏飞. 基于方法库的点云去噪与精

简算法[J]. 激光与光电子学进展, 2018, 55(01): 251-257.

[32] 焦晨, 王宝锋, 易耀华. 点云数据滤波算法研究[J]. 国外电子测量技术, 2019,

38(11): 18-22.

[33] 鲁东东, 邹进贵. 三维激光点云的降噪算法对比研究[J]. 测绘通报, 2019, S2:

102-105.

[34] He K, Gkioxari G, Dollár P, et al. Mask R-CNN[C]. Proceedings of the IEEE

international conference on computer vision. 2017: 2961-2969.

[35] Gao S, Cheng M M, Zhao K, et al. Res2net: A new multi-scale backbone

architecture[J]. IEEE transactions on pattern analysis and machine intelligence,

[36] He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C].

Proceedings of the IEEE conference on computer vision and pattern recognition.

2016: 770-778.

[37] 韩栋斌, 徐友春, 王任栋, 等. 基于多对点云匹配的三维激光雷达外参数标

定[J]. 激光与光电子学进展, 2018, 55(2): 022803.

[38] 薛安荣, 鞠时光, 何伟华, 等. 局部离群点挖掘算法研究[J]. 计算机学报, 20

07, 30(8): 1455-1463.

[39] Sandler M, Howard A, Zhu M, et al. Mobilenetv2: Inverted residuals and linear

bottlenecks[C]. Proceedings of the IEEE conference on computer vision and

pattern recognition. 2018: 4510-4520.

[40] Chollet F. Xception: Deep learning with depthwise separable convolutions[C].

Proceedings of the IEEE conference on computer vision and pattern recognition.

2017: 1251-1258.

[41] Kingma D, Ba J. Adam: A Method for Stochastic Optimization[J]. Computer

Science, 2014.

[42] Moghadam P, Starzyk J A, Wijesoma W S. Fast vanishing-point detection in

unstructured environments[J]. IEEE Transactions on Image Processing, 2012,

21(1): 425-430.

[43] Kong H, Audibert J Y, Ponce J. Vanishing point detection for road detection[C].

IEEE International Conference on Computer Vision, 2009: 96-103.

[44] Nguyen L, Phung S L, Bouzerdoum A. Enhanced pixel-wise voting for image

vanishing point detection in road scenes[C]. 2017 IEEE International Conference

on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 1852-1856.

[45] Shi J, Wang J, Fu F. Fast and robust vanishing point detection for unstructured

road following[J]. IEEE Transactions on Intelligent Transportation Systems, 2016,

17(4): 970-979.

[46] 吕恩利, 林伟加, 刘妍华, 等. 基于B 样条曲线的智能叉车托盘拾取路径规

划研究[J/OL]. 农业机械学报, 2019, 50(5): 394-402.

[47] 王晓栋, 徐成 ,刘彦. 一种实时鲁棒的非结构化道路检测算法[J]. 计算机应

用研究, 2010, 27(7): 2763-2765, 2769.

[48] 王任栋, 章永进, 徐友春, 等. 基于稀疏地图坐标的智能车导航路径生成与

优化[J]. 军事交通学院学报, 2015, 17(6): 26-31.

在学期间的研究成果

在学期间的研究成果

一、发表论文

1.毕松, 王宇豪. 基于自适应半径滤波的激光点云去噪方法[J]. 农业机械学

报, 2021.02

2.毕松, 王宇豪. 果园机器人行间位姿估计与果树目标定位方法[J]. 农业机

械学报, 2021.05

逝者如斯，回想硕士三年和过去的岁月，深感幸运和幸福。

一为有幸与恩师毕松相遇。作为科研的引路人，不厌其烦地为我指点迷津，

提供研究思路。从课题的选择，到开题报告、中期答辩、期刊论文、毕业论文，

老师一直帮我指正文章中的问题，不辞辛苦地指导我书写科技论文。作为生活中

的大朋友，一起喝茶论道，品尝人间风味，既关心我们的研究进展，也不忘关怀

每个人的生活琐事。

二为有幸加入IFR 实验室。实验室的每个IFRer 都很值得我学习，感谢通晓

硬件电路、机械设计、嵌入式开发、视觉算法等技术的伙伴，协助搭建实验条件，

倾囊相授相关技术。感谢所有遇到的IFRer，你们就像生活中的小甜点，有你们

在身边，痛苦都不苦，难题都不难。

三为有幸遇贵人和自己。从呱呱坠地至今已近27 年，很幸运能走出属于自

己的人生轨迹，算不上亮丽，但独一无二。回顾过去，在诸多关键点遇到贵人支

持，也感谢自己，无论在弯路直路，顺境逆境，始终在路上前行。

一为亲人身心康健，从心底感谢父母27 年的养育恩。从小到大，一直支持

我喜欢的事情，即使把卧室改造成工具间、加工间、健身房等等，你们仍然鼓励

我坚持自己的想法，徘徊犹豫迷茫的时候，你们总在背后挺我。十分感谢姥姥、

姥爷、奶奶、爷爷对我无微不至的关怀，总是想尽各种方式照顾我。

二为伴侣心意相通，感谢一直对我学业、事业的支持。在科研繁忙的时候，

总能鼓励我前行，能一起谈心，也能畅聊人生，令我深感温暖。

三为挚友如手足，有无话不谈的老友，有一见如故的同窗，有驴友徒步百里，

有研友鼓励支持，有舍友深夜畅聊。

值此临近毕业之际，以此表达不尽的感恩之情！