(19)国家知识产权局

(12)发明专利

(10)授权公告号 (45)授权公告日

(21)申请号 202111541714.X

(22)申请日 2021.12.16

(65)同一申请的已公布的文献号

申请公布号 CN 114186568 A

(43)申请公布日 2022.03.15

(73)专利权人 北京邮电大学

地址 100876 北京市海淀区西土城路10号

(72)发明人 李睿凡 刘云 石祎晖 冯方向 马占宇 王小捷

(74)专利代理机构 北京挺立专利事务所(普通

合伙) 11265 专利代理师 叶盛 高福勇

(51)Int.Cl.

G06F 40/30(2020.01) G06N 3/04(2006.01)

G06N 3/08(2006.01)

审查员 周永传

(54)发明名称

一种基于关系编码和层次注意力机制的图 像段落描述方法 (57)摘要

本发明公开了一种基于关系编码和层次注 意力机制的图像段落描述方法，方法模型由关系 编码模块和层次注意解码模块组成。关系编码模 块通过两个编码器捕获编码空间关系信息和语 义关系信息，其中语义关系编码时通过训练有监 督的语义分类器来学习语义关系的先验知识。层 次注意解码模块的层次注意力使用带有关系门 和视觉门的层次注意力来动态的融合关系信息 和物体区域特征，关系门用于在空间关系信息和 语义关系信息之间切换，视觉门用于决定是否嵌 入使用视觉信息，模型采用从粗粒度区域到细粒 度的空间和语义关系的策略在段落生成过程中 融合视觉信息。通过在斯坦福段落描述数据集上 的大量实验表明，本发明方法在本领域的多个评 价指标上显著优于现有方法。

权利要求书3页 说明书10页 附图2页

CN 114186568 B 2022.08.02

CN 114186568 B

1.一种基于关系编码和层次注意力机制的图像段落描述方法，其特征在于，包括关系 编码过程和层次注意力解码过程；

在关系编码过程中，输入区域特征V、区域位置B和区域类别O，通过空间关系编码器和 语义关系编码器分别生成空间关系编码特征VP和语义关系编码特征Vs，在语义关系编码时， 从外部数据中收集语义物体关系对进行监督，通过训练有监督的语义关系分类器来学习语 义关系编码的先验知识；

在层次注意解码过程中，使用两个LSTM和一个层次注意力动态融合关系信息和物体区 域信息，层次注意力由具有关系门和视觉门的层次注意力组成，层次注意力分为一层区域 注意力和一层关系注意力，区域注意力负责在生成当前单词时关注一个显著的物体，关系 注意力由空间关系注意力和语义关系注意力组成，用于提取与被注意对象可能相关的关系 信息；

空间关系编码过程的步骤为： 首先，根据物体框的几何结构得到相对坐标信息嵌入特征表示；给定两个物体框，bi＝ {xi，yi，wi，hi}和bj＝{xj，yj，wj}，它们的几何关系表示为四维向量λ(i，j)，即：

然后，使用一个线性层将λ(i，j)投影到一个高维空间中，该高维空间嵌入了两个物体 框之间的相对坐标，如下式：

Eb(i，j)＝ReLU(Wbλ(i，j)+bb)

其中 和 是可学习的参数；

通过相对坐标编码，空间关系信息编码 由下式得到：

v′ k＝ReLU(Wpvk+bp)

其中， 和 是可学习的权重和偏差，v′ k是物体区域特征向量vk的低维

投影，可学习的非线性函数fp(·)在实践中设置为一个两层的MLP，MLP的第一层和第二层 设置相同，均具有一个ReLU激活函数、一个批量规范化和一个Dropout层；

语义关系编码过程的步骤为： 首先，两个物体oi和oj的Eo(i，j)的类别嵌入表示定义为： Eo(i，j)＝ReLU(WoConcat(Wgoi，Wgoj)+bo)

其中， 和 是可学习的权重和偏差， 是一个固定的物体类

别嵌入矩阵，该矩阵由GloVe向量初始化，在训练过程中保持不变；

然后，语义关系信息 如下列公式所示：

v″k＝ReLU(Wsvk+bs)

其中， 和 是可学习的权重和偏差；可学习的非线性函数fs(.)在实践

中设置为一个两层的MLP，MLP的第一层具有一个ReLU激活函数、一个批量规范化和一个 Dropout层，第二层只具有单独的线性投影层；

权 利 要 求 书 1/3 页

CN 114186568 B

语义关系分类器的步骤为： 首先，从Visual Genome数据集的视觉关系标注中收集语义关系三元组数据，两个物体

oi，oj以及他们的语义关系 表示为语义关系三元组(oi，oj，rij)；然后将编码为 的

语义关系输入一个线性层，以获得语义关系的类别分数，即：

其中 和 是可学习的权重和偏差；

层次注意力的步骤为： 首先，通过如下公式获得物体区域注意力向量ao：

αt＝Softmax(at)

其中， 和 是可学习的参数，αit表示每个对象特征vi 归一化注意权重；

然后，并行生成空间关系注意力向量ap和语义关系注意力向量as； 空间关系注意力向量ap生成方法为：在每一个时间步t中，通过采用空间注意力来生成 空间关系注意力向量ap：

ρt＝Softmax(pt)

其中， 和 是可学习的参数，ρkt表示空间关系特征

的归一化注意权重；公式中 是对应物体区域g的第k个空间关系特征，通过获取第一

层区域注意力对应物体的最大的注意权重αit来获得物体区域g；语义关系注意力向量as以 与空间关系注意力向量ap同样的方式得到；

代表Attention LSTM的输出；

关系门gr控制空间关系注意力向量ap和语义关系注意力向量as，如下式所示：

其中，三个可学习的权重Wrp、Wrh和Wrs属于 σ(·)表示sigmoid激活函数；

据此得到最终的关系注意力向量ar，该向量表示同时包含了空间关系信息和语义关系 信息，如下式所示：

ar＝ap ⊙gr+as ⊙(1‑gr) 其中⊙表示逐个元素相乘的运算符号； 得到关系注意力向量ar之后，将其输入一个线性层投影层，并将结果和物体区域注意力 向量ao相加并使用LayerNorm归一化，最终得到视觉上下文表示向量av，如下式所示：

av＝LayerNorm(ao+Wrar)

权 利 要 求 书 2/3 页

CN 114186568 B

其中， 是可学习的权重；

视觉门定义如下：

其中， 和 是可学习的权重， 是解码网

络在每个时间步t时对Attention LSTM的输入；

据此得到了注意向量a，如下式所示： a＝av ⊙gl+tanh(mt) ⊙(1‑gl) 其中，mt表示Attention LSTM的记忆单元在每个时间步t的输出；

最后通过将a与Attention LSTM的输出 拼接起来输入Language LSTM生成一个单词

yt，重复上述的过程直到生成结束符号为止，将生成的所有词拼接组成最终的段落即可。

2.根据权利要求1所述的基于关系编码和层次注意力机制的图像段落描述方法，其特 征在于，对于重叠物体对，空间关系编码器通过拼接其视觉特征和相对位置坐标嵌入表示 来获取空间关系编码的特征向量。

3.根据权利要求1所述的基于关系编码和层次注意力机制的图像段落描述方法，其特 征在于，语义关系分类使用了多标签分类。

权 利 要 求 书 3/3 页

CN 114186568 B

一种基于关系编码和层次注意力机制的图像段落描述方法

[0001] 本发明涉及图像处理技术领域，尤其涉及一种基于关系编码和层次注意力机制的 图像段落描述方法。

[0002] 图像描述是为给定图像自动生成一个描述性句子的任务，也叫做图像单句描述。 这项基本的跨模态任务可能有多种应用，如图像/视频检索、幼儿教育和帮助视力受损者理 解图像内容。因此，这项任务引起了人工智能界的极大关注。

[0003] 在过去的几年中，许多研究在生成一个句子的图像描述任务上取得了令人印象深 刻的进步。然而，由于一句话描述一幅图像的局限性，一句话对概括一幅图像中的各种细节 通常是不够的，因为“一图胜千言”。为了解决一句话描述图像的局限性，Li Fei‑Fei等人提 出了图像段落描述的任务。一般来说，图像段落描述任务的目标是生成一个连贯的、细粒度 的段落(通常包含四到六个句子)来描述给定的图像。

[0004] 以往关于图像段落描述的研究工作可分为两类：层次的方法和非层次的方法。层 次的方法通过显式推断生成句子主题，然后通过句子主题生成句子组成段落。近年以来，人 们提出了各种模型方法来改进图像段落描述任务，这些方法在很大程度上遵循编码器‑解 码器的框架。在最早期的工作中，Li Fei‑Fei等人提出了一种层次的循环神经网络 (Recurrent Neural Network,RNN)解码器来生成描述段落。该解码器由一个句子RNN和一 个单词RNN组成，句子RNN负责生成句子的主题，单词RNN则根据已经生成的主题生成由单词 组成的一句话，最后拼接所有的单词RNN生成的句子形成最终的描述段落。在之后的几年 中，许多研究都提出了对层次解码结构的改进。另一方面，一些研究如把段落描述作为一个 句子的词序列来进行生成段落，也实现了相似的性能和效果。

[0005] 然而，在以前的模型和方法中，图像中的单个物体通常由预训练的Faster R‑CNN 检测，之后表示为物体的区域特征。然后把图像中物体的区域特征输入后续的语言解码器 来隐式地学习这些物体之间的关系，最终生成段落描述。因此，物体之间的关系对于生成准 确、合理的描述非常有利，但这在之前的方法中没有得到充分的利用和编码。在图1中，给出 了一个示例来显示用于图像段落描述的物体之间的细粒度关系(包括空间和语义关系)。在 图中提到了多个物体，包括“beach”、 “kite”、 “water”、 “man”和“clouds”。并给出了这些物 体之间的空间关系(“kite‑above‑beach”和“kite‑in‑sky”)和语义关系(“man‑flying‑ kite”和“man‑standing on‑beach”)。直观地说，物体之间的关系(包括空间关系和语义关 系)可以丰富生成的段落描述的细节。

[0006] 在获得了物体间的关系信息之后，如何合理、有效的利用关系信息呢？一个简单的 解决方案是将关系信息与物体特征结合(通过拼接或者是相加的方式)起来，然后将其放入 语言解码器中，并以单层注意力的方式生成段落。然而，这种简单的融合方法存在着一个严 重的问题。那就是关系信息和物体信息的融合纠缠可能会在生成段落时分散语言解码器的 注意力，比如语言解码器需要去隐式地学习这些物体之间的关系。此外，这种简单的解决方

说 明 书 1/10 页

CN 114186568 B

案与人类的层次认知过程不一致。具体来说，当一个人描述一幅图像时，他/她首先会注意 到一个比较显著的物体，然后在描述这个物体时，他/她会进一步关注该物体与其他物体的 关系，再进行描述，然后重复这个过程直到描述完成。在图1中，以第一句描述“A man is standing on the beach.”为例；我们首先注意到图像中有一个人，然后进一步注意到他 “standing on”海滩上。这个例子表明，人类通过这种层次化的注意力机制，可以生成包含

详细信息(比如关系信息)的句子并形成一个信息丰富的段落。因此，需要一种新的用于显 式地利用更细粒度的空间和语义关系信息进行图像段落描述方法。

[0007] 本发明针对上述技术问题，提供一种基于关系编码和层次注意力机制的图像段落 描述方法。

[0008] 为了实现上述目的，本发明提供如下技术方案：

[0009] 一种基于关系编码和层次注意力机制的图像段落描述方法，包括关系编码过程和 层次注意力解码过程；

[0010] 关系编码过程输入区域特征V、区域位置B和区域类别o，通过空间关系编码器和语 义关系编码器分别生成空间关系编码特征VP和语义关系编码特征Vs，在语义关系编码时，从 外部数据中收集语义物体关系对进行监督，通过训练有监督的语义关系分类器来学习语义 关系编码的先验知识；

[0011] 层次注意力解码过程使用两个LSTM和一个层次注意力动态融合关系信息和物体 区域信息，层次注意力由具有关系门和视觉门的层次注意力组成，层次注意力分为一层区 域注意力和一层关系注意力，区域注意力负责在生成当前单词时关注一个显著的物体，关 系注意力由空间关系注意力和语义关系注意力组成，用于提取与被注意对象可能相关的关 系信息。

[0012] 进一步地，对于重叠物体对，空间关系编码器通过拼接其视觉特征和相对位置坐 标嵌入表示来获取空间关系编码的特征向量。

[0013] 进一步地，空间关系编码过程的步骤为：

[0014] 首先，根据物体框的几何结构得到相对坐标信息嵌入特征表示；给定两个物体框， bi＝{xi，yi，wi，hi}和bj＝{xj，yj，wj，hj}，它们的几何关系表示为四维向量λ(i，j)，即：

[0015]

[0016] 然后，使用一个线性层将λ(i，j)投影到一个高维空间中，该高维空间嵌入了两个 物体框之间的相对坐标，如下式：

[0017] Eb(i，j)＝ReLU(Wbλ(i，j)+bb)

[0018] 其中 和 是可学习的参数；

[0019] 通过相对坐标编码，空间关系信息编码 由下式得到：

[0020] v′ k＝ReLU(Wpvk+bp)

[0021]

说 明 书 2/10 页

CN 114186568 B

[0022] 其中， 和 是可学习的权重，v′ k是物体区域特征向量vk的低维投

影，可学习的非线性函数fp(·)在实践中设置为一个两层的MLP，MLP的第一层和第二层设 置相同，均具有一个ReLU激活函数、一个批量规范化和一个Dropout层。

[0023] 进一步地，语义关系编码过程的步骤为：

[0024] 首先，两个物体oi和oj的Eo(i，j)的类别嵌入表示定义为：

[0025] Eo(i，j)＝ReLU(WoConcat(Wgoi，Wgoj)+bo)

[0026] 其中， 和 是可学习的权重和偏差， 是一个固定的物

体类别嵌入矩阵，该矩阵由GloVE向量初始化，在训练过程中保持不变；

[0027] 然后，语义关系信息 如下列公式所示：

[0028] v″k＝ReLU(Wsvk+bs)

[0029]

[0030] 其中， 和 是可学习的权重和偏差；可学习的非线性函数fp(·)

在实践中设置为一个两层的MLP，MLP的第一层具有一个ReLU激活函数、一个批量规范化和 一个Dropout层，第二层只具有单独的线性投影层。

[0031] 进一步地，语义关系分类器的步骤为：首先，从Visual Genome数据集的视觉关系

标注中收集语义关系三元组数据，两个物体oi，oj以及他们的语义关系 表示为语义

关系三元组(oi，oj，rij)；然后将编码为 的语义关系输入一个线性层，以获得语义关系的

类别分数，即：

[0032]

[0033] 其中 和 是可学习的权重和偏差。

[0034] 进一步地，语义关系分类使用了多标签分类。

[0035] 进一步地，层次注意力的步骤为：

[0036] 首先，通过如下公式获得物体区域注意力ao：

[0037]

[0038] αt＝Softmax(at)

[0039]

[0040] 其中， 和 是可学习的参数，αit表示每个对象特

征vi归一化注意力注意权重；

[0041] 然后，并行生成空间关系上下文向量ap和语义关系上下文向量as。

[0042] 进一步地，空间关系上下文向量ap生成方法为：在每一个时间步t中，通过采用空 间注意力来生成空间关系注意力向量ap：

[0043]

说 明 书 3/10 页

CN 114186568 B

[0044] αt＝Softmax(at)

[0045]

[0046] 其中， 和 是可学习的参数，ait表示空间关系

特征 的归一化注意权重；公式中 是对应物体区域g的第i个空间关系特征，通过

获取第一层区域注意力对应物体的最大注意权重αit来获得物体区域g；语义关系注意力向 量as以与空间关系注意力向量ap同样的方式得到。

[0047] 进一步地，关系门gr控制空间关系注意力向量ap和语义关系注意力向量as，如下式 所示：

[0048]

[0049] 其中，三个可学习的权重Wrp、Wrh和Wrs属于 σ(·)表示sigmoid激活函数；

[0050] 据此得到最终的关系注意力向量ar，该向量表示同时包含了空间关系信息和语义 关系信息，如下式所示：

[0051] ar＝ap ⊙gr+as ⊙(1‑gr)

[0052] 其中⊙表示逐个元素相乘的运算符号；

[0053] 得到关系注意力向量ar之后，将其输入一个线性层投影层，并将结果和到物体区 域注意力向量ao相加并使用LayerNorm归一化，最终得到视觉上下文表示向量av，如下式所 示：

[0054] av＝LayerNorm(ao+Wr(ar))

[0055] 其中， 是可学习的权重。

[0056] 进一步地，视觉门定义如下：

[0057]

[0058] 其中， 和 是可学习的权重， 是解

码网络在每个时间步t时对Attention LSTM的输入；

[0059] 据此得到了注意向量a，如下式所示：

[0060] a＝av ⊙gl+tanh(mt) ⊙(1‑gl)

[0061] 其中，mt表示Attention LSTM的记忆单元在每个时间步t的输出；

[0062] 最后通过将a与Attention LSTM的输出 拼接起来输入Language LSTM生成一个

单词yt，重复上述的过程直到生成结束符号为止，将生成的所有词拼接组成最终的段落即 可。

[0063] 与现有技术相比，本发明的有益效果为：

[0064] 本发明提供的基于关系编码和层次注意力机制的图像段落描述方法(DualRel)， 是一种用于图像段落字幕的任务的新方法，DualRel模型的动机是有效地利用图像中存在 的细粒度的空间和语义关系。为此，DualRel模型由关系编码模块和层次注意解码模块组 成。关系编码模块通过两个编码器捕获图像中物体之间的空间关系信息和语义关系信息，

说 明 书 4/10 页

CN 114186568 B

利用细粒度的空间和语义关系信息，在编码过程中，语义关系编码时我们通过训练有监督 的语义分类器来学习和语义关系有关的先验知识。层次注意解码模块以Top‑Down注意力网 络为原型。层次注意力使用带有关系门和视觉门的层次注意力来动态的融合关系信息和物 体区域特征，我们设计的关系门用于在两种关系信息(空间关系信息和语义关系信息)之间 切换，设计的视觉门用于决定是否嵌入使用视觉信息，采用从粗粒度区域到细粒度的空间 和语义关系的策略在段落生成过程中融合视觉信息。通过在斯坦福段落描述数据集 (Stanford Benchmark Dataset)上的大量实验表明，本发明的方法在本领域的多个评价指 标上显著优于现有的方法。

[0065] 为了更清楚地说明本申请实施例或现有技术中的技术方案，下面将对实施例中所 需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明中记载的一 些实施例，对于本领域普通技术人员来讲，还可以根据这些附图获得其他的附图。

[0066] 图1为图像描述段落中的空间和语义关系展示，物体之间的空间关系如“kite‑ above‑beach”和语义关系如“man‑standing on‑beach；

[0067] 图2为本发明实施例提供的DualRel模型的架构图；

[0068] 图3为本发明实施例提供的关系编码模块的架构图，包含空间编码器，语义编码器 和语义关系分类器。

[0069] 图4为本发明实施例提供的层次注意力解码模块的架构图，包含区域注意力，两个 关系注意力和两个门控(关系门和视觉门)。

具体实施方式

[0070] 为了使本领域的技术人员更好地理解本发明的技术方案，下面将结合附图和实施 例对本发明作进一步的详细介绍。

[0071] 本发明的基于关系编码和层次注意力机制的图像段落描述方法(DualRel) ， DualRel模型详情如图2所示。我们的DualRel模型包含两个主要模块，一个关系编码模块和 一个层次注意力解码模块。关系编码模块输入区域特征V，区域位置B和区域类别O，通过空 间关系编码器和语义关系编码器分别生成空间关系编码特征VP和语义关系编码特征Vs，此 外为了监督模型学习到有关语义关系的先验知识，我们提出了一个新颖的语义关系分类损 失，该损失用于前期帮助模型学习到通用的先验语义关系信息。为了更好的利用学习到的 特征V，VP和Vs，让他们在解码过程中更好的交互融合，我们提出了一个层次注意力解码模 块，该模块通过使用层次注意力和门控机制来生成最终的段落P。接下来，我们将详细的介 绍关系编码模块和层次注意解码模块。

[0072] 对于图像段落描述来说，我们的目标是为任何给定的图像I生成一个段落P＝ {y1，…，yT}，其中T表示生成描述的长度。本文中图像特征使用预训练的Faster R‑CNN提取。 使用O＝{o1 ，…，o N}表示检测到的N个物体，检测到的物体个数取决于输入图像。让

作为它们的视觉特征表示，而B＝{b1，…，bN}，bi＝{xi，yi，wi，hi}∈R4

作为它们物体边界框。其中(x，y)表示物体框的中心坐标，(w，h)表示物体框的宽度和高度。

说 明 书 5/10 页

CN 114186568 B

此外，图像的全局表示 包含了总体的图像特征。

[0073] 关系编码模块概述如图3所示。

[0074] 空间关系编码器(Spatial Relation Encoder)：如前所述所述，为了生成详细的 段落描述，我们需要获取物体之间的空间关系信息(例如“above”和“on”)。我们观察到，许 多描述场景中物体的句子通常只包含附近物体的空间位置关系。因此，在本文中我们只考 虑一个物体与另一个物体重叠的情况来进行空间关系信息的编码。对于重叠物体对，我们 通过拼接其视觉特征和相对位置坐标嵌入表示来获取空间关系编码的特征向量。

[0075] 具体地，空间关系编码器的步骤为：

[0076] 首先，根据物体框的几何结构得到相对坐标信息嵌入特征表示；给定两个物体框， bi＝{xi，yi，wi，hi}和bj＝{xj，yj，wj，hj}，它们的几何关系表示为四维向量λ(i，j)，即：

[0077]

[0078] 然后，使用一个线性层将λ(i，j)投影到一个高维空间中，该高维空间嵌入了两个 物体框之间的相对坐标，如下式：

[0079] Eb(i，j)＝ReLU(Wbλ(i，j)+bb)

[0080] 其中 和 是可学习的参数；

[0081] 通过相对坐标编码，空间关系信息编码 由下式得到：

[0082] v′ k＝ReLU(Wpvk+bp)

[0083]

[0084] 其中， 和 是可学习的权重，v′ k是物体区域特征向量vk的低维投

影，可学习的非线性函数f p (·) 在实践中设置为一个两层的MLP (Multi‑la yer Perceptron)，MLP的第一层和第二层设置相同，均具有一个ReLU激活函数、一个批量规范化 和一个Dropout层。

[0085] 语义关系编码器(Semantic Relation Encoder)：语义关系编码器用于编码两个 物体之间另一种类型的关系信息(例如， “flying”和“eating”)，这对于生成描述至关重要。 如前文所述，与空间关系不同，语义关系需要一定的先验知识学习才能推断出来。并且我们 观察到，在对象类别和它们的语义关系之间存在着很强的相关性，比如“human”和“bike”之 间的关系大概率是“riding”或者“push”，而不会是“eating”或者“flying”这些关系，因此 在编码物体之间的语义关系时，我们会显式的加入两个物体的类别信息O。

[0086] 具体地，语义关系编码过程的步骤为：

[0087] 首先，两个物体oi和oj的Eo(i，j)的类别嵌入表示定义为：

[0088] Eo(i，j)＝ReLU(WoConcat(Wgoi，Wgoj)+bo)

[0089] 其中， 和 是可学习的权重和偏差， 是一个固定的物

体类别嵌入矩阵，该矩阵由GloVE向量初始化，在训练过程中保持不变；

[0090] 然后，语义关系信息 如下列公式所示：

说 明 书 6/10 页

CN 114186568 B

[0091] v″k＝ReLU(Wsvk+bs)

[0092]

[0093] 其中， 和 是可学习的权重和偏差；可学习的非线性函数fp(·)

在实践中设置为一个两层的MLP，MLP的第一层具有一个ReLU激活函数、一个批量规范化和 一个Dropout层，第二层只具有单独的线性投影层。

[0094] 语义关系分类器(Semantic Relation Classifier)：对于语义关系编码器来说， 直接从段落标注中直接学习语义关系是困难的，因为语义关系学习需要大量的先验知识监 督，而段落的解码生成过程距离语义关系编码器太远，可能无法在模型早期训练时实现有 效的学习。

[0095] 因此我们设计了一个语义关系分类器，利用先验知识对语义关系编码器进行显式 监督。

[0096] 具体地，语义关系分类器的步骤为：首先，从Visual Genome数据集的视觉关系标

注中收集语义关系三元组数据，两个物体oi，oj以及他们的语义关系 表示为语义关

系三元组(oi，oj，rij)；然后将编码为 的语义关系输入一个线性层，以获得语义关系的类

别分数，即：

[0097]

[0098] 其中 和 是可学习的权重和偏差。

[0099] 值得注意的是语义关系分类使用了多标签分类任务，因为两个物体之间可能存在 多个关系，因为我们没有真实的两个物体之间关系的标注。

[0100] 层次注意力解码模块(Hierarchical Attention Decoding Module)：如前文所 述，我们在关系编码模块中提取了空间关系特征VP和语义关系特征VS，并提取对象区域特 征V。为了融合这三个特征，生成包含更多关系的段落。基于人类层次的认知过程，我们提出 了层次注意解码模块。具体来说，当人类描述一个图像时，我们首先会观察并注意到一个显 著的物体，然后在描述这个物体的过程中，我们会进一步关注这个物体与其他物体之间的 关系信息(包括空间和语义关系信息)，从而生成一个信息性和描述性的段落。层次注意力 解码模块如图4所示。我们的解码模块基于Top‑Down注意力网络设计。我们设计了具有关系 门和视觉门的空间和语义关系注意力的层次注意力模块来替换原模型的注意力模块。接下 来我们将详细描述我们设计的层次注意力和门控机制的详细情况。

[0101] 层次注意力(Hierarchical Attention) ：Top‑Down注意力网络包括一个 Attention LSTM、一个Language LSTM和一个注意力模块。在生成段落期间的每个时间步t 时，可将其形式化为：

[0102]

[0103]

[0104]

[0105] 其中， 是Attention LSTM的输出， 是词汇表的词嵌入矩阵，yt‑1

说 明 书 7/10 页

CN 114186568 B

是输入单词在每个时间步时间t的一个独热编码。 是注意力向量， 是

Language LSTM的输出。

[0106] 具体地，层次注意力的步骤为：

[0107] 首先，通过如下公式获得物体区域注意力ao：

[0108]

[0109] αt＝Softmax(at)

[0110]

[0111] 其中， 和 是可学习的参数，αit表示每个对象特

征vi归一化注意力注意权重；

[0112] 然后，并行生成空间关系上下文向量ap和语义关系上下文向量as。

[0113] 空间关系上下文向量ap生成方法为：在每一个时间步t中，通过采用空间注意力来 生成空间关系注意力向量ap：

[0114]

[0115] αt＝Softmax(at)

[0116]

[0117] 其中， 和 是可学习的参数，αit表示空间关系

特征 的归一化注意权重；公式中 是对应物体区域g的第i个空间关系特征，通过

获取第一层区域注意力对应物体的最大注意权重αit来获得物体区域g；以同样的方式，我们 可以得到语义关系注意力向量as。

[0118] 关系门(Relational Gate)：在前文中我们通过层次的注意力机制获取了空间关 系注意力向量ap和语义关系注意力向量as。为了控制这两类关系信息在解码过程中如何融 合使用，我们设计了一个关系门gr来控制两种信息如何使用，具体地：

[0119] 关系门gr控制空间关系注意力向量ap和语义关系注意力向量as，如下式所示：

[0120]

[0121] 其中，三个可学习的权重Wrp、Wrh和Wrs属于 σ(·)表示sigmoid激活函数；

[0122] 据此得到最终的关系注意力向量ar，该向量表示同时包含了空间关系信息和语义 关系信息，如下式所示：

[0123] ar＝ap ⊙gr+as ⊙(1‑gr)

[0124] 其中⊙表示逐个元素相乘的运算符号；

[0125] 得到关系注意力向量ar之后，将其输入一个线性层投影层，并将结果和到物体区 域注意力向量ao相加并使用LayerNorm归一化，最终得到视觉上下文表示向量av，如下式所 示：

说 明 书 8/10 页

CN 114186568 B

[0126] av＝LayerNorm(ao+Wr(ar))

[0127] 其中， 是可学习的权重。

[0128] 视觉门(Visual Gate)：我们定义了一个视觉门来决定在解码时使用视觉信息还 是使用语言上下文信息。直观来说，解码器在生成一些词的时比如“the”和“is”，可能只需 要需要很少的视觉信息来生成这些单词。视觉门定义如下：

[0129]

[0130] 其中， 和 是可学习的权重， 是解

码网络在每个时间步t时对Attention LSTM的输入；

[0131] 据此得到了注意向量a，如下式所示：

[0132] a＝av ⊙gl+tanh(mt) ⊙(1‑gl)

[0133] 其中，mt表示Attention LSTM的记忆单元在每个时间步t的输出；

[0134] 最后通过将a与Attention LSTM的输出 拼接起来输入Language LSTM生成一个

单词yt，重复上述的过程直到生成结束符号为止，将生成的所有词拼接组成最终的段落即 可。

[0135] 此外，关于随时函数(Loss Function)的说明如下：

[0136] 语义关系分类损失(Semantic Relation Classification Loss)：语义关系分类 损失的目的是鼓励模型利用先验知识学习语义关系编码。我们应用了多标签分类损失函 数，即：

[0137]

[0138] 其中 是语义关系分类器输出的某一个语义关系的类别分数。集合Ωneg表示两个

物体oi和oj没有特定的某一类语义关系t(即 )，集合Ωpos表示两个对象具有某一类特定

的语义关系。

[0139] 词级损失(Word‑level Loss)：给定一幅图像和真实标注的段落对(I，P)，我们通 过最大化和真实标注段落P的相似性来训练DualRel模型，这等价于最小化交叉熵(XE)损 失：

[0140]

[0141] 总体损失(Total Loss)：最终损失函数定义为语义关系分类损失和词级损失的线 性组合。具体而言，总体损失L定义如下：

[0142] L＝ζLR+ηLXE [0143] 其中ζ和η是不同损失的权重。该权重通过实验确定，在模型实现细节里我们会进 一步介绍这两个权重的取值。

[0144] SCST(Self‑critical Sequence Training)：为了提升模型的效果，我们进一步使 用自我批评序列训练(SCST)的方式优化了我们的模型。指标的期望梯度计算如下：

说 明 书 9/10 页

CN 114186568 B

[0145]

[0146] 其中，ws和wg分别表示依据概率采样的段落和贪婪地采样段落。r(·)表示来自段 落评价指标的奖励，pθ表示DualRel模型的参数。此外，我们采用了两种类型的奖励的SCST 训练模型。其中一种是只使用CIDEr，这用于公平比较。另一种是CIDEr,METEOR和BLEU‑4三 种指标的混合训练模型。

[0147] 综上，我们提出了一个新颖的名为DualRel的新模型，用于显式地利用更细粒度的 空间和语义关系信息进行图像段落描述。

[0148] 首先，我们设计了一个关系编码模块，由空间关系编码器和语义关系编码器两个 部分组成。空间关系编码器强调重叠物体之间的空间位置关系的编码。而语义关系编码器 则用于编码物体之间的语义关系信息。为了有效地学习语义关系相关的先验知识，我们提 出使用从外部数据中收集语义物体关系对，然后构造语义关系分类器来显式的监督模型学 习语义关系的先验知识。

[0149] 其次，我们设计了一个层次注意解码模块，该模块使用两个LSTM和一个层次注意 力动态融合关系信息和物体区域信息。层次注意力分为一层区域注意力和一层关系注意 力，区域注意力负责在生成当前单词时关注一个显著的物体。关系注意力由空间关系注意 力和语义关系注意力组成，用于提取与被注意对象可能相关的关系信息。

[0150] 此外，关系门控制所需的关系信息类型(语义关系还是空间关系信息)。视觉门决 定输出特征是依赖于视觉信息还是语言上下文信息。

[0151] 我们的主要贡献如下：

[0152] 1、我们提出了DualRel模型用于图像段落描述，该模型由关系编码模块和层次注 意解码模块组成。关系编码模块通过两个编码器编码空间和语义关系信息。在编码过程中， 语义关系编码时我们通过训练有监督的语义分类器来学习和语义关系有关的先验知识。

[0153] 2、我们设计了一个层次化的注意力解码模块来动态地融合利用细粒度的关系信 息和物体区域信息。层次注意力由具有关系门和视觉门的层次注意力组成。

[0154] 3、我们在斯坦福段落描述数据集(Stanford Benchmark Dataset)上进行了广泛 的实验。我们采用了七种流行的评估指标，包括BLEU‑1，BLEU‑2，BLEU‑3，BLEU‑4，METEOR和 CIDEr以及BERTScore的F值指标。我们的模型在BLEU‑1，BLEU‑2，BLEU‑3，BLEU‑4上分别实现 了45 .30，28.91，18.46，11 .30的分数，在CIDEr值上实现了34 .02的分数，达到了84 .37的 FBERT(idf)BERTScore分数，现有基础方法的BLEU‑1，BLEU‑2，BLEU‑3，BLEU‑4，CIDEr和FBERT

(idf)分数分别为43.54，27.44，17.33，10.58，30.64和83.85，这些实验结果表明，我们提出 的DualRel在本领域的多个评价指标上显著优于现有的方法，并且具有实用性和创新性。

[0155] 以上实施例仅用以说明本发明的技术方案，而非对其限制；尽管参照前述实施例 对本发明进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施 例所记载的技术方案进行修改，或者对其中部分技术特征进行等同替换，但这些修改或者 替换，并不使相应技术方案的本质脱离本发明各实施例技术方案的精神和范围。

说 明 书 10/10 页

CN 114186568 B

说 明 书 附 图 1/2 页

CN 114186568 B

说 明 书 附 图 2/2 页

CN 114186568 B