(19)国家知识产权局

(12)发明专利

(10)授权公告号 (45)授权公告日

(21)申请号 202110266563.5

(22)申请日 2021.03.11

(65)同一申请的已公布的文献号

申请公布号 CN 112990302 A

(43)申请公布日 2021.06.18

(73)专利权人 北京邮电大学

地址 100876 北京市海淀区西土城路10号

(72)发明人 冯方向 牛天睿 王小捷 李睿凡 袁彩霞

(74)专利代理机构 北京德琦知识产权代理有限

公司 11018 专利代理师 孙清然 王琦

(51)Int.Cl.

G06V 10/774(2022.01) G06V 10/74(2022.01)

G06N 20/00(2019.01) G06T 11/00(2006.01)

审查员 马丽莉

(54)发明名称

基于文本生成图像的模型训练方法、设备和 图像生成方法

(57)摘要

本申请公开了一种基于文本生成图像的模 型训练方法、设备和图像生成方法，其中方法包 括基于预设训练样本集合中各训练样本的文本 信息，生成文本嵌入式表示，将所述文本嵌入式 表示输入至图像生成模型，触发图像生成模型基 于该文本嵌入式表示，生成人造图像，并采用模 态解纠缠方式，提取人造图像的真实度参数和相 应训练样本的真实图像的真实度参数；基于所述 人造图像，确定所述训练样本的正例和负例；利 用所述图像生成模型，基于每个训练样本的正 例、负例和真实图像各自对应的所述真实度参 数，计算总体损失函数；利用所述总体损失函数， 调整所述图像生成模型的参数。采用本申请可以 提高模型学习效率和图像生成效果。

权利要求书3页 说明书7页 附图1页

CN 112990302 B 2023.03.21

CN 112990302 B

1.一种基于文本生成图像的模型训练方法，其特征在于，包括： 对于预设训练样本集合中的每个训练样本，基于该训练样本的文本信息，生成相应的 文本嵌入式表示，并将所述文本嵌入式表示输入至图像生成模型，触发所述图像生成模型 基于所述文本嵌入式表示，生成所述文本信息对应的人造图像，并采用模态解纠缠方式，提 取所述人造图像的真实度参数和相应训练样本的真实图像的真实度参数；所述真实度参数 包括：图像风格的视觉可信度、图‑文相似度和图像的整体视觉可信度；

基于所述人造图像，确定所述训练样本的正例和负例； 利用所述图像生成模型，基于所述训练样本的正例、负例和真实图像各自对应的所述 真实度参数，计算相应样本的子损失函数，并基于所述子损失函数，计算相应样本的总体损 失函数；所述子损失函数包括内容损失函数、风格损失函数、生成器损失函数和判别器损失 函数；所述总体损失函数包括判别器总体损失函数和生成器总体损失函数；

利用所述总体损失函数，调整所述图像生成模型的参数； 其中，所述采用模态解纠缠方式，提取所述人造图像的真实度参数和相应训练样本的 真实图像的真实度参数包括：

利用所述图像生成模型的图像编码器，从所述人造图像中提取出模态公共表征和模态 特定表征，以及从所述训练样本的真实图像中提取出模态公共表征和模态特定表征；

基于所述人造图像的模态公共表征和模态特定表征、所述真实图像的模态公共表征和 模态特定表征，利用所述图像生成模型的判别器，提取所述人造图像和所述真实图像的真 实度参数。

2.根据权利要求1所述的方法，其特征在于，所述生成所述文本信息对应的人造图像包 括：

将所述文本嵌入式表示，输入至图像生成模型的文本编码器处理，得到所述文本信息 的文本特征；

将所述文本特征和训练样本对应的预设噪声样本，输入至所述图像生成模型的生成器 处理，得到所述文本信息对应的人造图像。

3.根据权利要求1所述的方法，其特征在于，所述真实度参数的提取包括：

按照 提取所述人造图像的图像风格的视觉可信度；其中，hss为所述人

造图像的模态特定表征；Ds为所述图像生成模型的模态特定判别器； 表示所述人造图

像的图像风格的视觉可信度；

按照ss(x)＝Ds(his)，提取所述真实图像的图像风格的视觉可信度；其中，his为所述真 实图像的模态特定表征；ss(x)表示所述真实图像的图像风格的视觉可信度；

按照 提取所述人造图像的图‑文相似度；其中，htc为所述文本信息的

文本特征；hsc为所述人造图像的模态公共表征；Dc为所述图像生成模型的模态公共判别器；

表示所述人造图像的图‑文相似度；

按照sc(x)＝Dc(htc，hic)，提取所述真实图像的图‑文相似度；其中，hic为所述真实图像 的模态公共表征；sc(x)表示所述真实图像的图‑文相似度；

按照 提取所述人造图像的整体视觉可信度；其中，Di为所述图像生成

权 利 要 求 书 1/3 页

CN 112990302 B

模型的整体视觉判别器； 表示所述人造图像的整体视觉可信度；

按照si(x)＝Di(hic，his)，提取所述真实图像的整体视觉可信度；其中，si(x)表示所述真 实图像的整体视觉可信度。

4.根据权利要求1所述的方法，其特征在于，所述确定每个所述训练样本的正例和负例 包括：

对于每个所述训练样本，将该训练样本对应的所述人造图像作为该训练样本的正例， 从基于非该训练样本对应的所述人造图像中，选择一个图像作为该训练样本的负例。

5.根据权利要求1所述的方法，其特征在于，所述计算相应样本的子损失函数包括：

按照 计算所述内容损失函数值 其中， 表示三元组损失函

数，htc为锚点，表示训练样本的文本信息的文本特征；hsc为正例，表示训练样本对应的人造

图像的模态公共表征；为负例，表示训练样本的负例的模态公共表征；

按照 计算所述风格损失函数 其中，z为噪声样本；hss表示训练样本对

应的人造图像的模态特定表征；ρ为预设的皮尔逊相关系数；

按照 计算所述生成器

损失函数 其中， 表示从生成器PG中采样得到的训练样本对应的人造图像

表示人造图像的图‑文相似度； 表示人造图像的图像风格的视觉可信度；

表示人造图像的整体视觉可信度；

按照 计算所述判别器损失函数

其中， 表示从训练样本集合pdata中得到的训练样本的真实图像x；ss(x)表示真实

图像x的图像风格的视觉可信度；sc(x)表示真实图像x的图‑文相似度；si(x)表示真实图像x 的整体视觉可信度。

6.根据权利要求1所述的方法，其特征在于，所述基于所述子损失函数，计算相应样本 的总体损失函数包括：

按照 得到所述判别器总体损失函数 其中，为所述判别器

损失函数；为所述内容损失函数；为所述风格损失函数；

按照 得到所述生成器总体损失函数 其中，为所述生成器损失

7.一种基于文本生成图像的方法，其特征在于，包括： 基于待生成图像的文本信息，生成相应的文本嵌入式表示； 将所述文本嵌入式表示输入至预训练的图像生成模型处理，得到所述文本信息的人造 图像；其中，所述图像生成模型采用权利要求1至6所述的任一模型训练方法训练得到。

8.一种基于文本生成图像的模型训练设备，其特征在于，包括处理器和存储器；

权 利 要 求 书 2/3 页

CN 112990302 B

所述存储器中存储有可被所述处理器执行的应用程序，用于使得所述处理器执行如权 利要求1至6中任一项所述的基于文本生成图像的模型训练方法。

9.一种计算机可读存储介质，其特征在于，其中存储有计算机可读指令，该计算机可读 指令用于执行如权利要求1至6中任一项所述的基于文本生成图像的模型训练方法。

权 利 要 求 书 3/3 页

CN 112990302 B

基于文本生成图像的模型训练方法、设备和图像生成方法

[0001] 本发明涉及人工智能技术，特别是涉及一种基于文本生成图像的模型训练方法、 设备和图像生成方法。

[0002] 图像的创作是一项复杂而重要的工作，它需要专业的绘图与美术知识。因此，面对 广泛的需求，机器辅助的图像创作已成为近期的热点，希望机器帮助人用更少的专业知识、 更简便快捷的方法创作出所需要的图像。对于无绘画经验者而言，通过语言交互来控制机 器绘制图像是最简单自然的方法。这样，就需要机器能够理解并利用人类语言中语义信息， 以生成相应的图像。为满足该需求，产生了基于文本生成图像的技术。这类技术需要完成两 个基本目标：可信度(fidelity)与一致性(consistency)，可信度是指产生的人造图像要与 真实图像相似，即看起来逼真；一致性则是指产生的图像能够反映出文本输入信息。

[0003] 发明人在实现本发明的过程中发现现有基于文本生成图像的方案中存在模型学 习效率低、效果差等问题。具体原因分析如下：

[0004] 由于文本信息无法覆盖图像的所有细节信息，在基于文本生成图像的方案中，对 于文本信息中没有限定的图像细节特征，需要随机产生。这样，在基于文本生成图像的场景 下，图像信息包括两部分，一部分是模态公共部分与模态特定部分。其中，模态公共部分与 文本信息相对应，反映了图像的内容，模态特定部分则是随机产生的，处于不受控制的半随 机状态，与图像的内容无关，反映了图像的风格。现有方案在训练图像生成模型时，基于包 含模态特定部分的图像特征确定损失函数值。而图文一致性仅与图像的模态公共部分有 关，与图像的模态特定部分无关，模态特定部分的存在引入了随机噪声，会干扰模型的学 习，从而会导致模型学习效率低、效果差。另外，由于模态特定部分反映了图像风格，该部分 不是文本限定的，具有随机性，因此，采用现有基于文本生成图像的方案时，仅能通过改变 文本条件来改变所生成图像的内容，而无法有效控制图像的风格，从而导致无法有效控制 图像的风格，进而降低了实用性。

[0005] 有鉴于此，本发明的主要目的在于提供一种基于文本生成图像的模型训练方法、 设备和图像生成方法，可以提高模型学习效率和图像生成效果。

[0006] 为了达到上述目的，本发明提出的技术方案为：

[0007] 一种基于文本生成图像的模型训练方法，包括：

[0008] 对于预设训练样本集合中的每个训练样本，基于该训练样本的文本信息，生成相 应的文本嵌入式表示，并将所述文本嵌入式表示输入至图像生成模型，触发所述图像生成 模型基于所述文本嵌入式表示，生成所述文本信息对应的人造图像，并采用模态解纠缠方 式，提取所述人造图像的真实度参数和相应训练样本的真实图像的真实度参数；所述真实 度参数包括：图像风格的视觉可信度、图‑文相似度和图像的整体视觉可信度；

说 明 书 1/7 页

CN 112990302 B

[0009] 基于所述人造图像，确定每个所述训练样本的正例和负例；

[0010] 利用所述图像生成模型，基于每个所述训练样本的正例、负例和真实图像各自对 应的所述真实度参数，计算相应样本的子损失函数，并基于所述子损失函数，计算相应样本 的总体损失函数；所述子损失函数包括内容损失函数、风格损失函数、生成器损失函数和判 别器损失函数；所述总体损失函数包括判别器总体损失函数和生成器总体损失函数；

[0011] 利用所述总体损失函数，调整所述图像生成模型的参数。

[0012] 基于上述模型训练方法实施例，本发明实施例还公开了一种基于文本生成图像的 方法，包括：

[0013] 基于待生成图像的文本信息，生成相应的文本嵌入式表示；

[0014] 将所述文本嵌入式表示输入至预训练的图像生成模型处理，得到所述文本信息的 人造图像；其中，所述图像生成模型采用如上所述的基于文本生成图像的模型训练方法训 练得到。

[0015] 基于上述模型训练方法实施例，本发明实施例还公开了一种基于文本生成图像的 模型训练设备，包括处理器和存储器；

[0016] 所述存储器中存储有可被所述处理器执行的应用程序，用于使得所述处理器执行 如上所述的基于文本生成图像的模型训练方法。

[0017] 基于上述模型训练方法实施例，本发明实施例还公开了一种计算机可读存储介 质，其特征在于，其中存储有计算机可读指令，该计算机可读指令用于执行如上所述的基于 文本生成图像的模型训练方法。

[0018] 由上述技术方案可见，本发明实施例提出的基于文本生成图像的模型训练方法、 设备和图像生成方法，在生成人造图像后，采用模态解纠缠方式，提取人造图像和相应真实 图像各自的真实度参数。如此，通过模态解纠缠，可以将模态特定部分从人造图像中抽离， 从而使得在提取人造图像的真实度参数时，一方面可以仅基于模态公共部分提取图‑文相 似度，有效避免了与图像内容无关的模态特定部分对图‑文相似度的影响，进而可以提高模 型学习效率和图像生成效果，另一方面可以单独基于模态特定部分提取出图像风格的视觉 可信度，实现对所生成的图像风格的有效控制，进而增加了实用性。

[0019] 图1为本发明实施例的模型训练方法流程示意图；

[0020] 图2为本发明实施例的基于文本生成图像的方法流程示意图。

具体实施方式

[0021] 为使本发明的目的、技术方案和优点更加清楚，下面将结合附图及具体实施例对 本发明作进一步地详细描述。

[0022] 图1为本发明实施例的基于文本生成图像的模型训练方法流程示意图，如图1所 示，该实施例实现的模型训练方法主要包括下述步骤：

[0023] 步骤101、对于预设训练样本集合中的每个训练样本，基于该训练样本的文本信 息，生成相应的文本嵌入式表示，并将所述文本嵌入式表示输入至图像生成模型，触发所述 图像生成模型基于所述文本嵌入式表示，生成所述文本信息对应的人造图像，并采用模态

说 明 书 2/7 页

CN 112990302 B

解纠缠方式，提取所述人造图像的真实度参数和相应训练样本的真实图像的真实度参数。

[0024] 其中，所述真实度参数包括：图像风格的视觉可信度、图‑文相似度和图像的整体 视觉可信度。

[0025] 本步骤中，在基于训练样本的文本信息生成人造图像后，需要采用模态解纠缠方 式，提取该人造图像和相应样本的真实图像各自的上述真实度参数。这里，通过模态解纠 缠，可以将模态特定部分从人造图像中抽离，如此，在提取人造图像的真实度参数时，一方 面可以仅基于模态公共部分提取图‑文相似度，从而避免模态特定部分对图‑文相似度的影 响，从而可以提高模型学习效率和图像生成效果，另一方面又可以单独基于模态特定部分 提取出图像风格的视觉可信度，从而可以有效控制图像风格，增加模型的实用性。

[0026] 对于所述文本嵌入式表示，本领域技术可以采用现有方法基于文本信息得到，例 如，可以利用预训练的深层注意力多模态一致性模型提取得到文本信息的文本嵌入式表 示，但不限于此。

[0027] 在一种实施方式中，具体可以采用下述方法生成所述文本信息对应的人造图像：

[0028] 步骤a1、将所述文本嵌入式表示，输入至图像生成模型的文本编码器处理，得到所 述文本信息的文本特征。

[0029] 具体的，上述文本编码器可以为单层全连接神经网络，但不限于此。

[0030] 本步骤所得到的文本特征htc，即文本的模态公共部分表征。

[0031] 步骤a2、将所述文本特征和训练样本对应的预设噪声样本，输入至所述图像生成 模型的生成器处理，得到所述文本信息对应的人造图像。

[0032] 在一种实施方式中，所述生成器可以由若干个采样与残差层构成，它以步骤a1得 到的文本特征htc与预设的噪声样本z为输入，并产生图像 即人造图像。本步骤生成器对应 的处理公式如下：

[0033] h＝F(htc,z)

[0034]

[0035] 在一种实施方式中，步骤101具体可以采用下述方法提取所述人造图像的真实度 参数和相应训练样本的真实图像的真实度参数：

[0036] 步骤b1、利用所述图像生成模型的图像编码器，从所述人造图像中提取出模态公 共表征和模态特定表征，以及从所述训练样本的真实图像中提取出模态公共表征和模态特 定表征。

[0037] 本步骤中，图像编码器EI以人造图像或者真实图像x为输入，并提取模态解纠缠 的图像特征：

[0038]

[0039] (hic,his)＝EI(x)

[0040] 上式中，hsc与hss分别代表人造图像的模态公共表征与模态特定表征；hic与his分别 代表真实图像的模态公共表征与模态特定表征。

[0041] 步骤b2、基于所述人造图像的模态公共表征和模态特定表征、所述真实图像的模 态公共表征和模态特定表征，利用所述图像生成模型的判别器，提取所述人造图像和所述 真实图像的真实度参数。

[0042] 具体地，与上述三种真实度参数相对应，图像生成模型的判别器将包括三部分，即

说 明 书 3/7 页

CN 112990302 B

模态特定判别器、模态公共判别器和整体视觉可信度。

[0043] 在一种实施方式中，具体可以采用下述方法对上述真实度参数进行提取：

[0044] 按照 提取所述人造图像的图像风格的视觉可信度；其中，hss为所

述人造图像的模态特定表征；Ds为所述图像生成模型的模态特定判别器； 表示所述人 造图像的图像风格的视觉可信度。

[0045] 按照ss(x＝Ds(his)，提取所述真实图像的图像风格的视觉可信度；其中，his为所述 真实图像的模态特定表征；ss(x)表示所述真实图像的图像风格的视觉可信度。

[0046] 按照 提取所述人造图像的图‑文相似度；其中，htc为所述文本信

息的文本特征；hsc为所述人造图像的模态公共表征；Dc为所述图像生成模型的模态公共判

别器； 表示所述人造图像的图‑文相似度。

[0047] 按照sc(x＝Dc(htc,hic)，提取所述真实图像的图‑文相似度；其中，hic为所述真实图 像的模态公共表征；sc(x)表示所述真实图像的图‑文相似度。

[0048] 按照 提取所述人造图像的整体视觉可信度；其中，Di为所述图像

生成模型的整体视觉判别器； 表示所述人造图像的整体视觉可信度。

[0049] 按照si(x)＝Di(hic,his)，提取所述真实图像的整体视觉可信度；其中，si(x)表示 所述真实图像的整体视觉可信度。

[0050] 在上述方法中，考虑到图像风格的视觉可信度ss只与图像的特定部分表征有关， 因此，仅以图像特定部分表征hss与his为输入；图‑文相似度sc仅与图像、文本的模态公共部 分表征有关，因此，仅以htc、hsc与htc,hic为输入；整体视觉可信度si与模态公共部分表征、特 定部分表征均相关，因此，需要同时以二者为输入。

[0051] 步骤102、基于所述人造图像，确定所述训练样本的正例和负例。

[0052] 本步骤中，将基于训练样本集合得到的所有人造图像，确定集合中每个训练样本 的正例和负例，以便在后续步骤中基于各样本的正例和负例的真实度参数进一步计算各训 练样本对应的损失函数。

[0053] 对于一个训练样本i而言，正例是基于训练样本i生成的人造图像，负例，是基于训 练样本集合中除练样本i之外的其他训练样本生成的人造图像。

[0054] 在一种实施方式中，具体可以采用下述方法确定每个所述训练样本的正例和负 例：

[0055] 对于每个所述训练样本，将该训练样本对应的所述人造图像作为该训练样本的正 例，从基于非该练样本对应的所述人造图像中，选择一个图像作为该训练样本的负例。

[0056] 上述方法中可以采用随机选择的方式，选择负例。为便于操作，也可以采用错位选 择的方式选择负例，即对于一个训练样本，将其下一相邻训练样本的人造图像作为该训练 样本的负例，但不限于此。

[0057] 步骤103、利用所述图像生成模型，基于每个所述训练样本的正例、负例和真实图 像各自对应的所述真实度参数，计算相应样本的子损失函数，并基于所述子损失函数，计算 相应样本的总体损失函数。

[0058] 其中，所述子损失函数包括内容损失函数、风格损失函数、生成器损失函数和判别 器损失函数；所述总体损失函数包括判别器总体损失函数和生成器总体损失函数。

说 明 书 4/7 页

CN 112990302 B

[0059] 本步骤中，为了提高后续基于损失函数对模型参数调整的准确性，将分别计算内 容损失函数(Content Loss)与风格损失函数(Style Loss)，以避免模态特定部分对模型训 练的影响，同时实现对图像风格的控制。

[0060] 在一种实施方式中，具体可以采用下述方法计算相应训练样本的各子损失函数：

[0061] 1、按照 计算内容损失函数值

[0062] 其中， 表示三元组损失函数，htc为锚点，表示训练样本的文本信息的文本特

征；hsc为正例，表示训练样本对应的人造图像的模态公共表征；为负例，表示训练样本的

负例的模态公共表征。

[0063] 上述计算内容损失函数值的方法中，内容损失函数采用了常用于建模图‑文对齐 关系的排序目标函数，该三元组损失函数(Triplet Loss)的具体计算公式如下：

[0064]

[0065] 其中,[q]+＝max(0,q)，f是相似度评分函数，u为文本表示，作为锚点(anchor)，v 与v‑分别为与文本u相匹配的正例图像表示和与u不匹配的负例图像表示；α为预设的正例 图像与文本的相似度与负例图像与文本的相似度的预期差值。f的具体形式为皮尔逊相关

系数(Pearson Correlation Coefficient)。

[0066] 上述方法中，内容损失函数以图、文的模态公共部分表征为输入，意图是最大化相 匹配的图、文公共部分表示之间的相似度。以文本描述htc为锚点，作为生成器的输入值；而 判别器以两种图像特征为输入，包括从锚点产生的图像特征(hsc,hss)和从其他文本产生的

图像特征 为了有效区分正例和负例，提高模型训练效率，这里，以“最大化相匹配

的图‑文对的相关性，同时最小化非匹配图‑文对的相关性”为内容损失函数的目标，因此，

将内容损失函数设计为：

[0067] 2、按照 计算所述风格损失函数

[0068] 其中，z为噪声样本；hss表示训练样本对应的人造图像的模态特定表征；ρ为预设的 皮尔逊相关系数。

[0069] 这里，考虑到生成器的输入分为htc和z两个部分，所生成的人造图像的内容完全 由文本特征htc决定，则的风格必然由相应的噪声样本z控制，即噪声z应与图像的特定部

分表征hss一致。基于此，风格损失函数的形式为z和hss的关联误差：

[0070] 3、按照 计算所述生成

器损失函数 其中， 表示从生成器pG中采样得到的训练样本对应的人造图像

表示人造图像的图‑文相似度； 表示人造图像的图像风格的视觉可信度；

表示人造图像的整体视觉可信度。

[0071] 4、按照 计算所述判别器损失函数

其中， 表示从训练样本集合pdata中得到的训练样本的真实图像x；ss(x)表示真

实图像x的图像风格的视觉可信度；sc(x)表示真实图像x的图‑文相似度；si(x)表示真实图

说 明 书 5/7 页

CN 112990302 B

像x的整体视觉可信度。

[0072] 在计算上述各损失函数时，使用的特征不再是全局的图像特征，而是解纠缠后的 图像特征。上述各损失函数经过线性组合，构成了训练时各训练样本对应的下述总体损失 函数：

[0073]

[0074]

[0075] 其中， 为判别器总体损失函数， 为生成器总体损失函数，为所述判

别器损失函数；为所述内容损失函数；为所述风格损失函数；其中，为所述生成器损

[0076] 步骤104、利用所述总体损失函数，调整所述图像生成模型的参数。

[0077] 本步骤中，将基于各训练样本对应的判别器总体损失函数和生成器总体损失函 数，对所述图像生成模型的参数进行调整

[0078] 具体地，在进行上述调整时，将基于判别器总体损失函数对模型中的图像编码器 和判别器进行参数调整；基于生成器总体损失函数对模型中的生成器和文本编码器进行参 数调整。

[0079] 基于上述步骤101～104，即可实现基于一个训练样本集合中训练样本对图像生成 模型的训练。在实际应用中，为了提高模型训练的准确性，可以利用多个训练样本集合循环 利用上述步骤101～104进行图像生成模型的训练。

[0080] 从上述模型训练方法实施例可以看出，上述模型训练方法实施例可以在不增加文 本生成图像模型的复杂度情况下，通过复用判别器，学习图文模态解纠缠表征，提升了文本 生成图像的图像生成质量和图文关联度，增加了对人造图像风格的控制能力。

[0081] 与上述模型训练方法实施例相对应，本发明实施例还提供了一种基于文本生成图 像的方法，如图2所示，包括：

[0082] 步骤201、基于待生成图像的文本信息，生成相应的文本嵌入式表示。

[0083] 步骤202、将所述文本嵌入式表示输入至预训练的图像生成模型处理，得到所述文 本信息的人造图像。

[0084] 其中，所述图像生成模型采用如上文所述的模型训练方法训练得到。

[0085] 由于上述模型训练方法训练在图像生成模型时，通过模态解纠缠，将模态特定部 分从人造图像中抽离，有效避免了与图像内容无关的模态特定部分对图‑文相似度的影响， 提高了模型生成图像的效果。因此，利用基于上述模型训练方法训练得到的图像生成模型， 为当前待生成图像的文本信息生成图像，可以保障图像生成质量。

[0086] 与上述模型训练方法实施例相对应，本发明实施例还提供了一种基于文本生成图 像的模型训练设备，包括处理器和存储器；

[0087] 所述存储器中存储有可被所述处理器执行的应用程序，用于使得所述处理器执行 如上文所述的基于文本生成图像的模型训练方法。

[0088] 其中，存储器具体可以实施为电可擦可编程只读存储器(EEPROM)、快闪存储器 (Flash memory)、可编程程序只读存储器(PROM)等多种存储介质。处理器可以实施为包括 一或多个中央处理器或一或多个现场可编程门阵列，其中现场可编程门阵列集成一或多个

说 明 书 6/7 页

CN 112990302 B

中央处理器核。具体地，中央处理器或中央处理器核可以实施为CPU或MCU。

[0089] 需要说明的是，上述各流程和各结构图中不是所有的步骤和模块都是必须的，可 以根据实际的需要忽略某些步骤或模块。各步骤的执行顺序不是固定的，可以根据需要进 行调整。各模块的划分仅仅是为了便于描述采用的功能上的划分，实际实现时，一个模块可 以分由多个模块实现，多个模块的功能也可以由同一个模块实现，这些模块可以位于同一 个设备中，也可以位于不同的设备中。

[0090] 各实施方式中的硬件模块可以以机械方式或电子方式实现。例如，一个硬件模块 可以包括专门设计的永久性电路或逻辑器件(如专用处理器，如FPGA或ASIC)用于完成特定 的操作。硬件模块也可以包括由软件临时配置的可编程逻辑器件或电路(如包括通用处理 器或其它可编程处理器)用于执行特定操作。至于具体采用机械方式，或是采用专用的永久 性电路，或是采用临时配置的电路(如由软件进行配置)来实现硬件模块，可以根据成本和 时间上的考虑来决定。

[0091] 本发明还提供了一种机器可读的存储介质，存储用于使一机器执行如本申请所述 方法的指令。具体地，可以提供配有存储介质的系统或者装置，在该存储介质上存储着实现 上述实施例中任一实施方式的功能的软件程序代码，且使该系统或者装置的计算机(或CPU 或MPU)读出并执行存储在存储介质中的程序代码。此外，还可以通过基于程序代码的指令 使计算机上操作的操作系统等来完成部分或者全部的实际操作。还可以将从存储介质读出 的程序代码写到插入计算机内的扩展板中所设置的存储器中或者写到与计算机相连接的 扩展单元中设置的存储器中，随后基于程序代码的指令使安装在扩展板或者扩展单元上的 CPU等来执行部分和全部实际操作，从而实现上述实施方式中任一实施方式的功能。

[0092] 用于提供程序代码的存储介质实施方式包括软盘、硬盘、磁光盘、光盘(如CD‑ROM、 CD‑R、CD‑RW、DVD‑ROM、DVD‑RAM、DVD‑RW、DVD+RW)、磁带、非易失性存储卡和ROM。可选择地， 可以由通信网络从服务器计算机或云上下载程序代码。

[0093] 在本文中， “示意性”表示“充当实例、例子或说明”，不应将在本文中被描述为“示 意性”的任何图示、实施方式解释为一种更优选的或更具优点的技术方案。为使图面简洁， 各图中的只示意性地表示出了与本发明相关部分，而并不代表其作为产品的实际结构。另 外，以使图面简洁便于理解，在有些图中具有相同结构或功能的部件，仅示意性地绘示了其 中的一个，或仅标出了其中的一个。在本文中， “一个”并不表示将本发明相关部分的数量限 制为“仅此一个”，并且“一个”不表示排除本发明相关部分的数量“多于一个”的情形。在本 文中， “上”、 “下”、 “前”、 “后”、 “左”、 “右”、 “内”、 “外”等仅用于表示相关部分之间的相对位 置关系，而非限定这些相关部分的绝对位置。

[0094] 以上所述，仅为本发明的较佳实施例而已，并非用于限定本发明的保护范围。凡在 本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护 范围之内。

说 明 书 7/7 页

CN 112990302 B

说 明 书 附 图 1/1 页

CN 112990302 B