硕 士 学 位 论 文

户外种植园行间可通行区域识别与路径

生成方法研究

学 生 姓 名 王远航

学 号 2019309030118

学科(专业学位) 工程硕士-控制工程领域

研 究 方 向 模式识别与智能控制

导 师 毕 松

校 外 导 师 李睿凡

2022 年 5 月 20 日

论文密级 公开

硕 士 学 位 论 文

户外种植园行间可通行区域识别与路径

生成方法研究

学 生 姓 名 王远航

学 号 2019309030118

学科(专业学位) 工程硕士-控制工程领域

研 究 方 向 模式识别与智能控制

导 师 毕 松

校 外 导 师 李睿凡

2022 年 5 月 20 日

Study on identification of passable area between

rows and path generation method in outdoor

plantation

Wang Yuanhang

A Dissertation Submitted to

North China University of Technology

In partial fulfillment of the requirement

For the professional degree of

Master of Engineering

North China University of Technology

May 20, 2022

户外种植园行间可通行区域识别与路径生成方法研究

农业是国民经济的重要组成部分，农业生产的稳定是社会问题和发展的基础

保障。随着社会平均用工成本的提高和人口老龄化的加剧，如何降低农业生产作

业中人力需求，提高生产效率成为农业可持续发展的重要问题。农业机器人能够

有效的降低农业生产过程中的人力需求，是保证农业生产可持续性的重要手段。

轮式移动机器人具有结构简单、成本低、承载能力大的优点，是农业机器人的一

种重要形式，但户外环境下地形存在起伏不定的特点，如何保证轮式移动机器人

在户外种植园环境中稳定可靠的通行是提升机器人可用性的重要保障。

本文通过对轮式移动机器人的可通过性理论分析，得到了移动机器人和地面

的可通行性边界条件，并研究了地面地形检测方法，实现了行间地形的可通行区

域识别，同时研究了基于视觉的地面图像分割方法，最终实现了户外种植园行间

地面可通行区域识别。本文的方法提升了移动机器人户外自主运行的可靠性，在

存在负障碍、视野内环境信息多样的情况下具有一定的鲁棒性，对移动机器人于

户外种植园行间的自主行驶技术实现具有一定的支撑作用。本文围绕户外种植园

行间场景下的可通行区域识别与路径生成方法展开研究，主要工作如下：

（1）户外种植园行间凹凸不平、起伏不定的负障碍区域对车辆产生倾翻、

拖尾、触底等影响，基于轮式移动机器人平台的结构参数，分析了轮式移动机器

人不可通行路面的特点及参数，获得了移动机器人可通行地面的边界条件，作为

可通行区域识别的通过性限制约束。

（2）针对负障碍地形的结构特点，设计了具有相对不变性的特征参数和提

取方法，设计了基于移动机器人平台参数和可通行边界条件的可通行区域识别方

法，设计了符合户外种植园行间场景下的道路通行性评价指标。

（3）针对行间大量干扰及不规则的道路特征，设计了基于图像分割模型的行

间道路区域分割方法，模型的分割精度达到了94%，具有一定的泛化能力和抗干

扰能力，结合行间道路分割结果，生成了可通行区域约束下的导航路径。

关键词：户外种植园行间，轮式移动机器人平台，车辆通过性检测，地形可

通行区域识别，图像语义分割与路径生成

Study on identification of passable area between rows and

path generation method in outdoor plantation

Abstract

Agriculture is an important part of the national economy, and the stability of

agricultural production is a basic guarantee for social problems and development. With

the increase of the average labor cost in society and the aging of the population, how to

reduce the manpower demand in agricultural production operations and improve

production efficiency has become an important issue for the sustainable development

of agriculture. Agricultural robots can effectively reduce the manpower demand in the

agricultural production process, which is an important means to ensure the

sustainability of agricultural production. With the advantages of simple structure, low

cost, and large carrying capacity, wheeled mobile robots are an important form of

agricultural robots. However, there is undulating terrain in the outdoor environment,

and how to ensure the stable and reliable passage of wheeled mobile robots in the

outdoor plantation environment is an important guarantee to enhance the usability of

robots.

In this paper, through the theoretical analysis of the passability of wheeled mobile

robots, the passability boundary conditions of mobile robots and ground are obtained,

and the ground terrain detection method is studied to realize the passable area

recognition of inter-row terrain, and the vision-based ground image segmentation

method is studied to finally realize the passable area recognition of inter-row ground in

the outdoor plantation. The method of this paper improves the reliability of outdoor

autonomous operation of mobile robots and has certain robustness in the presence of

negative obstacles and various environmental information in the field of view, which

supports the implementation of autonomous driving technology of mobile robots in

outdoor plantation rows. In this paper, we focus on the identification of passable area

and path generation method in the outdoor plantation inter-row scenario, and the main

work is as follows.

(1) The uneven and undulating negative obstacle areas between rows of outdoor

plantations have effects on vehicles such as tipping, trailing and bottoming out, etc.

Based on the structural parameters of the wheeled mobile robot platform, the

characteristics and parameters of the impassable road surface of the wheeled mobile

robot are analyzed, and the boundary conditions of the passable ground of the mobile

robot are obtained as the passability restriction constraint of the passable area

identification.

(2) For the structural characteristics of negative obstacle terrain, the feature

parameters and extraction method with relative invariance are designed, the passable

area recognition method based on the mobile robot platform parameters and passable

boundary conditions is designed, and the road passability evaluation index is designed

to meet the inter-row scenario of the outdoor plantation.

(3) For a large number of inter-row interference and irregular road features, the

inter-row road area segmentation method based on the image segmentation model is

designed, and the segmentation accuracy of the model reaches 94% with certain

generalization ability and anti-interference ability, and the navigation path under the

passable area constraint is generated by combining the interline road segmentation

results.

Keywords: outdoor plantation inter-row, wheeled mobile robot platform, vehicle

passability detection, terrain passable area recognition, image semantic segmentation

and path generation

摘 要 ................................................... I

ABSTRACT ................................................ II

第一章 绪论 ............................................. 1

1.1 课题背景及意义 ................................................................................................. 1

1.2 国内外户外种植园行间自主行驶的研究现状 ................................................. 1

1.2.1 地形负障碍检测研究现状 ........................................................................... 2

1.2.2 可通行道路识别研究现状 ........................................................................... 3

1.2.3 路径生成研究现状 ....................................................................................... 4

1.3 本文的主要研究内容与组织结构 ..................................................................... 5

1.3.1 主要研究内容 ............................................................................................... 5

1.3.2 组织结构 ....................................................................................................... 6

1.4 本章小结 ............................................................................................................. 7

第二章 可通行区域识别及路径生成相关理论 ................. 8

2.1 地形感知及可通行区域识别相关理论 ............................................................. 8

2.1.1 车辆质心求解原理 ....................................................................................... 8

2.1.2 深度数据处理原理 ....................................................................................... 9

2.1.3 地形数据高程描述及坡度求解原理 ......................................................... 13

2.1.4 顶起失效判定原理 ..................................................................................... 14

2.2 道路分割与路径生成相关理论 ....................................................................... 15

2.2.1 基于深度学习的图像语义分割原理 ......................................................... 15

2.2.2 路径生成原理 ............................................................................................. 19

2.3 本章小结 ........................................................................................................... 19

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析 及方案设计 .............................................. 20

3.1 户外种植园行间可通行区域识别与路径生成技术需求分析 ....................... 20

3.2 行间地形感知及可通行区域识别方案设计 ................................................... 22

3.3 行间道路识别与路径生成方案设计 ............................................................... 25

3.4 本章小结 ........................................................................................................... 25

第四章 行间地形感知及可通行区域识别 .................... 26

4.1 车辆、地形相对通过性假设与分析 ............................................................... 26

4.2 车辆通过性分析 ............................................................................................... 28

4.2.1 基于纵向、侧向的轮式移动机器人平台倾翻角度阈值分析 ................. 28

4.2.2 基于顶起失效判断和跨越固定尺寸负障碍能力的越障能力分析 ......... 30

4.3 地形特征提取分析 ........................................................................................... 35

4.3.1 地形相对不变性证明及其相关假设 ......................................................... 35

4.3.2 坡度计算 ..................................................................................................... 37

4.4 可通行区域识别综合分析与决策 ................................................................... 38

4.4.1 深度数据处理 ............................................................................................. 39

4.4.2 直行区域负障碍通行性判别 ..................................................................... 47

4.4.3 综合车辆通过性约束与负障碍地形分析的可通行区域识别 ................. 48

4.5 本章小结 ........................................................................................................... 54

第五章 行间道路识别与路径生成 .......................... 55

5.1 模型组网的构建 ............................................................................................... 56

5.2 模型训练 ........................................................................................................... 59

5.2.1 目标数据来源与获取 ................................................................................. 59

5.2.2 训练过程 ..................................................................................................... 61

5.2.3 训练结果 ..................................................................................................... 61

5.2.4 模型测试 ..................................................................................................... 62

5.3 路径生成 ........................................................................................................... 64

5.4 本章小结 ........................................................................................................... 65

第六章 总结与展望 ...................................... 66

6.1 工作总结 ........................................................................................................... 66

6.2 研究展望 ........................................................................................................... 66

参考文献 ................................................ 68

在学期间的研究成果 ...................................... 71

致 谢 .................................................. 72

第一章 绪论

第一章 绪论

1.1 课题背景及意义

我国种植业历史悠久，其产值约占全年农业总产值的50％以上，是农业生产

的重要组成部分[1][2]。种植业中又多以行间间作的模式进行规范化管理，行间间

种的生产管理中，劳动力需求最大的环节仍是以人力为主，使用智能化设施农业

装备替代劳动力，能够有效解决农业用工成本逐渐提高，劳动力年龄结构普遍偏

大，劳动力供给紧缺，大部分劳动力出现抵御相对恶劣环境的能力不足问题。适

用于户外种植园行间条件下的智能农业机器人对节省人力劳工成本，提升种植园

生产管理效率和产品的市场竞争力具有重要意义[3]。

主要的生产环节中应用的自主化、智能化能力是提升农业机器人有效性的关

键指标之一，采收、植保、播种等相关作业任务存在劳动强度大、作业集中等特

点，具有自主行驶能力的农业机器人能够长时间重复工作，能够有效地降低上述

关键生产环节的人力需求以提升生产效率。农业移动机器人的作业环境存在光照

强度变化大、路面凹凸不平且软硬不均的特点，对机器人自主运行提出了较高的

要求。本课题研究户外种植园行间运行的移动机器人行间自主通行的方法，通过

对机器人可通过性条件分析、可通行区域识别与路径生成，实现了负障碍识别与

规避系统，提高了移动机器人在户外行间条件下的可用性[4]。

户外种植园行间是非结构化的环境，地面负障碍区域成为限制轮式移动机器

人通过的潜在因素之一[5][6]，道路表面结构松软等因素使地形特征存在不确定性，

地面的起伏、坡度突变的负障碍地形为机器人正常通行的制约条件。本文研究的

户外种植园行间道路的可通行区域识别和路径生成技术为轮式移动机器人平台

于户外种植园行间通行提供了理论与实践支撑。

1.2 国内外户外种植园行间自主行驶的研究现状

户外种植园行间区域是农业机器人典型的工作环境。种植园场景存在光线变

化明显、植株整体呈规律性排布但规律性不同、路面参数具有随机性且变化范围

大，存在坑洼、土包等限制轮式移动机器人平台通行的地形区域。但由于轮式移

动机器人具有结构简单、载重量大、刚性连接且操作简单的优点，在种植园生产

第一章 绪论

中具有明显的应用优势，因此受到国内外研究者的持续关注。种植园路面坑洼不

平的特点决定了轮式移动机器人需具有良好的越障能力或具有避障能力，避障能

力应能对路面的正负障碍具有良好的适应性。如何有效的越障是移动机器人研究

者的重点关注的问题之一。

1.2.1 地形负障碍检测研究现状

近年来，对自主通行车辆的研究越来越多，大多存在于室内或者较规则的路

面，障碍的判别相对简单。但在户外种植园行间环境中的障碍判别相对复杂，户

外种植园行间地形障碍具有土面粗糙、有起伏，有坡度等特点，并且复杂的地形

导致了车体运动的不规律性。因此分析外部环境的地形信息，预测地形的通行性

边界，检测阻碍到车辆前进路线中的障碍区域是户外种植园行间自主通行的关键

[7][8]。

Karl Iagnemma等[9]针对月球车在有限监督的情况下穿越非常粗糙的地形中

的研究中表明，车轮和地形因素对于月球车在粗糙地形的行驶中起着至关重要的

作用，并提出了一种利用车载机器人传感器识别关键地形参数的在线估计方法。

该方法是基于经典地形力学方程式的简化形式，能够较准确的估计三种不同地形

类型的参数。此研究针对月球表面的复杂地形环境，月球地表相对坚硬，特征较

为清晰，道路寻找的区域面积较广，所以仅准确估计三种不同地形类型的参数，

不适用于种植园行间的复杂地形。

S. Dubowsky等[10]提出了一种基于刚体运动学方程的轮地接触角估计算法。

该算法利用一个扩展的卡尔曼滤波器来融合车载传感器信号。对轮式探测器的仿

真和实验结果表明，该算法能够准确地估计不平坦地形下的轮地接触角。同样也

是用大量堆叠传感器的方式，数据处理过程复杂且具备较高的不确定性。

彭湘等[11]针对具有起伏、坡度不均匀等特点的环境，设计了一种基于2.5维

栅格地图的半自由栅格与半障碍栅格地形描述方法，以便于对地形可通行区域的

识别，但该研究的应用场景多为地理测绘方面大比例尺下的区域地形障碍区域估

计，并不适用于户外种植园行间小范围区域的负障碍检测。

张艳国等[12]设计了基于融合姿态传感器和激光雷达的负障碍识别方法，将历

史有效点云数据与历史负障碍的检测结果结合分析，构建了姿态与点云数据的融

合模型，提高了负障碍检测的精度。此研究局限于对已测得数据的特征匹配与检

测，不具有较高的实时性，不适用于户外种植园行间场景下的车辆实时自主通行。

阮顺领等[13]对针对露天采矿区域的道路坑洼环境特征，设计了一款轻量化的

负障碍检测目标模型，包括MobileNetv3网络进行图片压缩方法，以及多尺度地

第一章 绪论

形特征提取方法，最终实现特征分类及边界框回归实现对负障碍的视觉检测。此

方法面向种植园行间不规则的负障碍特点，缺少大量的数据集，故不能很好地将

算法优势体现，并且此研究方式偏重避障能力，没有越障能力的内容体现。

从以上研究可以看出，现如今车辆在复杂路况的地形检测已经取得了一定的

进展，但由于种植园行间道路存在随机出现的负障碍，运用激光雷达进行密集点

云处理以及模型训练的方式并不能较好地解决地面负障碍识别和检测问题。同时，

针对于轮式移动机器人在松软土地路面的可通行性问题研究相对较少，所以移动

机器人参数与地形参数约束下的地面可通行参数检测及可通行性预测方法有待

1.2.2 可通行道路识别研究现状

道路可通行区域识别是户外种植园场景下的农业移动机器人研究的重要课

题。户外种植园行间进行可通行区域的识别存在以下问题：（1）移动机器人可

通行参数分析（2）道路可通行特征识别（3）可通行区域分析及可通行轨迹生成。

国内外众学者从通行区域内的空间道路分割、障碍种类及特征，车辆自身参

数等方面，对户外种植园行间环境下的通行性预测进行了多方面的研究。近年来，

激光雷达在移动机器人、无人驾驶等领域应用非常广泛[14]。由于激光雷达可以较

高频率扫描环境的距离信息，为移动机器人提供障碍物距离数据，被大量用于避

障、可通行区域的提取。同时激光扫描也可以获得周围环境信息，以实现机器人

的自主导航。

段建民等[15][16]针对户外环境中路沿规则的特征，设计了一种根据路沿检测

和坡度检测的算法，包括对COBWEB算法改进的依据路沿数据点特征，提取路沿

数据集的欧氏距离聚类分析，最后应用最小二乘法拟合出左右路沿。此算法多适

合于平整且两侧特征信息规则的路面，应对种植园行间不规则定植出现时，不具

备较高的拟合能力。

蒋剑飞等[17]利用改进欧氏聚类算法进行实时障碍物检测，提出一种相邻点云

间距算法对户外道路可通行区域进行实时提取方法。实现了地面与非地面点云分

离，标记了非地面点云中的障碍物。该方法将每个地面激光束固有的相邻点云间

距与实际相邻两点间距离进行对比，结合相邻点角度差以及点云聚类，最终融合

障碍物检测结果获得可通行区域，但在道路两侧不规则、不显著障碍特征出现时，

识别可通行区域与路径拟合的能力欠佳。

谌华等[18]针对传统合成孔径雷达（SAR）图像道路识别步骤繁杂的问题，提

出了一种新的基于深度学习的SAR图像道路识别方法。在原有全卷积神经网络基

第一章 绪论

础上改进激活函数，构造了一种新的卷积神经网络M-FCN，有效缓解了道路信息

丢失问题；进而利用将该卷积神经网络和自主构建的道路标签集应用于模拟

SAR和真实SAR图像道路识别实验中，提高了鲁棒性。该实验仍处于实际应用探

图像分割是视觉技术的重要组成部分，不仅可以提供物体类别信息，还可以

提供物体位置信息，可以有效地辅助农业机器人识别可通行区域和避障[19]。图像

分割领域的研究开始于20世纪70年代，早期的一般被称为传统图像分割方法的如

阈值法、区域生长法、分水岭算法、边缘检测法等。近些年来，卷积神经网络兴

起，图像分割也迎来了新的发展，发展方向转为基于深度学习的图像分割方法，

包括卷积神经网络、全卷积神经网络以及对全卷积神经网络进行改良后的方法，

分别基于编解码结构和空洞卷积[20]。

李文斌等[21]使用深度学习的方法对遥感图像进行特征提取，并将深度神经网

络与注意力机制相结合，利用多个深度神经网络集成方法对遥感图像进行分割。

该模型能够降低了神经网络的方差，相较于单个深度神经网络模型具有较高的决

策准确率。但该方法在数据量级较小情况下训练获得的模型可靠度较低。

张永辉等[22]提出基于U-Net的滨海湿地信息提取方法，该方法使用不同地物

的交接区域作为训练样本，使用U-Net模型进行训练和测试。但U-Net模型在保持

提取目标的边界轮廓的完整性上能力有限，数据集样本较小。

以上对目标区域的识别方法能够在一定程度上实现预期目标，但相对于常规

尺寸的目标以及小目标通常缺乏充足的外观信息，存在识别区域不完整、障碍物

形状不规则无法准确识别预测的情况，难以将它们与背景精确地区分开来。深度

卷积神经网络相比于传统分割模型具有更好的精度与抗干扰能力。应用于户外种

植园场景下其更适用于小尺度数据集，获得较好的分割效果。因此，深度卷积神

经网络可通行区域识别语义分割模型的构建是解决种植园行间场景下道路信息

识别问题的有效手段。

1.2.3 路径生成研究现状

路径生成的可通行路径是机器人自主运行的基础，国内外众学者对其进行了

大量的研究。日本生研中心的Tosaki.K等[23][24]选择电磁导航和机械导航原理为研

究对象，研发出多款种植园行间无人植保机械设备，降低了农业作业的强度。但

由于种植园行间暴露于不确定性的户外场景中，铺设大量的管道和电缆对植株的

生产和机械设备的维护带来了挑战，所以这类导航应用得到了大量的限制。

陈军等[25]选择果树的位置信息为研究对象，在研究过程中采用激光雷达传感

第一章 绪论

器对其位置信息进行采集和获取，得到了在种植园环境下移动机械设备直线与曲

线的路径导航算法。随着激光雷达应用于农业复杂环境下的自主导航应用增多，

但部分研究缺少真实环境的验证，仍处于应用探索的阶段。

艾长胜等[26]选择葡萄园作业的植保机器人为研究对象，在研究过程中提出了

一种基于多支持向量配比权重的垄行识别路径规划算法，最后根据样本点与分类

边际线存在的几何间隔关系判别各点所占相对权重，提升了农业植保机器人行间

作业导航线的规划拟合的准确性和可靠性。

薛金林等[27]以农业移动机器人为研究对象，在研究过程中采用激光雷达感知

的方式，对有行株距和有行无株距，特别是一侧存在缺失的树木行中进行导航路

径拟合，包括对航向偏差与方向偏角的求解，以及基于模糊控制算法按道路中心

线进行的导航控制，但使用模糊控制算法对其导航路径的提取精度产生了较大的

户外行间存在负障碍条件下，如何能够生成可以规避负障碍的可通行路径是

本课题主要的研究内容之一，现有研究工作对存在负障碍条件下的可通行区域及

相关的轨迹规划工作研究关注不足。通过对地面特征参数分析和车辆可通行约束

条件的基础上，研究存在负障碍的户外行间道路可通行区域及导航方法对提升移

动机器人在户外种植园行间环境的适应性，和此环境下的车辆自主行驶能力具有

重要的理论意义和应用价值。

1.3 本文的主要研究内容与组织结构

1.3.1 主要研究内容

本文针对户外种植园行间可通行区域识别与路径生成问题，着重从非结构

化环境的可通行区域识别与路径生成方法出发，研究户外种植园行间环境下轮

式移动机器人通过性条件及可通行区域识别，并结合适用于种植园行间环境下

的深度神经网络图像语义分割模型进行道路信息的分割、提取与路径生成方法

设计。具体内容如下：

（1）面向存在负障碍条件下的可通行区域识别方法研究

基于轮式移动机器人设计参数，进行了通过性条件的理论分析，接近角、离

去角、纵向通过角和最小离地间隙可作为移动机器人设计方面的限定参数。研究

移动机器人倾翻条件下的角度阈值，得到综合整车完整的自相关限定约束阈值集

合。研究了非结构化环境下的地形深度信息的采集与校正方法，提出了地形相对

第一章 绪论

不变特征。进而研究了考虑轮式移动机器人完整自相关限定阈值集合与地形坡度、

尺寸参数条件下的可通行区域识别方法，实现了适用于复杂环境路面下的负障碍

可通行区域的识别。

（2）种植园行间环境下的道路识别与路径生成方法研究

针对户外种植园行间图像数据，构建适用于轮式移动机器人平台的图像语义

分割模型，完成图像语义分割，将输入模型的图像分割成树木、天空、地面、背

景四部分并进行输出，进而研究对输出图像的地面信息提取后的路径拟合及生成

方法。构建具备较强的泛化能力和抗干扰能力的模型。

1.3.2 组织结构

根据本文的研究内容，本文共分为六个章节，每章节的概述如下：

第一章概括了本文的研究背景、目的及意义，介绍了国内外众学者针对地形

障碍检测、可通行区域识别、路径生成方法的相关研究工作，最后介绍了本课题

的主要研究内容和行文组织结构。

第二章概括了可通行区域识别和路径生成的相关基础理论，本章分别介绍了

对于户外种植园行间可通行区域识别所涉及的基于地形与车辆参数结合预测的

负障碍识别理论，以及路径生成所涉及的基于U-Net 的道路识别与路径生成相关

第三章分析了户外种植园行间的可通行区域识别与路径生成方法的技术需

求分析与总体设计，分析了在种植园行间环境下的可通行区域识别与路径生成系

统的总体需求，设计了行间地形感知及可通行区域识别方案，完成了行间道路识

别与路径生成方案。

第四章研究了轮式移动机器人平台行间地形感知及可通行区域的识别方法。

分析了移动机器人完整的自相关限定阈值集合，研究了地形相对不变特征分析及

提取方法，实现了负障碍可通行区域的识别。

第五章设计了行间道路识别与路径生成系统。本章基于图像分割方法设计了

户外行间地面识别方法，研究了道路中可通行轨迹生成方法。完成了户外种植园

行间地面分割模型的训练，测试结果表明所设计的模型具有良好的道路识别能力，

并根据移动机器人行驶方向生成可通行路径。

第六章为总结与展望。本章针对户外种植园行间可通行区域识别与路径生成

方法研究进行了分析和总结，指出本文系统设计最终达到的预期效果及评价，同

样指出目前研究中存在的不足，并对这些不足的解决方法研究进行了展望。

第一章 绪论

1.4 本章小结

文章阐述了对户外种植园行间环境下可通行区域识别与路径生成方法研究

的背景和意义，并介绍了国内外对不同场景下进行可通行区域识别与路径生成方

法的研究现状和相应的优缺点。最后介绍了本文的主要研究内容和论文组织结构。

第二章 可通行区域识别及路径生成相关理论

第二章 可通行区域识别及路径生成相关理论

根据车辆结构参数确定的接近角、离去角、纵向通过角以及最小离地间隙进

行纵向通过性检测的结果不够准确。本文通过研究在质心偏移下轮式移动机器人

的倾翻角度阈值约束，并结合车辆通过性理论中负障碍跨越能力的尺寸描述，得

到车辆通过性的综合检测方法。此方法更加准确地描述了车辆的越障能力。本节

分析了，在车辆倾翻情况下的极限倾翻角所需的质心求解原理，对车辆处于空载、

满载和理想状态下的质心分别进行了理论的推导和陈述。

2.1 地形感知及可通行区域识别相关理论

2.1.1 车辆质心求解原理

由于轮式移动机器人在户外种植园行间非结构化的道路上行驶时，会因道路

起伏而导致车辆相对于道路的车辆质心发生偏移，需进行车辆质心位置变化的求

解，质心到前轴（坐标原点）的水平距离由公式2-1 可知：

i i ) (

X g a 

公式2-1 中，a 为质心到前轴的水平距离， ig 为各总载荷质量，¤¤为各总载

荷到前轴的水平距离，轴荷重量由公式2-2、2-3 可得：

1 (1 ) i i i i

g X a G g g - L L

  = −  = 

( ) 2 i i i a G g g X L =  =  

式2-3 中 1 G 为前轴负荷， 2 G 为后轴负荷，L 为轴距，先对移动机器人的荷载

能力进行如公式2-4、2-5 所示计算，并通过如公式2-6 所示的方式进行质心位置

     −  = ig L Xi G ) 1( 1

      = ig L Xi G2

第二章 可通行区域识别及路径生成相关理论

) 1( 1 2

G G L G G L a −  =  =

式2-6 可以求得移动机器人的总负荷 ig G G G  = + = 2 1 。质心离地高度常规

公式2-7 如下所示。式2-7 中h 为质心到地面的高度， ih 各轴载荷能力下的离地

h g h 

  = ) ( （2-7）

2.1.2 深度数据处理原理

（1）实际物体尺寸与像素个数的转换关系

Basler ToF 3D 相机通过采集的点云数据和其相机内部部署的转换算法，得

到本文可通行区域识别所需的深度图，与本文题意相符的Mono16 范围图包含以

灰度值表示的每个像素的图像深度信息。为了将实际的物体直接转换到像素坐标

系下的像素个数的对应比较，可根据如图2-1 所示的轮胎宽度像素占比求解方式

为例进行相应的求解。

图2-1 X 方向轮胎像素个数求解原理图

图2-1 中，bo 为轮距的一半长度；mn 为相机离地高度；r 为车轮直径；p 为

车轮宽度。根据相机于X 方向的拍摄角度为57°，所以根据以下公式可知距离对

应的像素个数。根据¤¤¤¤与¤¤¤¤相似可得x=278；又根据¤¤¤¤与¤¤¤¤相似，

可得y=225；在直角¤¤¤¤中可得α=27.94°；最终在直角¤¤¤¤中可以求得θ=8.48°，

所以θ 相对于整体的57°可得占比为0.14，可求得最终占比像素个数为95。如上

轮胎对于像素个数的求解过程适用于车体所有零件对于图像坐标系下的值如公

式2-8 所示即为对应直线距离的求解公式。

第二章 可通行区域识别及路径生成相关理论

公式2-8 中：y 为像素个数，x 为物体的测量值，h 为相机离地高度。

（2）ToF 相机成像原理

图2-2 所示为针孔相机基本成像原理，将相机打开的第一帧图像的相机坐标

系预定义为世界坐标系，并计算相机接下来的移动路径及姿态。世界坐标系下的

坐标通常使用( ) , w w w x ,y z 来进行表示。

相机坐标系以一台相机的光心或者主点作为坐标系的原点。X 轴和Y 轴在拍

摄画面时分别平行于图像的横轴和纵轴，Z 轴为相机焦距所指方向。相机坐标系

下的坐标通常使用符号( ) , c c c x ,y z 进行表示。

图像坐标系根据图像进行定义，以图像的中心作为原点，X 轴和Y 轴与相机

坐标系的X 轴和Y 轴的方向一致。图像坐标系只有两个维度，图像坐标系下的

坐标通常使用符号( ) ,x y 来表示。

像素坐标系以像素为单位的坐标系。像素坐标系也是二维坐标系，其X 轴和

Y 轴的方向与图像坐标系一致，坐标系的原点位于二维图像的左上角。像素通用

的表示形式为一个方块或者矩形，每个像素里面存放的信息为像素的强度或灰度

相机内参校正的过程共涉及像素坐标系、图像坐标系，通过对相机坐标系进

行外参校正后的坐标值和深度值进行透视投影，其原理是针孔成像原理，根据图

坐标系如图2-6 所示为像素坐标系和相机坐标系的转换关系。

图2-2 像素坐标系与相机坐标系的转换关系

图像坐标系应在相机坐标系的另一边，为倒立反向成像，但为方便理解和计

( ) c c c z y x P , ,

第二章 可通行区域识别及路径生成相关理论

算，故投影至同侧。根据三角形相似性原理如公式2-9 可得到相机坐标系到像素

坐标系的转换矩阵。

   

   

•   

 =   

1 0 0 0

c Z Y X

f f y x Z

通过转换到图像坐标系下的数据，对其进行从图像坐标系向像素坐标系的

转换得到公式2-10 所示转换公式。

（2-10）

将公式2-9 代入公式2-10 可得到相机内参的转换矩阵如公式2-11 所示。

     

     

=   

1 1 0 0

y x v dy

（2-11）

进而可得世界坐标系与相机坐标系如公式2-12 所示的转换矩阵。

   

   

   

   

1 3 3 3

T R Z Y X

（2-12）

通过结合2-11 和2-12 两式，可以得到一个三维空间中的点从相机坐标系到

像素坐标系的整个如公式2-13 所示的投影过程，即内外参坐标系转换矩阵。

   

   

     

     

=   

1 1 O 1 0 0

1 3 3 3 0 y

c Z Y X T R v d

（2-13）

（3）畸变校正原理

Basler ToF 相机的测量来源是传感器的中心，当Z 值相同时，距离会发生变

化会进而出现桶形失真。桶形失真会导致图像边缘的分辨率降低。实际摄像机的

第二章 可通行区域识别及路径生成相关理论

透镜总是在成像仪的边缘产生显著的畸变。

对于径向畸变，成像仪中心（光学中心）的畸变为0，随着向边缘移动，畸

变越来越严重。径向畸变可以通过下面的泰勒级数展开式进行校正，对产生径向

畸变和切向畸变的整体过程如公式2-14 所示的整体畸变所示。

( ) 

 + + + = 

x r k r k r k y

x 6 3 4 2 2 1 1 ( ) ( )

+ + + 2 2 1 2

2 2 2 1

y r p xy p

x r p xy p

（2-14）

公式2-14 中，, , , x y x y  它们都是处于归一化平面下考虑的位置坐标，r 为曲

2 2 2 x r y = + ， 1 2, 3 , k k k 为径向畸变系数。,x y 为发生径向畸变后像点的

坐标，也就是我们实际看到的， , x y  为畸变校正后的正确像点坐标。 1 2 , p p 称为

切向畸变校正系数。

（4）位姿校正原理

对于在车辆结构上的相机斜拍地面的情况，建立如图2-3 所示的矢量拍摄模

型，已知P M  = PM = S ， , , x y z R R R 为旋转矩阵 0,1,2,3 B 为平面 0 1 2 3 B B B B 的四个点，

且过原点M 求P与 0,1,2,3 B 的连线与平面XMY 的交点 0,1,2,3 B 坐标。解得

( ) 0,1,2,3 320 , 240 , 0 x y z B dx dy R R R =      由相似得

0,1,2,3 0,1,2,3 0,1,2,3

0,1,2,3 0,1,2,3

y z z x

B P B B

− = =   

所以 0,1,2,3 B 坐标为( ) ( ) ( ) 0 z iz ix z iz iy P B B , P B B ,   − − 。

图2-3 矢量模型

根据陀螺仪对于三轴定义及表示，在此三维空间中，三轴对应的欧拉角通过

( ) , , 来定义旋转。根据欧拉角定义，每个欧拉角都可以依据roll，pitch 和yaw

的复合形式表达。在右手笛卡尔坐标中的主动旋转矩阵可表达为：

( ) ( ) ( ) ( ) , , z x z M R R R     = （2-15）

第二章 可通行区域识别及路径生成相关理论

根据此规则将陀螺仪安放在相机正上方固定连接，保证其与相机在一个水平

线上，本课题需要测得的是车身位姿发生变化导致的三个轴的角度变化，在车自

主行驶的过程中，根据如下2-16 的旋转平移矩阵公式可得到位姿校正的主动旋

− − − =

    

           

              

cos sin cos sin sin

sin cos sin sin cos cos cos sin cos cos sin cos

sin sin sin cos sin cos cos sin sin cos cos cos , , M （2-16）

2.1.3 地形数据高程描述及坡度求解原理

对于地形每一个像素点的距离值，在数字地面模型DTM（Digital Terrain

Model）[28]的定义中，DTM 是地形在计算机空间的离散化表达模型，在某一投影

平面上，DTM 满足一定精度及用途要求的规则和非规则格网点集，它是一组包

括点的平面坐标( ) ,x y 及单一高度值的数据集。DTM 用函数的形式以公式2-17

所示的描述为：

( ) , , 1,2, , i i i i V X Y Z i n = = ； （2-17）

公式2-17 中，( ) i i X ,Y 为平面坐标， iZ 为( ) i i X ,Y 对应的高程。当序列中各向

量的平面位置呈规则格网排列时，其平面位置坐标可以自动推算，此时DEM 就

简化为一向量序列。根据相对高程不变性的原理，可以对图像高程值通过梯度计

算表征坡度求解。

假设被作用图像为I，梯度的水平和垂直方向计算，水平变化为将I 与一个

奇数大小的内核 x G 进行卷积。当内核大小为3 时， x G 的计算结果如公式2-18 所

- Gx    

（2-18）

垂直变化：将I 与一个奇数大小的内核 y G 进行卷积。当内核大小为3 时，

y G 的计算结果为如公式2-19 所示。

I - - - Gy    

（2-19）

在图像的每一点，结合以上两个结果求出近似梯度 2 2 x y G G G = + 。

第二章 可通行区域识别及路径生成相关理论

2.1.4 顶起失效判定原理

如图2-4 所示的几何关系，根据汽车理论中的车辆顶起失效原理[29]，障碍顶

点A 的轨迹为直径等于 r D 的圆， r D 称为地隙直径。该圆与两车轮在B、C 点相

切。B、C 点的位置可由角 o 决定， o 为地隙圆心与轮心的连线与轮心所在的水

平面的夹角，交点O 即为地隙圆心。

图2-4 汽车顶起失效的几何关系

当障碍的尺寸使车辆轮距之间所示的间隙量h<0 时，即该圆和汽车底部某

零件相交，发生顶起失效。当h=0 时，即该圆和汽车底部某零件相切时，则是汽

车通过障碍的极限尺寸。式2-20、2-21 为车辆顶起失效的障碍条件：

( ) 0 0.5 sin 0.5 0.5 m r r h D D D D  + + −  （2-20）

( )( ) 0 0.5 1 sin m r h D D   + − （2-21）

其中 m h 为汽车中部地隙；D、r D 分别为车轮直径与地隙直径。进而可得到D、

r D 与 o 之间如式2-22 的关系：

( )cos r o D D L  + = （2-22）

将式2-22 代入到上面的2-21 式，可以得到由公式2-23 所示的顶起失效条件为：

( ) ( )     − + − +  2 2 5.0 L D D D D h r r m （2-23）

第二章 可通行区域识别及路径生成相关理论

2.2 道路分割与路径生成相关理论

2.2.1 基于深度学习的图像语义分割原理

图像语义分割基于深度卷积网络，其中卷积神经网络是深度学习领域的基础，

其中的卷积、池化、激活函数等模块贯穿始终。本章首先介绍卷积神经网络实现

图像分割的原理，最后介绍了分割模型的评价标准。

（1）卷积神经网络

图2-5 卷积神经网络结构图

图2-5 为一个典型的卷积神经网络（Convolutional Neural Networks，CNN）

结构图，其中的组成部分有卷积层、池化层和全连接层[30]。

卷积层计算过程如图2-6 所示。卷积核通过滑动的方式遍历整个图像，每滑

动一次进行一次计算，计算公式见式2-24，其中¤代表卷积神经网络的输入图片，

¤代表卷积神经网络输出特征图， ¤代表卷积核参数，按对应位置相乘计算，共

得到¤ℎ×¤¤个值，而后对¤ℎ×¤¤个值求和作为一次卷积的结果[31]。

图2-6 卷积计算过程示意图

¤[¤, ¤] = ∑ ¤[¤ + ¤, ¤ + ¤] ∙¤[¤, ¤] ¤,¤ （2-24）

input conv 1 conv 2 pool 1

pool 2

FC output

第二章 可通行区域识别及路径生成相关理论

在卷积计算示意图中，每次卷积运算都会减小图像的尺寸，卷积输出特征图

的尺寸按照如公式2-25、2-26 所示计算。¤¤¤¤代表卷积运算后输出图像的高度，

¤代表输入图像的高度，¤ℎ代表卷积核高度。¤¤¤¤卷积运算后输出图像的宽度，

¤代表卷积核宽度。

¤¤¤¤= ¤-¤ℎ+1 （2-25）

¤¤¤¤= ¤-¤¤+1 （2-26）

图像尺寸减小会导致图像边缘信息丢失，因为只经过一次卷积运算后，图像

边缘像素就不再参与后续运算了，可以利用卷积填充解决此问题，卷积填充通常

是将0 填充在图片的外围，保证输出相同大小的输出[32]。

在图像高度方向，在第一行之前填充¤ℎ1行，在最后一行之后填充¤ℎ2行，在

图像宽度方向，在第一列之前填充¤¤1列，在最后一列之后填充¤¤2列；则填充

之后的图像尺寸为(¤ + ¤ℎ1+¤ℎ2) × (¤ + ¤¤1+¤¤2)，卷积后的图像输出如公式

2-27、2-28 所示。

¤¤¤¤= ¤+¤ℎ1 + ¤ℎ2-¤ℎ+ 1 （2-27）

¤¤¤¤= ¤+¤¤1+¤¤2-¤¤ + 1 （2-28）

在卷积神经网络中采用等量填充的方法，即上下左右采取相等宽度和相等

高度的填充方式，则图像输出如公式2-29、2-30 所示。

¤¤¤¤= ¤ + 2¤ℎ-¤ℎ+1 （2-29）

¤¤¤¤= ¤+2¤¤-¤¤+1 （2-30）

当¤ℎ= ¤ℎ= 1时，填充示意图如图2-7(a)所示，当¤ℎ= ¤ℎ= 2时，填充示意

图见图2-7(b)。

图2-7 图像填充示意图：(a)以1 为单位的填充过程；(b)以2 为单位的填充过程

图像经过卷积层后会进入池化层，池化层的作用是获得图像局部特征，同时

第二章 可通行区域识别及路径生成相关理论

不改变图像深度，局部特征的获取一般依赖最大值池化或平均值池化，最大值池

化是指用一个区域内的最大值代表整个区域的值，平均值池化是指用一个区域的

平均值代表这个区域的值，如图2-8 所示。

图2-8 平均池化和最大池化示意图

池化可以使图像尺寸变小，一般情况下使用大小为2×2 的池化窗口，每次移

动的步长选择2，这样一来经过池化后图像尺寸将会变为原来的0.25 倍。池化的

作用主要有两个，一个是改善过拟合，图像在卷积过后会产生很多高维特征向量，

需要巨大的计算量，同时由于图像特征被重复提取出现过拟合，池化操作减小了

数据量，降低了特征维度，可以有效改善过拟合。另一个是帮助输入数据保持稳

定，如果输入数据发生了少量偏移，池化操作可以一定弥补这些偏移[33]。

③ 激活函数

ReLU 函数是激活函数的一种，激活函数通常是单调可微的，目的是在网络

中增加非线性，将线性值变为输出值。ReLU 激活函数的定义见式2-31，曲线图

如图2-9 所示。

¤ = {0, (¤ < 0)

¤, (¤ ≥0) （2-31）

ReLU 函数不会出现梯度衰减的现象，因为在横轴取正数时，ReLU 函数是

一条斜率为1 的直线，可以无损地传播梯度。另外，由于函数分段，计算速度加

快，由于没有指数运算，收敛速度较快[34]。

图2-9 ReLU 函数曲线图

第二章 可通行区域识别及路径生成相关理论

通过卷积层、池化层、激活函数即搭建好卷积神经网络，搭建完成后需要数

据进行训练，训练好进行预测，当滑动窗口从左到右、从上到下滑遍整个图像时，

分割任务完成[35]，分割流程如图2-10 所示。

图2-10 卷积神经网络图像分割流程

（2）确定分割结果的评价标准原理

语义分割系统的评价指标中最重要的是分割精度（Accuracy），主要的精度

指标有精确率、召回率和F1 分数。

图2-11 分割精度指标示意图

见图2-11，TP 代表分类准确的正类，TN 代表分类准确的负类，FP 代表分

类错误的负类，FN 代表分类错误的正类，通过TP、TN、FP 和FN 的数据可以

计算出反映分割精度的各个指标[36]。

精确率计算如公式2-32 所示，是用分类准确的正类数量与全部预测为正类

的数量做比值，代表预测正类中实际正类的比例。

¤¤ⅇ¤ⅈ¤ⅈ¤¤ =

¤¤+¤¤ （2-32）

召回率计算如公式2-33 所示，是用分类准确的正类数量与实际正类的数量

做比值，代表实际正类中，被预测准确的正类的比例。

¤¤¤¤¤¤ =

¤¤+¤¤ （2-33）

第二章 可通行区域识别及路径生成相关理论

F1 分数可以平衡精确率和召回率两个指标，可以有效衡量模型整体分割性

能，如公式2-34 所示。

¤1 = 2 ×

¤¤ⅇ¤ⅈ¤ⅈ¤¤×¤¤¤¤¤¤

¤¤ⅇ¤ⅈ¤ⅈ¤¤+¤¤¤¤¤¤ （2-34）

分割模型追求分类准确的正类和分类准确的负类多，分类错误的正类和分类

错误的负类少，反映在指标上就是追求精确率和召回率的提高。

2.2.2 路径生成原理

由于道路在相机水平拍摄的形状是远小近大的，所以对于路面来讲，图片中

道路的信息呈现的是梯形的形状且符合大部分路面信息的形状规则，所以本文采

用对道路信息的最小外接梯形提取导航线的方式进行路径生成。通过查找目标特

征区域的最小外接梯形，依据梯形的位置及方向来定位目标物体的位置与姿态。

通过道格拉斯-普克算法[42]能够得到道路信息的最小外接梯形。该算法将曲

线离散化由离散的点进行表示，并根据大体轮廓进行滤波处理。其算法描述如下：

（1）在曲线首尾两点A，B 之间连接确定曲线的弦AB；

（2）点C 为曲线上离该弦距离最大的点，并计算C 与弦AB 的距离，以d

（3）对d 与阈值进行大小的比较，如果距离小于阈值，则该直线段作为曲

线的近似，该段曲线处理完毕。

（4）如果距离大于阈值，则用点C 将曲线分为AC 和BC 两段曲线，并分

别对两段曲线进行（1~3）步骤的处理。

（5）处理完毕后，依次连接各个分割点形成的折线作为新曲线的近似。

2.3 本章小结

本章就介绍本文两大主要框架内容在存在负障碍条件下的可通行区域识别

和在行间行驶的可通行区域识别与路径生成进行相关理论介绍，先结合户外种植

园行间的环境，分析了存在负障碍条件下结合车辆自身参数与地形参数结合的预

测。最后对行间道路信息图像进行了基于U-Net 的图像语义分割模型构建原理以

及评价标准选取原理分析以及路线的生成方式原理。

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析及方案设计

第三章 户外种植园行间可通行区域识别与路径生成技术

需求分析及方案设计

3.1 户外种植园行间可通行区域识别与路径生成技术需求分析

户外种植园是典型的非结构化环境，存在光照变化大、路面起伏等特点。标

准的种植园对果树定植，形成具有一定规律性的种植模式。户外种植园定植后，

形成的行间区域是种植园中可通行区域，为土质松软路面，因此行间地面存在坑

洼不平的情况，对于轮式移动机器人通过性提出了挑战，户外种植园行间典型环

境如图3-1(a)所示。坑洼（负障碍）、土包（正障碍）是两种典型的会限制轮式移

动机器人通行的地形，负障碍区域如图3-1(b)所示。

(a)户外种植园行间场景 (b)负障碍区域

图3-1 户外种植园行间场景图

图3-1(b)中，箭头a 指示区域为低于水平面且相对于水平面有明显陡坡的区

域为负障碍区域，其中箭头b 指示区域为水平地面区域。因此，如何确定轮式移

动机器人的越障能力、检测地面障碍区域，并确定移动机器人是否能够通过是轮

式移动机器人行间运行问题的基本问题。

本文主要解决的三个问题为：

（1）轮式移动机器人的可通行路面的参数和参数范围。

（2）符合行间实际环境的负障碍参数检测和提取方法。

（3）户外环境下行间地面识别及可通行区域约束下的路径生成方法。

针对以上问题，课题组已完成的轮式移动机器人移动平台如图3-2 所示。

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析及方案设计

图3-2 轮式移动机器人平台整体结构图

图3-2 中，(a)为接近角、(b)为离去角；(c)为纵向通过角；(d)为轮距；(e)为

轴距；(f)为最小离地间隙，上述(a)、(b)、(c)、(f)参数为轮式移动机器人纵向通过

性分析的关键参数。(d)、(e)参数为车辆部分设计参数，图3-2 中移动机器人平台

的车辆整体设计参数与纵向通过性限制参数如表3-1 所示。

表3-1 轮式移动机器人平台整体参数表

参数 满载重量 空载重量 车高 车宽 轮胎直径 前轴载荷 后轴载荷

单位 kg kg mm mm mm kg kg

数值 570 270 1250 1028 425 116.1 108.8

参数 接近角 离去角 纵向通过角 最小离地间隙 轮距 轴距

单位 ° ° ° mm mm mm

数值 47.6 24.9 106.42 245 778 565

图3-2 中移动机器人平台的通过性限制参数如表3-1 所示，前轴载荷与后轴

载荷描述移动机器人平台静止时标称质心偏移的能力；接近角描述移动机器人平

台前端与水平地面发生触头事故的极限参数；离去角描述移动机器人平台后端与

水平地面发生拖尾事故的极限参数；纵向通过角描述移动机器人平台静止时标称

通过障碍物尺寸；最小离地间隙描述移动机器人平台静止时标称能通过最大障碍

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析及方案设计

物高度。上述纵向通过性限制参数综合描述了轮式移动机器人平台纵向通过能力。

表3-2 汽车通过性评价标准

参数 接近角(°) 离去角(°) 纵向通过角(°) 最小离地间隙(m)

数值 36 30 23.5 0.260

标准数值来源：GBT 12541-1990《汽车地形通过性实验方法》

通过表3-1 中轮式移动机器人平台纵向通过性参数与表3-2 中的评价标准数

值相比较的结果可知，当轮式移动机器人平台进入障碍地形并发生触头事故时，

机器人的接近角为高于标准的47.6°，说明该平台在纵向行驶时不易发生触头事

故；当其远离障碍地形且发生拖尾事故时，离去角为远高于标准的90°，说明该

平台驶出障碍的能力较强；该平台可以越过正反坡面与轮胎相切点构成最大夹角

为54°、最小离地间隙为245mm 的障碍物。所以根据以上通过性限制参数对车

辆通过性的评价，可以得出车辆具有较强的跨越恶劣地形的纵向通过能力。

上述通过性分析只考虑了车身外形设计对于触头、拖尾和触底事故的通过性

限制，没有考虑表3-1 所示的整车设计参数约束。车辆的通过性是相对于地形的，

对户外种植园行间的通过性分析还应结合地形感知，识别出综合车辆通过性限制

参数与地形感知的可通行区域，并根据可通行性信号对可通行道路进行识别并生

成行驶路径。

3.2 行间地形感知及可通行区域识别方案设计

在户外种植园行间环境下，轮式移动机器人平台面对到的地形更多是由疏松、

坚硬相间的土质以及经碾压或未经处理过的负障碍区域构成，轮式移动机器人平

台在道路行驶中经过这些负障碍区域，平台的姿态会随着地形的随机性变化发生

不同程度的倾斜。单纯以轮式移动机器人平台外形参数得到的纵向通过能力，不

能满足在户外环境下的移动机器人通过能力，在倾斜状态下质心的偏移程度与跨

越负障碍最大尺寸能力是轮式移动机器人能否发生倾翻的重要因素，避免轮式移

动机器人发生倾翻现象是其安全行驶的关键。

户外种植园行间是一个非结构化的环境，存在道路凹凸不平的问题，影响移

动机器人在行间通行。负障碍的长度、宽度、深度以及坡度是对车辆通过性产生

影响的关键因素。负障碍具有坡度变化明显、平均深度低于地面深度的特点，负

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析及方案设计

障碍可以通过提取坡度、尺寸信息的方式进行测量与评价，因此采用垂直于地面

拍摄的深度相机采集地面负障碍的深度来计算坡度及其尺寸，并采用陀螺仪采集

的三轴偏转角度进行地面起伏度估计。

本文首先对行间可通行区域识别与路径生成系统进行了行间地形感知及可

通行区域识别的研究。其次将地形感知及可通行区域识别的研究分为整车通过性

分析和地形识别两个部分进行研究，如图3-3 所示为地形感知与可通行区域识别

的整体流程图：

车辆、地形通过

性假设与分析

地形特征提取

整车通过性分析

车辆与地形特征结 合预测的通过性判

获得可通行区

图3-3 行间地形感知及可通行性识别整体流程图

如上图3-3 所示，在地形感知与可通行区域识别中，首先对车辆与地形的相

对位置处的通过性进行假设与分析，其次结合平台的倾翻角度阈值以及最大越障

尺寸进行整车通过性分析，获得综合通过性限制参数。再次将整车通过性分析后

的综合通过性限制参数与通过地形感知获得的坡度和深度信息相结合进行综合

可通行性的检测与可通行区域的识别，最终识别出地形的可通行区域。该识别系

统通过对从环境感知到的地形深度信息进行对应区域的可通行区域识别，地形感

知及可通行区域识别的整体工作流程如图3-4 所示：

平台结构通过

倾翻角度阈值、 最大越障尺寸预

整车通过性检测

地形信息 数据采集 像素、空间坐

处理 可通行性判

可通行区域识别

平台通过性综合

图3-4 地形感知与可通行性识别整体工作流程图

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析及方案设计

对于表3-1 中给出的根据车辆外形设计考虑的车辆通过性限制参数，限定了

车辆在纵向通行时的触头失效和拖尾失效角度以及对于跨越固定尺寸负障碍的

能力，但通过车辆外形限定的通过性参数仅局限于车辆的纵向直线行驶过程，没

有考虑负障碍中深度不均的特点。所以需要结合地形感知进行负障碍通过性的进

本文根据地形的坡度和起伏度特征，通过固定安装的Basler ToF 3D 深度相

机进行实时深度数据的采集。考虑到相机在固定安装时车辆的位姿会随着地形起

伏度的变化而变化，进而产生对深度数据的影响，本文选用维特智能JY901 陀螺

仪对其三轴偏转角度进行实时测量。通过坐标系畸变校正和陀螺仪位姿校正得到

真实的深度数据。进而对地形图像中的每个像素点所对应的距离数据进行坡度卷

积计算得到坡度值，实现对地形的坡度特征提取。最后结合平台通过性综合限制

参数，识别出相机视野内的可通行区域。

行间地形感知及可通行区域识别系统，能够对地形进行感知和目标区域的锁

定。由于本课题是进行基于地形感知与可通行区域识别的预测问题研究，所以将

深度相机和陀螺仪安装于车体前方的固定位置，进行对机器人正常行驶时的视野

内的地形进行感知，识别可通行区域，以达到对地形的感知及可通行区域的识别，

安装位置如图3-5 所示：

图3-5 地形感知及可通行区域识别系统安装位置示意图

地形感知模块安装在车体的前部0.85m 处，距离地面1.05m 处，如图3-5 所

示，箭头a 指示处安装一款垂直于地面拍摄的深度扫描相机，进行对地形深度数

据的感知；箭头b 指示处为相机所在刚性平面放置的陀螺仪。感知系统安装的位

置考虑到车体前端触头失效和摄像机成像原理并通过陀螺仪进行位姿校正减少

动态观测产生的误差风险。

第三章 户外种植园行间可通行区域识别与路径生成技术需求分析及方案设计

3.3 行间道路识别与路径生成方案设计

户外种植园行间环境复杂多变，存在大量的干扰因素，不能够准确地将道路

提取出来，在自然环境以及视角的变化下，道路特征是不规则的，在前景图像中

任意对象间的相互遮挡问题，使得道路的特征部分丢失或重叠。通过基于深度学

习的图像语义分割模型进行道路识别与路径生成，能够有效克服环境中多特征干

扰和道路特征不规则的影响。

本文首先对户外种植园环境进行数据量为1060 张的种植园行间图像数据进

行采集。进而通过人眼对图像数据进行人工标注，标注出天空、树木、背景、道

路四类特征，然后将所标注出的数据通过Labelme 进行裁剪最终得到1060 张图

像数据的数据集。通过模型构建模块的设计，达到对这1060 张人工标注的数据

集方式的学习方式。根据户外种植园行间图像的特点构建图像语义分割模型并选

择具有较高精度与环境抗干扰能力的深度卷积神经网络分割模型。模型训练过程

包括下采样和上采样两个过程，共包含九个模块，最终使用分类函数完成了图像

多分类任务，实现了将输入模型的图像分割成树木、天空、地面、背景四部分后

输出的效果。最后根据图像处理原理，将四分类中的道路部分提取，并根据环境

道路近大远小的特征确定道路最小外接梯形，最终确定沿行驶方向上的行驶路径。

3.4 本章小结

针对户外种植园行间场景下的道路情况，本章首先进行了可通行区域与路径

生成方法的技术需求分析，并确定了可通行区域识别与路径生成系统的路线和方

案。将可通行区域识别与路径生成分为地形感知与可通行区域识别和道路识别与

路径生成两部分。简述了地形感知与可通行区域识别部分中通过平台自身通过性

限制参数与整车通过性限制参数结合获得平台通过性综合限制参数的方案路线，

进而将此通过性综合限制参数与地形深度信息感知处理后的坡度和障碍尺寸结

合得到道路的可通行区域。最终通过道路识别与路径生成部分，简述了图像语义

分割模型的道路识别并最终生成行驶路径的方案路线，实现了轮式移动机器人平

台的安全行驶。

第四章 行间地形感知及可通行区域识别

第四章 行间地形感知及可通行区域识别

本章对于户外种植园行间场景下的地形感知及其可通行区域识别进行了以

下四个部分内容的研究：

（1）轮式移动机器人平台结合地形的通过性假设与分析。

（2）基于倾翻角度和最大跨越尺寸的平台通过能力分析。

（3）基于深度感知的地形高程描述及其特征提取分析。

（4）结合整车通过性限制参数与地形特征的道路可通行区域识别。

4.1 车辆、地形相对通过性假设与分析

根据车辆固性连接的特性，在检测到视野内负障碍时，对车辆面对不同负障

碍的地形做出以下情景假设：

假设1：负障碍左右宽度和前后长度均大于对应位置处车辆的空间结构参数。

假设2：负障碍左右宽度大于或等于两侧车宽、前后长度小于前后车长。

假设3：负障碍左右宽度小于两侧车宽、前后长度大于或等于前后车长。

假设4：负障碍左右宽度和前后长度均小于对应位置处车辆的空间结构参数。

通过对以上情景的假设，可以得到如图4-1 所示的各个场景下车辆与负障碍

的相对位置示意图。

第四章 行间地形感知及可通行区域识别

图4-1 (a)情景假设1；(b)情景假设2；(c)情景假设3；(d)情景假设4

图4-1(a)为情景假设1：检测到负障碍的左右宽度和前后长度均大于相对位

置处车辆的空间结构参数时，前后轴处车轮全部或单侧进入凹陷状态。

图4-1(b)为情景假设2：检测到负障碍的左右宽度大于等于、前后长度小于

相对位置处车辆的空间结构参数时，前后轴侧车轮进入单侧凹陷的状态；左右端

单侧车轮依次进入凹陷的状态。若三个轮子仍在平面，则可能会出现一个轮子悬

空的情况，再落下时可能会发生倾翻事故；车辆在负障碍两侧边缘直线行驶不发

生车轮凹陷的状态。

图4-1(c)为情景假设3：检测到负障碍的左右宽度小于、前后长度大于等于

相对位置处车辆的空间结构参数时，左右侧车轮进入单侧凹陷的状态或全部陷入

图4-1(d)为情景假设4：检测到负障碍的左右宽度和前后长度均小于相对位

置处车辆的空间结构参数时，左右端车轮进入单侧凹陷的状态。

根据上述对车辆跨越负障碍所遇到的所有情景中负障碍区域与车辆结构参

数结合的假设与分析可知，车辆发生倾翻事故和凹陷状态由车辆的空间尺寸与负

障碍构成的整体的空间尺寸决定。当车辆单侧方向上的空间尺寸小于负障碍的空

间尺寸时，车辆发生倾斜，甚至发生倾翻事故。因此对于负障碍地形的跨越能力

分析，优先根据负障碍与车辆的结构参数对比，判断出车辆直接跨越负障碍的能

力，当车辆单侧的空间尺寸小于负障碍的空间尺寸时，需要对车辆的极限倾翻角

度和最大越障尺寸进行限制参数的求取，保证轮式移动机器人具备一定的跨越负

第四章 行间地形感知及可通行区域识别

4.2 车辆通过性分析

4.2.1 基于纵向、侧向的轮式移动机器人平台倾翻角度阈值分析

轮式移动机器人在户外种植园行间环境中的行驶状态分为静止状态、匀速直

线运动状态和圆周运动转向状态。车辆因地面起伏的不确定变化导致车身侧倾、

前倾以及斜倾，进而造成车辆发生侧翻、前翻的危险情况。其中斜倾会因刚性连

接的轮式移动机器人平台自身内部受力条件所克服，所以在负障碍内运行条件下，

车身形体发生的改变可忽略不计。

车辆触发倾翻的条件为：当车辆一个轮胎与地面的接触面积为0

2 m 时，即当

左右单侧车轮的正向力为零时，车辆即将发生倾翻，并且当汽车重力分解在侧翻

台的压力和下滑力对汽车产生的转矩相等时，车辆姿态到达其发生倾翻的临界阈

值。图4-2(a)、(b)分别为轮式移动机器人侧翻、前翻极限情况下的受力分析图。

(a)车辆侧翻 (b)车辆前翻

图4-2 车辆倾翻受力分析图

在图4-2(a)中，根据公式4-1 所示的牛顿第一定律对静止于固定斜面时的轮

式移动机器人平台进行受力分析。

0 0 =  = 

dt dv F

其中 i i

F  为合力，v 为速度，t 为时间，i 为作用力序号。车辆整体所受外力

围绕车辆与斜坡的下侧轮胎接触点A 的动力矩守恒分析如公式4-2 所示，规定逆

2 0 0 Z y mghsin mgb cos F B ma h   − +  − = （4-2）

公式4-2 中，m 为整车的质量，g 为重力加速度，B 表示车体的轮距，h 表示

第四章 行间地形感知及可通行区域识别

质心的离地高度，0b 为车辆质心到左下侧车轮的距离，为车辆发生侧翻时的倾

翻角， 2 Z F 为车辆与斜坡的上侧轮胎接触点C 处所受的正向力， y a 为重力加速度

关于y 方向的分加速度。当车辆匀速直线行驶发生侧翻时， 2 0 0 y Z a F = = ， ，将

此倾翻临界条件代入4-1 与4-2 中，并联立4-1 和4-2 式，可得轮式移动机器人 如4-3 所示的侧翻角度正切表达式。

0b tan h =

直线行驶时，侧翻角与质心到左下侧车轮的距离 0b 和质心离地高度h 有关，

所以当车辆动态行驶时，由于质心位置变化，侧翻角要比 0b h 小，当车辆进入匀速

曲线行驶时的正切表达如式4-4 所示。

1 0b ay tan h g cos   = + 

公式4-4 所表示的侧翻角度的正切表达公式表明，匀速行驶时的侧翻角度大

于直线行驶中的侧翻角，因此当平台直线行驶或曲线匀速行驶时，平台向内侧翻

的概率减小。公式4-5 为车辆整体所受外力对车辆与斜坡的上侧轮胎接触点C 的

动力矩守恒分析下，规定顺时针为正。

1 0 0 y Z ma h mghsin mgb cos F B   − − +  = （4-5）

式4-5 中， 1 Z F 为车辆与斜坡的上侧轮胎接触点A 处所受的正向力，根据对

4-4 式的推理过程，可进一步根据公式4-5 得到式4-6 所示的向心加速度与重力

加速度的比值，即道路坡度角与车辆倾翻角之间的关系为：

1 0 1 Z y F B a b cos sin g h mg     = − +    

在公式4-6 中，弯道行驶发生侧翻的临界条件为 1 0 Z F = 且当角较小时，

sin cos 1    = = ， ，将此临界条件代入式4-6 中可得式4-7 的简化判别公式。

y 0 a b g h  = +

公式4-7 中， 0b h 为侧翻阈值，可评估车辆抵抗侧翻的能力。

由于轮式移动机器人的结构较为复杂，因此需要在Adams 系统中建立车辆

第四章 行间地形感知及可通行区域识别

的实际模型，根据表3-1 可知前轴载重116.1kg，后轴载重108.8kg，利用Adams

中view 模块并结合第二章式2-9、2-10 的求解，计算出平台满载和空载时的质心

的切向距离与垂向高度。

由于车辆前翻模型与侧翻模型分析过程一致如图4-2(b)所示，同侧翻原理可

得其侧翻阈值为 0l h ，其中0l 为质心到车辆前轴方向的距离，L 为车辆轴距。车辆

前翻、侧翻角度如表4-1 所示。

表4-1 车辆前翻、侧翻角度对应表

— 质心切向距离（mm） 质心垂向高度（mm） 倾翻角（°）

侧翻满载 0 329.38 l = 0 653.6 h = 26.7

侧翻空载 0 332.95 l = 0 459.09 h = 35.9

前翻满载 0 314.49 b = 0 653.6 h = 25.7

前翻空载 0 283.39 l = 0 459.09 h = 31.7

将表4-1得到的在满载和空载时的质心位置信息与极限倾翻角度参数和车辆

自身的通过性限制参数的综合分析中可知，在纵向角度通过性方面，车辆自身的

接近角和离去角构成的角度阈值为47.6°~90.0°，车辆前翻角度阈值为25.7°~31.7°，

前翻角度阈值远小于接近角和离去角构成的角度阈值。所以车辆先发生前翻事故，

后发生触头、拖尾事故，在现实情况下，当发生其中一个事故时，车辆立即停止

行驶，因此在此纵向角度通过性判别中，首要考虑倾翻角度阈值作为车辆通过性

检测的纵向角度阈值约束。侧向角度阈值约束选取本节的侧翻阈值26.7°~35.9°。

最终得到轮式移动机器人在户外种植园行间环境下行驶的纵向、侧向角度阈值约

4.2.2 基于顶起失效判断和跨越固定尺寸负障碍能力的越障能力分析

车辆是否能顺利通过负障碍区域，还需考虑车身底盘是否会在行驶时与地面

发生剐蹭，剐蹭对车身造成了损害，进而可能造成车身发生倾翻事故，影响轮式

移动机器人的通过性。所以还应对发生车底剐蹭的临界约束进行分析，根据汽车

理论中的车辆顶起失效原理[38]，对本课题组的轮式移动机器人平台发生顶起失效

的过程如图4-3 所示。

图4-3 中 0 为车辆一个车轮刚好滚过障碍顶点时对应的水平面与地隙圆心

的夹角；D 为车轮直径； w h 为车离地最大高度（即汽车中部地隙）； r D 为地隙直

径；L 为车辆的轴距；l 为车轴中心到地隙圆心的距离； 0h 为车辆重心到底盘的

第四章 行间地形感知及可通行区域识别

图4-3 轮式移动机器人平台顶起失效图

根据第二章的理论顶起失效判别关系推导，若平台参数满足公式2-23 所示

的不等式的判定条件，即车辆纵向不发生顶起失效。通过平台已知参数与图4-3

的实际模型分析，纵向地隙圆心O 所对应的车辆接触点构成的圆周角 BAC  即

为车辆的纵向通过角，根据表3-1 可知纵向通过角为106.42°，进而根据图4-3 所

示模型中的对称车辆切点圆的垂直平分特性，可知 1 为纵向通过角的一半，由

于圆O 内OA=OB，根据等腰三角形原则可知，1 = 2 =53.21°，并且在梯形BAEF

中，已知 2 与 1 的补角，并且OF 垂直于车轴，所以根据梯形内角和360°的特

性可得 0 为16.42°。在EOF  中可得到 0 与地隙直径 r D 之间的如4-8 所示的关

系，进而得到 r D 的值为164.155mm。

L D D = + （4-8）

通过顶起失效判别后，本课题组的轮式移动机器人平台满足此顶起失效的不

等式条件，即平台纵向行驶时不会发生底盘剐蹭现象。对于本课题轮式移动机器

人平台跨越负障碍的能力，还需要对其进行如图4-4、4-5 所示的经过动力学分析

后的负障碍越障能力分析。

如图4-4 所示为轮式移动机器人平台进入负障碍时的受力分析图，当平台前

轮与负障碍平面进行接触时，对平台分别进行水平方向和垂直方向的受力分析。

对平台进行水平方向、垂直方向以及力矩方向进行如公式4-9所示的动力学分析，

规定逆时针方向为正方向。

第四章 行间地形感知及可通行区域识别

图4-4 前轮进入负障碍时车辆的受力分析图

sin 0 0

cos sin cos 0 2 2

F cosα F sinα+ F G F sinα F F cosα Gcos

F D D G b h -F Lcos F L

    

     

+ − =   + − − =     + − − − =      

公式4-9 中G 为平台重心位置；a，b 分别为车轴的长轴和短轴距离；车轮

1F 为后轴载荷； 2F 为负障碍作用于从动轮（前轮）的反作用力；为机器人的附

着系数；β 为车辆的俯仰角； w h 为受力点与最低点垂直距离； 0h 为重心与底盘的

通过对公式4-9 中G、 1F 、 2F 的消除可求得如4-10 公式所示的附着系数与

已知参数的无因次关系方程。

( ) ( ) ( )

( ) ( ) ( )

1 cos cos cos 1 cos 1 2 2

cos sin 1 sin 1 cos sin sin sin 1 cos 2 2

1 cos sin 0

D D b L L h

         

          

   

    + − + + − + − +        

  + − + + + −     − + =

（4-10）

当平台后轮驶出负障碍而前轮不处于负障碍中时，受力分析如图4-5 所示，

同前轮进入负障碍的理论分析原理，对图4-5 所示的平台后轮进行受力分析并对

后轮进行如4-11 式所示的动力学分析：

sin 0 0

sin cos sin sin 1 0 2 2

Fcosα F sinα- F G F sinα F Fcosα Gcos

F D G a h +F Lcos F D

    

      

− − =   + + − =    − − + − − =      

（4-11）

第四章 行间地形感知及可通行区域识别

图4-5 后轮驶出负障碍时车辆的受力分析图

同前轮如式4-10 的处理方式，可得附着系数与已知参数的无因次关系方程：

2 2 2 0 0

cos cos cos sin sin 1 sin sin 2 2 2

sin 1 sin cos cos 0 2

D D D a a h h L

           

     

    − + + + − − + + − +        

（4-12）

对于式4-12，轴距大、前轴负荷大的车辆，其后轮越过负障碍的能力要比前

轮大，因此在考虑纵向通过能力参数时，优先考察前轮克服负障碍的能力。如4-

6 的示意图所示，当前轮刚好卡在负障碍的内部且不触底时，可得出所示的受力

点与最低点垂直距离 w h 。

图4-6(a)为前轮进入负障碍的实际场景图，图4-6(b)为前轮进入负障碍的数

学模型。图4-6(b)中dl 为车辆越过负障碍的最大宽度；w h 为车辆此状态最低点的

垂直距离即越过负障碍最大深度；B、N 为前轮与负障碍的接触点，当车辆刚好

卡在负障碍内，B 点为车辆的脱离临界点；E 点为临界点与最低点的垂直相交点。

w h 由车辆参数决定，将图4-4 中α 对应的三角关系可知， 2 sin 1 w h D = − 及

0 f = ，因此解得α 的值，并可由公式4-10 求得dl 。

通过由公式4-13 所示的dl 与 w h 对应关系并结合轮式移动机器人平台已知参

数，求得dl 满载时为424.7mm，空载时为357.0mm，w h 满载时为204.6mm，空载

时为100.7mm。

第四章 行间地形感知及可通行区域识别

(a)前轮进入负障碍实际场景图 (b)前轮进入负障碍数学模型

图4-6 最大越障深度 w h 求解原理

( ) 2 d w w l D h h = − （4-13）

dl 作为已知条件对负障碍纵向宽度进行条件分割，大于dl 的区域则为车辆不

可跨越的负障碍纵向宽度。

对于侧向方向，车辆在负障碍行驶过程中，由于车轮两侧高度不一，会出现

底盘与到由负障碍之间的间隙构成的陡坡之间的剐蹭，对于侧向方向上面的阈值

选取，为防止发生因底盘凹陷导致的拖尾事故，本文采取坐标系动点联系法，寻

找相同位置处的深度进行高差比较。

如图4-7 所示为侧向深度判别原理示意图，O 为坐标原点，即深度相机的拍

摄位置，建立如图所示的坐标系，A、B 为车轮与地面的接触点，C 为底盘直线

M 上的一动点，D 为地面曲线N 上的一动点，C、D 两点Y 向坐标相同，设点

( ) , C C C Y Z ， ( ) , D D D Y Z ，OT 长度为L。

如公式4-14 所示，若满足当底盘上的动点C 的距离值 C Z 与地面曲线上的动

点D 的距离值 D Z ，均有 C Z < D Z ，则车体不会接触地面。

( ) c c Z =Lcos - Y -Lsin tan    （4-14）

通过轮式移动机器人平台的力学特性和结构特性可知，相机拍摄位置与平台

上任一点的位置不发生相对位移，从平台相对不变的坐标位置出发，与地形对应

坐标点进行加权比较，进而得到如公式4-14 所示的侧向深度判别条件。

综合4-1 关于整车的通过性分析，得到车辆通过倾翻极限判断获得的角度阈

值处于接近角和离去角的限定范围之内，所以选取倾翻极限角度阈值作为整车通

过性角度限制方面的限定参数，满载时为25.7°~31.7°，空载时为26.7°~35.7°。

第四章 行间地形感知及可通行区域识别

图4-7 侧向深度判别原理示意图

关于对顶起失效和越障能力情况研究得到了车辆行驶时纵向的越障宽度dl

限制阈值为357.0mm~424.7mm，最大深度 w h 的限制阈值为100.7mm~204.6mm。

进而得出整车通过性对于角度、长度、宽度、深度上的限定参数。

4.3 地形特征提取分析

4.3.1 地形相对不变性证明及其相关假设

在户外种植园行间环境下，相对于室内或相对结构化的环境，行间负障碍的

检测条件较为复杂，地面粗糙且有起伏。在行间行驶的过程中，基于4.2 节研究

得到的车辆通过性角度阈值约束，进而得到车辆跨越负障碍地形的角度边界，进

而进行对负障碍中存在的可提取的相对不变特性研究。车辆对地形拍摄状态如下

图4-8 所示。

轮式移动机器人进入负障碍后，车体会前倾，其俯仰角度为，t 为水平地

面，t为偏转后的平面，在t 水平地面上，轮式移动机器人平台固定的相机位

置P 点的高度为 H P ，离车体重心 G O 的距离为 LP ，在t平面上，P 点的高度为 H P，

离车体重心的距离为 LP。

通过分析轮式移动机器人平台在偏转前后的几何关系，可知直角三角形

QSR PST   ∽ ，可得如公式4-15 的高程关系。

第四章 行间地形感知及可通行区域识别

图4-8 地形拍摄模型

( ) L H H

P L sin P P cos

  + + = （4-15）

其中的L 表示车体重心到后轮的距离。公式4-15 表示因相机与车体刚性连

接，相机与重心的水平距离不变时的对应位置关系。若车辆俯仰角的改变较小，

得到公式4-16 表示的结论。

L L P P = （4-16）

( ) H H L P P P L     + +  （4-17）

当车辆的俯仰角改变较大时，由公式（4-16）和（4-17）可以做出如下分析：

（1）因行间道路非结构化的特点，视野内各点的高程值会发生较大的改变，

改变的值由视野中的点到车身的距离和偏转角度决定；

（2）相机视野中的任意一点到车身重心的距离不随参照平面的改变而改变；

综合(1)、(2)两个结论可以得出，视野中某点的邻域内任意两点的相对高程

保持在移动机器人因路面颠簸而发生位姿改变时保持不变。

在对轮式移动机器人平台采集到的地形深度数据处理之前，需要对深度数据

的特征进行以下四点假设：

假设1：根据第二章2.2.2 节对于轮式移动机器人和深度相机采样频率的匹

配性结论，轮式移动机器人平台的采集过程，其车体的行驶速度与相机采集频率

产生的误差，符合统计学的误差规定。采集到的距离值准确，地形特征是随时间

变化的连续函数。

第四章 行间地形感知及可通行区域识别

假设2：根据行间环境下非结构性的地形可知，地形的高程分布是随机的，

不一定连续。

假设3：深度信息采集时地面不发生绝对运动，拍摄视野内无干扰，可视范

围内的道路信息是静止不变的。

根据前一节的相对高程不变特性，和以上四点假设，采取数字高程模型来对

这一相对不变特征进行描述，高程图在二维平面中使用规则网格的深度信息来描

述环境。对于平面域内任意一点( ) y x, ，对应着单一的高度值 ( ) y x, h = z 。

4.3.2 坡度计算

在地形特征的相关假设下，本文根据地形的相对不变高程特性进行特征提取

[37]，对于户外种植园行间环境下的负障碍地形，具有地面起伏、地面粗糙等特点。

结合4.3.1 的假设以及地形的特点，本文选择提取地形的坡度，并结合车辆于纵

向和侧向的极限倾翻角度限制参数，进而实现对地形可通行区域的识别。

如图4-9 所示为多负障碍高程描述图，箭头a 指示的蓝色区域为水平地面区

域；箭头b 指示的为负障碍的底部区域。从图4-9 的整体可以清晰地看到多负障

碍的大致轮廓，但其轮廓边缘存在着深度不均匀、数据偏离实际测量值的特点。

图4-9 多负障碍高程图

例如箭头a 指示的水平地面实际测量高度为1050mm，而图中数值大约为

1140mm，相差80mm；箭头b 指示的底部红色区域的实际数值应为1440mm，但

图中数值约为1190mm，有较大偏差。轮廓数值不稳定呈强波动性。这样的数据

对坡度提取造成了极大的干扰。对此本文采用核大小为3 的3*3 矩阵对所有高程

值进行中值滤波保留其整体轮廓、去除干扰数据值。

第四章 行间地形感知及可通行区域识别

地面上某点的坡度表示地面在该点倾斜程度的矢量。坡度的模值等于负障碍

曲面函数在该点的切平面与水平面夹角的正切，其方向等于在该切平面上沿最大

倾斜方向的某一矢量在水平面上的投影方向。

位置( ) ,i j 处的坡度数值计算方法采用二次曲面拟合的数值解法[8][38]，采用

3×3 坡度卷积模板。模型如图4-10 所示。

( ) -1, -1 f i j ( ) -1, f i j ( ) -1, 1 f i j +

( ) , -1 f i j ( ) , f i j ( ) , 1 f i j +

( ) 1, -1 f i j + ( ) 1, f i j + ( ) 1, 1 f i j + +

图4-10 坡度卷积计算模板

根据图4-10 的坡度卷积计算模板对整个图像每个像素数据进行卷积计算，

即可得到关于X，Y(侧向、纵向)方向的坡度值，公式4-18、4-19 为X，Y 方向上

的坡度计算：

( ) ( ) ( ) ( ) ( ) ( )

1, 1 2 1, 1, 1 1 8 1, 1 2 1, 1, 1 X

f i- j- f i- j f i- j

d -f i j- - f i j -f i j

+ + +    =    + + + +     （4-18）

( ) ( ) ( ) ( ) ( ) ( )

1, 1 2 , 1 1, 1 1 8 1, 1 2 , 1 1, 1 Y

f i- j- f i j- f i j-

d -f i- j - f i j -f i j

+ + +   =    + + + +     （4-19）

其中， X 为侧向坡度， Y 为纵向坡度，d 为高程网格间距，其中 1 d=  。

式4-18、4-19 中的坡度计算是根据高程上两点的相对高度而来，因此地形的坡度

特征同样具有相对不变性。

4.4 可通行区域识别综合分析与决策

通过对整车的通过性分析与地形特征提取的研究，得到了车辆在不同情况下

的倾翻角度限制阈值参数，以及轮式移动机器人平台在户外种植园行间环境下行

驶时的地形坡度提取方法。本文通过将高程上各像素点的坡度值进行纵向和侧向

的车辆位姿角转化，并通过与整车通过性角度限制阈值参数的比较，得到视野内

经角度阈值判别后的可通行区域；根据移动机器人平台能够跨越的最大负障碍宽

度、深度，对负障碍地形的宽度和深度进行对比，得到经最大越障尺寸判别后的

可通行区域。最后融合角度和最大越障尺寸识别的结果即为本文的探究的最优可

通行区域。算法流程如图4-11 所示：

第四章 行间地形感知及可通行区域识别

输入地形灰度图

数据采集、 转换与校正

负障碍区域 通过性图像

车辆与地形 的角度匹配

车辆与地形 的越障尺寸

输出不可通行

负障碍最大宽度大于轮距且相 邻负障碍最小宽度小于轮距？

图4-11 可通行区域综合检测算法流程图

4.4.1 深度数据处理

本文通过使用Basler ToF 3D 相机对地形垂直拍摄，采集地形的深度信息。

轮式移动机器人平台的运行速度为0.3m/s，结合相机拍摄的反应时间，数据在纵

向方向产生的距离为0.015m，对于镜头57°(h)×43°(v)的视野，以1050mm 的固

定拍摄高度，换算到此视界内的实际场景范围为1.167×0.847（m），则在此速度

的移动下，纵向误差占比约为1.77%，符合统计学中的可接受误差范围，因此使

用Basler ToF 3D 相机采集的数据具有准确性。

由于在户外种植园行间场景下负障碍的拍摄存在径向、切向畸变和因地面起

伏导致的车身位姿的偏转，如图4-12 所示。其中图4-12(a)为镜头失真下的桶形

失真现象，深度数据中部底四周高，呈近小远大的趋势；通过公式4-20 得到的

h 为通过灰度范围图的灰度值计算出的光传播实际距离。

( ) ( ) 65535

v max min min

P D -D h D  = + （4-20）

其中 vP 为图像的像素灰度值， max D 为拍摄设置的最大取样距离， min D 为拍摄

设置的最小取样距离，该公式计算出的h 为光传播的实际距离并非点到相机水平

面所对应的Z 坐标值。

图4-12(b)为车辆在不平整路面拍摄地面时产生俯仰变化的效果图，其中箭

头a 指示的为深度相机采集到的实际距离值；箭头b 指示的是深度相机在理想情

况下采集到的距离值。

第四章 行间地形感知及可通行区域识别

(a)桶形失真 (b)位姿偏移

图4-12 发生镜头失真和位姿偏移效果图

当位姿发生x，y，z 三轴偏移时，对地面的垂直拍摄的深度数据产生了巨大

的误差，采集到的深度数据会随着陀螺仪各轴的偏移角度不同程度地削减。

对于上述两个深度数据校正方式，可以总体概括为相机畸变校正和位姿校正

过程。通过相机的固定内参调整像素坐标位置，达成对相机坐标系向像素坐标系

的畸变校正。通过与相机固定连接的陀螺仪获得车辆在某一时刻的三轴偏转角度，

达成世界坐标系向相机坐标系的转化，最终结合相机内参和外参校正得到精确的

地形深度数据。

（1）畸变校正

对于相机镜片所导致的径向、切向畸变的校正，本文对棋盘格标定求取相机

内部的固定参数和根据每张焦点图整合的畸变系数。

图4-13 标定效果图

第四章 行间地形感知及可通行区域识别

首先采取对相机能够输出的来自不同位置、大小、距离、倾斜程度不同的弱

反光棋盘格进行相机最易识别角点的intensity 图进行拍摄，使用matlab 中的

camera calibrator 工具箱，可简单快捷输出相机的内参系数。其中标定效果如图4-

13 所示。

在图4-13 中主区域展示的为通过对棋盘格的角点的识别，结合棋盘格的长

宽参数25×25(mm)，总数量10×7 的特性，对相机进行内参的求取。

箭头a 所指示的部分为每一张图片的平均误差值，从图中可知对所有棋盘格

校正照片的平均重投影误差为0.3，低于统计学规定的0.5，所以此标定方法求得

的内参是正确的。箭头b 所指示的部分为camera calibrator 模拟的拍摄情境。

对棋盘格的标定结果输出相机内部的径向、切向畸变参数、旋转矩阵、转换

矩阵、平均重投影误差、旋转误差矩阵、旋转值、径向切向失真系数等。

将户外种植园行间场景垂直拍摄的灰度范围图的位置坐标与得到的相机内

部参数指标代入到公式4-21 所示的径向、切向畸变的坐标校正过程。可以得到

相机经过整体畸变校正后的正确位置坐标。

( ) 

 + + + = 

x r k r k r k y

x 6 3 4 2 2 1 1 ( ) ( )

+ + + 2 2 1 2

2 2 2 1

y r p xy p

x r p xy p （4-21）

公式4-21 中x , y , x, y为处于归一化平面下考虑的位置坐标。r 为曲率半

2 2 y x r + = 2 ，1k , 2k , 3k 为径向畸变系数，1p , 2p 称为切向畸变校正系数。x ,

y 为发生径向畸变后像点的坐标，x, y为畸变校正后的正确像点坐标。计算后

可得到图4-14 所示的对此相机拍摄的灰度图的校正效果。

(a)原图 (b)系统校正图

第四章 行间地形感知及可通行区域识别

(c)校正差异图

图4-14 畸变校正效果图

4-14 图中(a)、(b)图为相机拍摄到的实际灰度图与系统校正图，差异图(c)中

的差异是由原图坐标的距离值与校正后图的新坐标的距离值的差值二值化的形

式显示的。黑色的像素点即为两个对应坐标相同的像素差值，白色部分的点即为

两个对应坐标存在较大灰度差异的像素差值，其中白色像素占比为50.5742%，

黑色像素占比49.4258%，从此数据可以得知图像中多于一半的像素发生了径向、

切向畸变，并通过畸变校正过程恢复到真实坐标位置。

（2）坐标系转换

根据tof_ccd_MN34906BL 芯片手册及Basler ToF 用户操作手册可得对于深

度数据坐标系转换所需的如表4-2 所示的相机内部参数。

表4-2 相机内部参数表

参数 焦距 分辨率 传感器尺寸 像素尺寸 原始中心坐标

相机坐标系中心

2 m  — —

数值 3.15 640×480 3931×2788 5.6×5.6 320×240 513.029×542.168

根据表4-2 所示的相机内部参数，可以得到公式4-22 所示的像素坐标系向

相机坐标系的坐标转换矩阵，进而实现相机内参校正过程。经过畸变校正和坐标

系转换到相机坐标系下的数据得到如图4-15 所示的校正效果。

第四章 行间地形感知及可通行区域识别

   

   

•   

 =   

1 0 0 0

c Z Y X

f f y x Z

（4-22）

(a)原始数据图 (b)畸变校正后数据图

(c)内参校正数据图

图4-15 内参校正后的负障碍效果图

在4-15 图中，上面的(a)、(b)图是畸变校正的过程及结果，从畸变校正结果

的数据分布可以看出，其距离数据缩减明显，校正后的距离数据与实际拍摄的距

离更加吻合，但其中心点的距离值与实际拍摄距离值出现较大误差。内参矩阵校

正后，得到图4-15(c)的校正效果，从整体效果上看，整体数据对于水平面的径向

畸变失真基本消除，但X 轴方向上整体数据的数值沿X 轴的正方向逐渐增大；

在Y 轴正方向整体数据的数值沿Y 轴的正方向逐渐减小，呈整体下降趋势，所以

应继续对相机拍摄的数据进行位姿校正。

（3）位姿校正

由于在户外种植园行间环境下，深度相机采集的深度数据会受到地形起伏

的影响，进而导致车体发生沿陀螺仪所在坐标系下的（Pitch、Yaw、Roll）轴的

第四章 行间地形感知及可通行区域识别

偏转，从而使距离数据发生成角度的放大或缩小。

对于户外种植园行间非结构化的环境以及4.4.1 第2 节的处理误差，本文选

择维特智能JY901 姿态传感模块对轮式移动机器人的实时运动状态进行快速解

算。其内部具备数字滤波技术，可有效降低测量噪声，提高测量精度。JY901 模

块的静态姿态测量精度为0.04°，动态测量精度为0.1°，稳定性高，能够以最高

200Hz 数据输出速率。姿态传感模块与轮式移动机器人平台固性连接，通过陀螺

仪读到的位姿数据进行深度数据外参校正，陀螺仪采集到的部分数据如表4-3 所

表4-3 陀螺仪采集部分数据

拍摄序号 俯仰角(°) 横滚角(°) 偏转角(°)

1.6315

1.1865

0.4999

0.8020

0.5878

0.8734

0.8405

0.9833

-3.7518

-3.7244

-3.1805

-1.9281

表4-3 所示的陀螺仪部分数据中，车辆在第38 张深度数据的拍摄前后，相

机发生了上下颠簸，在此时刻的横滚角度和偏转角度相对稳定，说明路面产生了

明显的起伏。此数据可对车辆进行精准的位姿估计，从而进行对相机平面的三轴

此校正过程统称为相机的外参校正过程，即相机坐标系向世界坐标系的转换。

根据陀螺仪的三轴的偏转角度，求出偏转坐标系变换到水平坐标系下的旋转矩阵，

三维坐标向量与旋转矩阵相乘后得到水平坐标系下的三维坐标向量，Z 坐标即为

所求的水平坐标系下的真实深度。

对由于车身位姿偏移引起的深度（距离）数据误差采用以下步骤进行校正：

（1）以相机中心为原点建立空间直角坐标系，为所有深度点赋予空间直系

（2）车载陀螺仪姿态角本质上是车身坐标系与大地坐标系之间的姿态旋转

角，因此可以参照陀螺仪数据将相机坐标系下的深度数据经空间形态学校正至世

界坐标系，如图4-16 为车身坐标系的建立和定义。

规定沿每个轴正方向顺时针姿态角为正，分别为¤¤、¤¤、¤¤由地面坐标系与

车身-相机坐标系的转换过程中，需要首先对相机拍摄到图像的第一帧的位置数

据进行相机坐标系的建立。

第四章 行间地形感知及可通行区域识别

前视图（从后向前看） 侧视图

图4-16 车身坐标系的建立和定义

由此时刻的陀螺仪数据得到车身关于世界坐标系平面的偏转角度，进而可以

得到由世界坐标系转换到像素坐标系的对应关系。根据此转换过程可以得到以下

公式4-23 所示的转换关系：

   

   

     

     

=   

1 1 O 1 0 0

1 3 3 3 0 y

c Z Y X T R v d

（4-23）

通过此转换关系，得到最后经过三轴陀螺仪校正后的结果，如下图4-17 所

示的校正前X、Y 轴和整体的效果图。

(a)校正前Y 轴结果 (b)校正Y 轴结果

第四章 行间地形感知及可通行区域识别

(c)校正前X 轴结果 (d)校正后X 轴结果

(e)校正前整体效果 (f)校正后整体效果

图4-17 位姿校正后数据及效果图

从图4-17(b)所示的Y 轴校正后效果图可以直观看出，与校正前的(a)图相比，

沿Y 轴正方向，校正后的距离数据整体趋势与水平线趋于平行。

从图4-17(d)X 轴校正后的效果图直观看出，与校正前的图4-17(c)图相比，

沿X 轴正方向，校正后的距离数据的整体趋势与水平线的数值变化较小。

从图4-17(f)校正后的整体效果图中看出，与校正前如图4-17(e)图所示的整

体深度数据相比，经过陀螺仪位姿校正后的深度数据整体呈与水平面平行的趋势。

可以说明，车辆于颠簸路面行驶下的深度误差数据得到了还原，增加了地形

特征分析的准确性。

（4）负障碍分割

根据地面距离相机高度1050mm 对由4-20 公式转换的距离数据进行横截，

横截高度以下的部分即数值大于1050mm 部分的数值，在原图像中标记，标记的

区域即为负障碍区域。如下图4-18 所示。

第四章 行间地形感知及可通行区域识别

(a)侧视图 (b)正视图

图4-18 负障碍区域图

图4-18 中，4-18(a)为负障碍区域的侧视图，箭头a 指示的为水平地面，箭

头b 指示的为负障碍底部；进入负障碍的缓坡；图4-18(b)为负障碍区域的正视

图，箭头c 所指示的为相机距离地面-1050mm 的拍摄高度线。图4-18 中高程值

随颜色红、黄、绿、蓝颜色依次增加，低于-1050 值的区域即为负障碍区域，深

度在1050mm 至1280mm 之间，与真实测量场景基本吻合。

4.4.2 直行区域负障碍通行性判别

对于已分割出的数据区域，即低于水平地形高度的负障碍区域。本文首先对

直行区域的负障碍整体区域进行了如图4-19 所示的判别流程所示。

负障碍区域 通过性图像

负障碍区域最大宽

度大于轮距？

得到直行区域

图4-19 负障碍直行区域判别流程图

对于轮式移动机器人平台，在其正前方的负障碍区域，可以通过图像处理对

拍摄到的负障碍区域的每个子区域进行最小外接矩形的描绘，进而整合子区域并

计算出整合后的最大外接矩形区域，此矩形的宽为负障碍区域的最大宽度，长度

为负障碍区域的最大长度。通过图4-19 的判别流程，对直行区域负障碍进行通

第四章 行间地形感知及可通行区域识别

(a)实际多负障碍区域 (b)图像预处理后的多负障碍区域

图4-20 对负障碍区域的图像预处理判断图

如图4-20(a)所示为实际多负障碍区域图，图4-20(b)为图像预处理后的多负

障碍区域。箭头a 指示的绿色方框区域为由水平路面进入陡坡的缓坡和负障碍区

域，与如图4-20(b)中箭头d 指示的区域相吻合；箭头b 所指为陡坡及其绿色方

框对应的负障碍区域，与如图4-20(b)中箭头e 指示的区域吻合，没有包括外部

平整路面；箭头c 指示为缓坡及其绿色方框对应的负障碍区域，与图4-20(b)中

箭头f 指示吻合。通过实际多负障碍的区域分析，与图像预处理进行方法验证，

得到了与实际匹配较为吻合的通过性图像预处理方法。

车辆纵向直线行驶时，可以根据其最大宽度和车轮间距的对比可以通过此判

别流程进行对负障碍区域的初判别：当最大宽度小于等于轮距，车辆可以沿路边

缘直线行驶通过；当最大宽度大于轮距，则进入对车辆参数与地形的可通行性判

对直行方向负障碍的初步预测后若车仍有进入负障碍的可能。当车辆进入负

障碍时，地形的坡度与车辆的位姿角是不同的两个角，所以对车辆极限倾翻角对

坡度进行判别之前，需要计算车辆位姿角与地形坡度之间的关系。

4.4.3 综合车辆通过性约束与负障碍地形分析的可通行区域识别

本文通过4.1、4.2 节，分别研究并设计了关于车辆通过性角度阈值约束，和

地形的相对不变特征分析，轮式移动机器人平台对于户外种植园行间场景下的负

障碍识别工作，需要进一步结合两种限制约束，进行对地形更为准确地描述，综

合多约束条件下的地形可通行性识别如图4-21 流程所示：

第四章 行间地形感知及可通行区域识别

输入分割后的.txt深度

对x，y方向上求坡 度并转换到对应的

经对x，y方向分别进行位姿角分析后大于各

方向对应的位姿角？

宽度判断：对表面ld长度进行判断，几何中心点 向两边移动，求到y方向最大处的距离小于等于ld？

深度判断：对比能越过垂直障碍能力hw，

深度小于hw？

深度判断：根据x方向的深度判别，求得两边各 2/B位置点所构成的车辆倾斜状态下底盘处的位置高

度，若底盘上的点深度小于地形上对应点深度？

不可通行区域2

可通行区域1

不可通行区域1

可通行区域2

角度判断：对中心线上面的点的对称左右两边各2/B 位置处的点的高程值进行高差求取，根据坡度与位姿角

的对应关系，求出这个方向上对应的车辆倾斜角度。

图4-21 综合多约束条件下的地形可通行性识别流程

通过图4-21 的识别流程，对轮式移动机器人平台纵向、侧向分别进行结合

车辆已知的限制参数进行通过性分析，能够使车辆在户外种植园行间场景下最终

识别出多约束条件下的可通行区域。

（1）车辆倾翻角度与地形坡度的对应关系研究

当车辆发生如图4-22 所示状态时，且不考虑车辆的重心偏移和平面极限前

翻角的影响，对车体轮胎下一时刻倾翻的极限离地角度进行受力分析，从图4-22

可以看到，此时两个车轮均垂直于接触平面，且低于水平面的车轮不受垂直作用

力的影响，根据牛顿第三定律可知在与平面的接触为0，即相互作用力抵消时，

车辆下一时刻一定会发生倾翻。

由于车辆结构为刚性连接，参照图4-22 所示的极限情况，固定其在水平路

面上的车轮，按照此模型使与负障碍接触的车轮随坡度角逐渐减小至零度。可得

到由图4-23 表示的位姿角与坡度角之间的关系。图4-23 所示的几何关系可由公

式4-24 表示的位姿角与坡度角之间的关系表示。

   

+ + = 2

c - b a b ac arccos 2

2  （4-24）

第四章 行间地形感知及可通行区域识别

图4-22 车辆离地极限倾翻状态图

图4-23 坡度角、位姿角的变化关系图

公式4-24 中：  Ltan a = 、 L b = 、    tan Rsin R Rtan c + + = ，L 为轴距，R

为车轮半径，α 为坡度角，θ 为车身单侧姿态角，l 固定旋转半径；t 为过渡距离。

根据公式4-24 所示关系，可求得在不同状态下坡度对应的车辆位姿角，并结合

平台已知的侧翻阈值26.74°~35.69°，前翻角度阈值25.69°~31.68°，纵向的越障宽

度 dl 限制阈值为 357mm~424.66mm ，最大深度 w h 的限制阈值为

100.68mm~204.59mm，可以实现在倾翻阈值角度下的满载、空载状态实时°纵向、

侧向的可通行区域识别。使车辆在户外种植园行间场景下安全行驶。

坡度即为该点沿其所在的圆周的切线与水平面的夹角，如图4-24(a)(b)分别

为X 方向坡度数值俯视图和沿X 方向坡度数值侧视图。

图4-24 的X 轴俯视图和X 轴方向坡度数值侧视图中，红色部分为坡度值最

大的区域，坡度值按照由红到蓝顺序依次递减，红色、黄色即可定义为陡坡，浅

绿色和蓝色可定义为缓坡。

第四章 行间地形感知及可通行区域识别

(a)俯视图 (b)侧视图

图4-24 X 轴方向坡度数值俯视图及X 轴方向侧视图

图4-24(a)中，缓坡面积占比较大，且深蓝色点（角度值为0 的点）在负障碍

内部也有较大的占比。沿X 轴正方向，坡度变化是成规律的，如图4-24(b)所示，

每个负障碍边缘均得到了明显描述，坡度值在X 方向负障碍的边界处达到了最

大值，发生了坡度突变，与实际情况相符。坡度如图4-24 颜色的表征，可以得到

在X 方向上每个深度值所对应的坡度程度及大小，坡度最大为79.6951°，平均坡

度为23.93°。

如图4-25(a)(b)分别为Y 方向坡度数值俯视图和沿Y 方向坡度数值侧视图。

(a)俯视图 (b)侧视图

图4-25 Y 轴方向坡度数值俯视图及轴Y 方向侧视图 a.俯视图；b.侧视图

图4-25 中，Y 轴正方向的坡度值变化整体是规律的，坡度值大小随颜色蓝

色、浅绿色、黄色、红色依次递减，整体上，地面区域占比较大，坡度陡峭区域

占比较小，红色部分为陡坡，黄色和浅绿色部分为缓坡，蓝色部分为地面。在Y

轴方向，坡度的最大值为80.9073°，y 方向平均坡度为22.47°。

第四章 行间地形感知及可通行区域识别

根据公式4-23 所示的地形坡度与车辆位姿角的转换关系，得到如图4-26 所

示的每一像素点的车辆位姿角X，Y 方向的值。

(a)X 方向位姿正视图 (b)X 方向位姿整体图

(a)Y 方向位姿正视图 (b)Y 方向位姿整体图

图4-26 车辆位姿角X，Y 方向整体效果图

图4-26(a)(b)(c)(d)中，位姿角在负障碍边缘的近似值为20°，经统计X 方向

最大位姿角为28.4725°，平均位姿角为13.7273°；Y 方向最大位姿角为27.5256°，

平均位姿角为13.4971°。通过与移动机器人平台的侧翻角度阈值26.74°~35.69°，

前翻角度阈值25.69°~31.68°对比，可知，此地形整体通过性良好，但存在使车辆

发生倾翻事故的区域。

对于地形坡度特征，并结合国家车辆通过性评价标准[39]，本文规定在轮式移

动机器人平台道路通过性评价的标准中倾翻角度的占比指标σ 为70%，平均坡度

指标τ 为30%，最终指标大于0.2 的道路为不可通过；大于0.1 小于0.2 的道路

为通行困难道路。小于0.1 的道路为通行性良好道路。根据4.1 得出的车辆倾翻

通过性限制角度，对地形坡度特征及其通过性评价如表4-4 所示。

第四章 行间地形感知及可通行区域识别

表4-4 地形坡度特征及其通过性评价

x 向平均坡

y 向平均坡

23.93°

14.14%

0.1904

22.57°

0.0406

良好 30.81%

23.93°

0.0247

22.57°

0.1141

困难 1.98%

同样规定通行良好道路为当平均坡度不大于其阈值极限且倾翻角度占比低

于20%的道路；通行困难道路为平均坡度大于其阈值极限30%且倾翻角度占比

高于20%低于50%的道路；不可通行道路为平均坡度大于其阈值极限50%且倾

翻角度占比高于50%的道路，道路状态评价，如表4-5 所示：

表4-5 道路状态评价

— 良好道路 通行困难 不可通行

20%~50%

当车辆满载或空载并检测到多负障碍的地形情况时，地形中存在远大于车辆

发生倾翻的角度，但此地形平均坡度较小。从表4-4 的数据上可以说明车辆倾斜

角度相较于整体坡度而言占比较小，地形整体通过坡度分析，整体可通行，所以

此多负障碍存在继续通行的可能，所以应进一步根据通过性检测中的越障能力约

束条件对地形参数进行识别工作。

（2）结合倾翻角度阈值和通过性尺寸约束的可通行区域识别及结果对比

在4.1 关于对轮式移动机器人平台顶起失效和跨越负障碍能力的研究中，得

出本课题组的轮式移动机器人平台的侧翻阈值26.7°~35.7°，前翻角度阈值

25.7°~31.7°，纵向的越障宽度¤¤限制阈值为357.0mm~424.7mm，最大深度ℎ¤的限

制阈值为100.7mm~204.6mm。通过这两个纵向约束条件即可对整体坡度进行进

一步的优化选取得到发生倾翻阈值角度时刻的深度极限。在侧向方向，通过对以

相机为原点的坐标系内固定位置出车身底盘动点和地形动点的深度判断，进而得

到侧向深度约束。如图4-27 所示为通过坡度阈值识别并加以深度约束后并进行

图像处理面积估计的可通行区域识别结果。

图4-27 中蓝色部分为经角度阈值判别后的不可通行区域，绿色部分为经尺

寸约束判别后的不可通行区域，红字为对应负障碍区域的编号及像素尺寸面积。

第四章 行间地形感知及可通行区域识别

未被绿色框圈起和颜色勾画的部分即为行间可通行区域。

图4-27 综合约束下可通行区域识别效果

图4-27 中可以看出，对于此时刻的负障碍地形其坡度、尺寸均不满足通行

的条件，从实际拍摄场景，每一个负障碍的边缘均有近90°的坡度变化，且负障

碍内部坡度近似为0，负障碍的深度约为220mm。

与融合地面高差、地面坡度、地表粗糙度3 种地形因素的2.5D 栅格条件判

别的可通行区域识别方法[11]相比，综合车辆通过性约束和地形特征结合预测的方

法省略了高差和地表粗糙度的算法逻辑过程，提高了可通行区域的识别效率，得

到了更精确的车辆实际运动需求的通行区域，充分发挥车辆良好的越障能力；与

视觉、激光雷达、IMU 融合的可通行区域识别方法相比[9][10][12][13]，本文方法逻辑

更为简单，功能更易实现，对于农业成本需求上更为经济耐用且具有较高实用性。

4.5 本章小结

本章为解决轮式移动机器人平台在户外种植园行间行驶时，通过对平台通过

性分析与地形特征提取的研究，得到了车辆在不同情况下的倾翻角度阈值约束，

也得到了基于负障碍地形深度数据的地形坡度计算方法，将高程上各点的坡度值

进行纵向、侧向方向的车辆位姿角转化，进而通过对纵向、侧向上的位姿角和倾

翻角度阈值限制参数结合识别，得出识别后的可通行区域。并根据能够跨越的最

大负障碍宽度、深度参数，得到关于最大越障尺寸的不可通行区域，实现轮式移

动机器人平台缓慢行驶速度条件下的安全行驶。

第五章 行间道路识别与路径生成

第五章 行间道路识别与路径生成

针对户外种植园行间场景的道路识别与路径生成系统设计，本文通过构建一

个针对户外种植园行间图像的图像语义分割模型，对行间环境信息进行道路识别，

并设计了道路提取后的路径生成方式，实现对第四章处理后的可通行区域信号进

行道路识别及其路径生成。

在模型选择上，深度卷积神经网络分割模型相比于传统分割模型具有更好的

精度与环境抗干扰能力，所以本文选择深度卷积网络模型。在对各个深度卷积网

络模型调研中，本文最终选择了U-Net 网络作为户外种植园场景下的语义分割模

型，U-Net 网络更适用于小尺度数据集，能在较小数据集的情况下完成端到端训

练，获得较好的分割效果。

常见的深度学习包有TensorFlow、Caffe 和Theano。TensorFlow 是有针对张

量的命令格式，可安装在Linux、MacOS 和Windows 系统上。Caffe 速度快，适

合工业部署，提供了C++、MATLAB、Python 接口，但其不够灵活，占用内存较

多。Theano 支持高性能的符号运算，可将操作指令快速转换成底层代码，提升了

执行速度，同时，Theano 提供了GPU 的透明使用，大大提高了模型组网速度，

具有API 简单易懂、运行稳定等优点。

经过对各深度学习框架在户外种植园环境适应性方面的比较，最终选择

TensorFlow 深度学习框架作为开发工具，原因有以下几点：首先，TensorFlow 支

持各种CPU 和GPU，可以保证计算的高效。其次，TensorFlow 封装了很多高级

API，为实验提供了有效的支撑，因为使用这些高级API 可以通过几行代码实现

复杂的模型构建和训练，并且该工具具备丰富详实的文档辅助，有助于快速上手

学习，实现功能。此外，TensorFlow 提供了多语言接口，具有较强的可扩展性，

支持移动端、服务器等各种设备，具有较强灵活性。最后，TensorFlow 集成了

Keras，Keras 是一个使用Python 编写的专精于深度学习领域的框架，具有简洁

优美、可移植性强的特点，目前在深度学习领域，Keras 提供了最方便易行的模

块和接口，在性能没有损耗的条件下，实现了程序的简化。通过TensorFlow，可

以调用Keras 代码，大大方便了模型组网和训练。

在道路路径生成上，本文采用对经过图像语义分割后的道路图像进行行驶方

向和可通行区域双重约束的导航线拟合，实现行间可通行区域的路径生成。本文

的整体设计方案如图5-1 所示：

第五章 行间道路识别与路径生成

U-Net网

保存训练 好的模型

图像分割 结果评价

获得户外种植园行

间图像原始数据

数据集构建 模型训练 精度评价

种植园行间图像 语义分割数据集

提取道路并生

图5-1 道路识别与路径生成总体框架

5.1 模型组网的构建

本文对U-Net 网络基于编码器-解码器结构，模型可分为九个模块，其中左

侧四个模块为编码器下采样过程，右侧四个模块为解码器上采样过程。编码器利

用下采样的特征图做融合，依靠不断的卷积和池化操作完成对图像深层特征的提

取，解码器则依靠转置卷积操作来恢复原图像分辨率，实现最终的图像分割。U-

Net 网络模型结构如图5-2 所示。

图5-2 U-Net 网络模型结构

第五章 行间道路识别与路径生成

本文使用了U-Net 网络结构组成，除经过四次下采样提取特征，四次上采样

实现分辨率还原，本文在所有模块的卷积计算后加入了填充，保持了图像卷积后

尺寸不变，这样做可以不会丢失图像边缘特征信息，提升分割效果[40]。

在下采样过程中，需要不断进行卷积和池化的操作，在卷积过程中，使用尺

寸为3×3 的卷积核，使用ReLU 作为激活函数，在池化过程中，使用了2×2 的

池化窗口做最大池化。输入图像尺寸为224×224、深度为3，下采样过程中的网

络模型见表5-1。

表5-1 下采样网络模型

输入层 输出尺寸 承接

input （224，224，3） —

conv2d1_1 （224，224，64） input

conv2d1_2 （224，224，64） conv2d1_1

max_pooling2d1 （112，112，64） conv2d1_2

conv2d2_1 （112，112，128） max_pooling2d1

conv2d2_2 （112，112，128） conv2d2_1

max_pooling2d2 （56，56，128） conv2d2_2

conv2d3_1 （56，56，256） max_pooling2d2

conv2d3_2 （56，56，256） conv2d3_1

max_pooling2d3 （28，28，256） conv2d3_2

conv2d4_1 （28，28，512） max_pooling2d3

conv2d4_2 （28，28，512） conv2d4_1

max_pooling2d4 （14，14，512） conv2d4_2

下采样结束后，进入中间的第五模块，第五模块是下采样和上采样的中间结

合部分，只有两个卷积层。第五模块见表5-2。

表5-2 第五模块网络模型

输入层 输出尺寸 承接

conv2d5_1 （14，14，1024） max_pooling2d4

conv2d5_2 （14，14，1024） conv2d5_1

第五模块结束后，进行上采样操作，上采样网络构建见表5-3。

第五章 行间道路识别与路径生成

表5-3 上采样网络模型

输入层 输出尺寸 承接

conv2d_transpose_1 （28，28，512） conv2d5_2

concat1 （28，28，1024） conv2d_transpose_1

conv2d6_1 （28，28，512） concat1

conv2d6_2 （28，28，512） conv2d6_1

conv2d_transpose_2 （56，56，512） conv2d6_2

concat2 （56，56，768） conv2d_transpose_2

conv2d7_1 （56，56，256） concat2

conv2d7_2 （56，56，256） conv2d7_1

conv2d_transpose_3 （112，112，128） conv2d7_2

concat3 （112，112，256） conv2d_transpose_3

conv2d8_1 （112，112，128） concat3

conv2d8_2 （112，112，128） conv2d8_1

conv2d_transpose_4 （224，224，64） conv2d8_2

concat4 （224，224，128） conv2d_transpose_4

conv2d9_1 （224，224，64） concat4

conv2d9_2 （224，224，64） conv2d9_1

conv2d9_3 （224，224，4） conv2d9_2

下采样和上采样过程完成后，需要实现最终的图像输出，输出是对每个像素

进行分类，需要得出每个像素属于各类别的概率，此时需要使用Softmax 函数。

ReLU 函数是单节点激活函数，除此之外还有多节点激活函数，最常用的是

Softmax 函数，在U-Net 网络中被用来完成多分类任务，Softmax 的计算如公式

5-1 所示。

i V e S je = 

其中 iS 是一个向量，针对¤点，代表该点的回归概率，向量的各个分量代表

各个类别的概率，各分量中最大的分量所对应的类别被视为该像素所属类别，j

代表标注类别。可以看出Softmax 工作的原理是先将输入值进行处理，将其当成

幂指数求值，而后通过正则化转化为(0,1)区间上的概率，使各类别的概率总和为

1，针对U-Net 网络来说，就是每个像素会被给出属于各类别的概率，概率值均

为正数，且总和为1，在各类别的概率中的最大值对应的类别将被视作该像素的

第五章 行间道路识别与路径生成

类别，从此实现像素级分类。

5.2 模型训练

5.2.1 目标数据来源与获取

由于本文针对户外种植园行间场景，所以采集的图像都来自户外行间场地，

包括种植园、公园和野外。通过差异化比对，筛选出其中的53 张图像作为原始

数据。确定原始数据后需要对其进行标注，标注使用的工具是图像标注软件

labelme，见图5-3。标注首先要定义需要划分的类别，标注使用绳索的方式，将

目标区域用绳索围成一个封闭区域，然后将此区域划入定义好的类别中，标注过

程中要保证各区域之间不能有重叠，因为图像语义分割是像素级分类，每一个像

素只能从属于一个固定类别，标注完成后保存至.json 文件。

图5-3 图像标注操作界面

通过对图像类别的标注，可以自行设置相关类别的区域，通过后续训练、测

试，对个人的感兴趣区域进行学习，为风格多异的图像类别的识别工作提供了便

利，帮助我们标注图像，不需要我们在电脑中安装或复制大量的数据集。

模型训练的图像标签对格式有特定的要求，需要将.json 文件进行转换，转换

成模型可用的标签文件，数据集中数据共分成4 类，0 代表背景，1 代表树木，

2 代表地面，3 代表天空。标签制作完成后，包含原始图像和标注图像数据集初

步构建完成，其中的一组数据见图5-4。

第五章 行间道路识别与路径生成

(a)原始图像 (b)人工标注图像

图5-4 标注过程图

图5-4(a)为原始图像，图5-4(b)中红色部分代表树木，黄色部分代表天空，

绿色部分代表地面，未标注部分代表背景。其他样本数据库中的样本图像也都标

记如图5-4(b)所示。图像采集过程中，由于图像采集设备不同，导致图像尺寸不

一，U-Net 网络要求输入的图片是正方形，所以要对数据集图像和标签进行裁剪

操作，保证图像和模型的匹配。本文将图像裁剪成了224×224 大小的图像，首先

导入待裁剪的图像和标注好的标签，为防止裁剪超出图像范围，在图像和标签左

上角、距图像右边和下边224 像素的矩形里选择随机点，然后向右边和下边扩展

224 个像素，完成一次裁剪，重复20 次完成对1 张图像的裁剪，依次对53 张图

像重复操作。

裁剪的方式是对图像进行随机裁剪，裁剪数量是20，即对53 张图像中的每

张图像裁剪20 次，共获得53×20=1060 张224×224 的图像作为预处理后的数据

集，同时，对应的标签也执行相同操作，裁剪后的原始图像见图5-5(a)，预测图

像见图5-5(b)。

(a)原始图像 (b)标注预测图像

图5-5 裁剪后原始图像和预测图像

第五章 行间道路识别与路径生成

5.2.2 训练过程

模型组网接下来是模型训练，训练的目的是获得针对本模型的数据集的模型

参数，未来用这些参数进行预测。模型的输入图像尺寸为224 × 224，深度为3，

为RGB 三通道，共计1060 张，其中训练集与测试集的比例为8: 2，即训练集有

848 张，测试集有212 张，图像场景包含了种植园、公园和野外。

模型训练时，每次训练的样本数设置为2，训练代数设置为50，训练时需要

明确的五个参数，分别是模型指定训练数据、训练代数、训练数据组的数量、验

证数据、验证数据组的数量。

模型在训练过程中需要使用损失函数，目的是更新模型参数让模型不断拟合

实验数据，TensorFlow 框架中有封装好的优化器可以完成梯度下降，本文选择使

用Adam 优化器进行梯度下降，本文将学习率设置为0.0001，模型配置如下：

model.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),loss='sparse_ca

tegorical_crossentropy',metrics=['acc'])

Adam 可以针对不同的模型参数使用动量和自适应学习率来加快收敛速度，

具有计算效率高、内存需求小等优点，非常适合数据量较大或参数较多的场景。

5.2.3 训练结果

定义好网络和各相关参数后开始进行模型训练，由于训练集数量为1060×

80%=848，由于每次训练的样本数设置为2，所以训练数据组的数量为848×20％

=424。训练结束后绘制损失函数的变化和正确率的变化，损失函数的变化见图5-

图5-6 损失函数的变化

第五章 行间道路识别与路径生成

损失函数用来估量模型的预测值 ( ) f x 与真实值Y 的不一致程度，它是一个

非负实值函数，损失函数越小，模型的鲁棒性就越好。随着训练代数的增加，训

练集和测试集的损失函数值不断降低，前期梯度下降较快，且训练集快于测试集，

训练集在27 代基本保持稳定，测试集在22 代基本保持稳定。损失函数的下降趋

势稳定于33 附近。第40 代以后，预测值和真实值相差不大。如图5-7 所示为正

确率的变化。

图5-7 正确率的变化

随着训练代数的增加，训练集和测试集的准确度不断提升，前期上升很快，

训练集在40 代基本保持稳定，测试集在20 代基本保持稳定，在40 代时测试集

准确率达到了90.98%，这是一个比较好的成绩。由图5-6 和图5-7，针对此模型

可以说明训练代数在35 以上会获得效果比较好的模型。

5.2.4 模型测试

训练后，保存模型的权重至.h5 文件中，预测时，直接加载.h5 模型即可，为

了使模型可以适应不同尺寸的输入图像，需要对所有输入系统的待预测的图像进

行预处理，首先将图像横向裁剪，然后再进行纵向裁剪，从而覆盖整个图像，将

图像分成若干224×224 的区域，最后分别对这些区域进行预测，拼接成与输入

图像相同尺寸的图像输出，模型输出的预测图像与原图像的对比如图5-8 所示。

第五章 行间道路识别与路径生成

(a)原始图像 (b)预测图像

(c)原始图像 (d)预测图像

(e)原始图像 (f)预测图像

图5-8 原始图像、标签图像和预测图像三者对比

图5-8(a)、(c)、(e)为原始图像，5-8(b)、(d)、(f)为相对应的预测图像。从预

测结果来看，模型基本能较为精准地实现户外种植园行间场景的图像语义分割，

在树木和地面的分割效果较好，但也存在在图像的某些区域分割存在不准确的情

况。不准确的原因有以下几方面，首先，由于图像是裁剪成若干区域分别进行预

测，各区域中包含的图像信息在裁剪过程中会丢失。其次，实验数据集数量较少，

第五章 行间道路识别与路径生成

且图像标注精度较低，这些直接影响模型的各个参数以及后来的图像预测。

5.3 路径生成

通过5.2 节预测分割的四个类别的图像对其结果进行输出，由于轮式滑动转

向移动机器人在户外种植园行间需要对道路信息进行提取，所以根据采取各异

RGB 值图像分割的方式将道路信息提取出来，如图5-9 所示。

(a)原始图像 (b)分割图像

(c)提取道路 (d)提取导航线

图5-9 道路信息提取即路径生成图

通过颜色区域的二值化并分割出道路后，对道路进行多边形逼近拟合，根据

车辆行驶方向确定路径起始端位置和方向，其次根据可通行区域信号判断路径末

该方法采用道格拉斯-普克算法[41]实现。通过该算法计算出道路信息的轮廓，

根据速度运动方向的给定和可通行区域信号，判断出最小外接矩形的顶点和末点

坐标，两者的连线即为导航线如图5-9(d)所示，轮式滑动转向移动机器人即可沿

此导航线进行自主行驶中的行驶任务。

第五章 行间道路识别与路径生成

5.4 本章小结

本章首先完成了基于U-Net 网络的户外种植园行间场景下图像语义分割模

型的构建，构建一个针对户外种植园行间图像的图像语义分割模型，可以将输入

模型的图像分割成树木、天空、地面、背景四部分后输出道路并生成导航线，辅

助轮式滑动转向移动机器人实现在户外种植园行间场景下的导航和避障。在U-

Net 网络上进行了一定改进，在U-Net 网络的卷积层加入了填充，提升了分割精

度。在上采样时使用了反卷积的方式，一定程度上减少了图像信息的丢失。最终

使用Softmax 函数完成了像素多分类任务，实现了将输入模型的图像分割成树木、

天空、地面、背景四部分后输出的效果。进而通过对数据的采集、标注、制作、

裁剪，建立了一个基于户外种植园行间场景图像的语义分割数据集，通过该数据

集完成了模型训练和参数调整，再对分割后的图像数据根据道路标注进行分割，

根据车辆行驶方向和可通行区域信号，求得最小外接矩形的方式提取出行驶路径。

第六章 总结与展望

第六章 总结与展望

6.1 工作总结

本文针对户外种植园行间可通行区域识别与路径生成问题，着重从非结构化

负障碍地形环境下的可通行区域识别与路径生成方法出发，研究种植园行间环境

下轮式移动机器人平台车辆通过性理论与地形结合预测的可通行区域识别；结合

适用于种植园行间环境下的深度神经网络图像语义分割模型进行道路信息的分

割、提取与路径生成方法的设计。

本文首先将轮式移动机器人平台在户外种植园行间场景下凹凸不平的道路

进行可通行区域识别与路径生成方法系统设计，进而对此系统完成了基于平台已

知参数的通过性检测系统与基于地形感知的可通行区域识别系统的设计，通过对

此系统的设计，得到了适用于户外种植园行间轮式移动机器人平台的通过性综合

约束集合，并实现了结合对垂直拍摄的地形深度信息的通过性综合约束处理方法，

识别出可通行区域。本系统提升了根据车辆自身设计参数识别户外种植园行间恶

劣道路环境中可通行区域和克服负障碍行驶的能力，提升了行驶的安全性。

其次采用以U-Net 为基础的深度卷积神经网络图像语义分割模型，对种植园

行间图像进行道路识别与提取，以车辆真实行驶方向作为约束并形成行驶轨迹路

径。最终模型的分割精度达到了94%，且具备一定的泛化能力和抗干扰能力。证

明了U-Net 网络模型在户外种植园行间图像上具备较好的分割能力，同时对小规

模数据集也具备较好的适应能力。

本文通过对综合车辆自相关约束下的负障碍地形感知可通行区域识别系统

和行间道路识别与路径生成系统的设计，构建了户外种植园行间可通行区域识别

与路径生成的方法，在存在负障碍、视野内环境信息多样的情况中具有一定的鲁

棒性，对移动机器人于户外种植园行间的自主行驶技术实现具有一定的支撑作用。

6.2 研究展望

本文利用人工智能技术、图像处理技术和传感器感知融合技术实现了对户外

种植园行间轮式移动机器人平台行驶的道路可通行区域的识别和视野道路识别

与路径生成的功能。为户外种植园行间可通行区域识别与路径生成技术提供了理

第六章 总结与展望

论支撑和技术方案。但是由于户外种植园行间道路具有不确定性、非结构性、恶

劣性等，户外种植园行间可通行区域识别与路径生成技术的实现仍面临着以下的

问题亟待研究解决：

1、在基于车辆通过性检测的地形感知及可通行区域系统中，虽然对车辆进

行了详细的通过性理论分析，但仍因户外道路地形非结构化的特点，对于实际应

用场景中，通过性约束方案中对于横向侧翻的约束关系除了角度约束以外，对于

车辆最大横跨能力没有形成详细的判别方法，同坐标系下动点联系法仍仅适用于

车身固定范围的角度倾斜，当车辆具备大范围角度倾斜、车辆底盘拥有较高的离

地间隙且车轮纵向通过角较大的情况时，侧向触底的判别条件不够适用于负障碍

深度相差较大即车身倾斜角度大的场景。因此仍需要对汽车通过性理论进行更加

深入的研究，对不同路面的情况需合并考虑，融合其它可提供给参数的有效传感

器或能在一定程度上解决车辆和地面摩擦产生的不可预知的影响。

2、卷积神经网络模型需要通过数据集来学习和优化，本文虽对少量自采集

数据集进行了良好的预测和分割，但目前国内外并没有针对户外种植园行间图像

的成熟完备的数据集，所以需要自主采集图像并完成预处理。由于图像采集时间，

实地场景数量、成本等因素限制，自制数据集在尺度上和质量上都有待提高。

[1] 黄季焜, 胡瑞法, 易红梅, 盛誉, 王金霞, 宝明涛, 刘旭. 面向2050 年我国农

业发展愿景与对策研究[J]. 中国工程科学, 2022, 24(01): 11-19.

[2] 刘树军. 浅析种植业生产成本影响因素及控制策略[J]. 河南农业, 2022(05):

63-64.

[3] 黎星池, 朱满德, 刘超. 农业劳动力价格对种植结构的影响研究——基于空

间溢出视角的分析[J]. 价格理论与实践, 2022(01): 83-86.

[4] Zhichao Lian, Jie Song, Yang Li. Adaptive illumination normalization approach

based on denoising technique for face recognition[J]. Journal of Shanghai Jiaotong

University (Science), 2017, 22(1).

[5] Gao Hongyang, Yuan Hao, Wang Zhengyang, et al. Pixel Transposed

Convolutional Networks[J]. IEEE Transactions on Pattern Analysis and Machine

Intelligence. 2019(5).

[6] Li Chang, Sun Hanxu, Ye Ping. Multi-sensor fusion localization algorithm for

outdoor mobile robot[J]. Journal of Physics:Conference Series, 2020, 1453.

[7] Howard A, Seraji H. An intelligent terrain-based navigation system for planetary

rovers[J]. Robotics & Automation Magazine IEEE, 2001, 8(4): 9-17.

[8] 刘华军, 陆建峰, 杨静宇. 基于相对特征的越野地形可通行性分析[J]. 数据

采集与处理, 2006(01): 58-63.

[9] K. Iagnemma, H. Shibly, and S. Dubowsky. On-line terrain parameter estimation

for planetary rovers[J]. Robotics and Automation, 2002. 3142-3147.

[10] Iagnemma K, Dubowsky S. Vehicle Wheel-Ground Contact Angle Estimation:

With Application to Mobile Robot Traction Control[M]. Springer Netherlands,

[11] 彭湘, 向凤红, 毛剑琳. 多地形约束条件下的移动机器人路径规划方法[J].

小型微型计算机系统, 2021, 42(09): 1900-1905.

[12] 张艳国, 李擎, 汪天生. 基于IMU-LiDAR的负障碍检测方法[J]. 电光与控制,

2019, 26(08): 106-110.

[13] 阮顺领, 李少博, 卢才武, 顾清华. 多尺度特征融合的露天矿区道路负障碍

检测[J/OL]. 煤炭学报, 2022. 1-10.

[14] Wei Liao, Xiaohui Wei, Jizhou Lai, Hao Sun. Numerical Method with High Real-

time Property Based on Shortest Path Algorithm for Optimal Control[J].

International Journal of Control, Automation and Systems, 2021.

[15] 段建民, 王昶人, 任璐, 刘丹. 基于多层激光雷达的可行驶区域信息提取算

法[J]. 电子技术应用, 2017, 43(10): 78-82.

[16] Fang Zeping, Duan Jianmin. Optimal lane change motion of intelligent vehicles

based on extended adaptive pseudo-spectral method under uncertain vehicle

mass[J]. Advances in Mechanical Engineering, 2017, 9(7).

[17] 蒋剑飞, 李其仲, 黄妙华, 龚杰. 基于三维激光雷达的障碍物及可通行区域

实时检测[J]. 激光与光电子学进展, 2019, 56(24): 249-258.

[18] 谌华, 郭伟, 闫敬文, 卓文浩, 吴良斌. 基于深度学习的SAR 图像道路识别

新方法[J]. 吉林大学学报(工学版), 2020, 50(05): 1778-1787.

[19] Wenyue Zheng. Design and Experimental Analysis of Agricultural Autonomous

Walking Robot Based on Visual Navigation Technology[J]. Journal of Research in

Science and Engineering, 2020, 2(8).

[20] 郑利浩, 郑秋岚, 林志洁等. 医学图像语义分割的深度学习技术综述[J/OL].

计算机工程与应用, 2021. 1-15.

[21] Cui Yuyong, Wang Shengzhe, Gao Xinyi, Wu Zhongjian, Yong Yang. Multi-source

image target detection technology based on salient feature fusion[J]. Journal of

Physics: Conference Series, 2021, 2024(1).

[22] Qulin Tan, Bin Guo, Jun Hu, Xiaofeng Dong, Jiping Hu. Object-Oriented Remote

Sensing Image Information Extraction Method Based on Multi-Classifier

Combination and Deep Learning Algorithm[J]. Pattern Recognition Letters, 2020.

[23] Tosaki K, Miyahara S, Ichikawa T, et al. Development of Microcomputer

Controlled Driverless Air Blast Sprayer (Part 1): Unmanned Traveling System[J].

Journal of JSAM, 1996, 58: 101-110.

[24] Koichiro, OKAZAKI, Masahiro, et al. Automation of Farm Work by an Overhead

Monorail System in Steep Sloped Citrus Orchards[J]. JOURNAL of the

JAPANESE SOCIETY of AGRICULTURAL MACHINERY, 1996, 58(3): 103-

[25] 陈军, 蒋浩然, 刘沛, 张勤. 种植园移动机器人曲线路径导航控制[J]. 农业机

械学报, 2012, 43(04): 179-187.

[26] 艾长胜, 林洪川, 武德林, 冯志全. 葡萄园植保机器人路径规划算法[J]. 农业

工程学报, 2018, 34(13): 77-85.

[27] 薛金林, 张顺顺. 基于激光雷达的农业机器人导航控制研究[J]. 农业机械学

报, 2014, 45(09):55-60.

[28] Croneborg Louise et al. Digital Elevation Models[M]. World Bank, 2020.

[29] 陈浩, 王岩松. 汽车理论[M]. 北京: 清华大学出版社, 2015.

[30] Goodin Christopher, Carrillo Justin, Monroe J. Gabriel, Carruth Daniel W, Hudson

Christopher R. An Analytic Model for Negative Obstacle Detection with Lidar and

Numerical Validation Using Physics-Based Simulation[J]. Sensors, 2021, 21(9).

[31] Xie Yutong, Cheng Chunlei, Wang Zhihua, et al. Exploration of O-3-precursor

relationship and observation-oriented O-3 control strategies in a non-provincial

capital city, southwestern China[J]. Science of the Total Environment. 2021,800:

149422.

[32] Hale, Gregory A. Autologous hematopoietic stem cell transplantation for pediatric

solid tumors. [J]. Expert Review of Anticancer Therapy, 2005, 5(5): 835-46.

[33] Ji J, Han L, Wei J, et al. Histogram-based perceptual hash algorithm for synthetic

aperture radar image segmentation[J]. Journal of Electronic Imaging, 2018, 27(3):

033044. 1-033044. 8.

[34] 吴凉, 吕晓琪, 谷宇, 李菁, 张文莉, 任国印, 张薇. 基于低剂量CT 图像的肺

实质分割方法[J]. 生物医学工程研究, 2018, 37(02): 163-167.

[35] 王彤, 朱凌, 范亚洲, 黄勇, 宋海龙, 郭圣, 罗敏. 基于改进U-net 语义分割遥

感影像的线路走廊隐患检测方法[J]. 南方电网技术, 2019, 13(08): 67-73.

[36] Zhao Yibing, Li Jining, Yang Yuan. Study on Environment Perception and

Automatic Navigation Technology for the Automatic Parking System[J]. World

Journal of Engineering and Technology, 2015, 03(03).

[37] 李志林, 朱庆. 数字高程模型[M]. 武汉: 武汉大学出版社, 2001.

[38] 陈刚, 张笑, 薛梦姣. 数字地形建模与地学分析[M]. 南京：东南大学出版社,

2019. [39] 全国汽车标准化技术委员会. GB/T 12541-1990 汽车地形通过性实验方法[S].

中国标准出版社, 1991.

[40] Zheng Qinxiang, Zhang Xin, Zhang Juan, Bai Furong, Huang Shenghai, Pu Jiantao,

Chen Wei, Wang Lei. A texture-aware U-Net for identifying incomplete blinking

from eye videography[J]. Biomedical Signal Processing and Control, 2022, 75.

[41] Bo Liu et al. A Vector Line Simplification Algorithm Based on the Douglas–

Peucker Algorithm, Monotonic Chains and Dichotomy[J]. ISPRS International

Journal of Geo-Information, 2020, 9(4): 251-251.

在学期间的研究成果

在学期间的研究成果

一、撰写论文

1．毕松, 王远航, 李嘉伟, 刘蕾. 户外种植园行间可通行区域识别[J]. 计算机仿

二、研究成果转化或应用情况

1．“绿茵先锋”全自动足球识别、抓取与投掷机器人团队设计-2020.10.30-

ROBOCON 全国大学生机器人大赛三等奖

2．“投壶行觞”全自动箭矢抓取、精准投掷机器人团队设计-2020.07.27-

ROBOCON 全国大学生机器人大赛三等奖

感谢您看完我的论文，您辛苦了！

我的三年硕士生活如同恍惚一梦，再回首仿佛我还是那个手握着北方工业大

学正红色录取通知书报道的新生，在开学典礼上，校长为我们全体新生隆重地介

绍了学校丰富的科研资源和充足的实验场地，让我不禁感慨是否相见恨晚，感谢

彼时的我奋力考研成就了现在的我，让我如愿以偿成为北方工大人。

首先感谢我的导师毕松教授以及校外导师李睿凡先生，依稀记得复试后毕松

教授在楼道与我交换联系方式的场景，那是我在首都第一次感受到被重视、被认

可；依稀记得李睿凡先生在无数个夜晚对我每个阶段的研究成果进行悉心指导。

感谢毕松教授接纳我于IFR 实验室工作学习，以及这三年对我的耐心培养，这三

年的IFR 拓宽了我的视野，夯实了我的专业基础，丰富了我的科研生活，树立了

我严谨的科研态度以及正确的三观，教导我要切身投入到国家需要的研究中去，

做一个对国家、社会和人民有帮助的科研工作者。最喜和您说笑，领略人生百态，

最愿听您教导，得以终身受用，其中毕松教授说过的对我研究生生涯乃至余生影

响最深的13 句话如下：(1)主要矛盾才是第一生产力。(2)目标是有效和高效地解

决问题，每种方法都要注重核心问题。(3)不能拿着锤子，看啥都像钉子。(4)虽然

精力和时间是有限的，但是坚持一件事做下去，总会达到顶尖水平。(5)做任何尝

试前都要总结经验及时备份。(6)一定要搞清楚研究的边界在哪。(7)每个解决方

案都有解决的条件和时间。(8)一切解决问题的方式要尽可能最简可用。(9)早起

会让一天的时间变得很长。(10)学语言最好的状态是可以用它说话，闭眼一想就

有其逻辑。(11)集中精力，毕其功于一役。(12)别挖了3 米的井，哪个都不出水。

(13)绝不能陷入某一点中出不来而影响大局。

其次感谢北方工大让我遇到了我的实验室同学们，自我来到实验室的第一天

起，你们每一个人即是我的老师，这三年里我在你们的身上学到了很多的专业知

识，在和你们的交往和相处中，我深刻感到了对待科研的求真、务实精神，让我

真正脚踏实地地追求真理以及追求解决问题的最佳方式。感谢我的大师兄张潞先

生，您是我科研生活的领路人，是我生活中的一盏明灯，为我切身设计了众多基

础技能的学习路线，感谢您让我感受到科研及竞赛中的乐趣；感谢我的二师兄王

宇豪先生，您是我科研态度的塑造者，您用您严谨的科研态度以及对待事情的认

真考虑，帮我在无数无尽的黑夜中找到光亮；感谢我的师弟张国轩、韩奕非、隗

朋峻、张东航、余鑫和李东先生，感谢你们对我的耐心帮助与倾心陪伴，有你们

的生活充满乐趣不会孤单。

再次，感谢我的父母，感谢你们生下了我，并培育了我27 年之久，感谢你

们的督促与警示，使我能够更加灵活地应对来自社会面上的困难险阻；感谢你们

对我倾注的精力及财力，这都将转化为对我的投资，我会在未来努力工作，将这

份投资转化为你们能够看的到、感受的到的回馈。感谢我的岳父岳母，感谢你们

对我的信任，将宝贝女儿交到了我的手中，感谢你们给予我精神上的极大帮助。

最后，着重感谢我的未婚妻张静怡女士，感谢您在我研究生期间的鼓励和支

持。感谢您在我情绪崩溃时给予安抚和关怀，给予我坚定不移的信任与陪伴，给

予我充足的理解和包容，您是点亮漫天繁星的缕缕阳光，我的生活因您而闪亮。

感谢您陪我度过孤独、枯燥的岁月，让我知道有您的日子如此岁月静好。感谢您

爱我的所有，接纳我的过去，并参与我的余生。感谢您选择了我做您的未婚夫，

允许我在您的身边陪您走到世界的尽头。我们的美好，未完待续……

从一个空白的文档到如今满满当当的四万余字，我用了整整三年，感谢我自

己付出的努力没有白费，也感谢在此期间给予过我帮助的人，感谢大家对我的帮

助，让我熬过了大学最后也是最重要的环节，感谢每一位存在于我生命里的人，

愿疫情早日退散，愿你们一切安好，让我们江湖再见！