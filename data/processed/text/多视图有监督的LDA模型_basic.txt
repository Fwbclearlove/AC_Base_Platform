多视图有监督的ＬＤＡ模型

李晓旭１，李睿凡２，３，冯方向２，曹 洁１，王小捷２，３

（１．兰州理工大学计算机与通信学院，甘肃兰州７３００５０；２．北京邮电大学计算机学院，北京１００８７６；

３．教育部信息网络工程研究中心，北京１００８７６）

摘 要：本文主要关注多视图数据的分类问题．考虑到集成分类方法可组合多个弱分类器构成一个强分类器，

以及主题模型能学习复杂数据的语义表示，本文试图将集成学习思想引入主题模型中，以便同时学习多视图数据的分

类规则和预测性语义特征．具体地，结合概率主题模型ＬＤＡ模型和集成分类方法Ｓｏｆｔｍａｘ混合模型，提出了一个多视图

有监督的分类模型．基于变分ＥＭ方法，推导了该模型的参数估计算法．两个真实图像数据集上的实验结果表明了提

出模型有较好的分类性能． 关键词： 多视图分类；概率主题模型；变分期望最大化

中图分类号： ＴＰ１８１ 文献标识码： Ａ 文章编号： ０３７２２１１２（２０１４）１０２０４００５ 电子学报ＵＲＬ：ｈｔｔｐ：／／ｗｗｗ．ｅｊｏｕｒｎａｌ．ｏｒｇ．ｃｎ ＤＯＩ：１０．３９６９／ｊ．ｉｓｓｎ．０３７２２１１２．２０１４．１０．２６

Ｍｕｌｔｉｖｉ ｅｗＳｕｐｅｒｖｉ ｓｅｄＬａｔｅｎｔＤｉｒｉ ｃｈｌ ｅｔＡｌｌ ｏｃａｔｉ ｏｎ

ＬＩＸｉａｏｘｕ １，ＬＩＲｕｉｆａｎ ２，３，ＦＥＮＧＦａｎｇｘｉａｎｇ ２，ＣＡＯＪｉｅ １，ＷＡＮＧＸｉａｏｊｉｅ ２，３

（１．ＣｏｌｌｅｇｅｏｆＣｏｍｐｕｔｅｒａｎｄＣｏｍｍｕｎｉｃａｔｉｏｎ，ＬａｎｚｈｏｕＵｎｉｖｅｒｓｉｔｙｏｆＴｅｃｈｎｏｌｏｇｙ，Ｌａｎｚｈｏｕ，Ｇａｎｓｕ７３００５０，Ｃｈｉｎａ；

２．ＳｃｈｏｏｌｏｆＣｏｍｐｕｔｅｒＳｃｉｅｎｃｅ，Ｂｅｉｊ ｉｎｇＵｎｉｖｅｒｓｉｔｙｏｆＰｏｓｔｓａｎｄＴｅｌｅｃｏｍｍｕｎｉｃａｔｉｏｎｓ，Ｂｅｉｊ ｉｎｇ１００８７６，Ｃｈｉｎａ；

３．ＥｎｇｉｎｅｅｒｉｎｇＲｅｓｅａｒｃｈＣｅｎｔｅｒｏｆＩｎｆｏｒｍａｔｉｏｎＮｅｔｗｏｒｋｓ，ＭｉｎｉｓｔｒｙｏｆＥｄｕｃａｔｉｏｎ．Ｂｅｉｊ ｉｎｇ１００８７６，Ｃｈｉｎａ）

Ａｂｓｔｒａｃｔ：Ｉｎｔｈｅｐａｐｅｒ，ｗｅｍａｉｎｌｙｆｏｃｕｓｏｎｃｌａｓｓｉｆｉｔｉｏｎｏｎｍｕｌｔｉｖｉｅｗｄａｔａ．Ｃｏｎｓｉｄｅｒｉｎｇｔｈａｔｅｎｓｅｍｂｌｅｍｅｔｈｏｄｓｃａｎｃｏｍｂｉｎｅ

ｗｅａｋｃｌａｓｓｉｆｉｅｒｓｔｏｃｏｎｓｔｒｕｃｔａｓｔｒｏｎｇｃｌａｓｓｉｆｉｅｒ，ａｎｄｔｏｐｉｃｍｏｄｅｌｃａｎｌｅａｒｎｌａｔｅｎｔｒｅｐｒｅｓｅｎｔａｔｉｏｎｓｆｒｏｍｃｏｍｐｌｅｘｄａｔａ，ｗｅｔｒｙｔｏｉｎｔｒｏ

ｄｕｃｅｅｎｓｅｍｂｌｅｉｄｅａｔｏｔｏｐｉｃｍｏｄｅｌ，ｓｕｃｈｔｈａｔｐｒｅｄｉｃｔｉｖｅｌａｔｅｎｔｒｅｐｒｅｓｅｎｔａｔｉｏｎｃｏｕｌｄｂｅｏｂｔａｉｎｅｄａｎｄｍｕｌｔｉｖｉｅｗｃｌａｓｓｉｆｉｅｒｃｏｕｌｄｂｅ

ｌｅａｒｎｅｄ．ＷｅｐｒｏｐｏｓｅｍｕｌｔｉｖｉｅｗｓｕｐｅｒｖｉｓｅｄｌａｔｅｎｔＤｉｒｉｃｈｌｅｔａｌｌｏｃａｔｉｏｎ（ｍｕｌｔｉｖｉｅｗｓＬＤＡ）ｍｏｄｅｌｂｙｃｏｍｂｉｎｉｎｇｌａｔｅｎｔＤｉｒｉｃｈｌｅｔａｌｌｏ

ｃａｔｉｏｎｍｏｄｅｌａｎｄｔｈｅｍｉｘｔｕｒｅｏｆｓｏｆｔｍａｘｍｏｄｅｌｗｈｉｃｈｉｓａｎｅｎｓｅｍｂｌｅｃｌａｓｓｉｆｉｃａｔｉｏｎｍｏｄｅｌ．Ｍｏｒｅｏｖｅｒ，ｗｅｄｅｒｉｖｅａｐａｒａｍｅｔｅｒｅｓｔｉｍａ

ｔｉｏｎａｌｇｏｒｉｔｈｍｏｆｔｈｅｐｒｏｐｏｓｅｄｍｏｄｅｌｂａｓｅｄｏｎｖａｒｉａｔｉｏｎａｌｅｘｐｅｃｔａｔｉｏｎｍａｘｉｍｉｚａｔｉｏｎ（ＥＭ）ｐｒｏｃｅｄｕｒｅ．Ｔｈｅｅｘｐｅｒｉｍｅｎｔａｌｒｅｓｕｌｔｓｏｎ

ｔｗｏｒｅａｌｄａｔａｓｅｔｓｓｈｏｗｔｈｅｅｆｆｅｃｔｉｖｅｎｅｓｓｏｆｔｈｅｐｒｏｐｏｓｅｄｍｏｄｅｌ．

Ｋｅｙｗｏｒｄｓ：ｍｕｌｔｉｖｉｅｗｃｌａｓｓｉｆｉｃａｔｉｏｎ；ｐｒｏｂａｂｉｌｉｓｔｉｃｔｏｐｉｃｍｏｄｅｌ；ｖａｒｉａｔｉｏｎａｌｅｘｐｅｃｔａｔｉｏｎｍａｘｉｍｉｚａｔｉｏｎ

在计算机视觉和机器学习中，很多问题都包含多视 图数据，例如一段视频可分为声音、图像、文本字幕等数 据，一个物体可以分为颜色、形状等特征．目前，多视图 数据的分类问题已被广泛关注，目的是希望利用多视图 信息提高分类性能．传统的多视图分类方法包括特征水 平上的融合［１］，即初期融合方法，以及输出水平的融 合［２］，即后期融合方法．近期的研究逐渐开始关注中期 融合方法．在中期融合方法中，一类方法是先使用无监 督的特征学习方法学习多视图特征，如ＣｏｒｒＬＤＡ［３］，

ＣＣＡ［４］以及Ｍｅｍｉｓｅｖｉｃ提出的方法［５］，然后使用一般的单

视图分类方法预测其类别．这种两阶段的多视图分类方 法，往往不能学到适合分类的特征表示．另一类方法是 将特征学习和分类器学习整合为一个模型，以便能学到 适合分类的特征表示，如ＭＭＨ［６］，ＭＣｓＬＤＡ［７］以及文献 ［８］给出的多核学习方法．其中文献［８］的方法没有直接 从多视图数据中学习特征表示，而是通过学习多视图的 核来融合多视图数据．总之，这两种中期融合方法，都是 从特征学习的角度来融合多视图信息． 本文提出了一种一阶段的中期融合方法，该方法没 有在特征学习部分而是在分类器学习部分融合多视图 信息．其动机是，主题模型适合学习数据的语义特征，集 成分类方法能将多个弱分类器组合为一个强分类器，将

收稿日期：２０１３０５０２；修回日期：２０１３１００５；责任编辑：赵克

Ｏｃｔ．２０１４

其结合以便构建兼具二者优势的多视图分类方法．本 文建立在概率主题模型ＬＤＡ［９］和集成分类方法Ｍｉｘｔｕｒｅ ｏｆＳｏｆｔｍａｘＭｏｄｅｌ（ＳＭＭ）［１０］上，通过令ＬＤＡ模型学习出的 语义特征作为ＳＭＭ模型的输入，提出了用于分类多视 图数据的概率主题模型．另外，两个模型的结合并不是 简单的联合，增加了参数优化中求解ＳＭＭ模型参数的 困难．本文使用一些近似技巧，并基于变分期望最大化 （ＥＭ）方法，推导了提出模型的参数估计算法．两个真实 图像集上的实验结果表明了提出模型有较好的分类性 能．

２ＭｖｓＬＤＡ模型

通过嵌入ＬＤＡ模型到ＳＭＭ中，提出多视图有监督 的ＬＤＡ模型———ＭｕｌｔｉｖｉｅｗｓＬＤＡ（ＭＶｓＬＤＡ）模型．该模 型条件依赖视图数目Ｈ和视图的主题数目Ｋｈ，ｈ∈｛１，

２，…，Ｈ｝，并假设带有类标的多视图数据（（Ｖ１，Ｖ２，…，

ＶＨ），ｃ）的生成过程如下：

（１）对于视图

Ｖｈ＝｛ｖ ｈ１，ｖ ｈ２，…，ｖ ｈＭｈ｝，ｈ∈｛１，２，…，Ｈ｝

（ａ）抽取主题比例θｈ～ｐｄｉｒ（αｈ）． （ｂ）对于每个视图词汇ｖ ｈｍ，ｍ∈｛１，２，…，Ｍｈ｝： （ｉ）抽取主题分派ｚ ｈｍ｜ θｈ～ｐｍｕｌｔ（θｈ）． （ｉｉ）抽取视图词汇ｖ ｈｍ｜ｚ ｈｍ～ｐｍｕｌｔ（πｚ ｈｍ）．

（２）对于类标ｃ （ａ）抽取“视图”的分派，ｓ｜ｙ～ｐｍｕｌｔ（ｙ）． （ｂ）抽取类标ｃ｜ｚ ｈ，ｓ～ｐｓｏｆｔｍａｘ（ 珋ｚ ｈ，ｓ，μ），其中珋ｚ ｈ＝

Ｍｈ ｍ＝１ｚ ｈｍ为经验主题频次，Ｓｏｆｔｍａｘ函数为：

ｐ（ｃ｜珋ｚ，ｓ，η）＝∏

ｅｘｐ（η Τ ｈｃ珋ｚ ｈ） ∑

ｌ＝１ｅｘｐ（η Τ ｈｌ珋ｚ ｈ ( ) ）

该模型确定了一个潜变量和观测变量的联合分 布：

ｐ（Ｅ，Ｈ｜Ω）

ｈ＝１ ｐ（θｈ｜αｈ）∏

ｍ＝１ ｐ（ｚ ｈｍ｜θｈ）ｐ（ｖ ｈｍ｜ｚ ｈｍ，π）

·ｐ（ｓ｜ｙ）ｐ（ｃ｜珋ｚ，ｓ，η） （１） 其中，Ｅ＝（（Ｖ１，Ｖ２，…，ＶＨ），ｃ），Ｈ＝｛θ１，Ｚ１，…，θＨ，

ＺＨ，ｓ｝和Ω ＝｛α１，π１，…，αＨ，πＨ，ｙ，η｝．其图模型表示

见图１． 在上述生成过程中，步骤（１）描述了视图Ｖｈ＝ ｛ｖ ｈ１，ｖ ｈ２，…，ｖ ｈＭｈ｝，ｈ∈｛１，２，…，Ｈ｝的生成过程，其中每

上的分类器生成类标．参数ｙ记录了每个视图的权重， 值越大意味着越重要．

值得指出的是，提出模型既可分类单视图数据，亦 可分类多视图数据，只需要将每个视图的特征表示成 词袋表示形式．

３参数估计和预测

３１参数估计 使用最大似然估计优化提出模型的参数．考虑到 潜变量上的后验概率ｐ（Ｈ｜Ｅ）很难计算，因而采用变分 近似［１０］来获得近似的后验分布．给定一个数据（（Ｖ１，

Ｖ２，…，ＶＨ），ｃ），定义一个全分解的潜变量上的变分分

ｑ（Ｈ｜Λ）＝∏

ｈ＝１ ｑ（θｈ｜γｈ）∏

ｍ＝１ ｑ（ｚ ｈｍ｜ｆ ｈｍ）ｑ（ｓ｜λ）

（２） 其中，Λ ＝｛γ１，φ１，…，γＨ，φＨ，λ｝，γｈ是一个Ｋｈ维的

Ｄｉｒｉｃｈｌｅｔ参数，φｍｈ是一个Ｋｈ维的多项式参数．给定模型

Ω ＝｛α１，π１，…，αＨ，πＨ，ｙ，η｝和变分分布ｑ，基于ＫＬ散 度，可得到（（Ｖ１，Ｖ２，…，ＶＨ），ｃ）的似然下限：

ｌｏｇｐ（Ｅ｜Ω）Ｅｑ［ｌｏｇｐ（Ｅ，Ｈ｜Ω）］－Ｅｑ［ｌｏｇｑ（Ｈ｜Λ）］

＝Ｌ（Λ；Ω） （３） 则优化目标由原来的最大化ｌｏｇｐ（Ｅ｜Ω）变为相对于变 分参数Λ ＝｛γ１，φ１，…，γＨ，φＨ，λ｝和模型参数Ω ＝ ｛α１，π１，…，αＨ，πＨ，ｙ，η｝最大化Ｌ（Λ；Ω）． （１）变分Ｅｓｔｅｐ 在Ｅｓｔｅｐ中，固定模型参数Ω，相对于变分参数Λ 最大化Ｌ（Λ；Ω），可得到

γｈｉ＝αｈｉ＋∑

ｍ＝１φｈｍｉ （４）

φｈｍｉ∝πｈｉｖ ｍｅｘｐψ（γｈｉ）＋λｈ １ Ｍｈηｈｃｉ－（ｂ Τ ｈφ ｏｌｄ ｈｍ）－１ｂ ( ) ( ) ｈｉ

（５） 其中，符号“∝”代表“正比于”，并且

１ ４ ０ ２ 第 １０期 李晓旭：多视图有监督的ＬＤＡ模型

和φ ｏｌｄ ｈｍ是上一次被更新的值．

ｅｘｐη Τ ｈｃ珔 φｈ＋ｌｎ（ｙ ｈ）－ｌｎ∑

ｊ＝１φｍｉｅｘｐ１ Ｍｈη ( ) ( ) ( ) ｈｌｊ

λｈ是当前数据分派给第ｈ个视图分类器的概率，λ 的

值越大意味着该视图的特征分辨性越强． 迭代式（４），（５）和（６）直到数据的ｌｏｇ似然（ｌｏｇｌｉｋｅ

ｌｉｈｏｏｄ）方程（３）收敛． （２）Ｍｓｔｅｐ 重复ＥｓｔｅｐＤ次，得到所有数据的近似后验分布，

从而简化了Ｍｓｔｅｐ的计算．在Ｍｓｔｅｐ中，相对于模型参

数Ω ＝｛α１，π１，…，αＨ，πＨ，ｙ，η｝最大化Ｌ（Ｄ）＝

ｄ＝１Ｌ（Λｄ；Ω）．视图的主题和权重参数更新如下：

πｈｉｊ∝∑

ｍ＝１φｄｈｍｉｖｊ ｄｈｍ （７）

ｄ＝１λｄｈ （８）

对于视图的分类规则η 的优化，挑选Ｌ中包含η 的项：

Ｌ［η］＝∑

ｎ＝１λｄｈη Τ ｈｃ珔 φｄｈ－ｌｎ∑

ｌ＝１ Ｅｑ［ｅｘｐ（η Τ ｈｌ 珋ｚ ｄｈ ( ) [ ] ）］

关于Ｅｑ［ｅｘｐ（η Τｈｌ 珋ｚ ｄｈ）］的计算，采用多变量ｄｅｌｔａ方

法［１１］，Ｅｆ（Ｖ）ｆ（ＥＶ）＋１ ２ｔｒ［ ２ｆ（ＥＶ）／ ＶＶΤｃｏｖ（Ｖ）］．其

中，ｆ（Ｖ）是一个Ｋ维空间的函数．令ｆ（ 珋ｚ）＝ｅｘｐ（η Τ珋ｚ），则

有Ｅｑｆ（ 珋ｚ）ｅｘｐ（η Τｈｌ 珔 φ）１＋１ ２η Τｈｌｃｏｖ（ 珋ｚ）η ( ) ｈｌ．另外，为了防

止过拟合，采用Ｌｏｇｉｓｔｉｃ回归［１０］等分类器的优化中常用的

方法，在目标函数中加入一个正则化项－τ‖η‖ ２，则Ｌ［η］ 近似为：

Ｌ［η］－∑

ｎ＝１λｄｈｌｎ∑

ｌ＝１ ｅｘｐ（η Τｈｌ 珔 φｄｈ ( ）

· １＋１ ２η Τｈｌｃｏｖ（ 珋ｚ ｄｈ）η ( ) ) ｈｌ

ｎ＝１λｄｈη Τ ｈｃ 珔 φｄｈ－τ∑

ｌ＝１ηｈｌ·ηｈｌ （９）

Ｌ［η］相对于ηｈｃ的导数为：

Ｌ［η］ ηｈｃ∑

ｄ＝１λｄｈｃｃ ｄ珔 φｄｈ－２τ·ηｈｃ－∑

ｄ＝１λｄｈＡ（１０）

λｄｈ ｅｘｐ（η Τｈｃ 珔 φｄｈ）珔 φｄｈ１＋１ ２η Τｈｃｃｏｖ（ 珋ｚ ｄｈ）η ( ) ｈｃ＋η Τｈｃｃｏｖ（ 珋ｚ ｄｈ ( ) ）

ｌ＝１ ｅｘｐ（η Τｈｌ珔 φｄｈ）１＋１ ２η Τｈｌｃｏｖ（ 珋ｚ ｄｈ）η ( ) ｈｌ

Ｍｄ ｍ＝１（φｄｈｍｉ１（ｆ＝ｉ）－φｄｈｍｆφｄｈｍｉ）／Ｍ２ ｄｈ．显然得不到η

的封闭解，因而采用共轭梯度法来优化η．

重复调用ＥＭ步骤，直到Ｌ（Ｄ）＝∑

ｄ＝１ Ｌ（Λｄ；Ω）收

敛． ３２预测分类 从提出模型的生成过程看，类标的生成依赖每个视 图的主题频次珋ｚ和权重ｙ．对于一个新数据，需要使用训 练好的模型参数π 计算每个视图的主题频次．这里通过

Ｅｓｅｔｐ计算Ｅｑ［ 珋ｚ］＝珔 φ 来近似珋ｚ．得到视图的主题频次珋ｚ 后，利用训练好的模型参数η（即每个视图的分类规则） 和视图的权重参数ｙ，采用加权求和方式，最高值的决策 将被选择为最终的决策．具体计算公式如下：

Ｃ＝ａｒｇｍａｘ ｃ∈｛１，２，…，Ｃ｝∑

ｈ＝１ ｙ ｈ ｅｘｐ（η Τ ｈｃ珋ｚ ｈ）

ｌ＝１ ｅｘｐ（η Τ ｈｌ珋ｚ ｈ）

＝ａｒｇｍａｘ ｃ∈｛１，２，…，Ｃ｝∑

ｈ＝１ ｙ ｈ ｅｘｐ（η Τｈｃ珔 φｄｈ）

ｌ＝１ ｅｘｐ（η Τｈｌ珔 φｄｈ） （１１）

可见，最终的决策考虑了每个试图的决策和权重， 这和提出模型的生成过程是一致的，也符合人的一般 的思维方式．

４１数据和预处理 为了评估提出模型的性能，选择了两个真实图像 数据集．一个是带有标注的场景分类数据集：ＬａｂｅｌＭｅ的 子集［１２］．该数据集包含８类自然场景图像，共１６００个图 像．另一个是带有标注的事件分类数据集：８类的ＵＩＵＣ Ｓｐｏｒｔ数据集［１３］，共１７９１个图像．图像和标注文本分别 被作为两个不同的单视图特征． （１）对于图像视图，采用文献［７］中相似的方法．对 于ＬａｂｅｌＭｅ数据集相关参数设置如下：设置网格的大小 为５×５，图像区块为１６×１６，码书长度为２４０．对于

２ ４ ０ ２ 电 子 学 报 ２０１４年

ｓＬＤＡ是有监督的主题模型，该模型嵌入ｓｏｆｔｍａｘ ［１０］模型 到ＬＤＡ模型中，并且在上述两个数据集上报告了较高的 分类性能．ＳＢＭＬＲ是一个带有Ｌａｐｌａｃｅ先验的ｓｏｆｔｍａｘ分 类器，常常具有很好的泛化能力．对于两个ＳＶＭ方法， 本文使用ｌｉｂｓｖｍ进行测试． ＦｕＬ模型是先分别在图像和文本视图上构建单分 类器，然后使用第三个分类器综合前面的结果．ＭＣａｓＬ ＤＡ模型是可同时做图像分类和标注的概率主题模型， 也可看做使用了文本和图像两个视图的分类模型． 表１给出了提出模型ＭｖｓＬＤＡ在文本和图像两个 视图数据上的性能．为了方便起见，在两个视图上设置 相同的主题数目．实际上，可以设置不同的主题数目． ＭｖｓＬＤＡ模型中的视图的权重参数ｙ是二维数组，第一 维表示图像的权重，第二维表示文本的权重．实验结果 表明：两个数据集上文本特征的权重比图像特征都较 高，及文本特征较为重要，即有更好的分辨性．提出模 型在ＬａｂｅｌＭｅ数据上可达到９２．２％准确率，在ＵＩＵＣ Ｓｐｏｒｔ数据上可达到９９．０％的准确率．

对于方法（１）～（４），分别测试了在两个数据集的图 像视图、文本视图以及将图像和文本特征平行拼接而 构成的联合试图上的性能．对于方法（５）～（６）和本文的 方法，测试了在图像和文本两个视图上的性能．对于

ＭＣｓＬＤＡ模型和ＭＣａｓＬＤＡ模型，均匀的从２０到１００选 择５组主题数目，并选其最佳性能，见从表２可以看出， 在ＬａｂｅｌＭｅ数据集上，当只使用图像视图的时候，单视 图方法的最好性能是ＳＶＭＲＢＦ的８１．１％．当只使用文 本视图的时候，单视图方法的最好性能是ＭＣｓＬＤＡ的

８９．０％．当使用图像和文本的联合试图时，四个单视图 方法的最好性能是ＳＶＭＰＯＬ的８８．９％．另外，四个单视 图方法在联合视图上的性能有时居然比在单视图上的 性能还差一些．在多视图方法中，后期融合方法ＦｕＬ的 性能是８２．２％，中期融合方法ＭＣａｓＬＤＡ的性能是７６． ８％．而提出方法ＭｖｓＬＤＡ的性能是９２．２％． 在ＵＩＵＣＳｐｏｒｔ数据集上，提出模型的性能也有相似 的提升，见表３．总之，提出的模型在这两个数据集上有 较高的分类性能．

表１在ＵＩＵＣｓｐｏｒｔ和ＬａｂｅｌＭｅ数据集的５个随机训练和测试子集上ＭｖｓＬＤＡ模型的平均性能和视图的权重分派．ＡＡ表示平均性能，Ｗｅｉｇｈｔ表示

权重的分派．二元组的第一个元素表示图像视图的权重，第二个元素表示文本视图的权重

多视图 Ｋ１＝Ｋ２＝５ Ｋ１＝Ｋ２＝１０ Ｋ１＝Ｋ２＝２０ Ｋ１＝Ｋ２＝３０ Ｋ１＝Ｋ２＝４０

ＡＡＬａｂｅｌＭｅ ０．７９６ ０．８４３ ０．８８２ ０．９０５ ０．９２２

ＡＡＵＩＵＣ ０．８７６ ０．８８２ ０．９９０ ０．９８７ ０．９９０

ＷｅｉｇｈｔＬａｂｅｌＭｅ （０．５９，０．４１） （０．３３，０．６７） （０．２３，０．７７） （０．１２，０．８８） （０．２２，０．７８）

ＷｅｉｇｈｔＵＩＵＣ （０．０３，０．９７） （０．０１，０．９９） （０．００，１．００） （０．００，１．００） （０．００，１．００）

表２在ＬａｂｅｌＭｅ数据集的５个随机训练和测试子集上模型的平均性能比较．图像视图是指当图像特征作为一个单视图，文本视图指文本特征作

为单视图，联合特征指文本和图像的联合特征作为单视图，多视图指将文本和图像的分别作为两个不同的视图

视图类型 ＳＶＭＰＯＬ ＳＶＭＲＢＦ ＳＢＭＬＲ ＭＣｓＬＤＡ ＭｃａｓＬＤＡ ＦｕＬ ＭｖｓＬＤＡ

图像视图 ０．７７９ ０．８１１ ０．７４８ ０．７６６ Ｎ／Ａ Ｎ／Ａ ０．７６８

文本视图 ０．７８９ ０．８７９ ０．８６０ ０．８９０ Ｎ／Ａ Ｎ／Ａ ０．８９０

联合视图 ０．８８９ ０．８３７ ０．７７８ ０．７８９ Ｎ／Ａ Ｎ／Ａ ０．７８９

多视图 Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ ０．７６８ ０．８２２ ０．９２２

表３在ＵＩＵＣｓｐｏｒｔ数据集的５个随机训练和测试子集上模型的平均性能比较．图像视图是指当图像特征作为一个单视图，文本视图指文本特征

作为单视图，联合特征指文本和图像的联合特征作为单视图，多视图指将文本和图像的分别作为两个不同的视图

视图类型 ＳＶＭＰＯＬ ＳＶＭＲＢＦ ＳＢＭＬＲ ＭＣｓＬＤＡ ＭｃａｓＬＤＡ ＦｕＬ ＭｖｓＬＤＡ

图像视图 ０．６４７ ０．６９２ ０．６４３ ０．６４０ Ｎ／Ａ Ｎ／Ａ ０．６３９

文本视图 ０．９７６ ０．９７８ ０．９８０ ０．９８１ Ｎ／Ａ Ｎ／Ａ ０．９８３

联合视图 ０．４９３ ０．９３２ ０．９１６ ０．６６０ Ｎ／Ａ Ｎ／Ａ ０．６６２

多视图 Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ ０．６７０ ０．８４１ ０．９９０

４３结果分析

对于上述实验结果，可总结为以下三点：（１）四个

单视图方法在联合视图上的性能有时低于在单视图上

信息，而提出的模型却表现的比较好．原因在于，在上

述两个数据集中，文本特征的值相比图像特征的值较

小，然而又比较重要．两个视图的值较大的差距增加找

３ ４ ０ ２ 第 １０期 李晓旭：多视图有监督的ＬＤＡ模型

化程序一般能够辨别不同的特征的重要性．特别在

ＳＢＭＬＲ方法中，Ｌ１约束的使用使得该方法更难辨别两 个视图特征的重要性．而提出的模型属于中期融合方 法，通过构建集成分类器来融合多视图信息，避免上面 提到的使用联合视图的问题． （２）提出的模型表现的比后期融合方法ＦｕＬ好，原 因也许是：在ＦｕＬ中，每个视图分类器的训练是独立 的．相反，在提出的模型中，分类器的训练是交互的．另 外，提出的模型能学习适合分类的预测特征，以致更容 易构建适合分类多视图数据的分类器． （３）提出的模型表现的比多视图中期融合方法

ＭＣａｓＬＤＡ好，是因为本文使用的两个数据集上文本特 征值比较小，并且高频词对主题模型ＭＣａｓＬＤＡ学习语 义特征的影响大，以致文本特征对语义特征学习有较 小的作用．而提出的模型集合了特征学习和集成分类 器的学习，并选择在视图分类器的训练阶段利用多视 图信息，从而避免该问题．

本文提出了一个分类多视图数据的概率主题模型

ＭｖｓＬＤＡ，并基于变分ＥＭ推导了参数估计算法．两个真 实图像数据集上的实验结果表明了提出模型有较好的 分类性能，也表明了该模型充分利用了多视图信息．下 一步工作，将在本文算法的基础上，考虑如何确定主题 数目，以及当给定一组特征时，如何确定特征的视图分 组等问题．

［１］ＷｕＬ，ｅｔａｌ．Ｍｕｌｔｉｍｏｄａｌｉｎｔｅｇｒａｔｉｏｎ—Ａｓｔａｔｉｓｔｉｃａｌｖｉｅｗ［Ｊ］．

ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＭｕｌｔｉｍｅｄｉａ，１９９９，１（４）：３３４－３４１． ［２］ＷａｎｇＧ，ｅｔａｌ．Ｂｕｉｌｄｉｎｇｔｅｘｔｆｅａｔｕｒｅｓｆｏｒｏｂｊｅｃｔｉｍａｇｅｃｌａｓｓｉｆｉ

ｃａｔｉｏｎ［Ａ］．ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎ

Ｒｅｃｏｇｎｉｔｉｏｎ（ＣＶＰＲ０９）［Ｃ］．ＩＥＥＥ，２００９．１３６７－１３７４． ［３］ＢｌｅｉＤＭａｎｄＪｏｒｄａｎＭＩ．Ｍｏｄｅｌｉｎｇａｎｎｏｔａｔｅｄｄａｔａ［Ａ］．Ｐｒｏｃ

ｏｆｔｈｅ２６ｔｈＡｎｎｕａｌＩｎｔｅｒｎａｔｉｏｎａｌＡＣＭＳＩＧＩＲＣｏｎｆｅｒｅｎｃｅｏｎ

ＲｅｓｅａｒｃｈａｎｄＤｅｖｅｌｏｐｍｅｎｔｉｎＩｎｆｏｒｍａｉｏｎＲｅｔｒｉｅｖａｌ［Ｃ］．ＡＣＭ，

２００３．１２７－１３４． ［４］ＦｒａｗｌｅｙＷＪ，ｅｔａｌ．Ｋｎｏｗｌｅｄｇｅｄｉｓｃｏｖｅｒｙｉｎｄａｔａｂａｓｅｓ：Ａｎ

ｏｖｅｒｖｉｅｗ［Ｊ］．ＡＩＭａｇａｚｉｎｅ，１９９２，１３（３）：５７． ［５］Ｍｅｍｉｓｅｖｉｃ，Ｒ．Ｏｎｍｕｌｔｉｖｉｅｗｆｅａｔｕｒｅｌｅａｒｎｉｎｇ［Ａ］．Ｐｒｏｃｅｅｄｉｎｇｓ

ｏｆｔｈｅ２９ｔｈＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＭａｃｈｉｎｅＬｅａｒｎｉｎｇ （ＩＣＭＬ１２）［Ｃ］．ＮｅｗＹｏｒｋ，ＵＳＡ：Ｏｍｎｉｐｒｅｓｓ，２０１２．１６１－

１６８． ［６］ＣｈｅｎＮ，ｅｔａｌ．Ｐｒｅｄｉｃｔｉｖｅｓｕｂｓｐａｃｅｌｅａｒｎｉｎｇｆｏｒｍｕｌｔｉｖｉｅｗｄａｔａ：

Ａｌａｒｇｅｍａｒｇｉｎａｐｐｒｏａｃｈ［Ａ］．ＡｄｖａｎｃｅｓｉｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎ

ＰｒｏｃｅｓｓｉｎｇＳｙｓｔｅｍｓ［Ｃ］．Ｖａｎｃｏｕｖｅｒ：ＣｕｒｒａｎＡｓｓｏｃｉａｔｅｓ，２０１０．

３６１－３６９． ［７］ＷａｎｇＣ，ｅｔａｌ．Ｓｉｍｕｌｔａｎｅｏｕｓｉｍａｇｅｃｌａｓｓｉｆｉｃａｔｉｏｎａｎｄａｎｎｏｔａｔｉｏｎ ［Ａ］．ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇ

ｎｉｔｉｏｎ（ＣＶＰＲ０９）［Ｃ］．ＩＥＥＥ，２００９．１９０３－１９１０． ［８］ＳｏｎｎｅｎｂｕｒｇＳ，ｅｔａｌ．Ｌａｒｇｅｓｃａｌｅｍｕｌｔｉｐｌｅｋｅｒｎｅｌｌｅａｒｎｉｎｇ［Ｊ］．

ＴｈｅＪｏｕｒｎａｌｏｆＭａｃｈｉｎｅＬｅａｒｎｉｎｇＲｅｓｅａｒｃｈ，２００６，７：１５３１－

１５６５． ［９］ＢｌｅｉＤＭ，ｅｔａｌ．Ｌａｔｅｎｔｄｉｒｉｃｈｌｅｔｌｅｔａｌｌｏｃａｔｉｏｎ［Ｊ］．ＴｈｅＪｏｕｒｎａｌ

ｏｆＭａｃｈｉｎｅＬｅａｒｎｉｎｇＲｅｓｅａｒｃｈ，２００３，３：９９３－１０２２． ［１０］ＢｉｓｈｏｐＣＭ，ｅｔａｌ．ＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎａｎｄＭａｃｈｉｎｅＬｅａｒｎｉｎｇ ［Ｍ］．ＳｐｒｉｎｇｅｒＮｅｗＹｏｒｋ，２００６．４６１－６７４． ［１１］ＢｒａｕｎＭ，ＭｃＡｕｌｉｆｆｅＪ．Ｖａｒｉａｔｉｏｎａｌｉｎｆｅｒｅｎｃｅｆｏｒｌａｒｇｅｓｃａｌｅ

ｍｏｄｅｌｓｏｆｄｉｓｃｒｅｔｅｃｈｏｉｃｅ［Ｊ］．ＪｏｕｒｎａｌｏｆｔｈｅＡｍｅｒｉｃａｎＳｔａｔｉｓ

ｔｉｃａｌＡｓｓｏｃｉａｔｉｏｎ，２０１０，１０５（４８９）：３２４－３３５． ［１２］ＲｕｓｓｅｌｌＢＣ，ｅｔａｌ．Ｌａｂｅｌｍｅ：Ａｄａｔａｂａｓｅａｎｄｗｅｂｂａｓｅｄｔｏｏｌ

ｆｏｒｉｍａｇｅａｎｎｏｔａｔｉｏｎ［Ｊ］．ＩｎｔｅｒｎａｔｉｏｎａｌＪｏｕｒｎａｌｏｆＣｏｍｐｕｔｅｒ

Ｖｉｓｉｏｎ，２００８，７７（１）：１５７－１７３． ［１３］ＬｉＬＪ，ＦｅｉＦｅｉＬ．Ｗｈａｔ，ｗｈｅｒｅａｎｄｗｈｏ？ｃｌａｓｓｉｆｙｉｎｇｅｖｅｎｔｓｂｙ

ｓｃｅｎｅａｎｄｏｂｊｅｃｔｒｅｃｏｇｎｉｔｉｏｎ［Ａ］．ＩＥＥＥ１１ｔｈＩｎｔｅｒｎａｔｉｏｎａｌ

ＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ（ＩＣＣＶ２００７）［Ｃ］．ＩＥＥＥ，

２００７．１－８． ［１４］ＣａｗｌｅｙＧＣ，ｅｔａｌ．Ｓｐａｒｓｅｍｕｌｔｉｎｏｍｉａｌｌｏｇｉｓｔｉｃｒｅｇｒｅｓｓｉｏｎｖｉａ

ｂａｙｅｓｉａｎＬ１ｒｅｇｕｌａｒｉｓａｔｉｏｎ［Ａ］．Ａｄｖａｎｃｅｓｉｎｎｅｕｒａｌｉｎｆｏｒｍａｔｉｏｎ

ｐｒｏｃｅｓｓｉｎｇｓｙｓｔｅｍｓ［Ｃ］．ＣａｍｂｒｉｄｇｅＭＡＵＳＡ：ＭＩＴＰｒｅｓｓ，

２００７．２０９－２１６． ［１５］ＣｈａｎｇＣＣ，ＬｉｎＣＪ．Ｌｉｂｓｖｍ：Ａｌｉｂｒａｒｙｆｏｒｓｕｐｐｏｒｔｖｅｃｔｏｒｍａ

ｃｈｉｎｅｓ［Ｊ］．ＡＣＭＴｒａｎｓａｃｔｉｏｎｓｏｎＩｎｔｅｌｌｉｇｅｎｔＳｙｓｔｅｍｓａｎｄ

Ｔｅｃｈｎｏｌｏｇｙ（ＴＩＳＴ），２０１１，２（３）：２７．

李晓旭 女，１９８２年生于吉林白城．兰州理

工大学计算机与通信学院讲师．研究方向为计

算机视觉、机器学习．

Ｅｍａｉｌ：ｘｉａｏｘｕｌｉｌｕｔ＠ｇｍａｉｌ．ｃｏｍ

李睿凡 男，１９７５年生于河北完县．北京邮

电大学计算机学院讲师．主要研究兴趣为多模

态智能信息处理．

Ｅｍａｉｌ：ｒｆｌｉ＠ｂｕｐｔ．ｅｄｕ．ｃｎ

４ ４ ０ ２ 电 子 学 报 ２０１４年