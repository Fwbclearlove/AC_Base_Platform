密级 ：保密期限 ：  

ｉ＆ｔｆｔ大ｆ  

颂士学位论文   美   Ｗ  

题目 ：基于深度卷积结构的  

图像段落描述研究  

学号 ：２０１７１１０６５２  

姓名 ：梁昊雨  

专业 ：智能科学与技术  

导师 ：李睿凡  

学院 ：计算机学院  

２０２０年 ４月 １０ 日  

？北京  

密级 ：保密期限 ：  

分耆却ｔ大摩  

硕士学位论文   ？  

题目 ：基于深度卷积结构的  

图像段落描述研究  

学号 ：２０１７１ １０６５２  

姓名 ：梁昊雨  

专业 ： 智能科学与技术  

导师 ：李睿凡  

学院 ：计算机学院  

２０２０年 ０４月 １０ 日  

基于深度卷积结构的图像段落描述研究  

摘 要  

段落式图像描述任务旨在为给定图像生成描述性的自然语言段  

落 ，连接着计算机视觉和自然语言处理两个关键领域 ， 是跨媒体智能  

的重要研究方向 ，其研究进展对于打破图像和文本间的语义鸿沟至关  

重要 。  

近年来 ， 随着深度学习的发展 ，得益于循环神经网络 （Ｒｅｃｕｒｒｅｎｔ  

ＮｅｕｒａｌＮｅｔｗｏｒｋ ， ＲＮＮ ） 家族出色的时间序列建模能力 ， 基于层次性   ＲＮＮ的解码器已被广泛采用于段落式图像描述任 务 上。 然 而，Ｒ Ｎ

结构上的限制使得这类方法存在如下 问题。 首 先，由于捕获长时 信 息

的能力 有限，ＲＮＮ生成段落这类长文本 存 在困难，生成的 段 落

连贯 性不 足 。此外，ＲＮＮ的串行结构导致其训练时间复 杂 度较 高 ，

效率 低下。受启发于卷积 神经网络（ＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｕｒａｌＮｅｔ ｗｏｒｋ， Ｃ Ｎ

） 的 特点，本文展开以 下 工 作

。提出了基于全卷积神经结构的段落 解码器。将门控结构融 入 层

次性的ＣＮＮ解 码 器中，该解码器具有更强的长时记 忆 能力，并 拥 有

并行化训练 的能力。

提出了一种衡量段落连贯性 的指标。经在斯 坦 福

像－段落数据集上进行评 测 指标、连贯 性指标、时间复杂度以 及 主

观  分析，证明所提解码器提升了生成段落 的 质 量

。提出了融合区域注意力的段落式图像描述模型Ｄ

ｕａｌ－ Ｃ ＮＮ ， 增

强了图像理 解能力，提升了段落内句子描述的详细度和 多样度。 提 出

了一种衡量段落内句子多样度 的指标。经评 测 指标、多样 度 指标 、 区

域注意 力 分析、主 观 分析，Ｄ

ｕａｌ－ＣＮＮ显著提升了段落式图像描 述 任

务 的 性 能 。

关键词 ： 深度学习 卷积神经网络段落式图像描述 连 贯 性

ＰＡＲＡＧＲＡＰＨＩＭＡＧＥＣＡＰＴＩＯＮＩＮＧＢＡＳＥＤＯＮ  

ＣＯＮＶＯＬＵＴＩＯＮＡＬＮＥＵＲＡＬＮＥＴＷＯＲＫ

ＡＢＳＴＲＡＣＴ  

Ｔｈｅｔａｓｋｏｆｐａｒａｇｒａｐｈｉｍａｇｅｃａｐ ｔｉｏｎ ｉｎｇ ｔａｓｋａｉｍｓｔｏｇｅｎｅｒａｔｅａ  

ｄｅｓｃｒｉｐ ｔｉｖｅｐａｒａｇｒａｐｈｆｏｒａｇ

ｉｖｅｎｉｍａｇｅ ．Ａｓａｎｉｍｐｏｒｔａｎｔｒｅｓｅａｒｃｈ  ｄ

ｉｒｅｃｔｉｏｎｏｆｃｒｏｓｓ－ ｍｅｄｉａｉｎｔｅｌｌｉ ｇｅｎｃｅ， ｉｔ ｃｏｎｎｅｃｔｓｔｗｏｓｉｇ ｎｉｆｉｃ ａｎｔａｒｅａｓ：  ｃ ｏ

ｍｐｕｔｅｒｖｉｓ ｉｏｎａｎｄｎａｔｕｒａｌｌａｎｇｕａｇｅｐｒｏ ｃｅｓｓｉｎｇ．Ｔ

ｈｅｒｅｓｅａｒｃｈｐｒｏｇ ｒｅｓｓｏ ｆ 

ｔｈｉｓ ｔａｓｋｉｓｖｅｒｙｉｍｐ

ｏｒｔａｎｔｔｏｂｒｅａｋｔｈｅｓｅｍａｎｔｉｃｇａｐｂｅｔｗｅｅｎｉｍａｇｅｓａ ｎ ｄ

ｔｅｘｔ． Ｉ ｎ 

ｒｅｃｅｎｔｙｅａｒｓ，ｔｈ ａｎｋｓｔｏｔｈｅｓｅｑｕｅｎｃｅｍｏｄｅｌｉｎｇ ｃａｐａｂｉｌｉｔｉ ｅ ｓｏｆｔｈｅＲＮ 

（ＲｅｃｕｒｒｅｎｔＮｅｕｒａｌＮｅｔｗｏｒｋ）ｆａ ｍｉｌｙ， ｈ ｉｅ ｒａｒｃｈｉｃａｌ ＲＮＮｄｅｃｏｄｅｒｓｈａｖ ｅ 

ｂｅｅｎｗｉｄｅｌｙ ｕｓｅｄｉｎｐａｒａｇｒａｐｈｉｍａｇｅｃａｐｔｉｏｎｉ ｎｇ．Ｈ ｏｗｅ

ｖｅｒ，ｔｈｅ ｌｉｍｉｔ ａ ｔ

ｉ ｏｎ ｓｏｆｔｈｅＲＮＮｓｔｒｕｃｔｕｒｅｍａｋｅｓｕｃｈｍｅｔｈｏｄｓｈａｖｅｔｈｅｆｏｌｌｏｗｉｎｇ  ｐｒｏｂｌ ｅ ｍ

ｓ．Ｆｉ ｒｓｔ， ｄｕｅ ｔｏ ｔｈｅｌｉｍｉｔｅｄａｂ ｉｌ ｉｔｙｔｏ ｃ ａ ｐｔｕｒ ｅｌｏｎｇ －ｔｅｒｍｉｎ

ｆ ｏｒｍａ ｔ ｉ

ｏｎ，ＲＮＮｉｓｄ ｉｆｆｉｃｕｌｔｔ ｏｇｅｎｅ ｒａｔｅｌｏｎｇｐａｒａｇｒａｐｈｓ．Ｔｈｅｇｅｎｅｒ ａｔｅｄｐａｒａｇｒａｐｈ ｓ 

ａｒｅｎｏｔｓｕｃｈｃｏｈｅｒｅｎｔ．Ｉｎａｄｄｉｔｉｏ ｎ，ｔｈｅｓｅ ｒｉａｌ ｓｔｒｕｃｔｕｒｅｏｆＲＮＮｒｅｓｕｌｔｓｉｎ ｈ ｉ

ｇｈｅｒ ｔｒａｉｎｉｎｇｔｉｍｅｃｏｍｐｌｅｘｉ ｔｙａｎｄｌｏ ｗｅｒｅｆｆｉｃｉｅｎｃｙ．Ｉｎｓｐｉ ｒｅｄｂｙ

ｔｈｅｃ ｈａｒａ ｃ ｔ

ｅｒｉ ｓｔｉｃｓｏｆｔｈｅＣＮＮ（ＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｕｒａｌＮｅｔｗｏｒｋ），ｗｅｃｏｎｄｕｃｔ ｔｈｅｆ ｏ ｌ

ｌｏｗｉｎｇｗｏｒｋｓ． Ａｐａｒａｇｒａｐｈ ｄ ｅ ｃ

ｏ ｄｅｒｂａｓｅｄｏｎａｆｕｌｌｙｃｏｎｖｏｌｕｔｉｏｎａｌｎｅｕｒａｌｎｅｔｗｏｒｋｉｓｐｒｏｐｏｓｅｄ．Ｔ ｈ ｅ

ｇａｔｅｄｓｔｒｕ ｃｔｕｒｅｉｓｉｎｃｏｒｐｏｒａｔｅｄｉｎｔｏａｈｉｅｒａｒｃｈｉｃａｌＣＮＮｄｅｃｏｄｅｒ，ｗｈｉｃｈ ｈ ａ

ｓｓｔｒｏｎ ｇｅｒｌｏｎｇ－ｔｅｒｍｍｅｍｏｒｙｃａｐａ

ｂｉｌｉｔｉｅｓａｎｄｔｈｅａｂｉｌｉｔｙｔｏｔｒａｉ ｎ 

ｉｎｐａｒａｌ ｌｅｌ．Ａｍｅｔｒｉｃｔｏｍ ｅａｓ ｕｒｅｔｈｅｃｏｈｅｒｅｎｃｅｏｆｐａｒａｇｒａｐｈｓｉｓｐｒ ｏ ｐ

ｏｓｅｄ．Ｗｅｐｅｒｆｏｒｍｔｈｅｅｘ ｐｅｒｉｍｅｎｔｓｏｆｅｖａｌｕａｔｉｏｎｍｅｔｒｉｃｓ，ｃｏｈｅｒｅｎｃｅ  ｍ

ｅｔｒｉｃ，ｔ ｒａｉｎｉｎｇｔｉｍｅｃｏｍｐｌ ｅｘｉｔｙａｎｄｓ ｕｂｊｅｃｔｉｖｅ ａｎａｌｙｓｉｓｏｎｔｈｅＳｔａ ｎ ｆ

ｏｒｄｉｍａｇｅ－ｐａｒａｇｒａｐｈｄａｔａｓｅｔ．Ｗｅ

 ｃｏｍｅ ｔｏｔｈｅ

ｃｏｎｃｌｕｓｉｏｎｔｈａｔｏｕｒｄｅｃｏｄｅｒｉｍｐｒｏｖｅｓｔｈｅｑｕａｌ ｉｔｙｏｆｔｈｅｇｅｎｅｒａｔｅｄ  

ｐａｒａｇｒａｐｈｓ ．  

－ＣＮＮ ，ａｐａｒａｇｒａｐｈｉｍａｇｅｃａｐｔ ｉｏｎｉｎｇｍｏｄｅｌｔｈａｔｉｎｔｅｇｒａｔｅｓ  ｒ

ｅｇｉ ｏｎａｌａｔｔｅｎｔｉｏｎｉｓｐｒｏｐｏｓｅｄ， ｉｎ ｏｒｄｅｒｔｏｅｎｈａｎｃｅｔｈｅｉｍａｇｅ ｃ ｏ

ｍｐｒｅｈｅｎｓｉｏｎａｂｉｌｉｔ ｙ．Ａ

Ｍｅｔｒｉｃｆｏｒｍｅａｓｕｒｉｎｇｔｈｅ ｄｉｖｅｒｓｉｔｙｏｆｓｅｎｔｅｎｃｅｓｉ ｎ 

ａｐａｒａｇｒａｐｈｉｓｐｒｏｐｏｓｅｄ．Ｔｈ ｒｏｕｇｈｔｈｅｅｘｐｅｒｉｍｅｎｔｓｏｆｅｖａｌｕａｔｉｏｎｍｅ ｔ ｒ

ｉｃｓ，ｄｉｖ ｅｒｓｉｔｙｍ ｅｔｒｉｃ，ｒｅｇｉ ｏｎａｌ ａｔｔｅｎｔｉｏ ｎａｎａｌｙｓｉｓａｎｄｓｕｂｊｅｃｔｉｖｅａｎａｌ ｙ ｓ

ｉｓ，Ｄｕａｌ－ ＣＮＮｓｉ

ｇｎｉｆｉｃａｎｔｌｙｉｍｐｒｏｖｅ

ｄｔｈｅｐｅｒｆｏｒｍａｎｃｅｏｆｔｈｅｐａｒａｇ ｒ ａ

ｐｈｉｍａｇｅｃａｐｔｉｏｎｉｎｇ ｔａｓｋ．

ＫＥＹＷＯＲＤＳ ：ｄｅｅｐ ｌｅａｒｎｉｎｇ，ｃｏｎｖｏｌｕｔｉｏｎａｌｎｅｕｒａｌｎｅｔｗｏｒｋ ，ｐａｒａｇｒａｐｈ  

ｉｍａｇｅｃａｐｔｉｏｎｉｎｇ，ｃｏｈｅｒｅｎｃｅ

目录  

一章 绪论  ＃ １

  １ ．１研究背景及 意 义 

＃ １１．２研究现 状 及 分

析 ＃ ３  １．２．１单 句 式 图

像 描述 ＃ ３１．２．２段 落 式 图

像 描述 方法 ＃５１．２．３ 研 究 现

状 的总 结与分析＃６  １ ．

３ 本 文的研究工作＃ ７  

． ４本 文的 组 织

结 构  ＃８第二章基 础知 识 

＃ １ ０   ２．１深度神 经网 络 模

型  ＃ １０ ２．１．１  卷 积 神

经 网络 ＃１

０２．１． ２ 循 环

神 经网 络 ＃１１ ２ ． ２

 编码 器－ 解码器结构 ＃ １ ２

 ２ ．２ ．１概述＃ １２  

２ ．２ ．２模型详 述 ＃ １

３  ２．２．３单词采 样方 法 

＃ １３   ２．３注意力机制＃１４  ２ ．

４ 数 据集 及评价指标＃１６ ２． ４ ．

１ 段 落式图像描 述任 务 数

据集 ＃１６２．４．２图像描述任 务评 价 指

标  ＃１７２．５本章小结＃１ ９  第

三 章 基于全卷积神经结构 的段 落 解

码 器 ＃ ２ ０３．１ ＣＮ 解

码 器与 ＲＮＮ解码器＃２ ０  ３

． ２ 全卷积段落解码器＃ ２３  

３ ．２ ．１模型整体描述 ＃ ２ ３

 ３ ．２ ．２图像编码器 ＃ ２ ４

 ３ ．２ ．３句子ＣＮ Ｎ ＃ ２ ５   ３ ． ２ ． ４  词 Ｃ Ｎ  ＃ ２ ６   ３ ． ２ ． ５  模 型 训 练 与 推 理  ＃ ２ ７   ３ ． ２ ． ６  段 落 生 成 算 法  ＃ ２ ７

３ ．３实 验对 比 与

分 析 ＃ ２ ８３．３．１ 实 验 参

数 与设 置＃２８３． ３． ２ 

基 线方 法介绍＃２９３．３ ．３  评

测 指标 对比与分析＃３０３． ３． ４ 

连 贯性 指标 对比与分析＃３３ ３． ３ ．

５ 时 间复杂度对比与分析＃ ３５  

３ ．３ ．６生成段落定性分 析 ＃ ３

６  ３． ３．７卷积 层参 数 探

究 ＃３８３ ．３ ． ８

束大 小探究＃３８３．４本章小结 ＃３ ９ 

 第 四 章融合区域注意力的段落式图像描述模型＃

４０４ ．１  融

合 区 域 注 意 力的段落式图像 描述 模 型

Ｄ ｕ ａ ｌ－ ＣＮＮ＃４０  ４ ．

１ ． １ 模 型整体描述＃４０４．１ ．２  区

域 提议 网络＃４１ ４． １ ．

３ 融 合 区 域注意力的句子 ＣＮ 

＃ ４２ ４． ２实验对比与分析 ＃４ ３ 

 ４． ２． １基线方法介绍＃４ ３  ４

． ２． ２ 评测指标对比与分析＃４ ４  ４

． ２． ３多样度指标对比与分 析 ＃ ４

５  ４．２．４ 区 域 注

意力机 制效果分析 ＃４ ７ 

 ４ ． ２．５生 成段 落 定

性 分析 ＃４７４ ．３  本

章 小结 ＃ ４ ９

第五章总结与展望＃５ ０  ５ ． １  工 作 总 结  ＃ ５ ０   ５ ． ２  未 来 工 作 展 望  ＃ ５ ０   参 考 文 献  ＃ ５ ２   攻 读 学 位 期 间 取 得 的 研 究 成 果  ＃ ５ ８

一章 绪论  

第 一章 绪论  

１ ．１研究背景及意义  

在现今的移动互联信息时代 ，多模态数据无所不在 ，人们在网络上通过图像 、  

文本 、视频等多种信息载体进行交流 。在微信朋友圈 、微博 、推特等社交软件上 ，  

用户常常以图文结合的形式来沟通 。在新闻类网站和软件上 ， 图文结合的呈现方  

式也受到用户和内容发布者的青睐 。 一方面 ，图像等视觉信息是人们感知信息的  

最直观最有效形式 。另

一方面 ， 文本等语言信息是人类独有的交流形式 ， 其中蕴  

含着丰富的语义信息 。 二者的结合能让人们更有效地获取和处理信息 。  

人类凭借大脑拥有了强大的信息感知 、综合和响应能力 ，而人们还致力于让  

计算机拥有感知世界并做出反应的人工智能 （Ａｒ ｔｉｆ ｉｃｉａｌＩｎｔｅｌ ｌ ｉｇｅｎｃｅ ，ＡＩ ） 。虽然  

计算机在暴力计算 、批量数据处理等方面的能力已经远超人类 ，但其尚无真正智  

能 ，人们还迫切希望计算机能够拥有智能化处理海量互联网数据的能力 。更重要  

的是 ， 拥有人工智能的计算机将会给人们生活创造极大的便利 。 随着深度学习  

（ＤｅｅｐＬｅａｒｎｉｎｇ ） 的迅速崛起 ， 人工智能的两个重要学术领域 ： 计算机视觉  

（ＣｏｍｐｕｔｅｒＶｉｓｉｏｎ ，ＣＶ ） 和自然语言处理 （ＮａｔｕｒａｌＬａｎｇｕａｇｅＰｒｏｃｅｓｓｉｎｇ ，ＮＬＰ ）  

取得了相当进展 。在ＣＶ领域 ，建立在卷积神经网络（Ｃｏｎｖｏ ｌｕｔｉｏｎａｌＮｅｕｒａｌＮｅｔｗｏｒｋ ，  

ＣＮＮ ）架构基础上 ， 深度学习方法大幅度刷新了多项任务的新纪录 ， 在人脸识  

别 、 目标检测等领域已成熟投入工业界使用 。在 ＩｍａｇｅＮｅｔ大型视觉数据集

［ ｜ ］上  

的图像分类准确率已超过人类

。在ＮＬＰ领域 ， 得益于循环神经网络 （Ｒｅｃｕｒｒｅｎｔ  

ＮｅｕｒａｌＮｅｔｗｏｒｋ ，ＲＮＮ ） 、 Ｔｒａｎｓｆｏｒｍｅｒ

１ ３ １等

一系列网络的提出 ， 机器翻译 、 文本蕴  

含 、 情感分析等任务取得了很大突破 。基于ＲＮＮ端到端模型的谷歌翻译 ， 凭借  

其优越的性能被全世界无数人使用 。  

夏威夷欧胡岛 ■Ｗ一 ／＾ ． 、 ｖ普

图 １ － 丨 社交软件和新闻网站上的图文信息  

一章 绪论  

然而 ， ＣＶ和ＮＬＰ的研宄都是单

一模态的研宄 。正如人类能够处理多种形式  

的信息 ，人工智能也应当具有处理多模态数据的能力 。作为新

一代人工智能的关  

键构成部分 ， 跨媒体智能 （Ｃｒｏｓｓ

－ＭｅｄｉａＩｎｔｅｌｌｉｇｅｎｃｅ ） 近年来开始被研宄人员重  

点关注 。 ２０１７年 ７月 ８ 日 ， 国务院文件 《新

一代人工智能发展规划》

［４ ］将跨媒体  

智能列为人工智能理论与技术的五个亟待突破的重点研宄方向之

。斯坦福大学  

发布的 《２０３０年的人工智能与生命》 （ＡＩ１００ ）报告将跨媒体智能列入未来人工  

智能领域有重大突破的研宄方向

图像描述 （ ＩｍａｇｅＣａｐ ｔｉｏｎｉｎｇ） 任务考虑为给定的图像生成描述其内容的自  

然语言 ， 是跨媒体智能研究的

一个重要方向 。 该任务连接着 ＣＶ和ＮＬＰ两个领  

域 ，对打破图像和文本之间的语义鸿沟具有重要的作用 。另

一方面 ，该任务可应  

用于盲人导航 、幼儿早教以及自动导游等领域 ， 有着丰富的应用前景 。例如 ，

台装有摄像头 、音频输出设备以及图像描述系统的终端可为视觉障碍者提供眼前  

景象的语音描述 。 因而 ， 开展图像描述任务的研宄具有十分重要的意义 。  

当前图像描述研究以单句式图像描述 （Ｓ ｉｎｇ ｌｅ

－ＳｅｎｔｅｎｃｅＩｍａｇｅＣａｐ ｔｉｏｎｉｎｇ ）为  

主 ， 即以

一句话描述图像内容 。 以编码器

－解码器的深度神经网络为基础 ， 单句  

式图像描述己取得了

［６］ｍ ［８ ］ ［９ ］ ［ １Ｇ ］ ［ Ｉ １ ］ ［ １２］［ １３ ］ ［ １４ ］

一张图片中通常蕴涵了极为丰富的语义信息 ，正所谓

“ 一图胜千言

单句描述通常不足以充分涵盖图像中的大部分信息 ，是

一种粗颗粒度的描述 。 因  

一个有着更高要求的任务开始被研宄者所关注

一 一段落式图像描述研宄  

（ＰａｒａｇｒａｐｈＩｍａｇｅＣａｐｔｉｏｎｉｎｇ ） 。与单句式图像描述相比 ，段落式图像描述不仅需  

要更加准确的图像理解和更细颗粒度的描述 ，更需要考虑语言篇章或段落层面的  

上下文相关性和逻辑性 ， 因此具有相当的研究难度 。  

综上 ，段落式图像描述研宄具有较强的研宄意义和较高的挑战性 。本文开展  

对段落式图像描述的研宄 。  

ｇｍｍｊｇｇ＾＾＾＾＾ｇ＾ｇｇｇ＾＾ｇｙ＾ｊ ｗｉｎｗ ｉｗ，．一 丁ｈｅｒｅ ｉｓａ ｐ

ｌａｎｅｐａｒｋ ｉｎｇｏｎｔｈｅｒｕｎｗａｙ

段落式描述 ：  

ｌａｎｅ ｉｓｐａｒｋｅｄｏｎｔｈｅｒｕｎｗａｙ

Ｔｈｅｔａ ｉ ｌｏｆｔｈｅｐ

ｌａｎｅｈａｓａｃ ｉｒｃ ｌｅｏｎｉｔ ．  

Ｔｈｅ ｔｏｐ ｏｆ ｔｈｅ ｐ

ｌａｎｅ ｉｓｗｈ ｉｔｅ ．  

一 —Ｕｎｄｅｒｎｅａｔｈｔｈｅｐ

ｌａｎｅ ｉｓａｇｒｅｙｃｏ ｌｏｒ ．    — — ， Ｔｈｅｓｕｎｉｓｓｈ ｉｎ ｉｎｇｏｕｔｓ ｉｄｅ ．  

一丁ｈｅｒｅａｒｅｏｔｈｅｒｐ

ｌａｎｅｓｐａｒｋｅｄｏｕｔ ．  

图 １ －２ 单句式图像描述与段落式图像描述的任务差别  

一章 绪论  

１ ．２研究现状及分析  

图像描述方法的研宄可以分为单句式图像描述研宄和段落式图像描述研宄 。  

一幅给定的图像 ，前者的目标是为该图像生成

一个描述性句子 ，后者的目标  

一个语义连贯 、细颗粒度的描述性段落 。 在图像理解侧 ， 由于单个句子的  

信息容量限制 ，单句式图像描述着重于生成概括性的整体描述 ，其在视觉侧仅需  

较粗颗粒度的检测和识别 。而段落式图像描述需较完整地对图像信息进行理解以  

便能够生成详细的段落 ， 实现图像和段落的较高度语义对应 。在语言推理侧 ， 段  

落式图像描述不仅要将图像内容进行细颗粒度的表达 ，更要考虑语言层面上的逻  

辑性和上下文相关性 ， 以生成较为连贯的段落 。 区别于单句描述仅需保证

一句话  

的流畅性 ，段落描述更需建模段落内句子间的逻辑性 。 以下分别介绍单句式图像  

描述方法和段落式图像描述的研宂进展 ，并提出目前段落式图像描述方法仍存在  

的问题 。  

１ ．２．１单句式图像描述  

在２０ １５年之前 ，单句式图像描述方法大多为基于模板的方法（Ｔｅｍｐ ｌａｔｅ －ｂａｓｅｄ ）  

丨 丨５ 丨 丨 丨６ 】 ［

丨寧 ］叫和基于检索的方法 （Ｒｅｔｒｉｅｖａｌ ＿ｂａｓｅｄ ）

。 基于模板的方  

法首先检测出图像中的视觉概念 ，并使用预定义的句子模板和这些概念结合 ， 得  

到输出句子 。 由于预定义的模板是固定的 ，生成句子缺乏语言表达上的灵活性和  

自然性 。基于检索的方法把图像描述任务转换为检索问题 ，通过将待描述图像和  

文本映射到同

一语义空间上 ， 试图为待描述的图像检索寻找语义最接近的句子 ，  

作为输出句子 。这种方法可以生成更自然 、 更类似于人的文本表达 ，但很难生成  

新颖的描述 。  

随着大数据时代的到来和深度学习方法的兴起 ，数据驱动的深度神经网络方  

法逐渐成为求解图像描述问题的主流方法 。 受端到端的编码器

－解码器  

（Ｅｎｃｏｄｅｒ －Ｄｅｃｏｄｅｒ ）结构在机器翻译任务上成功应用的启发 ， Ｖｉｎｙａｌｓ等人

［６ ］在  

２０ １５ 年介绍了

一种建立在编码器

－解码器架构上的单句式图像描述模型 ＮＩＣ  

（ＮｅｕｒａｌＩｍａｇｅＣａｐ ｔｉｏｎｉｎｇ） ， 其中 ＣＮＮ作为编码器首先将输入图像表示为视觉  

向量 ， 随后基于ＲＮＮ的解码器将视觉向量解码为自然语言文本 。 在本文中 ， 我  

们将这种模式记为ＣＮＮ＋ＲＮＮ 。由于该模型的端到端训练特性以及其表现出的明  

显性能优势 ， 之后的图像描述研究大多根据ＣＮＮ＋ＲＮＮ进行扩展和改进 。  

Ｘｕ等人ｍ将注意力机制 （ＡｔｅｎｔｉｏｎＭｅｃｈａｎｉｓｍ） 纳入ＮＩＣ模型中 ， 其动机  

是图像认知过程中注意力的变化性 。 区别于ＮＩＣ仅在解码的第

一个时刻输入全  

局图像特征 ，该工作中 ， 融合了注意力机制的解码器在每个时刻接收富有变化的  

一章绪论  

加权图像特征 。编码器首先将图像按网格状分割并通过ＣＮＮ输出每个网格特征 ，  

在解码过程中 ，注意力模块通过硬关注 （ＨａｒｄＡｔｅｎｔｉｏｎ）和软关注 （Ｓｏｆ ｔＡｔｅｎｔｉｏｎ ）  

两种方法对输入的网格特征进行加权得到图像特征 。这种更具针对性的图像内容  

理解带来了模型性能的提高 。 此后 ， 许多研宄对融合注意力机制的 ＣＮＮ＋ＲＮＮ  

网络进行拓展 。Ｙｏｕ等人＿从图像中抽取语义标签作为注意力模块的输入 ，通过  

从图像中提取更丰富更准确的语义概念提高了模型的性能 。 Ｌｕ等人

［８ ］指出在生  

“ ｏｆ ” 的视觉无关词语时 ，解码器应当相对较少地关注图像语义而  

更多依赖于上下文语义 。 他们通过

一个视觉哨兵门 （ＳｅｎｔｉｎｅｌＧａｔｅ ）控制输入到  

解码器中的图像特征 ， 实现了

一种自适应的视觉注意力机制 。 Ｃｈｅｎ等人 认为  

传统的空间注意力忽视了不同卷积通道 （Ｃｈ＿ｅｌ ） 中信息的不平衡性 ， 提出了  

基于卷积通道的注意力机制 ， 结合空间注意力机制生成图像描述 。 Ａｎｄｅｒｓｏｎ等  

［ １２ ］将目标检测器 Ｆａｓｔｅｒ

［２５＾ＲｅｓＮｅｔ网络结合 ， 检测出若千感兴趣区域  

并生成区域特征向量 ，并通过对区域特征向量的关注生成图像描述 。相较于传统  

的网格划分方法 ， 通过区域检测减少了图像信息的损失 ，降低了解码器理解图像  

的难度 。  

以上基于有监督的极大似然原理方法存在着优化目标和评价指标不

一致的  

问题 。具体来说 ， 图像描述模型的损失函数通常为所有单词预测的交叉熵损失之  

和 ，而衡量生成描述质量通常采用ＢＬＥＵ（ＢｉＬｉｎｇｕａｌＥｖａｌｕａｔｉｏｎＵｎｄｅｒｓｔｕｄｙ ）

ＭＥＴＥＯＲ（ＭｅｔｒｉｃｆｏｒＥｖａｌｕａｔｉｏｎｏｆＴｒａｎｓｌａｔｉｏｎｗｉｔｈＥｘｐ ｌｉｃｉｔＯＲｄｅｒｉｎｇ ）

、 ＣＩＤＥｒ  

（Ｃｏｎｓｅｎｓｕｓ

－ｂａｓｅｄＩｍａｇｅＤｅｓｃｒ ｉｐ ｔｉｏｎＥｖａｌｕａｔ ｉｏｎ）

［２８ ］等ＮＬＰ评价指标 。针对该问  

题 ， Ｒｅｎｎｉｅ 等人

［ １４ ］基于强化学习中的策略梯度算法 ， 提出了

一种新的图像描述  

优化方法 ＳＣＳＴ（Ｓｅｌｆ －ＣｒｉｔｉｃａｌＳｅｑｕｅｎｃｅＴｒａｉｎｉｎｇ） 。通过使用 ＳＣＳＴ方法直接优化  

？指标 ，将评价指标和优化目标统

， 在与传统方法模型结构基本

一致的情  

况下 ， 大幅度提升了评价结果 。  

总体而言 ， 单句式图像描述模型在以 ＣＮＮ＋ＲＮＮ的编码器

－解码器框架下发  

展 ，各种注意力机制的变体旨在提高图像信息的利用率 。优化方法以基于交叉熵  

的极大似然方法和基于策略梯度的强化学习方法为主 。然而 ，单句式描述并不足  

以充分承载和表达

一幅图像中的语义信息 ， 是

一种概括性的 、 粗颗粒度的描述 。  

一些需要更加细致描述的场景下 ， 单句描述不能够满足需求 。  

一些工作开始通过多个短语或句子描述图像内容 。 Ｊｏｈｎｓｏｎ等人

［２９］提  

出密集多句图像描述方法 ，为Ｆａｓｔｅｒ

－ＲＣＮＮ检测出的每个区域生成

一个描述短语 。  

［９］提出主题驱动的多句图像描述方法 ， 为ＬＤＡ（ＬａｔｅｎｔＤｉｒｉｃｈｌｅｔＡｌｌｏｃａ

ｔｉｏｎ）主题模型发掘出的多个主题生成对应的句子 ，从不同侧重点描述

一幅图像 。  

与单句式图像描述方法相比 ，以上图像描述方法已经可以涵盖图像中更多的信息  

一章 绪论  

Ｈ ｉｅｒａｒｃｈ ｉｃａ ｌＲｅｃｕｒｒｅｎｔＮｅｔｗｏｒｋＧｅｎｅｒａｔｅｄ  

？ｍａｇｅ ：Ｒｅｇ ｉｏｎｓｗｉｔｈＳｅｎｔｅｎｃｅｔｏｐ ｉｃ广＾

ｓｅｎｔｅｎｃｅｓ  

３ ｘ Ｈ ｘＷＤｅｔｅｃｔｏｒｆｅａｔｕｒｅｓ ：ＭｘＤｖｅｃｔｏｒ ．ｒｃ

．ＱｖｐｗｏｒｄＪａｂａｓｅｂａｌｌ

ｐ ｌａｙｅｒ  

－ｖ１ｘＰ

ｙｆｅｃｉｏｒ

．＾Ｘ ＾

ＲＮＮ／ｓｓｗｉｎｇ ｉｎｇａｂａｔ ．  

＿Ｊｉ＾Ｓ＾ ｒｏ ｉＬ〇ｎ ，＼ ；  

ｐｏｏ ｌ ｉｎｇ＼

ｔｈｅｂＢｔｔｅｒ．  

图ｌ －３Ｈ ｉｅｒａｒｃｈ ｉｃａｌ

－ＲＮＮ模型  

生成更细颗粒度的描述。但是 ， 由于这类方法所生成的句子之间缺乏语言层面的  

关联和逻辑 ， 这些描述不能形成

一个语义连贯的段落 。  

１ ．２．２段落式图像描述方法  

Ｋｒａｕｓｅ 等人

１３（） ］在 ２０ １７ 年公布了斯坦福图像

－段落数据集 （ Ｓｔａｎｆｏｒｄ  

－Ｐａｒａｇ ｒａｐｈＤａｔａｓｅｔ） ， 数据集中的每个样本包含

一幅图像和 一段描述该图像  

的段落 。基于该数据集 ， 并根据自然语言中段落 、句子及词语的层次性 ，他们提  

一种段落式图像描述模型Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ ， 如图 １ －３所示 。 该解码器由句  

子ＲＮＮ和词ＲＮＮ组成 ，句子ＲＮＮ建模段落内句子间逻辑关系 ， 并生成句子主  

题 ， 词ＲＮＮ建模句内关系并根据句子主题生成句子内的所有单词 。在图像理解  

侧 ， 他们釆用了ＲＰＮ网络结合ＶＧＧ网络

［３ １ ］作为图像编码器检测图像中的区域  

并生成区域特征 ，然后将所有区域特征做最大池化操作得到全局图像特征 。然而 ，  

解码器仅以全局特征作为输入 ，造成了图像信息的损失 ，生成的段落丢失了图像  

中的许多信息 ，解码器输入特征的单

一也造成段落内大量重复句子的出现 。并且 ，  

Ｈ ｉｅｒａｒｃｈ ｉｃａ ｌ －ＲＮＮ对句间逻辑性的监督也较弱 ， 生成的段落连贯性有待提高 。  

基于Ｋｒａｕｓｅ等人的工作 ， 一些关于段落式图像描述的研宂开始展开 。 Ｌｉａｎｇ  

的ＲＴＴ

－ＧＡＮ网络 ， 引入生成对抗网络 （ＧｅｎｅｒａｔｉｖｅＡｄｖｅｒｓａｒｉａｌＮｅｔｗｏｒｋ ，  

ＧＡＮ ）

｜３３ ］到 Ｈ ｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ 中 ， 通过两个判别器构建了

一个对抗框架来提高  

生成段落的连贯性 。

一个句子判别器用以评估句子级别的可读性 ，

一个主题转换  

判别器用以评估段落级别的主题转换连贯性 。 除句子＿和词 ＲＮＮ外 ，段落  

ＲＮＮ被加入到解码器中组成三层ＲＮＮ解码器 ，进

一步提升了模型的段落建模能  

力 ， 增强了生成段落的连贯性 。此外 ， ＲＴＴ

－ＧＡＮ通过注意力机制对区域特征进  

行关注 ， 相较Ｈ ｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ减少了图像信息的损失 ， 图像和段落的语义对应  

程度较高 。但生成对抗网络结合三层 ＲＮＮ解码器的网络训练复杂 ，模型收敛慢 ，  

需要大量的参数实验和较高的调参技巧 。 Ｃｈａｔｅｉｊｅｅ等人

［３４ ］提出了全局主题向量  

一章绪论  

ＲａｗＩｍａｇｅ ：  

３ｘＨｘＷ？Ｒｅｇ

ｉｏｎｆｅａｔｕｒｅｓ ＿   燈邏ｆ，調ｆ於耀ｗ 醒ｎ

Ｖ ｉｓｕａ ｌｆｅａｔｕｒｅＧｅｎｅｒａｔｅｄｓｅｎｔｅｎｃｅ＊  

Ｉ Ｉ今＿二ｒ＝ｒ ｄ

ｋ   一Ｉ＾＾ｆ！Ｔ５ｒｅ ｌａｔ ｉｏｎｆｅａｔｕｒｅ？  

＇必〇  ＾ Ａ ｓ ｉｇｎｏｎｔｈｅ ｓ ｉｄｅｏｆ ｔｈｅｒ ｏａｄ  

８ 丨  

』    

Ｒｅ ｌａｔｉｏｎｓｈ ｉｐｐｒｅｄ ｉｃｔｉｏｎ —Ｖａ ｌ ｉｄｒ ｅ ｌａｔｉｏｎｐａ

｜费  

國ｉｉ｜ｉ■ 酾 雾 ― ＿   ＿國 ，§Ｂ｜ ＳｕｂｊｅｃｔＯｂｊｅｃｔ  

§ －—＞ ？一

； 羅 一＾ｃｌ Ｒｅ ｌａｔ ｉｏｎｓｈ ｉｐ  

广ｕ！  

Ｉ？＾ ° ｎ Ｆｅａｔｕｒｅｓ５ｆ Ｏｎｅｈｏｔｖｅｃｔｏｒ  

§ ／

   

＼ ＜ ｌ ｉ ｎｅ＞＜ｐａ ｒｋ＞＜〇ｎ＞＜ｗａ ｌｋ＞   

图 １ －４ 结合空间关系识别的段落式图像描述模型  

（Ｇｌｏｂａ丨Ｔｏｐ ｉｃＶｅｃｔｏｒｓ ） 和连贯性向量 （ＣｏｈｅｒｅｎｃｅＶｅｃｔｏｒｓ） ， 用更细粒度的监督  

信息指导段落的生成 。  

为了生成与图像更加吻合的段落描述 ，提高图像和段落的语义对应程度 ， 一  

些研宄人员开始尝试整合更多的图像信息监督段落的生成 。 Ｗａｎｇ等人

【３５］利用图  

像的估计深度图来发掘物体之间的三维空间关系 。Ｃｈｅ等人 显式提取了图像中  

显著物体间的空间关系 ， 其模型如图 １ ＿４所示 。  

上述段落式图像描述方法的优化目标同样以交叉熵损失为主 ，除单词预测的  

交叉摘外 ， 还包括预测句子个数的交叉熵 。 Ｍｅｌａｓ

－Ｋｙｒｉａｚｉ等人

１３７ ］首先尝试了将  

单句式图像描述方法 ＳＣＳＴ中的 ｓｅｌｆ －ｃｒｉｔｉｃａｌ方法用于段落式图像描述模型中 ，但  

取得了较差的评测结果 ，生成段落内句子之间的重复性很高 。 当加入了三元语法  

重复的惩罚项之后 ， 评测结果大幅提高 ， 将原先的 ＳＯＴＡ（Ｓｔａｔｅ

－Ａｒ ｔ）的  

ＣＩＤＥｒ值从 １６ ．９提升到 ３０ ．６ ， 显示了强化学习方法用于段落式图像描述方法的  

巨大潜力 。  

综上所述 ， 当前段落式图像描述研究在 ＣＮＮ＋ＲＮＮ结构上拓展 。 由于段落  

建模的复杂性 ， 单层次的ＲＮＮ难以有效生成连贯段落 ， 段落解码器通常由多层  

次的ＲＮＮ构成 。 现有工作对模型的改进通常围绕着两个目标 ： 一是通过改进层  

次＿结构 、或构建对抗学习网络提高段落质量 ， 二是发掘更丰富 、 更明确的  

视觉信息 ， 减少语义丢失 ，提升图像和段落的语义对齐程度 。  

１ ．２ ．３研究现状的总结与分析  

一章绪论  

前文介绍了解决单句式和段落式图像描述任务的

一些方法 。简言之 ，单句式  

图像描述己在ＣＮＮ＋ＲＮＮ的编码器

－解码器框架下取得了瞩目的阶段性进展 ， 生  

成句子有较好的准确性 、 连贯性 。 从具体方法上来讲 ， ＲＮＮ 系列网络以其所独  

有的时间序列结构和隐藏状态 （ＨｉｄｄｅｎＳｔａｔｅ ）带来的

” 记忆能力 ， 被广  

泛采用为图像描述解码器的基本结构 。而段落式图像描述的研究仍处于起步状态 ，  

生成段落在准确性 、 详细程度 、 连贯性仍有欠缺 。  

段落式图像描述方法也延伸于ＲＮＮ及其变体网络长短时记忆网络 （ＬＳＴＭ ，  

－ｓｈｏｒｔＴｅｒｍＭｅｍｏｒ ｉｅ ）

、 门控循环单元 （ＧＲＵ ， ＧａｔｅｄＲｅｃｕｒｒｅｎｔＵｎｉｔｓ ）

１３９］  

段落解码器的框架之下 ， 无法避免ＲＮＮ的若干固有问题 。其

， ＲＮＮ无法记忆  

长时信息 ，这限制了其建模语言的性能 。尽管ＬＳＴＭ被提出用来捕捉长时信息 ，  

但当建模诸如段落的长文本时 ， 随着时间序列的向后推移 ，隐藏信息的衰减极大  

地削弱了解码器关注

” 的视野大小 ， 由此带来的长时记忆能力不足同样造  

成生成段落连贯性的下降 。 其二 ，＿ 的时间序列特性使得这些段落解码器运  

行所需的时间复杂度较高 、时间消耗大 ，也无法使用ＧＰｌＫＧｒａｐｈｉｃＰｒｏｃｅｓｓＵｎｉｔ）  

对其进行并行化加速 ， 这给训 和推理过程带来了极大的时间消耗 。  

综合本节研宂现状分析 ， 当前段落式图像描述研宄存在以下问题亟待解决 ：  

（ １ ） 在语言生成侧 ， 增强生成段落的连贯性 。  

（２）在图像理解侧 ， 减少图像信息的损失 。  

（３ ）对于模型而言 ， 降低模型和算法的时间复杂度 。  

本文针对以上若干问题 ， 开展对段落式图像描述的研宄 。  

１ ．３本文的研究工作  

针对问题 （ １ ） 和 （３ ） ， 本文第

一个研宄内容为 ： 基于全卷积神经结构的段  

落式图像描述方法 。第

一个研究内容的成果是提出了

一种适合于段落式图像描述  

任务的全卷积解码器 。全卷积解码器由双层的门控卷积神经网络构成 ， 其中的门  

控结构赋予ＣＮＮ记忆能力 。 该解码器包括句子ＣＮＮ解码器和词Ｃ＿解码器 ，  

句子 ＣＮＮ解码器捕捉段落内的句子之间关系以加强句子间的连贯性 ， 词 ＣＮＮ  

解码器负责生成段落内的单词 。通过将层次结构 、卷积结构 、 门控结构结合 ， 相  

较于ＲＮＮ解码器 ， 全卷积解码器具有更大的

” 视野 ， 拥有更强的长时记  

忆能力 。 我们提出了

一种衡量段落连贯性的指标 ， 并在斯坦福图像

－段落数据集  

上经过评测指标 、运行时间 、段落连贯性指标 、主观评价等多种评价方法的验证 ，  

证明了所提方法的有效性 。  

针对问题 （２ ） ，本文第二个研宄内容为 ：融合区域注意力机制的段落式图像  

描述方法 。 第二个研宄内容的成果是通过区域提议网络和区域注意力模块结合 ，  

一章 绪论  

实现对图像的高度语义理解 ，并将区域注意力模块融合到全卷积解码器中 ，提出  

一种新模型Ｄｕａｌ

－ＣＮＮ 。 区域注意力模块加强了图像和段落的语义对齐 ， 生成段  

落描述更加详细 。通过评测指标 、段落多样度指标 、 区域注意力分析 、 主观评价  

等多种评价方法的验证 ， Ｄｕａｌ

－ＣＮＮ提升了段落式图像描述任务上的性能 。  

１ ．４本文的组织结构  

本论文总共包含五章 ， 每

一章的重点内容归纳如下 ， 结构示意图如图 １ －５ 。  

一章 ，绪论 。首先介绍了段落式图像描述的相关研宄背景及意义 ，并对研  

究现状进行综述 ，对目前段落式图像描述方法存在的问题进行了分析 ， 最后概述  

了本文主要的研宄工作和成果 。  

第二章 ，基础知识 。介绍了本文涉及到的基础知识 。首先介绍了几种深度学  

习基本模型 ，接下来介绍图像描述任务的基础编码器

－解码器结构和注意力机制 ，  

最后概述了段落式图像描述数据集以及评价指标 。  

第三章 ，基于全卷积神经结构的段落式图像描述方法 。详细介绍了所提出的  

全卷积解码器 ， 并提出了

一种评价段落连贯性的指标 。实验表明 ，全卷积解码器  

的训练时间复杂度小于传统方法 ， 所生成的段落具有更好的连贯性 。  

第四章 ， 融合区域注意力的段落式图像描述模型 。为提高图像理解能力 ，将  

区域提议网络 、 区域注意力机制融合到全卷积段落解码器中 ， 提出了Ｄｕａｌ －ＣＮＮ  

一章绪论  

第二章基础知识  

＾＾＾  

「 问题 １

．ｖ１ｒ 问题３ ：１   生成段落连模型的时间  

贯性不足复杂度极高   Ｖ／ＶＪＶ＾ｙ  

笛二音 其＋公裘＊□油以件 Ｉ Ｉ 第四章融合区域注  

构ｉｉ段落式图像４

、 述■ 意力 篇ＨＩ

图像  

， 办＾   第五章总结与展望  

图 １ －５ 本文的组织结构  

一章 绪论  

模型 ， 并提出了

一种评价段落内句子多样性的指标 。实验表明 ， Ｄｕａｌ

－ＣＮＮ生成  

的段落更加详细 ， 句子多样性更强 。  

第五章 ， 总结与展望 。总结了本文的研宄工作 ，并对未来工作进行展望 ，提  

出了几个可能的研宄方向 。  

第二章 基础知识  

第二章基础知识  

基于深度学习方法的图像描述模型以ＣＮＮ＋ＲＮＮ的编码器

－解码器框架为基  

础 ，因此本章首先介绍ＣＮＮ 、ＲＮＮ和ＬＳＴＭ的模型实现 ，再介绍基于ＣＮＮ＋ＲＮＮ  

－解码器结构 ， 以及注意力机制在该结构中的实现 ， 最后介绍段落式图  

像描述任务的相关数据集和评价指标 。  

２．１深度神经网络模型  

２丄１卷积神经网络  

卷积神经网络 ， 本质上是

一种特殊的前馈神经网络 （ＦｅｅｄｆｏｒｗａｒｄＮｅｕｒａｌ  

Ｎｅｔｗｏｒｋ ，ＦＮＮ ） ，由于在计算中使用了数学上的卷积操作来替代矩阵运算而得名 。  

ＣＮＮ普遍应用于图像分类 、 图像分割 、 人脸识别等领域中 ， 也是当今深度学习  

应用的前沿 。 从最早上世纪 ９０年代的 ＬｅＮｅｔ＿用于商业上的手写数字识别 ， 到  

近年来 ＩｍａｇｅＮｅｔ图像分类竞赛促使了

一批 ＣＮＮ 网络的涌现 ， 如 Ａｌｅｘｎｅｔ

［４ １ ］

［３ １ ］

、 ＧｏｏｇＬｅＮｅｔ

、 ＲｅｓＮｅｔ

［２ 】等 。  

典型的ＣＮＮ通常由卷积层 （ＣｏｎｖｏｌｕｔｉｏｎａｌＬａｙｅｒ） ，池化层 （ＰｏｏｌｉｎｇＬａｙｅｒ）  

和激活层 （ＡｃｔｉｖａｔｉｏｎＬａｙｅｒ）构成 。卷积层拥有出色的提取图像特征的能力 ，其  

通过卷积核 （ＣｏｎｖｏｌｕｔｉｏｎａｌＫｅｒ ｎｅｌ ）在图像上以

一定的步长 （Ｓｔｒ ｉｄｅ）滑动对图像  

实施卷积的操作 ， 且卷积层的权重共享 （ＳｈａｒｅｄＷｅｉｇｈｔｓ ）减少了计算量 。 池化  

层也起到明显降低ＣＮＮ计算量的作用 ，同时增强了ＣＮＮ防止过拟合（Ｏｖｅｒｆ ｉｔｉｎｇ）  

的能力 ， 提升 ＣＮＮ对图像噪声的鲁棒性 。 池化层赋予 ＣＮＮ的另

一个重要特性  

是对图像具有平移不变性 。  

当处理图像这类的二维结构时 ， 常采用二维卷积核 。在卷积层 ， 需要设定卷  

积核数量 、卷积核大小和滑动的步长 。卷积核数量确定了输出的特征映射（Ｆｅａｔｕｒｅ  

Ｍａｐ ） 的通道数 ， 不同的卷积核可捕获图像中不同类型的信息 。在卷积层后通常  

设置对应的池化层 ，池化层可降低数据的维度 ，使用广泛的池化方法有最大池化  

（ＭａｘｉｍｕｍＰｏｏｌｉｎｇ）和平均池化 （ＭｅａｎＰｏｏｌｉｎｇ ） 。  

激活层使用非线性激活函数增强网络的非线性特性 ，使用广泛的非线性激活  

函数包括Ｓｉｇｍｏｉｄ函数 、Ｔａｎｈ函数和线性整流单元（Ｒｅｃｔｉｆ ｉｅｄＬｉｎｅａｒＵｎｉｔ ，ＲｅＬＵ ）  

。 Ｓ ｉｇｍｏｉｄ函数是较早被使用的激活函数 ， 但经常遭遇梯度消失现象 ， 且该函  

数并非中心对称 。 Ｔａｎｈ函数是中心对称函数 ，但仍存在梯度消失的问题 。现今 ，  

１０  

第二章 基础知ｉ只  

＿＿＿ 自  

Ｗ５５＼Ｊ＾Ｎｒ １＼ Ｊ ＮＷｏ  

＼ ｊ ｌ＼＼

１ ９２ １９２ １２８ＭａｘＵＬ＿  

２２＼ｓｔｒ ｉｄ＼ Ｍａ＊

一－ Ｍａｘ ｐｏｏ ｌ ｉｎｇ测２脚  

＼Ｊ ０ｆ４＼ｐｏｏ ｌｉｎｇｐｏｏ ｌ ｉｎｇ  

Ｎｉｉ  

图２ － １Ａ ｌｅｘＮｅｔ糢型

线性整流单元 （Ｒｅｃｔｉｆ ｉｅｄＬｉｎｅａｒＵｎ ｉｔ ，ＲｅＬＵ ） 以其训练平稳 、计算快速的优势 ，  

为深度学习最广为应用的激活函数 ， 其表达式为ｆ（ｘ） ＝ｍａｘ （０ ， ；〇 。  

ＣＮＮ 同样可用于处理

一维结构上 ， 如文本 、语音 、信号等 ， 可采用

一维卷  

积核组成的卷积层对其进行处理 。文本可视作按时间序列组成的 一维结构 ，本章  

提出的方法中将会采用

一维ＣＮＮ生成段落 。  

２ ． １ ．２循环神经网络  

循环神经网络代表了

一系列带有信息自传递功能的神经网络家族 ，能够对时  

间序列类结构建模 ， 例如文本 、 语音 、 信号等 。 朴素ＲＮＮ通过隐藏信息的传递  

进行信息记忆 ，但其难以捕捉长时信息 ，且训练存在梯度消失和爆炸问题 。在此  

基础上提出了包含长时记忆单元的ＬＳＴＭ

，ＬＳＴＭ能在

一定程度上解决梯度消  

失和爆炸问题 ，并拥有

一定的长时记忆能力 。＿类网络的成功应用有编码器

解码器结构等 。  

将 ／时刻朴素ＲＮＮ的隐藏单元信息记为／ｉ ｔ ， 输入记为ｘ ｔ

， 输出为ｏ ｔ ，／ｉ ｔ的更  

新公式为 ：  

ｈ ｔ ＝ ｇｈ（Ｗ＾ ／ｉ ｔ ＿ｉ＋Ｕｈｘｔ＋ｂｈ）（２ － １）  

其中 ， 叭 、Ａ为可学习的权重参数 ， ｈ为可学习的偏置参数 ， ｇｈ表示激活  

函数 。 根据＆可得到输出 ：  

〇 ｔ ＝ ｇ〇（Ｗ〇ｈ ｔ＋ ｂ０＾（２ －２）  

％表示可学习的权重参数 ， ６。表示可学习的偏置参数 ， ｇ。表示输出层的激  

活函数 。  

然而 ， ＲＮＮ在训练时往往会遭遇梯度消失和爆炸问题 ， 当使用反向逆传播  

（ＢａｃｋＰｒｏｐａｇａｔｉｏｎ ）算法对其进行训练时 ， 在梯度的求解中 ， 由于连续的矩阵  

相乘 ， 造成梯度无限接近于零或无限大 ， 导致 ＲＮＮ难以有效更新 ， 因而 ＲＮＮ  

的性能十分有限 。  

１ １  

第二章基础知识  

ＬＳＴＭ除隐藏单元外 ， 还包含了记忆长期信息的细胞单元ｃ ｔ 。 此外 ， ＬＳＴＭ  

通过三个门 ：遗忘门 （ＦｏｒｇｅｔＧａｔｅ） ，输入门 （ ＩｎｐｕｔＧａｔｅ ） ，输出门 （ＯｕｔｐｕｔＧａｔｅ）  

对信息进行更新 ：  

ｆｔ ＝＋ｂ ｆ）（２ － ３）  

ｉ ｔ ＝ａｆＷ

ｉ ｌｈ＾Ｘ ｔ］＋ｂ

ｉ）（２ －４）  

ｏｔ ＝ａｉＷｏ ｌｈ ｔ＾ ；ｘ ｔ］＋ｂ ０）（２ － ５）  

ａ表示 ｓｉｇｍｏｉｄ激活函数 ，其值域为（０ ， １ ） ，因此三个门的值也都在（０ ，１ ）之间 。  

／ｔ ，ｉ ｔ ， 〇 ｔ依次为遗忘门 ，输入门 ，输出门 。％

，％为可学习权重参数 ， 卜

为可学习偏置参数 。  

根据遗忘门和输入门 ， 细胞单元和隐藏单元更新如下 ：  

ｃｔ ＝ｔａｎｈ（Ｍ／ ｃ ［ ／ｉ ｔ

＿ｘ ；ｘ ｔ］＋６Ｃ）（２ — ６）  

ｃ ｔ ＝ ｆｔ〇 ｃ ｔ

．１＋ｉ ｔＱ ｃ ｔ（２

－ ７）  

ｈ ｔ ＝〇 ｔＯｔａｎｈ （ｃ ｔ） （２

— ８）  

叫为可学习权重参数 ，＼为可学习偏置参数 。〇表示按位相乘符号 ， ｔａｎｈ表  

示 ｔａｎｈ激活函数 。 遗忘门／ｔ对上个时刻的细胞单元信息Ｃ ｔｑ进行筛选 ， 对过去的  

信息有选择地遗忘 。输入门对该时刻的输入信息￥进行筛选 ，对当前的信息有选  

择地输入 。 输出门对＆的信息进行筛选 ， 将ｃ ｔ有选择地输出到＼中 。  

在ＬＳＴＭ的训练过程中 ， 通过结构的改进 ， 避免了ＲＮＮ更新过程中矩阵的  

连乘操作 ， 将连乘操作转换为了加操作 ，避免了产生过大梯度或过小梯度 ，

一定  

程度上缓解了梯度消失和爆炸问题 。  

２ ．２编码器

－解码器结构  

２ ．２．１概述  

近几年 ，无论是单句式图像描述研宄 ，还是段落式图像描述研宄 ， 都围绕着  

端到端的编码器

－解码器结构展开 。 该思路受启发于机器翻译任务的最新模型 。  

这些模型利用 ＲＮＮ 处理可变长度的待翻译文本 ， 将其编码为固定维度的向量 ，  

再将该向量用 ＲＮＮ解码为翻译文本输出 。而图像描述任务 ， 可理解为将输入图  

像翻译为文本 。因此在给定图像的情况下 ，很自然地使用类似的方法 ，利用ＣＮＮ  

将图像编码为特征向量 ， 再将该向量解码为文本 。 ＮＩＣ

［６ ］是较开创性 、 有代表性  

的单句式图像描述模型 ， 接下来根据该模型来介绍图像描述模型的基本框架 。  

１２  

第二章 基础知识  

给定图像／ ， 模型的参数记为０ ， 应输出的正确描述是ｉ 则模型的学习目标  

为求出最佳的模型参数 ：  

＊＝ａｒｇｍａｘ

ｌｏｇｐ（Ｓ

｜／ ；６ ）（２ — ９）  

０ ，ｓ）  

因为Ｓ的长度在不同的样本中是不

一致的 ， 因此 ， 使用链式法则对供 ＳＮ｝  

进行等价建模 ， ／Ｖ为某个特定样本中句子的长度 。  

ｌｏｇｐ（５

｜／ ；６） ＝

＼ｏｇｐ（Ｓ ｔ ＼Ｉ ，Ｓ０ ，

． ． ． ，５＾！ ；６ ）（２

— １０）  

ｔ＝ｉ  

的建模采用 ＲＮＮ系列网络 ， 所依赖的 ／个词的信息蕴含  

在了ＲＮＮ网络的隐藏状态＼中 ， 隐藏状态的更新过程为  

ｈ ｔ＋１ ＝Ｒｍ（ｈ ｔ ，ｘ ｔ） （２ － １１）  

其中 ， ｘ ｔ为５ ￡的词向量形式 。  

联合模型的学习目标和链式法则 ， 模型的损失函数为 ：  

，Ｓ） ＝－

ｌｏｇｐ（ ．Ｓ ｔ ＼Ｉ ，Ｓ０ ，

． ． ． ，５ ｔ

＿ ｉ）（２ －１２）  

ｔ＝ｉ  

通过该损失函数 ， 可端到端地对模型中所有参数进行更新 。  

２ ．２．２模型详述  

－２为ＮＩＣ模型示意图 。 由于 ＬＳＴＭ相较于朴素ＲＮＮ的诸多优势 ， 因此  

采用 ＬＳＴＭ作为解码器 。 句子中的单词最初为独热 （〇ｎｅ －ｈｏｔ ） 向量＆表示 ， 其  

维数等于词表的容量 。 表示

一个特殊的幵始词 ，心表示

一个特殊的停止词 ， 它  

们分别指定句子的开头和结尾 。 当发出停用词时 ，便表示该句子已生成完毕 。为  

了将视觉和文本的语义统

， 图像和单词被映射到相同维度的欧式空间 ， ＣＮＮ  

对图像进行压缩 ， 嵌入层％对单词进行映射 。 在ＮＩＣ模型中 ， 图像／仅在 ／ ＝ － １  

一种可选的方案是图像在每个时刻都和当前时刻的单词向量拼接  

作为输入 。 以上过程可形式化如下 ：  

＝ＣＮＮ（ ／）（２

－ １３）  

ｅ… Ｗ — １｝（２ － １４）  

ｐｔ＋１ ＝ＬＳＴＭ〇ｔ） ，ｔ６Ｖ －１｝（２

－ １５）  

２．２．３单词采样方法  

１３  

第二章 基础知识  

ｌ （Ｓ ｌ ）｜ ｜

ｌｏｇｐ３ （Ｓ７ ）｜ Ｉ

ｌｏｇｐｎ （Ｓｎ ？Ｉ   ＺＴｎｔＴｔ  

４ｓ ［ｐ

ｊ［ＰＮ  

．ｔｔｔ   ＳＴ   ＺＺ２：Ｚ  

：５：Ｊｉ＝—＾ ｉ＝—？ＨＨ  

： ｜Ｔ３３２５  

ｍＷｗｗｗ  

１ｊＶＶＹ  

ｆ＼Ｊ ｜ｗｅＳｏ

｜ｆｗＺ ］ ｜ｗ？Ｓｎｍ  

ｔｔｔｔ  

ｉｍａｇｅＳ〇 ｜ Ｓ

｜ Ｓｎ －

图 ２ －２ＮＩＣ模型示意图  

Ｐｔ＋１为词的预测概率分布 ， 在每个时刻根据该分布进行采样 ， 得到单词 。采  

样的方法主要有两种 ， 一是最大概率采样 ， 该方法本质上是

一种贪心策略 。最大  

概率采样在每个时刻仅保留

一个概率值最大的候选词序列 ，由于局部最优解并不  

等价于全局最优 ， 因而这种方法会错过很多较优解 。 第二种方法为集束搜索  

（ＢｅａｍＳｅａｒｃｈ） ， 相较于最大概率采样 ， 该方法扩大了搜索空间 ， 始终保留 是个  

概率值最大的候选词序列作为候选 。显然 ，当 Ａ为 １时 ，便等价于最大概率釆样 。  

集束搜索的时间和空间消耗较大 ，但也更容易获得较优解 ， 因而被广泛采用 ， 其  

具体步骤如下 ：  

输入 ： 每个时刻的词预测概率分布 ， 词表  

输出 ： 句子采样结果  

步骤 １ ： 在 ／ ＝ １时刻 ，采样得到概率最大的 Ａ个词 ，每个词分别作为

一个词  

序列 ： ｛５叫丨 ，分仏 … ，Ｓｅ＃｝ ， 并记录对应的对数概率｛

ｌｏｇ ， ｌｏｇ … ， ｌｏｇｐｇ｝ 。  

步骤２ ： 在 ／＞１时刻 ， 将 ／ － １时刻的输出卩叫ｆ＇Ｓｅｇ

｝分别输  

入到 ＬＳＴＭ中 。 对于每

一个 广Ｙｌ幺 ｉＳｆ ｃ） ， 都得到 个最大概率的词序列 ，  

即 （Ｓｅｑ广

１ ＋ ｖｖｏｒｄ 丨 广

１ ＋ｗｏｒｄＬ

？ ？ ？ＪｅＷ

－１ ＋ ｖｖｏｒｃ＾｝ ， 其对数概率分别为  

－１ ＋ｌｏｇｐ＾

ｉ． ｌｏｇｐ＾

１ ＋ｉ〇ｇｐｗｏｒｄ

ｉｉ〇ｇｐｆ

＿１ ＋丨〇ｇＰｗｏｒ４ ） 。 以上过程  

可共得到 ／ｃ ＊ｆ ｃ个序列 ， 从这Ａ： ＊ｆ ｃ个词序列中 ， 取前 个最大概率的序列 ， 输出  

｛５叫丨 ，分 ￡ ７｜ ，

， 并输出其对应的对数概率｛

ｌｏｇｐ〖 ， 丨ｏｇｐ！ ，

． ． ． ， ｌｏｇＷ｝ 。 当满  

足句子停止条件时 ， 停止生成句子 。  

２．３注意力机串

Ｉ Ｊ  

２０ １５年Ｂａｈｄａｎａｕ等人

［４４ ］将注意力机制首次应用于端到端结构的机器翻译模  

１４  

第二章基础知识  

Ｉｇ｜ ｜ Ｃ  

？Ｉ？ｅ１ｓｓＩ｜ ａ１２ ＿￥ｉ＝ＩＡ   Ｊｊ ｊ ｌ ｌ ｌ ， ｌ ｌ ｌ＾ ｌ ． １  

＇ＱＶ  

，：ｒｆｉ  

ｆｋｏｎｏｒｍｑｕｅ  

ｏｐｏｒｎｎｏ ｒｎｖｒｏｎｎｅｍｅｍ ；  

￥ ｇ ｒｅ ｍｏｍｓ  

＾ＢＨＢＨ ｜＾＾ＨＨＢ＾

￣ ＷＢ＾Ｍ  

ｅｎ ｖｒｏｎｎｅｍｅｎ ｔ

图 ２ －３ 机器翻译任务中源语言和目标语言关注示意图

［４４ １  

＿ＱＤｃｎｓ■围圆■   ＿■■■■■■■＿■  

Ａｂ ｉ ｒｄｆｌｙ

ｉｎｇｏｖｅｒａｂｏｄｙｏｆｗａｔｅｒ ？  

图 ２ －４ 图像描述任务中源图像和 目标语言关注示意图

１７ １  

型上 ，其动机在于 ， 生成目标语言的不同时刻 ，模型应更有针对性地关注源语言  

的不同位置 。 图 ２ －３为源语言和目标语言的关注示意图 。  

之后 ，Ｘｕ等人

［７］将注意力机制迁移到图像描述任务上 ，以图像作为源信息 。  

生成描述时 ， 注意力关注图像中的不同位置 ， 如图 ２

－４所示 。具体地 ， 使用 ＣＮＮ  

来提取图像的

一组特征向量 ， 共 Ｉ个 ， 每个向量为对应于图像

■〇维表  

示 ：  

ａ＝ ｛ａ１ （ ． ． ． ，ａＬ｝，ａ ＾£ ＲＤ （２ — １６）  

在生成描述中的第 ／个词时 ， ＲＮＮ的隐藏状态 作用于｛ａ ｉ ， ． ． ． ，ａｔ｝之上 ，  

得到特征向量对应的

一组分数｛ｅ ｔｌ ， ． ． ． ，ｅｔｉ｝ ， 对于ｅ ｔｉ ， 生成过程如下 ：  

￣ｆａｔｔ（＾ ｔ －ｌ ＊ａ ｉ） （２ — １７）  

【４５］中总结了／ａｔｔ的三种实现 ：  

ｆａｔｔ（Ｖｉ ．？ ｉ） ＝ｈ ｔ＾Ｕ ｉ ７ （２

－ １８）  

ｆａｔｔ（＾ ｔ －ｉ ．ａ ｉ）＝ｈ ｔ＾ＷａａＪ（２ — １９）  

ｆａｔｔ〇ｔ －ｉ ，Ａ）＝ ％［ａ

ｉ ；Ｕ（２ － ２０）  

得到特征组对应的分数后 ， 对分数进行归

一化 ：  

ｅｘｐ （ｅｔｉ）   ％ ＝ ｗ；

￣ ｒ （２ －２１）   Ｘｋ＝ｉｅｘＰＣｅ ｔｆ ｃ）  

再根据分数得到加权特征 ：  

１５  

第二章 基础知识  

ａｆ ｎ＝

ｓ ｔｋａｋ （２ － ２２）  

ｋ＝ｌ  

ｆｔ作为ＲＮＮ输入的

一部分 ， 可实现富注意力的图像描述模型 。  

２．４数据集及评价指标  

２ ．４．１段落式图像描述任务数据集  

段落式描述数据集由Ｋｒａｕｓｅ等人

［３（＞ ］收集 ，该数据集包含从ＶｉｓｕａｌＧｅｎｏｍｅ

和ＭＳＣＯＣＯ

［４７ ］两个图像数据集中选取的 １９５５ １张图片 ，每张图片对应

一个描述  

段落 。每个段落平均包含 ５ ．７个句子 ，每个句子平均包含 １ １ ．９个词 。数据集的段  

落标注任务由ＡｍａｚｏｎＭｅｃｈａｎｉｃａｌＴｕｒｋ网站上的工作者完成 ，标注的段落还需接  

受自动和手动抽查质量 。 图 ２

－５ 展示了其中的

一个示例 ， 并将标注段落和 ＭＳ  

ＣＯＣＯ中对应的五个单句描述进行了对比 。很明显 ， 比起单个句子 ，段落描述得  

更加详细 ，不仅如此 ， 即便将五个单句结合在

一起 ， 其描述的详细程度仍逊于段  

落 。这是由于单句式图像描述的目标是对图像进行整体性的刻画 ，尽管这五句话  

用了不同的方式来描述图像 ，但往往都在描述相同的图像语义 ， 因此它们在描述  

多样性和细颗粒度上都有严重的限制 。此外 ，这五句话之间也无明显的上下文关

系 ， 而在段落中 ， 出现了共指现象 ， 例如在第二句话中有

“ ｏｎｅｌｉｔｌｅｇ ｉｒｌａｎｄｏｎｅ  

ｌｉｔｌｅｂｏｙ

， 在下文中出现了指代

ｔｈｅｂｏｙ

ｔｈｅｇ ｉｒｌ ”

。 因此 ， 将多个单句描述  

简单堆砌形成的文本和段落文本之间有着显著的区别 。  

－ １为段落数据集和ＭＳＣＯＣＯ数据集的统计信息对比 ， 包含以下几项 ：  

描述文本平均长度 、 句子平均长度 、多样性 、 名词比例 、 形容词比例 、 动词比例  

和介词比例 。 在统计信息中 ， 两个数据集差异最大的是平均描述长度和多样性 。  

段落的平均描述长度为 ６７ ．５０ ，单句的平均描述长度为 １ １ ．３０ 。值得注意的是 ，段  

ｉ （ Ｓｅｎｔｅｎｃｅｓ  

ｆ ｔ Ａ ９

ｉｒ ｉ ｉｓｅａ ｔ ｉｎｇｄｏｎｕ ｔｓｗ ｉｔｈａｂｏｙ

ｉｎａｒｅｓｔａｕ ｒａｎｔ  

ａ ｊ２ ）Ａｂｏｙａｎｄｇ

ｉ ｒ ｌｓ ｉｔｔ ｉｎｇａｔａｔａｂ ｌｅｗ ｉ ｔｈｄｏｕｇｈｎｕｔｓ ．  

３ ）Ｔｗｏｋ ｉｄｓｓ ｉｔｔ ｉｎｇａｃｏｆｆｅｅｓｈｏｐｅａｔ ｉｎｇｓｏｍｅｆｒｏｓｔｅｄｄｏｎｕ ｔｓ  

ＩＴＲ ４ ）Ｔｗｏｃｈ ｉ ｌｄｒｅｎｓ ｉｔｔ ｉｎｇａｔａｔａｂ ｌｅｅａｔ ｉｎｇｄｏｎｕｔｓ

５ ）Ｔｗｏｃｈ ｉ ｌｄｒｅｎｅａｔｄｏｕｇｈｎｕ ｔｓａｔａｒｅｓｔａｕｒａｎｔｔａｂ

ｌｅ ．  

Ｔｗｏｃｈ ｉ ｌｄ ｒｅｎａｒｅｓ ｉｔｔ ｉｎｇａ ｔａｔａｂ ｌｅ ｉｎａｒｅｓｔａｕｒａｎ ｔ ．Ｔｈｅ  

ｃｈ ｉ ｌｄｒｅｎａｒｅｏｎｅ ｌ ｉ ｔｔ

ｉ ｒｌａｎｄｏｎｅ ｌ ｉｔｔ ｌｅｂｏｙ

．Ｔｈｅ

ｌ ｉｔ ｌｅｇ

ｉｒ ｌ ｉｓ  

ｅａｔ ｉｎｇａｐ

ｉｎｋｆｒｏｓｔｅｄｄｏｎｕｔｗ ｉｔｈｗｈ ｉｔｅ ｉｃ ｉｎｇ

ｌ ｉｎｅｓｏｎｔｏｐｏｆ ｉｔ   １＾Ｔｈｅ ｇ

ｉｒ ｌｈａｓｂ ｌｏｎｄｅｈａ ｉ ｒａｎｄ ｉｓｗｅａｒ ｉｎｇａｇ ｒｅｅｎ  ｊａｃｋｅｔｗ ｉ ｔｈａ  

ＩＪＢＨ

＾ｂ ｌａｃｋ ｌｏｎｇｓ ｌｅｅｖｅｓｈ ｉ ｒｔｕｎｄｅｒ ｎｅａｔｈ ．Ｔｈｅ ｌ ｉｔｔ ｌｅｂｏｙ

ｉｓｗｅａ ｒ ｉｎｇａ  

警 、 ｂ ｌａｃｋｚ ｉｐｕｐｊａｃｋｅｔａｎｄ ｉｓｈｏ ｌｄ ｉｎｇｈ ｉｓｆ ｉｎｇｅｒｔｏｈ ｉｓ ｌ ｉｐｂｕｔ ｉｓ  

ｎｏ ｔｅａ ｔ ｉｎｇ

．Ａｍｅｔａ ｌｎａｐｋ ｉｎｄ

ｉｓｐｅｎｓｅｒ ｉｓ ｉｎｂｅｔｗｅｅｎｔｈｅｍａｔ  

ｔｈｅｔａｂ ｉｅ －Ｔｈｅｗａ ｌ ｎｅｘ ｔｔ０ｔｈｅｍ ｉｓｗｈ ｉ ｔｅｂｒ ｉｃｋ ．Ｔｗｏａｄｕ ｌ ｔｓａ ｒｅ  

ｏｎｔｈｅｏｔｈｅｒｓ

ｉｄｅｏｆｔｈｅｓｈｏｒｔｗｈ ｉｔｅｂｒ ｉｃｋｗａ ｌ ｌ ．Ｔｈｅｒｏｏｍｈａｓ  

ＪＨＰ ｗｈ ｉ ｔｅｃ ｉ ｒｃｕ ｌａｒ ｌ ｉｇｈｔｓｏｎｔｈｅｃｅ ｉ ｌ ｎｇａｎｄａ

ｌａ ｒｇｅｗ ｉｎｄｏｗ ｉｎｔｈｅ  

ｘ＾ ｒｏｎｔｏｆｔｈｅｒｅｓｔａｕ ｒａｎｔ

， ｉｔ ｉｓｄａｙ

ｌ ｉｇｈｔｏｕｔｓ ｉｄｅ ．Ｊ  

图 ２ －５ 斯坦福图像

－段落数据集示例 ， 及与ＭＳＣＯＣＯ的对比  

１６  

第二章 基础知识  

表 ２ － １ 数据集的统计信息对比  

参数量 （Ｍ）训练时间 （ｓ）  

描述文本平均长度 １ １ ．３０６７ ．５０  

句子平均长度 １ １ ．３０ １ １ ．９ １  

多样性 １９ ．０ １７０ ．４９  

名词比例３３ ．４５％２５ ．８ １％  

形容词比例２７ ．２３％２７ ．６４％  

动词比例 １０ ．７２％ １５ ．２ １％  

介词比例 １ ．２３％２ ．４５％  

落中所有句子的平均长度也是 １ １ ．３０ ， 与单句相同 。段落的句子多样性为 ７０ ．４９ ，  

远高于多个单句的 １９ ．０ １ 。这种可量化的证据表明 ， 段落中的句子提供了图像的  

大量信息 ， 描述更为细粒度 。 关于词性的分析 ， 段落内的动词和代词占比更大 ，  

名词占比稍小 ，形容词占比接近 ，其原因在于段落描述了更多有关对象的属性和  

位置关系等信息 。  

２．４．２图像描述任务评价指标  

评价图像描述模型生成段落质量通常采用评价指标的方式 ，其基本原理是计  

算机器生成文本Ｃ和参考标签文本Ｓ的相似度 ：  

Ｓ ｉｍ＝Ｍｅｔｒｉｃ（５ ，Ｃ）（２ － ２３）  

相似度越高 ， 表明机器生成段落质量更高。本小节详细介绍本文所采用的几  

种评价指标 ： ＢＬＥＵ

、 ＭＥＴＥＯＲ

｜２７ ＷＱＣＩＤＥｒ

ＢＬＥＵＢＬＥＵ 由 ＩＢＭ公司于 ２００２年提出 ，起初用于评测机器翻译任务的性  

能 ， 现今也被用于评价图像描述任务上 。 ＢＬＥＵ基于精确率 （ＰｒｅｃｉｓｉｏｎＲａｔｅ）计  

算机器描述和参考描述中ｎ元组的相似程度 。 ＢＬＥＵ指标的基本思想是考虑机器  

描述和参考描述两者间语法文字的重合度 ， 并对计算结果进行

一定程度的调整 。  

具体如下 ， 首先计算生成描述和参考描述的ｎ元组重合度 ：  

Ｓ ｉＥｆ ｃｍｉｎ（ｈｋ（Ｃ ｉ） ，ｍ＾

／ｉｋ（ｓ ｉ；）

Ｃｎ ＝Ｅ ｉＸｋＫ（ｓ〇

（２ ＿ ２４）  

其中 ， ｑ表示生成的待评价描述 ， 对应的

一组参考描述为丨％ ，ｓ

ｈＣｃ ｉ）表示第ｆ ｃ个ｎ元组在待评价描述中出现的次数 ， ／Ｉｆ ｃ（ｓｙ）表示第Ａ：个ｎ元组在第  

个参考描述中出现的次数 。根据ｎ元组重合度Ｃｎ ， 可以计算ＢＬＥＵ评分 ：  

１７  

第二章基础知识  

ＢＬＥＵｎ （Ｃ ，５） ＝Ｐ（Ｃ ，Ｓ）ｅｘｐ

（ ＾ ＾

ｗｎ ｌｏｇＣｎ

－ ２５）  

其中 表示ｎ元组的权重因子 ， Ｐ （Ｃ （ ｌＳ）表示对短机器描述的惩罚因子 ， 其计  

算公式如下 ：  

， ＼ｆ ｌｃ ＞ ｌｓ  

Ｐ（Ｃ５）＝

ｅｘｐ（１

） ，ｉｆ ／ｃ ＜ Ｚｓ

￣ ２６）  

其中 ， 乙表示待评价描述的长度 ， 而Ｇ表示参考描述的长度 。  

ＭＥＴＥＯＲＢＬＥＵ在计算相似度时仅考虑了精确率 ， ２００４年 ， Ｌａｖｉｒ等人提  

出结合召回率 （ＲｅｃａｌｌＲａｔｅ ） 的相似度衡量方法ＭＥＴＥＯＲ ， 相比于ＢＬＥＵ ， 其评  

测结果与人类判断更加相关 。 具体地 ， ＭＥＴＥＯＲ计算

一元组 （ｕｎｉｇｒａｍ） 精确率  

和召回率的调和平均值 （ＨａｒｍｏｎｉｃＭｅａｎ） ， 并具有同义词匹配等其他功能 。精石角  

率和召回率计算如下 ：  

（２ — ２７）  

（２ ＿ ２８）  

｜是机器描述和参考描述的

一元组 ， 即公共词的数量 。 ５＾＼匕）为  

一元组数量 ，

： 心 （ｓ〇〇为参考描述中

一元组数量 ， 接下来计算调和  

平均值 ：  

Ｆｍｅａｎ ＝

（ｌ － ａ）Ｒｍ

￣ ２９）  

其中 ， ａ为权重参数 ， 召回率权重大于精确率 ， 取 ０ ．９ 。 最后计算惩罚项和  

ＭＥＴＥＯＲ值 ：  

Ｐｅｎ＝ Ｖ（＾ ） ０ （２ －３０）  

ＭＥＴＥＯＲ＝ （１

－ Ｐｅｎ）Ｆｍｅａｎ（２

－ ３１）  

ＣＩＤＥｒ２０ １５年Ｖｅｄａｎｔａｍ等人提出专门针对图像描述任务的评价指标ＣＩＤＥｒ ，  

旨在考虑机器描述和人类描述的相似性 ， 经实验 ， ＣＩＤＥｒ相较于 ＢＬＥＵ 和  

ＭＥＴＥＯＲ ， 其评价与人类评测相关性更高 。对于

一个ｎ元组叫和参考描述Ｓ

， 首  

先计算其ＴＦ

－ ＩＤＦ（词频

－逆文档频率 ）值汍（％） ，  

９ｋ（ ｓ ｉｊ） ＝Ｈ（

￣＾ ｒｒ） （２ －３２）   ＬＷ ｌｅｎｈ｛Ｓ

ｉｊ）ｙ ｌ；／ｐｅ／ｍ ｉｎ （ｌ ，Ｙｑｈｋｋ （ｓ ｐｑ）ｊ）  

１８  

第二章 基础知识  

其中 ， ／２表示全部ｎ元组构成的词表 ， ／表示测试集图片的集合 。 随后计算待  

评价描述和参考描述ＴＦ －ＩＤＦ向量的余弦相似性 ， 得到ｎ元组对应的 ＣＩＤＥｒ值 ：  

… Ｐ，ｒ 、 １ Ｖ５

（Ｃ ｉ）５ ｎ

（ｓ＂）   ＣＩＤＥｒｎ（Ｃ ｉ ，５＾） ＝ — ／ —— ｒ —

— ｒｒ（２ — ３３）  

丨 丨炉⑷ 丨 丨 丨 丨圹⑷

丨 ｜  

Ａ ，ｓ ｉｗｌ｝为参考描述集合 ，垆（ｑ）和ｆＯ＂）表示待评价描述和参  

考描述的ＴＦ －ＩＤＦ向量 。 当使用多种长度的ｎ元组时 ， 需要给出平均值如下 ，  

ＣＩＤＥＫｑ ，＾） ＝－

＾ ＣＩＤＥｒｎ（ｑ ，＾）（２

－ ３４）  

ｎ －ｌ  

上述评价指标中 ， ＢＬＥＵ基于精确率计算文本间的 ｎ元组相似度 ， ＭＥＴＥＯＲ  

综合了精确率和召回率 ， ＣＩＤＥｒ 则基于共识的方法更直接地衡量描述的类人  

（ｈｕｍａｎ － ｌ ｉｋｅ ）程度 。 需要强调的是 ， ＢＬＥＵ和ＭＥＴＥＯＲ起初被提出以用在机器  

翻译任务上 ，后来迁移到图像描述任务上 ，而ＣＩＤＥｒ是为图像描述任务定制的 ，  

并且ＣＩＤＥｒ是这几种指标中与人类评价相关性最高的 。因此 ， ＣＩＤＥｒ指标在本文  

的评价指标对比中具有更高的参考权重 。  

２ ．５本章小结  

本章介绍了段落式图像描述模型涉及到的基础知识 ， 先介绍了ＣＮＮ 、＿  

和 ＬＳＴＭ ， 然后介绍了基于 ＣＮＮ和ＲＮＮ的图像描述基本结构 。 本文使用了区  

域注意力机制 ， 因此又介绍了注意力机制在图像描述任务中的实现细节 。在本章  

的最后 ， 我们介绍了段落式图像描述的相关数据集和评价指标 。  

１９  

第三章基于全卷积祌经结构的段落解码器  

第三章基于全卷积神经结构的段落解码器  

传统段落式图像描述方法的段落解码器都基于ＲＮＮ及其变种网络 ， 本章针  

对此类方法中存在的问题 ， 提出了

一种全卷积神经结构的ＣＮＮ段落解码器 ， 并  

根据该解码器形成了

一套段落式图像描述方法 。本章首先对比了用于图像描述任  

务上基本的ＣＮＮ解码器和 ＲＮＮ解码器的结构 ， 阐明了使用卷积结构的动机 ，  

接下来详细描述了本文提出的全卷积段落解码器 ，并通过评测指标 、连贯性指标 、  

时间复杂度和定性分析的对比实验证明了所提模型的有效性 。  

３ ．１ＣＮＮ解码器与ＲＮＮ解码器  

近年来的图像描述方法大多基于ＣＮＮ＋ＲＮＮ框架 。 ＣＮＮ编码器将输入图像  

表示为较低维的图像特征 ，＿解码器再将图像特征解码为描述文本输出 。 由  

于该框架可端到端训练 ， 且得益于ＣＮＮ提取图像特征和＿建模序列文本的  

强大能力 ， ＣＮＮ＋ＲＮＮ框架的性能较为突出 。 但ＲＮＮ解码器其实并非完美解决  

方案 ，其长时记忆能力不足和无法并行化的缺点 ，在建模段落这样的长文本时尤  

为突出 。 因此 ，生成段落的质量不令人满意 ， 其

，段落内的句子间缺少上下文  

关联性 ， 段落更像是句子的简单堆砌 ； 其二 ， 信息表达冗余严重 ，很多情况下几  

句话都在描述同

一个对象或事情 ，甚至几句话完全相同 。 同时 ，模型的训练和推  

理时间较长 ， 时间消耗很大 。  

受启发于卷积结构的可并行化特点 ， 已有工作

［４８ ］将ＣＮＮ作为解码器 ， 构建  

ＣＮＮ＋ＣＮＮ框架生成单句图像描述 ， 展示了ＣＮＮ作为语言生成器的潜力 。

［４９ ］  

也尝试了将该框架用于段落式图像描述任务上 ， 但由于这种ＣＮＮ解码器模型层  

， 仅考虑了单词级别的连贯性 ， 忽视了句子级别的连贯性 ， 因而并未  

取得亮眼的结果 。本文针对段落的特点 ，提出了

一种全卷积段落解码器 ， 以下首  

‘Ａ ｌａｒｇｅｄｏｕｂ ｌｅｄｅｃｋｅｒｂｕｓｄｒ ｉｖｅｓｄｏｗｎｔｈｅｓｔｒｅｅｔ ．  

Ｔｈｅｂｕｓ ｉｓｒｅｄ ｉｎｃｏ ｌｏｒ．  

＊ ＊  ，

；Ｔｈｅｂｕｓ ｉｓｒｅｄｗ ｉｔｈｌａｒｇｅｂ ｌａｃｋｔ ｉｎｔｅｄｗ ｉｎｄｏｗｓ ．  

Ｔｈｅｂｕｓ ｉｓａｔｔｈｅｎａｒｒｏｗｓｔｒｅｅｔ ．  

叉麻 Ｔｈｅｂｕｓ ｉｓａｄｏｕｂ ｌｅｄｅｃｋｅｒ．   露

Ｔｈｅｒｅａｒｅ ｐｅｏｐ

ｌｅ ｉｎｔｈｓｓ ｔｒｅｅｔ ＊  

图 ３ － １ＲＮＮ解码器生成段落结果 ， 标红色和蓝色的位置出现了信息冗余  

２０  

第三章 基于全卷积神经结构的段落解码器  

先介绍这种基础的 ＣＮＮ解码器 ， 并和 ＲＮＮ解码器进行对比 。 所提出的全卷积  

段落解码器在下

一节进行介绍 。  

给定图像／， 编码器将其压缩为图像特征 ， 记为 Ｖ 。 以 ｖ为输入 ，解码器将 ｖ  

解码为文本 ７Ｘ。 ＩＸ由｛ｕ＾ｕ＾ ，组成 ， Ｗ

ｊ为句子中的

一个单词 ，下标符号Ｗ  

为生成句子中单词的总个数 。  

具体地 ，在解码过程中的每个时刻 ，解码器根据

，并结合图像特征 ，  

一个单词 。 在 ｆ时刻 ， 无

” 信息损失的该过程可用公式表示如下 ：  

ｗ ｔ ＝Ｄｅｃｏｄｅｒ＾！ ，ｗ２ ， ． ． ． ．Ｗ ｔ ．ｊ ，ｕ）（３

— １）  

针对ＲＮＮ解码器而言 ， “ 上文

” 信息｛＾ ，化 ，

． ． ． ， ！＾』依赖于隐藏单元ｈｙ存  

储 ， 其生成过程为 ：  

ｈ＾Ｒｍ ｉｈ＾ ．ｗ＾ ．ｖ）（３ － ２）  

ｗ ｔ ＝ｓｏｆｔｍａｘ（ｆｃ（ｈ ｔ）） （３ — ３）  

其中 ， ／ｉ ｔ表示 ／时刻的隐藏状态向量 ， ｆｃ表示全连接前馈神经网络 ， ｓｏｆｔｍａｘ  

表示 ｓｏｆｔｍａｘ激活函数 。 随着时间步的向后推移 ，

” 信息逐渐发生衰减 ，  

产生了信息损失 。 在 ／时刻共有 ／ －Ｉ个

” 信息 ，＿关注

” 的视野  

小于等于Ｐ １ 。 因此 ，＿解码器的长时记忆能力受到了限制 。  

单词ｔ单词１  

ａ ａ  

－ １ —？ＬＳＴＭＣＮＮ  

￣￣  

单词ｔ － １单词１ 单词２． ． ？单词ｔ － １  

－２ＣＮＮ解码器和ＲＮＮ解码器结构对比  

再观 ＣＮＮ 解码器 ， 其无需通过隐藏状态存储

” 信息 ， 直接将  

｛Ｗｉ ，ｗ２ ， ，说＾丨作为输入 ，其生成过程表示如下 ：  

ｏ ｔ ＝ＣＮＮ（ｗ １ （ｗ２ ， ． ． ． ，ｗ ｔ －ｖｖ）（３ －４）  

ｗ ｔ ＝ｓｏｆｔｍａｘ（ ｆｃ（〇 ｔ））（３ — ５）  

其中 ， ｏ ｔ表示 ／时刻的ＣＮＮ解码器输出 。 可看出 ＣＮＮ解码器关注 “ 上文

的视野大小始终为Ｍ 。 相较于＿ ， ＣＮＮ解码器拥有更大的长时视野 。 然而 ，  

仅有充足的长时视野是不够的 。 常规ＣＮＮ的卷积层结合池化层并不具有记忆能  

２ １  

第三章 基于全卷积神经结构的段落解码器  

单词 １单词２单词３ — 一单词Ｎ  

？；… ｔ ？头 ；

ｉ 可堆叠的＠＠＠

．… ＂ ＠ｊ  

Ｉ 卷积层ＴＴｔＴ ：  

ｊ／ ＾ ／卷积核 掩码 ＼

ｉ （词嵌入层 ）

… ？ ？… ＂  

ｊ ＜Ｓ＞单词 １单词２ — ？ 单词Ｎ

－ １  

－３ 门控ＣＮＮ解码器结构  

力 ， 要想拥有长时记忆能力 ， 还需赋予 ＣＮＮ解码器记忆能力 。在图像处理中 ，  

池化层对计算量的减少 ，以及对图像具有平移不变性的特点使其作为基本结构广  

为应用 。但对于文本处理而言 ， 更需要的是对上下文的建模能力 。 为赋予 ＣＮＮ  

？乙能力 ， 我们在卷积层后加入ＧＬＵ门控模块

， 替换池化层 。 结合长  

时视野 ， 门控 ＣＮＮ解码器具有较好的长时记忆能力 ， 更适用于长文本的生成 。  

以下对门控ＣＮＮ解码器的结构进行详述 。  

门控ＣＮＮ解码器的结构如图 ３ －３所示 。该结构包含三个主要模块 ：嵌入层 、  

门控卷积层 、预测层 。嵌入层将

” 单词｛Ｗｐ 丨映射为词嵌入向量  

。 门控卷积层接收 Ｖ和词嵌入向量序列 ， 输出预测向量Ｏ ｔ 。 预  

测层最后将预测向量通过全连接前馈神经网络和 ｓｏｆ ｔｍａｘ激活函数将预测向量映  

射为词表上的概率分布ｖｖｐｔ 。  

在门控卷积层中 ， 假设图像特征 Ｖ作为第 ０时刻的输入 ，且 Ｖ和词嵌入向量  

的维度都为尺。 在 ／时刻 ， ＣＮＮ解码器的输入 组成的向量矩  

， 其形状为ｔｘＥ 。 接下来

一维卷积核作用于／ ｔ之上 ， 步长为 １ ，￡

■为输入通  

道数量 ， 输出通道数量为２ ＊因此输出的向量维度为１Ｘ２Ｆ ， 该向量可视作两  

个维度为五的向量岵 、 吋的拼接 ， 用公式表示如下 ：  

ｈｆ ＝Ｗａ ＊ ｌ ｔ＋ｂａ （３

－ ６）  

ｔ ＝Ｗｂ ＊ ｌ ｔ＋ｂｂ （３

－ ７）  

其中 ，％ 、叭为可学习的卷积核权重参数 ， ＆ａ 、＆为可学习的卷积核偏置  

参数 ，符号＊表示

一维卷积操作符 。  

此时值得注意的有两点 。第

一点 ，为确保卷积层只关注

” 且屏蔽掉未  

， 需采用掩码机制 （ＭａｓｋＭｅｃｈａｎｉｓｍ） ， 使卷积核中与

２２  

第三章 基于全卷积神经结构的段落解码器  

进行计算的后半部分权重置为零 。第二点 ， 当卷积层深度为 １时 ， 卷积核的大小  

应不小于句子长度从 以确保 ／时刻的视野大小等于 ／ － Ｉ 。 但当 ｉＶ较大时 ， 可采  

用堆叠多层卷积层的做法 ，通过卷积层的深度和卷积核的大小综合控制感受野的  

大小 。  

接下来 ，在卷积层之后执行门控操作 ， 得到门控卷积层的输出向量０ ｔ

〇ｔ ＝ｈ？Ｑｃ（ｈ＾ （３ － ８）  

其中 ， 符号ｃ表示 Ｓｉｇｍｏｉｄ激活函数 ， 即ａ〇） ＝ ｌ／（ｌ＋ｅ

， 符号〇表示  

按位乘法操作符 。 向量／ｉｆ蕴含

” 中的语义信息 ， 起 门控的作用 ，  

有选择地记住ｈｆ中的信息 。  

然后 ， 预测层将 映射为词表上的概率分布ｗｐｔ ， 即  

ｗｐｔ ＝ｓｏｆ ｔｍａｘ（Ｍ＾ｐ ｏ ｔ） （３ — ９）  

其中 ， Ｍ／ｗｐ为可学习的全连接层权重参数 。  

最后 ， 根据ｗＰｔ在词表上进行采样 ， 可选择的采样方式有最大概率采样和集  

束搜索两种方法 ， 得到 ／时刻的单词输 。当生成的单词为句子结束符时 ， 停  

止生成 ， 将所有生成的单词组合得到解码生成的句子 。  

３．２全卷积段落解码器  

本节将首先介绍模型的总体结构 ，接下来依次介绍图像编码器 ， 以及段落解  

码器的两个组成部分 ： 句子ＣＮＮ解码器和词ＣＮＮ解码器 ， 然后介绍模型的训  

练和推理方法 ， 最后根据所提模型总结出

一种段落生成算法 。  

３．２ ．１模型整体描述  

上节所介绍的门控ＣＮＮ解码器 ， 虽具有较强的长时记忆能力 ， 但只考虑了  

词间关系而没有考虑句间关系 ， 因此并不适用于直接对段落建模 。本文根据段落  

的层次性 ， 同时考虑句子间和词间的关系建模 ， 提出了

一种针对段落的层次性  

ＣＮＮ解码器 。 该段落解码器为全卷积结构 ， 包含两个层次的 ＣＮＮ ： 句子 ＣＮＮ  

解码器和词ＣＮＮ解码器 。  

首先针对段落式图像描述任务定义符号 。对于图像／ ， 目标是生成

一个连贯  

的段落Ｐ＝＾Ｊ２ 夂｝

， 其中交表示

一个句子 ， 且ｉ ｅ ［ｌ ，Ｍ ］ ， 下标Ｍ是段落中  

句子的数量 。 对于每个句子 ， 有矣 ＝ ？

，＾｝ ， 其中兩

？是第 ｉ个句子爻  

中第ｊ个单词的符号表示 ， 且 叫］ ， 叭为该句子的长度 。  

给定输入图像 ，首先通过Ｅ域提议网络组成的目标检测器检测图像中的若干  

区域 ， 并将每个区域表示为特征向量 ， 从而生成

一组视觉语义代码 。 接下来 ，所  

２３  

第三章 基于全卷积神经结构的段落解码器  

输出段落  

；   输入图像 ； ｜

 ＾句子１句子２ ． ． ． 句子Ｍ

 ｜   

… ＠   编码器＾ 解码器  

「 卷《＇神 ）

ｌ ｉｉｋ ＼ｍｋ ｌ ｉｉｉ Ｉ

Ｖ挪＠Ｊ向量１向量２

… 向量Ｍ  

｜ ｔ ｜  

（） ｜  

－４椟型整体框架图  

提出的全卷积段落解码器将这些视觉代码解码生成段落文本 。具体来说 ，在视觉  

特征向量的作用下 ， 句子ＣＮＮ建模段落内句子间的上下文语义逻辑关系 ， 生成  

Ｍ个句子的多模态语义向量｛仏＇２ 来指导接下来每个句子的生成 。接下来 ，  

词ＣＮＮ以每个句子的多模态语义向量＆为输入 ，生成对应句子￥中的所有单词 。  

当所有句子生成完毕 ， 这些句子组成起来形成了

一个连贯的段落 。综上 ， 模型整  

体框架图如图 ３ －４所示 。  

３ ．２．２图像编码器  

在编码器部分 ，本章采用和

ｌ３° ］中类似的做法 。区域提议网络 （Ｒｅｇ

ｉｏｎＰｒｏｐｏｓａｌ  

Ｎｅｔｗｏｒｋ ，ＲＰＮ ） 和ＶＧＧ － １６网络检测出图像中的若干区域并抽取特征 。 ＲＰＮ通  

一组锚点进行回归学习 ， 来提出感兴趣的区域 。 然后 ， 通过双线性插值法  

（Ｂ ｉ ｌ ｉｎｅａｒＩｎｔｅｒｐｏｌａｔｉｏｎ ）和两个全连接网络将每个区域映射到固定维数为 的向  

量巧 。接下来 ，再通过

一个全连接网络将込映射为维度Ｄ的向量巧 。通过该操作 ，  

获得代表局部的详细视觉信息的

一组区域特征ｖ 。 最后 ， 使用最  

大池化操作得到总体的图像全局特征％

， 即 ：  

ｆ ｐ ＝ｍａｘ｛ ｉ；

／｝［＝１ （３ －１０）  

其中 ， ｍａｘ表示按位最大池化函数 。池化特征％可以有效地捕获图像的显著  

特征 ， 将作为图像特征输入到句子ＣＮＮ中 。 在实验中 ， 我们尝试了两种方式以  

期获得图像的显著特征 。方法

一己如上所述 ， 方法二是直接通过 ＶＧＧ 、 ＲｅｓＮｅｔ  

等在 ＩｍａｇｅＮｅｔ数据集上预训练的ＣＮＮ网络提取特征 ，实验结果显示方法

一取得  

了更好的效果 。可能的原因是 ，方法

一采用的ＲＰＮ网络是在ＤｅｎｓｅＣａｐ模型预训  

练的 ， ＤｅｎｓｅＣａｐ也是图像描述模型的 一种 ，相比方法二的ＣＮＮ是在图像分类数  

２４  

第三章 基于全卷积神经结构的段落解码器  

据集上训练的 ， ＲＰＮ更接近于我们的任务 。 此外 ， 我们还尝试了最大池化和平  

均池化两种方式 ， 根据实验结果在此处采用了最大池化方法 。  

３．２．３句子ＣＮＮ  

句子ＣＮＮ解码器的作用是为每个句子生成其对应的多模态语义向量 。 句子  

ＣＮＮ包含三个模块 ： 句子嵌入层 ， 门控卷积层和语义向量输出层 。 对于每个句  

， 句子嵌入层首先为其上文句子 ｛＆次 禽 ＿ｉ｝生成句子嵌入向量  

，Ｓｆ Ｓｆｕ｝ 。其中 ， 第零句话夂为设置的段落开始符 。 然后 ， 门控卷积层将  

这些句子嵌入向量和图像特征ｖ ｐ作为输入 ，再通过语义向量输出层生成＆的多模  

态语义向量仏 。  

在句子嵌入层中 ，通过将句子中单词的词嵌入向量做平均池化得到句子嵌入  

表示 ：  

５ｆ ＝ｍｅａｎ ｛ｗ？

；！ １ （３ － １１）  

其中 ， 表示第 ｚ

‘ 句话中第 ＿／个词的词嵌入向量 ， ｍｅａｎ表示按位平均  

池化函数 。 因此可以得到 ， ５／ｅＭ ￡

一提的是 ， 在实验中我们尝试了多神  

句子嵌入的方法 ， 包括对词向量做平均池化 、 最大池化 ， 以及用 ＬＳＴＭ对句子  

进行编码的方式 。根据实验结构 ，对词向量做平均池化是效果最好且无额外计算  

消耗的方法 。  

接下来 ，门控卷积层将最大池化的区域特征ｖ ｐ及所有上文句子的句子嵌入向  

量序列作为输入 ， 生成第 ／个句子的多模态语义向量 。这个过程可以表述如下 ：  

ｉ ＝ＣＮＮ ｇｔＣ ／ｏ ， ／ ！ ／

ｉ ＿ｔ）（３ — １２）  

其中 ， 是句子索引 。 ／

． ｅＲ Ｅ＋Ｄ是句子嵌入向量矽和最大池化图像  

表示％的拼接向量 ， 即 ／

／ ＝ ［Ｓ／

；Ｖ Ｐ］ ， 其中

— １ ］ 。 门控 ＣＮＮ 将序列  

ｅ 作为输入 ， 从而生成语义向量序列说 ，６２， … ，心） 。生成多模态语义  

向量时 ， 门控ＣＮＮ解码器应该仅能观察上文句子序列 。为此 ， 我们使用掩码机  

制来屏蔽尚未生成的下文句子 。  

／的维度为ｆ＋Ｄ ， 因此输入通道数分别为ｆ＋ Ｚ） 。给定输入｛ ／

（＾ ， … ，／＾ ｝

组成特征矩阵／Ｍ ｉ

，得到隐藏向量％和６呔 ， 即  

ｉ ＝Ｗｕ ＊ＩＭ

ｔ＋ｂｕ（３ — １３）  

ＧＨ ， ＝Ｍ／ ５ｈ ＊ ／Ｍ ？＋Ｖ（３ － １４）  

其中 ，＾叶 ￡阪 ￡

，是卷积核的可学习权重参数 ，心＆＃是卷积核  

的可学习偏置参数 ， 卷积核的输出通道数为２￡ 。 卷积核的大小等于段落中句子  

的最大个数 ， 以保证解码器的视野覆盖所有上文句子 。  

２５  

第三章 基于全卷积神经结构的段落解码器  

接下来执行门控操作 ， 得到门控卷积层的输出  

Ｓ〇 ｉ ＝Ｕ ｉ〇ａＣＧＨ

ｉ） （３

－ １５）  

随后 ， 通过全连接层 在两个标签上输出概率分布ｐｉ

Ｐｉ ＝ｓｏｆｔｍａｘ（Ｍ＾５〇

ｉ＋ｂ ｖ）（３ — １６）  

其中 ，％是可学习权重 ， 是可学习偏置 。两个标签分别是标签

ＣＯＮＴＩＮＵＥ ”  

（Ｐｉ＜ ０ ．５ ）或标签

“ ＳＴＯＰ

（Ｐｉ２０ ．５ ） 。生成

“ ＳＴＯＰ

”标签时便意味着当前句子  

是该段落的最后

一句 。  

最后 ，通过语义向量输出层得到多模态语义向量  

＆ ＝叫吨 ＋￣） （３ － １７）  

其中 ，％是可学习权重 ， 、是可学习偏置 。 ｆ表示ＲｅＬＵ函数 。  

３．２ ．４词ＣＮＮ  

在多模态语义向量Ｇ的引导下 ， 词 ＣＮＮ解码器生成每个句子乌中的单词 。  

一个句子中 ，

一个单词的预测依赖于该句子中的上文单词 。 词ＣＮＮ包含三个  

模块 ：词嵌入层 ，门控卷积层和词预测层 。对于第 ／句话中的第 ＿／个单词 ，首先 ，  

词嵌入层将上文单词的独热编码投影到维度为五 的词嵌入空间中 ， 得到词嵌入  

向量序列 ＜０｝ 。其中 ，第零句话 为设置的句子开始符 。接下来 ，  

门控卷积层以序列悅 ，＜０ ， １＾ 作为输入 ， 并生成恥 的分布ｗｐｉ ）；

。 以  

上过程形式化如下 ：  

ｗｐｔｊ ＝ＣＮＮ ｇｔＣＧ＾ｗ＾ ｏ ．ｗ？

！ ， （３ － １８）  

在词ＣＮＮ解码器中 ， 卷积层的输入通道为五 ， 输出通道为 ２￡ ， 因此经门控  

模块后的输出向量维度为五。在实验设置中 ，

一个句子中最多的单词个数＆？设  

置为 ３０ 。 因此 ，采用多层卷积层堆叠的方式保证词ＣＮＮ的感受野 。 在实验中 ，  

我们确保感受野的大小大约等于Ａ／ｍａ；ｃ 。 同时 ， 为增强特征传递并减弱堆叠卷积  

层带来的梯度消失和爆炸现象 ， 在卷积层之间设置了残差连接 （Ｒｅｓｉｄｕａｌ  

Ｃｏｎｎｅｃｔｉｏｎ）〇  

残差连接的实现描述如下 。 假设有尤个卷积层 ， 将第 是层的输出向量表示  

。对于堆叠卷积层中的第

一层 ， 综合了残差连接的卷积层输出计算方式如  

下 ：  

° ｕ！ ＝ Ｋ｝＋Ｗｎ＜ｊ

－ １（３

－ １９）  

对于其余层 （即ｆ ｃ２２ ） ， 卷积层输出计算方式为 ：  

ｋ＝ｈｌ！＋ｗｒ， °Ｔ ，ｒ（３ － ２０）  

２６  

第三章 基于全卷积神经结构的段落解码器  

其中 ， 是残差连接的可学习权重参数 ， 〇

ｌＸ／是卷积层的输出 。  

最后 ， 词预测层以卷积层最后的输出〇

；７为输入 ， 通过全连接网络输出在词表上  

的概率分布ｗｐｉ

ｗｐｉｊ ＝ｓｏｆｔｍａｘ（Ｍ＾ｖｐｏ ｌ

）（３ － ２１）  

其中 ， 州ｗｐ是可学习权重 。 最后 ， 根据

？在词表上采样得到输出单词 。  

３．２ ．５横型训练与推理  

首先介绍损失函数和训练步骤 。所提全卷积段落解码器的损失函数为两项交  

叉熵损失的加权和 。 第

一项为句子ＣＮＮ解码器中预测段落停止的概率巧的句子  

级损失 ， 第二项为词ＣＮＮ解码器中预测单词的概率 的单词级损失 。 整体损  

失函数Ｘ定义如下 ：  

Ｉ＝Ａｓ

＾ Ｘｓ（巧 Ｊ ｌ＝Ｍ）＋／ｌｗ

＾＾ ￡ｗ０ ＞

ｉ ；）（３ － ２２）  

ｅ＝ｌ ｉ＝ｌ７ ＝１  

其中 ， 系数；１，和；＾分别为句子级损失和单词级损失的系数 ， ｉ

｝表示指示函  

数 （ Ｉｎｄｉｃａｔ ｏｒＦｕｎｃｔｉｏｎ ） 。在实际训练中 ， 首先对区域检测器进行预训练 ，并据此  

得到训练集中图像的特征向量 。 然后 ， 将预训练的区域监测器中的权重冻结 ， 以  

图像的特征向量和对应的段落文本以端到端的方法训练全卷积段落解码器 。  

接下来介绍推理过程 。给定待生成段落的输入图像 ， 首先利用预训练的区域  

检测器抽取图像区域并得到图像特征 。 以图像特征为输入 ， 句子ＣＮＮ解码器会  

依次生成每个句子的多模态语义向量 ， 直到句子的数量大于最大值Ｍｍａｘ或生成  

“ ＳＴＯＰ ” 标签为止 。接下来 ，在多模态语义向量的指导下 ，词 ＣＮＮ解码器为每  

个句子生成单词 ， 当句子的长度大于Ｗｍａｘ或生成了句子结束符＜Ｅ＞时 ， 句子生成  

结束 。将所有生成句子按序组合 ， 得到生成段落 。  

３．２．６段落生成算法  

根据以上模型 ，我们总结出基于全卷积神经结构的段落式图像描述算法 ，主  

要分为三个过程 ：

一是利用基于卷积网络的目标检测器对图像进行编码 ；二是通  

过句子ＣＮＮ解码器生成段落中每句话的多模态语义向量 ； 三是在多模态语义向  

量的指导下 ，词ＣＮＮ解码器生成每句话中的所有词 。算法实现步骤可总结如下 ：  

算法 １基于全卷积神经结构的段落式图像描述算法  

输入 ： 图像Ｊ  

输出 ： 描述段落Ｐ ， 包含Ｍ个句子 ， 其中第洵话包含恥个单词 。 Ｍ为算法过  

程中确定的参数 。  

２７  

第三章 基于全卷积神经结构的段落解码器  

步骤 １ ：利用目标检测器 （ＯｂｊｅｃｔｉｏｎＤｅｔｅｃｔ ｏｒ）提取图像中Ｌ个感兴趣区域 。  

步骤２ ：通过预训练的卷积神经网络 ，对每个感兴趣区域提取出维度为 的  

特征 ， 并使用全连接前馈神经网络将其压缩为 五维的向量表示 ， 从而得到图像  

区域向量集｛力 ，ｖ２ ，

． ． ． ，叫｝ 。  

步骤３ ：对区域向量集进行按位最大池化操作 ， 得到该图像的全局向量表示  

步骤 ４ ：在 ｉ＝ｌ时刻 ，通过词嵌入层获取句子开始标志的嵌入向量沿

，将砧  

和％拼接 ， 得到＇ ， 输入到句子 ＣＮＮ解码器中 ， 获得指导第

一句话生成的多模  

态语义向量心 ， 并生成段落终止概率Ｐｌ 。  

步骤 ５ ： 将＆输入到词 ＣＮＮ解码器中 ， 解码得到第

一个句子 私

，２ ，  

Ａ ，Ｗ ｌ｝ ， 并跳至步骤 ８ 。  

步骤 ６ ： 在ｉ＝２ ，

． ． ．时刻 ， 通过句子嵌入层获取第 ０至 ｉ － １句话的句子嵌入  

向量序列说 ，对 ，

． ． ． ，５＾

， 句子嵌入向量为句子中所有词嵌入向量的按位平均向  

量 。将｛Ｓ〇

，Ｓｆ Ｓｆ＾｝中的每个向量分别和ｖ拼接 ， 得到 Ｕ ，输入到句  

子ＣＮＮ解码器中 ， 获得指导第Ｚ句话生成的多模态语义向量＆ ， 并生成段落终止  

概率Ｐｉ 。  

步骤 ７ ： 将＆输入到词ＣＮＮ解码器 ，解码得到第 ｉ个句子 恥 ，２ ， … ，〇＞

ｉ ，Ｗ ｉ｝ 。  

步骤 ８ ：根据段落终止概率Ｐ ｉ判断当前第ｉ句话是否为段落的最后

一句话 ，若  

是 ， 则Ｍ＝ｉ ， 否则 ， 回到步骤 ６ 。  

步骤 ９ ： 将Ｍ个句子皂 灵＾按序排列 ， 即可得到描述段落Ｐ  

３ ．３实验对比与分析  

以上详细介绍了全卷积段落解码器的结构和算法流程 ，接下来通过在公开数  

据集上进行实验 ，并与若干基线方法进行评测指标结果的对比与分析 。通过三种  

一步证明所提模型的性能 ： （ １ ）提出了

一种连贯性指标来定量评价段落的  

连贯性 ； （２ ）分析了卷积段落解码器和Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ模型的时间复杂性 ， 并  

通过记录训练时间进行验证 ； （３ ）对不同模型生成的段落进行主观的定性分析 。  

最后 ， 我们对比了在不同卷积层参数 、束大小设置下 ， 所提模型的性能表现 ，并  

根据对比实验确定卷积层参数和束大小设置 。  

３ ．３ ．１实验参数与设置  

为验证所提出的全卷积段落解码器的有效性 ，本文在斯坦福大学最新建立的  

一一斯坦福图像

－段落数据集上进行实验验证 。为了与基线方法进行  

公平比较 ， 遵循

［３Ｇ ］的做法将数据集划分为三个子集 ： 训练集 、验证集以及测试  

２８  

第三章 基于全卷积神经结构的段落解码器  

集 。它们分别包含 １４７５７、 ２４８７以及２４８９个图像

－段落描述对的样本 。 词表根据  

训练集中的段落文本建立 ， 并筛去出现次数小于 ５次的单词 ， 得到大小为 ４５８０  

的词表 。 其中还包含四个特殊标记 ： 句子开始符＜Ｓ＞ ， 句子结尾符＜Ｅ＞ ， 未知单  

词＜循１０以及 Ｐａｄｄｉｎｇ符＜卩＾＞ 。  

本文实验所使用的服务器操作系统环境为 Ｌｉｎｕｘ ， 该服务器配置了英伟达  

ＧｅＦｏｒｃｅＧＴＸ１０８ＯＴｉ 显卡 。 软件环境为采用 Ｐｙ ｔｈｏｎ编程语言的开源框架  

ＰｙＴｏｒ ｃｈ

［５ １ ］

。 Ｐｙ ｔｏｒｃｈ是由 Ｆａｃｅｂｏｏｋ公司开发的开源机器学习库 ， 其计算可使用  

ＧＰＵ进行加速 ， 且带有自动微分系统 ， 因此广受深度学习研宄者青睐 。  

一些参数设置如下 。区域检测器所检测的区域个数Ｌ设定为 ５０ 。 区域  

特征向量初始维度Ｕ为４０９６ ，经全连接层压缩后的区域特征维度Ｄ为 １０２４ 。词嵌  

入向量的维度Ｅ同样设定为 １０２４ 。 通过对比实验 ， 釆用集束搜索方法生成段落 。  

其中束的大小设置为 ２ 。 段落中最大句子数目设定为 ６ ， 每句话的最大单词数设  

定为 ３０ 。 通过对卷积核大小的实验 ，句子ＣＮＮ解码器中采用

一层卷积 ， 即深度  

为 １ ， 卷积核大小为 ６ ； 词ＣＮＮ解码器中采用 ７层卷积 ， 即深度为 ７ ， 每层的卷  

积核大小为 ５ 。损失函数中的两个系数；１￣和４分别设置为 ５ ．０和 １ ．０ 。整个模型使  

用Ａｄａｍ优化算法进行训练 ，学习率参数设置为１０

。实验中依据算法在验证集  

上的表现确定超参数 。  

３．３．２基线方法介绍  

本节简单介绍我们所对比的六个基线方法 ： Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ

ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ

，Ｉｍａｇｅ －Ｆｌａｔ（ＲＮＮ ）

ｌ＂ ＾Ｉｍａｇｅ

－Ｆｌａｔ（ＣＮＮ ）

Ｈ ｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ

１ ）Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ方法使用单句式图像描述模型

， 为每个图像生成五个  

独立的单句并将他们拼接起来合成

一个段落 。 该模型在单句式图像描述数据集  

ＭＳ －ＣＯＣＯ上训练 。  

２ ）ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ方法使用密集式短语图像描述模型 ＤｅｎｓｅＣａｐ ， 为每个  

图像生成十四个短语并连接起来 。 该模型在ＭＳ －ＣＯＣＯ数据集上的图像

－区域级  

标注样本对上进行训练 。 Ｓｅｎｔｅｎｃｅ －Ｃｏｎｃａｔ和ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ同属于Ｃｏｎｃａｔ类  

方法 。  

３ ）Ｉｍａｇｅ －Ｆｌａｔ（ＲＮＮ ）方法也使用

［ １ １ ］中的模型 ， 与 Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ不同的  

是 ， 在训练时 ， Ｉｍａｇｅ －Ｆｌａｔ（ＲＮＮ ）在斯坦福图像

－段落数据集上进行训练 ， 在推  

理时 ， 直接将输入图像解码为段落 。  

２９  

第三章基于全卷积神经结构的段落解码器  

４）Ｉｍａｇｅ

－Ｆｌａｔ（ＣＮＮ ）方法也直接将图像解码成段落 ， 也在斯坦福图像

－段  

落数据集上训练 ，类似于 Ｉｍａｇｅ －Ｆ ｌａｔ（ＲＮＮ ） 。而与 Ｉｍａｇｅ

－Ｆｌａｔ（ＲＮＮ ）使用单层  

次的ＲＮＮ解码器不同的是 ， 此方法使用单层次的ＣＮＮ作为解码器 。  

５ ）ＤＡＭ方法使用具有深度感知能力的单层次ＲＮＮ解码器生成段落 ， 因此  

该方法属于 Ｉｍａｇｅ

－Ｆｌａｔ（ＲＮＮ ） 方法的变种 。 相比 Ｉｍａｇｅ

－Ｆｌａｔ（ＲＮＮ ） ，ＤＡＭ拥  

一定程度的三维建模能力 。  

６）Ｈ ｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ方法针对段落的结构层次性提出了层次性的ＲＮＮ解码  

器 。该方法为本章重点比较的基线方法 。  

￣Ｓｅｎｔｅｎｃｅ —  

Ｃｏｎｃａｔ  

Ｃｏｎｃａｔ类 ）

Ｓｅｎｔｅｎｃｅ

Ｃｏｎｃａｔ  

Ｉｍａｇｅ －  

Ｆ ｌａｔ（ＲＮＮ ）  

ｆ本节对比的＾ｙ／  ＼ ￣—  

ｖｊＥｍＪ＜（― 类 ）ｆＳ

ｎ ）  

ＤＡＭ  

（ Ｈ ｉｅｒａｒｃｈｙ类

）Ｊ Ｈ ｉｅｒａｒｃｈ ｉｃａ ｌ   ＾ ＾ Ｉ

－ＲＮＮ  

－５ 基线方法分类示意图  

以上六个方法可分为三类 ， 如图 ３

－５所示 ， 第

一类是Ｃｏｎｃａｔ类方法 ， 包含  

Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ和ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ ， 此类方法的特点是将句子级图像描述模型  

迁移到段落式图像描述任务上 ，通过将多个句子或短语拼接形成段落 。第二类是  

－Ｆ ｌａｔ方法 ， 包含Ｉｍａｇｅ

－Ｆｌａｔ（ＲＮＮ ） 、 Ｉｍａｇｅ

－Ｆｌａｔ（ＣＮＮ ）和ＤＡＭ ， 此类方  

法通过单层次的ＲＮＮ或ＣＮＮ解码器为图像生成段落 。 第三类方法是Ｈ ｉｅｒａｒｃｈｙ  

方法 ， 包含Ｈ ｉｅｍｒｃｈｉｃａｌ －ＲＮＮ ， 此类方法通过层次性的解码器生成段落 。  

３ ．３．３评测指标对比与分析  

本小节通过ＢＬＥＵ

－ １ 、 ＢＬＥＵ

－２ 、 ＢＬＥＵ －３ 、 ＢＬＥＵ －４和 ＣＩＤＥｒ五个指标对所  

提方法和基线方法的性能进行评测 。 表 ３ － １所示为评测指标结果 。  

为了表明机器合成的段落和人类自然描述的段落的差异 ， Ｋｒａｕｓｅ等人

［３（） ］从  

－段落数据集随机抽取了５００张图像让参与实验者对其进行段落式描  

述 ， 并对参与者的描述进行评测 ， 得到了人类表现的评测结果 ， 在表 ３ －１的最后  

３０  

第三章 基于全卷积神经结构的段落解码器  

表 ３ － １ 模型评测结果对比  

模型ＣＩＤＥｒＢＬＥＵ －１ＢＬＥＵ －２ＢＬＥＵ －３ＢＬＥＵ －４  

Ｓｅｎｔｅｎｃｅ －Ｃｏｎｃａｔ６ ．８３ １ ． １１５ ． １７ ．６４ ．０  

ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ１２ ．５３３ ．２１７ ．０８ ．５４ ．５  

Ｉｍａｇｅ －Ｆｌａｔ（ＲＮＮ ） １ １ ． １３４ ．０２０ ．０１２ ．２７ ．７  

Ｉｍａｇｅ －Ｆ ｌａｔ（ＣＮＮ ） １５ ．２３５ ．０１９ ．４１０ ．７５ ．９  

ＤＡＭ １７ ．３３５ ．０２０ ．２１ １ ．７６ ．６  

Ｈｉｅｒａｒｃｈ ｉｃａｌ

－ＲＮＮ１３ ．５４ １ ．９２４ ． １１４ ．２８ ．７  

全卷积解码器 １５ ．９４ １ ．３２３ ．９ １４ ． １８ ．２  

人类２８ ．６４２ ．９２５ ．７１５ ．６９ ．７  

一行展示 。 可以看出 ， 在四个 ｂｌｅｕ指标上 ， 机器表现和人类表现较为接近 ，  

表现最好的基线方法Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ在ＢＬＥＵ － １ 、 ＢＬＥＵ －２ 、 ＢＬＥＵ －３ 、 ＢＬＥＵ

－４  

上的得分分别比人类表现只低 １ ．０ 、 １ ．６ 、 １ ．４ 、 １ ．０ 。 但这并不能说明机器生成的  

段落己经接近于人类的描述 ，因为ＢＬＥＵ －ｎ计算的是 ＩＩ元语法重合度 ，无法衡量  

诸如语法正确性 、语言连贯性 、 语义等因素 。 再观 ＣＩＤＥｒ指标得分 ， 人类得分  

２８ ．６远超表现最好的Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ的 １３ ．５ ， 多出 １ １ １ ．８５％ ， 而ＣＩＤＥｒ更能衡  

量机器描述的类人程度 。因此得出两个推论 ，

一是机器生成段落

■ 的效果还远未达  

到接近于人类的性能 ， 二是相比于ＢＬＥＵ ， ＣＩＤＥｒ指标可以更有说服力地衡量模  

型的性能和生成段落的质量 。  

在所有方法中 ， Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ方法的效果最差 ， ＣＩＤＥｒ和ＢＬＥＵ的得分都  

是最低 ，ＱＤＥｒ得分仅为６ ．８ ，比Ｃ ＩＤＥｒ第二低的Ｉｍａｇｅ

－Ｆｌａｔ（ＲＮＮ ）低３８ ．７４％ ，  

这充分说明将多个独立的单句不足以形成

一个段落 。原因

一是段落中的每句话要  

从不同角度来描述图像 ， 而 Ｓｅｎｔｅｎｃｅ －Ｃｏｎｃａｔ生成的多个单句重复度太高 ， 原因  

二是段落中的句子间需要有上下文连贯性 ， 而 Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ生成的单句之间  

显然没有连贯性的约束 。以上同时也证明了段落式图像描述任务和句子级图像描  

述任务的显著差异 。 ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ方法的效果稍好于 Ｓｅｎｔｅｎｃｅ －Ｃｏｎｃａｔ ， 取得  

了１２ ．５的ＣＩＤＥｒ得分 ， 但四个ＢＬＥＵ得分为除 Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ外的最低值 。 相  

比 Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ ，ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ生成的多个短语能够更细颗粒度地描述图  

像 ， 使图像和描述之间的语义对齐度更高 ，但这种方法同样没有监督上下文的连  

贯性 。 以上两个 Ｃｏｎｃａｔ类方法都缺少连贯性的建模 ， 并且未在段落数据集上训  

练 ， 因此性能较差 。  

３ １  

第三章 基于全卷积神经结构的段落解码器  

针对Ｉｍａｇｅ

－Ｆｌａｔ类方法 ， Ｉｍａｇｅ

－Ｆ ｌａｔ（ＣＮＮ）的ＣＩＤＥｒ得分比Ｉｍａｇｅ

－Ｆｌａｔ（ＲＮＮ ）  

高出 ３６ ．９４％ ，

一定程度上说明了卷积结构用于图像描述任务的优势 。 本章所提  

出的全卷积段落解码器在ＣＩＤＥｒ指标得分比 Ｉｎｉａｇｅ －Ｆ ｌａｔ（ＲＮＮ） 、 Ｉｍａｇｅ

－Ｆｌａｔ（ＣＮＮ ）  

高出４３ ．２％ 、 ４ ．６％ ，在ＢＬＥＵ

－ １上高出２１ ．４７％ 、 １８％ ，在ＢＬＥＵ

－２上高出１９ ．５％ 、  

２３ ．２０％ ，在ＢＬＥＵ

－３上高出１５ ．５７％ 、３ １ ．７８％ ，在ＢＬＥＵ

－４上高出６ ．４９％ 、 ３８ ．９８％ 。  

这证明了我们模型的有效性 ，也表明了层次结构相比于 Ｉｍａｇｅ －Ｆｌａｔ类的单层次方  

 ｊ     

－２ Ｉ  

４５ ＢＬＥＵ

－ １ ｜  

３Ｑ  

２５  

５ １０１５２０２５３０３５４〇  

｜ 一ＢＬＥＩＭ  

１４ ｊＢＬＥＵ

ｉ １〇＾  

５ １０ １５２０２５３０３５４０   鷀轮次  

１ ■— ■

２５  

２０  

１   班气  

？５／ ＾ＶＶ＾ＡＡｓ／＼ ＿Ａ＾ｙ ｓ  

５ １０１５２０２５３０３５４〇  

调琢轮次  

图 ３ －６评测指标随训练轮次变化曲线  

３２  

第三章 基于全卷积神经结构的段落解码器  

法的优越性 。  

相比于Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ方法 ， 所提方法将ＣＩＤＥｒ从 １３ ．５提升至 １５ ．９ ， 在  

ＢＬＥＵ得分上也取得了与Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ接近的结果 。在同样使用层次性解码  

器的情况下 ， 以上结果体现了卷积结构的独特优势 ， ＣＩＤＥｒ值的提升说明全卷积  

解码器能够生成更高质量 、 更类人的段落描述 。  

我们还考察了在训练过程中各个指标的变化曲线图 ，如图 ３ －６所示 。 结果显  

示 ， 在第五至第十五轮次间指标逐渐上升 ， 之后有

一定的过拟合趋势 。  

在接下来的实验中 ， 我们将通过连贯性评测 、训练时间评测 、段落定性分析  

一步证明该结论 。 在与基线方法的对比中 ， 将重点关注和  

Ｈ ｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ方法的对比 。  

３．３ ．４连贯性指标对比与分析  

由于段落连贯性的评价是

一项相当主观的工作 ，因而将段落的连贯性进行量  

化极具挑战性 ， 且尚无权威方法 。

｜３５ ］通过 ３０名参与实验者为段落的连贯性打分

的方式 ，对不同模型生成的段落进行量化并对比 。 在本节 ，我们提出

一种简单且  

直观的衡量段落连贯性的方法 ， 以进

一步验证所提模型的优势 。  

我们引入语言学中指代 （Ａｎａｐｈｏｒａ ， 也可称复指 ） 的概念 。 Ａｎａｐｈｏｒａ 表示  

文本中向后引用的行为 ， 即下文词 （组 ）返指上文词 （组 ） 。 下文词 （组 ） 被称  

为Ａｎａｐｈｏｒ ， 被引用的上文词 （组 ）称为Ａｎｔｅｃｅｄｅｎｔ。例如 ，在两个句子

“ Ｔｈｉｓｂｏｙ  

ｉｓＣｈｒｉｓ ．ＨｅｉｓｍｙｂｅｓｔＦｒｉｅｎｄ ．

” 中 ，第二句话中的

“ Ｔｈｉｓｂｏｙ

一次Ａｎａｐｈｏｒａ的出现 ，

“ Ｔｈｉｓｂｏｙ

” 即为Ａｎｔｅｃｅｄｅｎｔ ，

” 即为Ａｎａｐｈｏｒ 。  

在语言学中 ， Ａｎａｐｈｏｒａ是反映段落连贯性的重要概念 ， 因为它在句子层面将不  

同的句法元素结合在

一起 。 因此 ， 接下来通过对Ａｎａｐｈｏｒａ相关现象进行统计 ，  

来对比不同模型生成段落的连贯性 。  

我们对每两个相邻的句子之间发生的Ａｎａｐｈｏｒａ次数进行统计 。 对于

一个包  

含五句话的段落 ，共有四对相邻句子 。在统计中 ， 前

一句话中的Ａｎｔｅｃｅｄｅｎｔ定义  

“ Ａ （ａ）

、 “ Ａ（ａ）ｎ

一个名词或名词词组 ， 例如

“Ａ （ａ）ｈａｐｐｙｂｏｙ

“ Ａ （ａ）ｎ ｉｍａｇｅ

一句话中的Ａｎａｐｈｏｒ包含两种 ： １ ）定冠词后接前

一句话中出  

现的Ａｎｔｅｃｅｄｅｎｔ ， 例如

“ Ｔ （ ｔ ）ｈｅｂｏｙ

“ Ｔ （ｈ）ｈｅｉｍａｇｅ

；２ ） 当Ａｎｔｅｃｅｄｅｎｔ为有性  

别的名词时 ， 和Ａｎｔ ｅｃｅｄｅｎｔ性别

一致的单数人称代词 ， 例如

“ Ｈ （ｈ ）ｅ ”

“ Ｈ（ｈ ） ｉｓ ”  

也可作为Ａｎａｐｈｏｒ。 以下进行举例阐明统计思路和方法 。  

一个句子 ：

“ Ｔｈｅｒｅｉｓａｈａｐｐｙｂｏｙ

，从该句中可提取出

一个Ａｎｔｅｃｅｄｅｎｔ ：  

ａｈａｐｐｙｂｏｙ

， 那么在该句话的下

一句话中 ，

Ｔ（ｔ）ｈｅｈａｐｐｙｂｏｙ

Ｔ （ ｔ ）ｈｅｂｏｙ

都可作为Ａｎａｐｈｏｒ。此外 ，由于

一个男性名词 ，

“ Ｈ（ｈ ）ｅ ”

、 “ Ｈ （ｈ ） ｉｓ ”

“ Ｈ（ｈ ） ｉｍ

３３  

第三章 基于全卷积神经结构的段落解码器  

Ａｍａｎ ｉｓｒ ｉｄ ｉｎｇｈ ｉｓｓｕｒｆｂｏａｒｄｏｎｔｈｅｗａｔｅｒ．  

丨Ｈｅ ｉｓ ｒ ｉｄ ｉｎｇ ａｗａｖｅ ．  

Ｔｈｅｗａｔｅｒｈａｓｓｍａ ｌ ｌｗａｖｅｓ ．  

：Ｔｈｅｓｕｒｆｂｏａｒｄ ｉｓｗｈ ｉｔｅｗ ｉｔｈａｂ ｌａｃｋｄｅｓ ｉｇｎｏｎｉｔ ．  

＾ ？ Ｔｈｅｒｅｉｓａｓｈａｄｏｗｏｆｔｈｅｍａｎｏｎｔｈｅｓｕｒｆｂｏａｒｄ ．  

； Ｔｈｅｗａｔｅｒ ｉｓａｇ ｒｅｅｎ ｉｓｈｃｏ ｌｏｒ ．  

論 Ａｔｒａ ｉｎ ｉｓｏｎｔｈｅｔｒａ ｉｎｔｒａｃｋｓ ．  

Ｔｈｅｔｒａ ｉｎ ｉｓｂ ｌａｃｋａｎｄｗｈ ｉｔｅ ．  

Ｔｈｅｔｒａ ｉｎｈａｓａｎｕｍｂｅｒｏｎｔｈｅｆｒｏｎｔｏｆｉｔ ．  

Ｔｈｅｒｅ ｉｓａ ｌａｒｇｅｍｅｔａ ｌｂｕ ｉ ｌｄ ｉｎｇｏｎｔｈｅｏｔｈｅｒｓ ｉｄｅ  

ｏｆｔｈｅｔｒａ ｉｎｎｅａｒｔｈｅｔｒａ ｉｎ ．  

」 Ｔｈｅｒｅａｒｅｍａｎｙ ｔｒｅｅｓｏｎｔｈｅｓ ｉｄｅｏｆｔｈｅｔｒａ ｉｎ ．  

图３ －７Ａｎｔｅｃｅｄｅｎｔ和Ａｎａｐｈｏｒ举例  

－２Ａｎｔｅｃｅｄｅｎｔ和Ａｎａｐｈｏｒ对照关系  

ＡｎｔｅｃｅｄｅｎｔＡｎａｐｈｏｒ  

Ａ （ａ ）或Ａ （ａ）ｎ＋名词 １ ．Ｔ （ ｔ ）ｈｅ＋对应名词  

１ ．Ｔ （ ｔ ）ｈｅ＋对应名词 、   Ａ （ａ）或Ａ（ａ）ｎ＋形谷词＋名词甘，—   ２ ．Ｔ （ｔ）ｈｅ＋形容词＋对应名词  

ｒ ｏ ｔ ｌ＾、 １ ．Ｔ （ ｔ ）ｈｅ＋对应名词 、   Ａ⑷或Ａ （ａ）ｎ＋ 男性名词 （如ｍａｎ ，ｂｏｙ）  

２ ．Ｈ （ｈ ）ｅ 、 Ｈ （ｈ ） ｉｓ 、 Ｈ （ｈ ） ｉｍ  

Ａ（ａ）或Ａ（ａ ）ｎ＋ 女性名词 （如ｗｏｍａｎ ，ｌ ．Ｔ⑴ｈｅ＋对应名词 、  

ｇ ｉｒｌ）２ ．Ｓ （ｓ）ｈｅ 、 Ｈ （ｈ ）ｅｒ  

也是合法的Ａｎａｐｈｏｒ 。 表 ３ －２列举了几种Ａｎｔｅｃｅｄｅｎｔ和对应的Ａｎａｐｈｏｒ 。 以下介  

绍统计步骤和统计的内容 。  

一个包含ｗ个句子的段落 ， 则其中共有 ｗ

－ １个相邻的句子对 。 首先计  

一个句子外的 Ａｎｔｅｃｅｄｅｎｔ总数量 ， 记为Ｃａｔｃ 。 接下来统计成功出现  

Ａｎａｐｈｏｒａ的总次数 ， 记为Ｃａｎｐ 。 那么得到平均Ａｎｔｅｃｅｄｅｎｔ和平均Ａｎａｐｈｏｒａ ：  

ＡＶＧａｔｃ ＝Ｃａｔｃ／（ｒｎ － １）（３

— ２３）  

＾＾ａｎｐ ＝＾ａｎｐ／（ ．ｍ

￣ １）（３

— ２４）  

最后计算平均Ａｎａｐｈｏｒａ率 ， 假设在 ｍ

－ １个句子对中 ， Ａｎｔｅｃｅｄｅｎｔ个数分别  

为ａｔｑ ，ａｔｃ ２ ， … ， ，成功出现Ａｎａｐｈｏｒａ的次数分别为ａｎｐｉ ，ａｎｐ２ ， … ， ，  

则该段落中的平均Ａｎａｐｈｏｒａ率为 ：  

ａｔｃ ｉ）   Ｒａｔｅａｎｐ ＝＾ １

－ １Ｐｌ／ ￣￣－（３ － ２５）   ＾７７１ — １  

３４  

第三章 基于全卷积神经结构的段落解码器  

表 ３ －３平均Ａｎｔｅｃｅｄｅｎｔ、 平均Ａｎａｐｈｏｒａ和平均Ａｎａｐｈｏｒａ率对比  

平均平均平均   模型 ＆   ＡｎｔｅｃｅｄｅｎｔＡｎａｐｈｏｒａＡｎａｐｈｏｒａ率（％）  

Ｈ ｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ０ ．８９０ ．０９６ ．３  

全卷积解码器０ ．９２０ ． １３８ ．４  

人类０ ．９００ ． １８ １ １ ．４  

最后在整个数据集的段落上求平均 ， 得到两种模型在数据集上的平均  

Ａｎｔｅｃｅｄｅｎｔ、平均Ａｎａｐｈｏｒａ和平均Ａｎａｐｈｏｒａ率 ， 同时计算了数据集的标签段落  

的这三个统计量 ， 作为人类表现 。 结果如表 ３ －３所示 。  

由表 ３ －３可看出 ，在人类和两种机器模型的平均Ａｎｔｅｃｅｄｅｎｔ相差不大的前提  

下 ， 人类的平均Ａｎａｐｈｏｒａ和平均Ａｎａｐｈｏｒａ率都要大于两种机器模型 ， 这说明平  

均Ａｎａｐｈｏｒａ和平均Ａｎａｐｈｏｒａ率能够

一定程度上反映出段落的连贯性 。  

全卷积解码器的平均 Ａｎａｐｈｏｒａ 比 Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ 高出 ４４ ．４４％ ， 平均  

Ａｎａｐｈｏｒａ率高出 ３３ ．３３％ ， 这在

一定程度上可说明该解码器生成的段落具有更强  

的连贯性 。  

３．３．５时间复杂度对比与分析  

本章所提出的全卷积解码器的

一大优势是它的两个组 部分 ： 句子ＣＮＮ解  

码器和词 ＣＮＮ解码器都能够被并行训练 。 相比之下 ， 传统的层次＿解码器  

Ｈ ｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ逐个生成段落中的单词 ， 无法并行化 。本小节首先分析训练这  

两种段落解码器的时间复杂度 ，再通过实际实验的训练时间对比来证实我们复杂  

度的分析 。  

虽然不同段落是非等长的 ， 但为分析方便起见 ， 假设段落由ｍ个句子组成 ，  

每个句子有ｎ个单词 ， 特征维度均为ｄ 。对Ｈ ｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ而言 ， 句子ＲＮＮ和  

词 ＲＮＮ每层的复杂度分别为 和Ｃ ＊ （ｍｘｎｘｄ ２

） 。对全卷积段落解码器 ，  

假设句子ＣＮＮ解码器和词ＣＮＮ解码器的卷积核大小均为ｆ ｃ ， ｒ

？是词ＣＮＮ中卷积  

层的个数 。 则句子 ＣＮＮ 和词 ＣＮＮ 的每层复杂度分别为 （Ｐ（ｆ ｃｘｍｘｄ ２

）和  

０（ｆ ｃｘｍｘｎｘｄ ２

） 。 传统的 ＲＮＮ解码器

一次只能生成

一个单词或句子的主题 ， 因  

此句子 ＲＮＮ和词 ＣＮＮ分别需要０（ｍ ）和ｆ？（ｍｘｎ）的顺序操作 。与此相比 ， 全卷  

积段落解码器中 ， 句子ＣＮＮ和词ＣＮＮ分别只需０ （１）和 的顺序操作 。  

结合每层的复杂度和顺序操作复杂度 ， 句子 ＲＮＮ 的总时间复杂度为  

０（ｍ ２ｘｄ ２

） ， 词ＲＮＮ的总时间复杂度为０（ｍ

２ｘｎ ２ｘｄ ２

， 那么Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ  

总时间复杂度也为〇 （ｍ ２ｘｎ

） 。 句子ＣＮＮ的总时间复杂度为０（ ／ｃｘｍｘｄ ２

） ，  

３５  

第三章基于全卷积神经结构的段落解码器  

词ＣＮＮ的总时间复杂度为ＣＪ （ｆ ｃｘｒｘｍｘｎｘｄ ２

） ， 那么全卷积段落解码器的总时间  

复杂度为０（ｆ ｃｘｒｘｍｘｎｘｄ ２

） 。由于ｆ ｃｘｒ＜ｍｘｎ ，因此与Ｈ ｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ相比 ，  

我们提出的全卷积段落解码器具有更低的训练时间复杂度 。  

一步验证我们模型的训练效率 ，首先对比两种模型训练

一个轮次所分  

别花费的时间 ，然后对比两种模型的收敛时间 。表 ３ －４展示了两种模型训练

一个  

轮次花费的时间 。所提模型比Ｈ ｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ需要更少的轮次训练时间 ， 仅为  

Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ所需时间的 ３４ ．２０％ 。并且 ，所提模型具有更大规模的参数 ，为  

Ｈ ｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ的 ４ ． １４倍 ， 这意味着全卷积段落解码器具有更强的学习能力 。  

所提模型和Ｈｉｅｒａｒｃｈ ｉｃａｌ

－ＲＮＮ每单位参数需要的训练时间分别为２５ ．５７ｓ和 ２ ．００ｓ 。  

－８记录了两个模型的 ＣＩＤＥｒ得分与训练时间的关系 ， 并以 ＣＩＤＥｒ值的  

收敛作为训练达到收敛的标准 。 由图可看出 ， 所提模型训练收敛大约需要 ８００  

秒 ， 而Ｈ ｉｅｒａｒ ｃｈｉｃａｌ －ＲＮＮ大约需要 ３６００秒 。  

综上可以得出结论 ，相较于传统方法 ，所提出的全卷积段落解码器在具有更  

大参数的同时 ， 训练的理论时间复杂度和实际时间消耗都更少 。  

３ ．３ ．６生成段落定性分析  

我们随机挑选测试集中的若干张图片 ，并将标签段落和两种模型生成的段落  

进行对比 ， 如图 ３ －９所示 。  

表 ３ －４ 参数规模和单Ｅｐｏｃｈ训练时间对比  

每单位参数训练时   模型参数量 （Ｍ ）训练时间 （ｓ）   间 （ｓ／Ｍ ）  

Ｈ ｉｅｒａｒｃｈ ｉｃａｌ －ＲＮＮ７ １７９２５ ．５７  

全卷积解码器２９５８２ ．００  

， ， ，

■ － — ．  

Ａ ＊Ｏｕｒｍｏｄｅ ｌ  

＊Ｈｉｅｒａｃｈｉｃａｌ

－ＲＮＮ  

０５００ １０００ １ ５００２０００２５００３０？０３５００４０００４５００  

Ｔｒａ ｉｎ ｉｎｇ Ｔｉｍｅ

（ｓ）  

图 ３ －８ＣＩＤＥｒ值随训练时间和轮次的变化  

３６  

第三章 基于全卷积神经结构的段落解码器    Ｏｕｒｍｏｄｅｌ

ｗ＾電： Ｔｈ ｉｓ ｔｓａ ｐ

ｉｃｔｕｒｅｏｆａｎａｎｃｉｅｎｔｃ ｉｔｙ

．Ｔｈｅ ｒｅ ｉｓａｂｕｓ ｏｎ  ｔｈｅｓｔ ｒｅｅ ｔ ． Ｔｈｅｂｕｓ ｉｓ ａ ｄｏ ｉＡ ｌｅｄｅｃｋｅｒ ｂｕｓ ．   一 Ｔｈｅｒｅ ｉｓ ａ ｌａ ｒｇｅｂｕ ｉ ｌｄ ｉｎｇｂｅｈ ｉｎｄ ｔｈｅｂｕｓ ． Ｔｈｅｒｅ ｉｓ ａ ｌａｄｙｓｔａｎｄ ｉｎｇ ｏｎ ｔｈｅｓ ｉｄｅｗａ ｌｋ ．Ｔｈｅ ｒｅ  ｉｓ ａ  

；览 ％

ｌａ ｒｇｅｔｒｅｅ ｔ ｒｕｎｋ ｔｏｔｈｅｒｉｇｈｔ ｏｆ ｔｈｅｂｕｓ ．   ＾Ｈ ｉｅｒａｒｃｈ ｉｃａ ｌ

－ＲＮＮ ：   露Ａ ＾Ｔｈｅｒｅ ｉｓａ ｄｏｕｂ ｌｅｄｅｃｋｅ ｒ ｂｕｓ ｄｒ ｉｖｉｎｇｏｎ  ｔｈｅｓｔｒｅｅｔ Ｔｈｅｂｕｓ ｉｓ ｒｅｄ ｉｎｃｏ ｌｏｒ ． Ｔｈｅ ｒｅ ｉｓａｂｕｓ ｏｎ  

ｔｈｅｒｏａｄ ． Ｔｈｅ ｒｅ ｉｓａ ｌａｒｇｅ ｗｈ ｉｔｅｂｕ ｉ ｌｄ ｉｎｇ ｂｅｈ ｉｎｄ ｔｈｅｂｕｓ ．Ｔｈｅｒｅ ｉｓ ａｍａｎ ｉｎ ａ ｂ ｌｕｅｓｈ ｉ ｒｔ ｓ ｔａｎｄ ｉｎｇ  

■ｊ Ｍ＾

＇ ｉｎ ｆｒｏｎｔｏ！  ｔｈｅｂｕｓ ．Ｔｈｅｒｅ ｉｓ ａｍａｎ ｉｎ ａｂ ｌｕｅｓｈ ｉ ｒｔｓ ｔａｎｄ ｉｎｇ

ｉｎ  Ｉｒｏｎ！ ｏｆ Ｉｈｅｂｕｓ ．   辭為Ｎ

：遽 条翔｜ ＧｒｏｕｎｄＴｒｕｔｈ ：  

ＴＮｓ ｐ

ｉｃ ｔｕｒｅ ｉｓ  ｔａｋｅｎ ｏｕｔｓ

ｉｄｅ ｏｎａｃ ｌｏｕｄｙ ｄａｙ

．Ａ ｇ ｒｏｕｐｏ ｆ ｐｅｏｐ

ｌｅ ｉｓ ｗａ ｌｋ ｉｎｇ ｏｎ ａｓ ｉｄｅｗａ ｌｋ Ｔｈｅ  

ｓ ｉｄｅｗａ ｌｋ？ｍａｄｅ ｆ ｒｏｍｓｔｏｎｅｓ Ｔｗｏ ｔａ ｌ ｌ ｔ ｒｅｅｓａ ｒｅ ｌｅａｎ ｉｎｇｏｎ Ｉｈｅ ｓ ｉｄｅｗａ ｌｋ Ｏｎｅ ｍａｎｏｎ ｔｈｅ  

ｓ ｉｄｅｗａ ｌｋ ｉｓ ｗｅａ ｒ ｉｎｇａｂ ｌｕｅｂａｃｋｐａｃｋ ｏｎｈ ｉｓ ｂａｃｋ Ｔｈｅ ｒｅ ｒｓａｄｏｕｂｌｅ ｄｅｃｋｅ ｒｒｅｄｂｕｓｐａ ｒｋｅｄ ｏｎ  

ａｒｏａｄｎｅａ ｒ  ｔｈｅｓ ｉｄｅｗａ ｌｋ ．Ｌａ ｒｇｅｔａ ｌ ｌｗｈ ｉ ｔｅｂｕ ｉ ｌｄ ｉｎｇｓ ｃａｎｂｅｓｅｅｎ ａｃｒｏｓｓｔｈｅ ｓｔ ｒｅｅｔ ｆｒｏｍ  ｔｈｅｂｕｓ ．  

Ｏｕｒｍｃｘｔ ｅ．

Ａ ｗｏｍａｎ Ｉｓ ｓ ｌａ ｒｘｌ ｉｎｇ ｏｎ ａ ｔｅｎｎｉｓ ｃｏｕ ｒｔ ｏｎａｓｕｎｎｙ ｄａｙ

．Ｓｈｅ ｉｓ ｗｅａｒ ｉｎｇａｗｈ ｉｔｅ ｖｉｓｏｒ ，ａｗｈ ｉｔｅ  

ｓｈｏｒｔｓ ｌｅｅｖｅ ｓｈ ｉ ｒｔ ，ａｎｄａｂ ｌａｃｋｓｋ ｉｒｔ Ｓｈｅ ｉｓｈｏ ｌｄ ｉｎｇ ａｂ ｌａｃｋａｎｄｗｈ ｉ ｔｅ ｔｅｎｎ ｉｓｒａｃｋｅ ｔ ．Ｔｈｅ ｔｅｎｎ ｉｓ  

ｃｏｕ ｒｔ ｉｓｂｒｏｗｎｗｔｔｈａ ｉｄｅｎｔ ｉｃａ ｌ ｗｈｔｅＨｎｅ ．  

ＪＨ ｉｅｒａｒｃｈ ｉｃａ卜ＲＮＮ

ｒ Ａｗｏｍａｎ  ｉｓ

ｔｅｎｎ ｉｓ ．Ｓｈｅ ｉｓ ｗｅａｒ ｉｎｇａｒｅｄｖ ｉｓｏｒ ．Ｓｈｅ Ｉｓ ｗｅａｒ ｉｎｇａｗｈ ｉ ｔｅｖｉｓｏｒ

，ａｗｈｒ ｔｅ  

ｓｈｏｒｔｓ ｌｅｅｖｅｓｈ ｉｒｔａｎｄ ｂｌｕｅｓｈｏｒ ｔｓ ．Ｓｈｅｈａｓ ｂ ｌａｃｋｈａ ｉｒ Ｔｈｅｗｏｍａｎ ｂｅｈ ｉｎｄｈｅｒ  ｉｓ ｗｅａｒ ｉｎｇａｒｅｄ  

＂ｆ ｌＺ

ｓｈ ｉｒ ｔａｒｔｄａ ｌ ｉｇｈｔ ｂｒｏｗｎｈａ ｌ ．  

＇ ＧｒｏｕｎｄＴｒｕｔｈ ：  

Ａ ｗｏｍａｎ Ｉｎ ａ ｗｈ ｉｔｅｓｈ ｉ ｒｔ ａｎｄａｂ ｌａｃｋｓｋ ｉｒ ｔ ｉｓｓ ｔａｎｄ ｉｎｇ ｏｎ ａｒｅｄ  Ｉａｎｎ ｉｓ ｃｏｕｒｔ ．Ｔｈｅｗｏｍａｎ  ｉｓ  

ｗｅａｎｎｇａｖｖｈ ｉｔｅｖｉｓｏｒ ．Ｔｈｅｗｏｍａｎ ｉｓｓｗｉｎｇ

ｉｎｇａｒｅｄ  ｔｅｎｎｉｓｒａｃｋｅｔ ．   ｍ，ｔ＾  

Ｏｕｒｍｏｄｅｌ

■■■ ＿ ＿一 ＿

ｌＴｈｅ ｒｅ ｉｓａｗｈ ｉ ｔｅｐ

ｌａ ｌｅｏｎ ｔｏｐｏｌａ ｔａｂ ｌｅ Ｔｈｅ ｐ

ｉｚ２ａ ｉｓ ｏｎ ａｗｈ ｉ ｔｅ

ｌａ ｔｅ Ｔｈｅ ｐ

ｉｚｚａ ｏｎ ｔｈｅ ｐ

ｌａ ｔｅ   ＾１ ｈａｓ ｍｕｓｈｒｏｏｍｓ ｏｎ ｉｔ ．Ｔｈｅ ｒｅ ｔｓ ａ ｇ

ｌａｓｓｏ ｌｗａ ｔｅｒｎｅａ ｒ  Ｉｈｅ ｐ

ｌａ ｔｅ ｏｎ  ｔｈｅ ｌｅ ｆｔｓ ｉｄｅ Ｔｈｅ ｒｅｔ ｅａ ｇ

ｌａｓｓ   ＾ｏｎ  Ｉｈｅ ｔａｂ ｌｅｎｅｘｔ ｔｏ Ｉｈｅ ｐｔ ｅｔｅ Ｔｈｅ ｐ ｌａ ｔｅ ｉｓ ｏｎ ａｗｈｒ ｔｅ ｔａｂｌｅ ．  

ｌａ ｌｅｏ ｌ ｌｏｏｄ ｉｓ ｏｎａｗｏｏｄｅｎ ｔａｂ ｌｅＴｈｅ ｐ

ｌａ ｔｅ ｉｓｗｈ ｉ ｌｅ ａｎｄｒｏｕｎｄａｎｄｆ ？ａｓｂ ｌａｃｋｗｉｎｅａ ｒｏｕｎｄ  

Ｈ Ｔｈｅ ｐ

ｌａ ｌｅ ｉｓ ｏｎａｗｏｏｄｅｎ ｔａｂ ｌｅＴｈｅ ｒｅ ａ ｒｅ ｔｗｏ ｇ

ｌａｓｓｅｓｏｎＩｈｅ ｔａｂｔ ｅ ｎｅｘｔ ｔｏ Ｉｈｅ

ｌａ ｔｅｓＴｈｅ ｒｅ  

ｉｓ ａ ｌｓｏａｂｏ ｔ ｔ ｌｅｏ ｌｗ？ ｒ＞ｅ Ｔｈｅ ｓｋｙ ａｂｏｖｅ  ＩｈｅＰｅ ｌｄｈａｓｗｈ ｉｌｅ ｃｌｏｕｄｓ  ｉｎ  ＩＩ ．  

ＧｒｏｕｎｄＴｒｕｔｈ ：  

Ｔｈｅ ｒｅ ｉｓａ ｐ

ｌａ ｌｅ ｓ ｉｔ ｔ ｉｎｇｏｎ  ｌｏｐ ｏｌａｗｈ ｉｌｅ ｔａｂ ｌｅ ．Ｔｈｅｒｅ  ｉｓ ａ ｐ

ｉｚｚａｏｎ  ｌｏｐ ｏｆ Ｉｈｅ ｐ

ｌａ ｔｅＴｈｅｒｅ ？ｓ   Ｗ ． ， ？ １ｇ

ｒｅｅｎ ｌｅａｖｅｓ ｏｎ  ｔｏｐｏ ｌ ｔｈｅ ｐ

ｉｚｚａ ．Ｔｈｅｒｅ ｉｓ ａｓ ｉ ｌｖｅ ｒ ｆｏｒｋ ａｎｄａｓ ｉ ｌｖｅ ｒ ｋｎ ｉ ｌｅｏｎ ｔｏｐ ｏ ｌ  Ｉｈｅ ｐ ＞ｉ２７ａ   Ｍｎｅｘｌ  ｔｏ ｔｈｅ ｐ

ｌａ ｌｅ Ｔ ｆｉｅｒｅａ ｒｅ ｔｗｏ

ｌａｓｓｅｓ ｏｎ  ｔｈｅ ｔａｂ ｌｅｂｅｈ ｉｎｄｔｈｅ ｐ

ｌａ ｌｅ ． Ｔｈｅｒｅ ｉｓ ａ ｓ ｌ ｉｃｅｍ ｉｓｓ ｉｎｇ   ？ ． ． ｆｒｏｍ  ｔｈｅ ｐ

ｉｚ２ａ ．  

匿Ｏｕ ｒｍｏｄｅｌ

ｌａｎｅ ｉｓｏｎ  ｔｈｅｒｕｎｗａｙ Ｔｈｅ

ｌａｎｅ ｉｓ ｗｈ ｉ ｌｅａｎｄｒｅｄＴｈｅ  ｔａ ｉ ｌｏ ｌ Ｉｈｅ ｐ

ｌａｎｅ ｉｓ ｒｅｄ ｗｉ ｔｈｗｈ ｉ ｌｅ  

ｗｒ ｉｔ ｉｎｇＴｈｅ ｒｅ ｉｓ ｌａ ｒｇｅ ｌｏｇｏ ｏｎ ｔｈｅ ｆ ｒｏｎｔｏ ｌ ｔｈｅａ ｉ ｒｐ ｌａｎｅＴｈｅｓｋｙ 

ｉｓ ｃｌｏｕｄ ｌｅｓｓ

Ｔｈｅ ｒｅ ｉｓａ ｌａ ｒｇｅ ａ ｉ ｒｐ

ｌａｎｅ ｏｎ ａ ｒｕｎｗａｙＴｈｅ  ｌａｄｏｆｔｈｅ ｐ ｌａｎｅ ｉｓｒｅ＜１ｗｉｔｈ ｗｈｒ ｔｅｗｒｉｔ ｉｎｇＴｈｅ ｐ

ｌａｎｅ  

‘ … ＾

Ｉｓ ｗｈ ｉ ｔｅｗｉｔｈ ａｂ ｌｕｅｔａ ｉ ｌａｎｄａ ｙｅ ｌ ｌｏｗ

ｌｏｂｅ ｐａ ｉｎ ｔｅｄｏｎ ｌｏｐ ｏｆ？ ．Ｔｈｅ

ｌａｎｅ Ｉｓｗｈ ｉ ｌｅ ａｎｄｈａｓｂ ｌｕｅ  

ｏｎ ｔｈｅ  ｔａ ｉ ｌＴ ｈｅ ｓｋｙ

ｉｓｂ ｌｕｅａｎｄ ｃｌｏｕｄｙ

．Ｔｈｅ ｓｋｙ

ｉｓｂ ｌｕｅｗ ｉｔｈ ｗｈ ｉｔｅ ｃ ｌｏｕｄｓ

Ｇ ｒｏｕｎｄＴｒｕ ｔｈ  

Ａ  ｌａ ｒｇｅｗｈ ｉ ｔｅ ａｎｄ ｒｅｄａ ｉ ｒｐ

ｌａｎｅ Ｉｓｓ ｉｔｔ ｉｎｇ ｏｎ ａｒｕｎｗａｙ

．Ｔｈｅｒｅ Ｉｓｂ ｌｕｅ ｗｒ ｉ ｔ ｉｎｇｏｎ ｔｈｅ ｓ ｉｄｅｏｆｔｈｅ  

＾ ｐ ｌａｎｅ ．Ｔｈｅｒｅ Ｉｓ ａｗｈｒｔｅｂｕ ｉ ｌｄ ｉｎｇｂｅｈ ｉｎｄ ｔｈｅ

ｌａｎｅ ．  

图 ３ －９生成段落的例子  

一幅图 ，全卷积解码器生成的段落在第

一句话中首先介绍了图像中的  

最显著信息 ： 两只长颈鹿 （Ｔｈｅｒｅａｒｅｔｗｏｇ ｉｒａｆｆｅｓ） 。 第二句话至第五句话描述了  

这两只长颈鹿的细节特征 ： 这两只长颈鹿非常高 （Ｔｈｅ ｇ ｉｒａｆｅｓａｒｅｖｅｒｙ ｔａｌ ｌ ） ， 右  

边的长颈鹿直站着往摄像机的方向看着 （Ｔｈｅｇ ｉｒａｆｅｏｎｔｈｅｒｉｇｈｔｉｓｓｔａｎｄ ｉｎｇ  

ｓｔｒａｉｇｈｔｕｐａｎｄｌｏｏｋｉｎｇａｔ ｔｈｅｃａｍｅｒａ ） ， 这只长颈鹿有着长长的角 （Ｔｈｅｇ ｉｒａｆｅｈａｓ  

ｌｏｎｇｈｏｒｎｓ） ， 这只长颈鹿的脖子很长 （Ｔｈｅｇ ｉｒａｆｅｈａｓａｌｏｎｇｎｅｃｋ） 。最后

一句话  

介绍了图像中的非显著内容 ， 长颈鹿左边有

一条路 （Ｔｈｅｒｅ ｉｓ ａｐａｔｈｗａｙ ｔｏ ｔｈｅ ｌｅｆ ｔ  

ｏｆｔｈｅ ｇ ｉｒａｆｆｅ） 。生成的该段落有两个特点 ， 一是该段落呈现出金字塔式的总

－分型  

描述 ，首先概括图像中的内容 ，然后对其中的对象细致地描述 ， 这种描述方式更  

３７  

第三章 基于全卷积神经结构的段落解码器  

贴近人类的认知系统 ； 二是出现的指代合适且正确 。反观Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ生成  

的段落 ，在段落结构上较为混乱 ， 且有多次指代不明确的情况出现 ，例如第三句  

Ｉｔｉｓｃｒｅａｍｗｉｔｈｂｒｏｗｎｓｐｏｔｓ

Ｉｔ ” 指代不明确 ， 且描述准确性不足 。  

３ ．３ ．７卷积层参数探究  

卷积层的深度 、 卷积核大小的设置决定了ＣＮＮ的感受野 ， 对全卷积段落解  

码器的性能至关重要 。 本小节探宄词ＣＮＮ中卷积层的深度和卷积核大小对指标  

得分的影响 。  

当卷积层深度为 １时 ， 卷积核大小取 ５ ， １０ ， １５ ，２０ ，２５ ，３０ ，３５ 。 由于句  

子的最大单词数为 ３０ ， 因此当卷积核大小大于 ３０时 ， 解码器的视野大小才可覆  

盖整个句子 。 在卷积核为 １５时 ， ＣＩＤＥｒ值达到最高 ， 之后随着卷积核的增加 ，  

ＣＩＤＥｒ得分下降 。卷积层深度过小 ， 卷积核大小过大造成性能的下降 。 总体上 ，  

卷积层深度为 １时 ， 模型效果较为

一般 。 当卷积层深度为 ３时 ， 卷积核大小取 ７  

时 ＣＩＤＥｒ值最高 ， 和深度取 １时类似 ， 此时解码器视野大小仍不足以覆盖整个  

句子 。  

当卷积层深度为 ５ 、 ７ 、 ９时 ， 模型分别在卷积核大小取 ７、 ５ 、 ３时达到最佳  

效果 ， 此时解码器视野大小均在 ３０左右 。这说明当取适中的卷积层深度时 ， 通  

过调整卷积核大小使得解码器视野覆盖整个句子是较合适的选择 。  

当卷积层深度为 １ 、 ３ 、 ５ 、 ７ 、 ９时 ， 模型的最高ＣＩＤＥｒ得分如表 ３

－５所示 。  

当深度取 ７ ， 卷积核的大小取 ５时 ， ＣＮＮ的性能最好 。  

－５ＣＩＤＥｒ随卷积层深度变化的最佳值  

卷积层深度ＣＩＤＥｒ值  

１ １４ ．８  

３ １５ ．５  

５ １５ ．７  

７ １５ ．９  

９ １５ ．７  

３ ．３ ．８束大小探究  

对于图像描述任务 ，束大小的设置对实验结果有重要的影响 ，本小节探究不  

同的束大小设置对全卷积段落解码器的评测指标得分影响 。表 ３

－６展示了束大小  

为 １ 、 ２ 、 ３和 ４时 ， 生成段落的评测结果 。 可以看出 ， 当束大小为 １时 ， 由于单  

＇ 词采样的搜索空间过小 ， 丢失了大量解码信息 ，错过了许多较优解 ， 因此生成的  

３８  

第三章 基于全卷积神经结构的段落解码器  

－６评价指标随束大小变化  

束大小ＣＩＤＥｒＢＬＥＵ －１ＢＬＥＵ －２ＢＬＥＵ －３ＢＬＥＵ －４  

１ １４ ．８４０ ．９２３ ． １１３ ．６７ ．７  

２ １５ ．９４ １ ．３２３ ．９１４ ． １８ ．２  

３ １５ ． １４ １ ．５２３ ．７１４ ．０７ ．８  

４ １３ ．７４０ ．４２２ ．３１２ ．８７ ．５  

段落质量不佳 ，指标得分较低 。 当束大小增加到 ２时 ， 单词的搜索空间增大 ， 更  

容易获得较优解 ， 指标得分最高 。而当束大小继续增大到 ３和４时 ，搜索空间的  

一个段落内的句子之间相似度快速增加 ，段落的质量快速下降 ，导致评测  

得分降低 。 并且 ， 过大的束大小会导致解码的时间复杂度显著上升 。综上分析 ，  

束大小取 ２是平衡训练效率和段落质量的较好选择 。  

３．４本章小结  

本章详细介绍了

一种针对段落式图像描述任务的全卷积段落解码器 。首先通  

过 ＣＮＮ解码器和 ＲＮＮ解码器的对比 ， 阐明了本文使用卷积结构的动机 。 接下  

来介绍了全卷积解码器的两个组成部分 ：句子ＣＮＮ 、词ＣＮＮ的详细实现 ， 以及  

该模型的训练与推理过程 ，最后总结出了

一个使用全卷积解码器生成段落的段落  

生成算法 。  

在实验验证部分 ，通过评测指标得分 、连贯性指标得分 、 时间复杂度以及主  

观评价四个方面综合证明了全卷积段落解码器的优势 ，该解码器在四项上的表现  

都超越了基线方法 。在实验部分的最后 ，选取了具有代表性的两种超参数 ： 卷积  

层参数和束大小 ， 通过对比实验确定了参数的设置 。  

３９  

第四章 融合区域注意力的段落式图像描述模型  

第四章融合区域注意力的段落式图像描述模型  

在段落式图像描述任务上 ，对图像编码并解码的过程会损失图像信息 ，导致  

图像与段落的语义相关性较低 、描述颗粒程度较低 、段落内句子重复等问题 。本  

章针对这些问题 ，将图像编码过程中的区域提议网络和解码过程中的区域注意力  

模块结合 ， 并融合到上

一章提出的全卷积段落解码器中 ， 得到

一种新的模型  

－ＣＮＮ 。 Ｄｕａｌ

－ＣＮＮ拥有更强的图像理解能力 ，并结合了全卷积段落解码器的  

优点 ： 训练复杂度低 ， 生成段落连贯性高 。  

本章首先详细介绍了Ｄｕａｌ

＿ＣＮＮ的模型细节 ， 并通过在斯坦福图像

－段落数  

据集上进行实验证明了模型的性能 。在实验部分 ，我们提出了

一种评测段落内句  

子间多样度的手段 ， 并据此证明了注意力机制的作用 。  

４ ．１融合区域注意力的段落式图像描述模型Ｄｕａｌ －ＣＮＮ  

本节首先对Ｄｕａｌ －ＣＮＮ模型整体进行概述 ， 再详细介绍区域提议网络ＲＰＮ ，  

以及融合了区域注意力机制的句子ＣＮＮ 。  

４．１ ．１模型整体描述  

段落式图像描述任务的符号定义沿用 ３ ．２ ． １ 中的符号定义 。 给定输入图像／ ，  

编码器中的区域提议网络ＲＰＮ提议出Ｌ个区域 ， 并通过ＣＮＮ网络将这些区域压  

缩为特征向量 ， 得到区域特征集”＝〇＾ ， １； ２ ， ． ． ． ，以丨 。 接下来 ， 句子£ ＿解码器  

＼Ｇｉ＾４ｓ

… …ｓＭ  

？  、

ｔ Ｔ  

ｔ ｆＢＩＢｌｌｉｉｌｉｌＩＢ！ｉ！ｌｔＢｉｉｉ  

Ｓｅｎ ｔｅｎｃｅ ＣＮＮ Ｔ  

ｇ） Ｃｏｎａｔｉｏｎ ； 丨＼丨 （Ｓｉ丨 Ｊ２丨＆］  

：ＴＫ ｉｆＲＥＧ ＩＯＮＩ ｆ ＲＥＧ ＩＯＮ｜ ｆＲＥＧ ＩＯＮ］［ ＲＥＧ ＩＯＮｌ    ＡＴＴＥＮＴＩＯＮ

ｌ ＼

Ｎ以ＡＴ

［ ＡＴＴＮ｜  

： Ｔｈｅ ｐ

ｌａｎｅ ｉｓ ｐａ ｒｋｅｄ ｏｎ ｔｈｅ ｒｕｎｗａｙ

＾ ｜／＾

ｓｔＭｆ ／７

：＝二＝＝＝￡

＂— ； ？

： Ｔｈｅｒｅ ａ ｒｅｂａｇｇａｇｅ ｃａ ｒｔｓ ａｒｏｕｎｄ ｔｈｅ＾广  ｎ 

ｂｏｔｔｏｍ ｏｆ ｔｈｅ ｐ

ｌａｎｅｓ ． １   ｜ ＾―— １ ！ Ｃｏｎｖｏｌｕｔ ｉｏｎａ ｌＬａｙｅｒ＾  

ＩＳ广 湖—

： －ｒ ＊  

＼／Ｌ Ｉ ｔｔｔｔ  

＜Ｓ ＞Ｓ

，Ｓ ２ ＳＭ ＿ ，  

图 ４ － １Ｄｕａｌ －ＣＮＮ模型图  

４０  

第四章 融合区域注意力的段落式图像描述模型  

中的区域注意力模块作用于区域特征集上 ， 为Ｍ句话生成加权区域特征  

． ． ． ，＜ ？

｝ ， 句子 ＣＮＮ根据每个句子的加权区域特征 ， 生成更富变  

化的多模态语义向量 。词ＣＮＮ解码器在 的指导下生成句子句子矣中的所  

有单词 。 最后将所有句子连接起来得到段落Ｐ 。 Ｄｕａｌ －ＣＮＮ的整体结构图如图 ４ －１  

所示 。  

４．１ ．２区域提议网络  

区域提议网络为给定的图像抽取出若干感兴趣区域 ， 包含 ＶＧＧ 卷积网络 ，  

全卷积定位层 （ＦｕｌｌｙＣｏｎｖｏｌｕｔｉｏｎａｌＬｏｃａｌ ｉｚａｔｉｏｎＬａｙｅｒ）和识别网络 （Ｒｅｃｏｇｎｉｔｉｏｎ  

Ｎｅｔｗｏｒｋ） ， 流程图如 ４

－２所示 。  

所使用的ＶＧＧ网络包含 １３层的３ｘ３卷积层和 ５层的２ｘ２最大池化层 ，最后  

一个池化层被移去 。

一个输入形状为３ＸＶ／ＸＨ的图像 ，输出形状为ＣｘＶＴｘ／Ｔ ，  

其中Ｃ＝５１２ ，Ｗ＝

。 ＶＧＧ网络的输出作为全卷积定位层的输入 。  

定位层包含卷积锚 ，框回归 ， 框采样和双线性插值 。通过卷积锚选出固定数  

量的备选锚框 ， 框回归模块对这些框进行位置的调整 ，得到区域提议 。框采样模  

块从区域提议中选出最终的Ｌ个区域 ， 最后双线性插值模块为区域生成其特征 。  

因此 ， 定位层的输出为区域的若干相关信息 ： １ ． 区域坐标组成的 矩阵 ； ２ ．Ｌ  

个置信分数 ３ ．Ｌ个区域特征组成的ＬｘＣｘＸｘｙ张量 。  

定位层通过回归

一组锚点的偏移量来预测区域提议 。具体地 ，我们将输入区  

域特征的ＶＴｘ／Ｔ网格中的每个点投影回ＷｘＨ空间中 ， 并设置以该投影点为中心  

的ｆ ｃ个不同纵横比的锚框 ， 纵横比包含｛１ ： １ ， １ ： ２ ， ２ ： １｝三种 。 对于每

一个锚框 ， 定      

—？ 特征图

ｎｗ ｜  

； （ 框回归 ）宏

ｉ   输入图像 丨 Ｖ

； （ ）

 ｜  

！ 广 双Ｓ性 、

输出区域 ＾—

ｉｖ ：  

图 ４ －２ 区域提议网络流程图  

４ １  

第四章 融合区域注意力的段落式图像描述模型  

一个置信分数 ， 和四个从锚框到预测框的标量 。 这部分输出为  

５ｆ ｃｘ ｌＴｘ／ｒ的张量 ， 包含置信分数和回归偏移量 。  

得到回归偏移量后 ， 框回归将锚回归到区域的提议 。给定

一个中心点为  

（Ｘｘ ？ｙａ） 、 宽为ｗａ 、 尚为 的锚框 ，模型根据回归偏移量ｄ ｔ ｙ

，ｔｗＡ） ，输出的区  

域中心〇 ，ｙ） 、 宽Ｗ 、 高／ｌ计算方式如下 ：  

ｘ＝ｘａ＋ｔｘｗａ （４

－ １）  

ｙ ＝ ｙａ＋ｉｙＫ （４

－ ２）  

ｗ＝ｗａｅｘｐ（ｔｗ） （４

－ ３）  

ｈ＝ｈａｅｘｐ（ｈｗ）（４ －４）  

框采样模块接下来从备选区域中选出最终的Ｌ＝５０个区域提议 。 例如 ， 当处  

理撕 ＝３６０ ，Ｗ＝２７０的图像 ， 设置ｆ ｃ＝１２时 ， 会产生 ４３２０个区域提议 。 因为为  

所有区域提议产生描述会产生大量冗余 ，并消耗过多计算量 ， 因此 ， 需要对这些  

区域提议进行采样 。  

训练和测试的采样过程是不

一致的 。在训练时 ， 对于

一个包含Ｌ＝２５６个框  

的小样本 ， 最多Ｌ／２个正例区域 ， 其余为负例区域 。 如果

一个  

Ｇｒｏｕｎｄ

－Ｔｒｕｔｈ标签区域的交集 （ ＩＯＵ ） 为 ０ ．７ 以上 ， 则该区域为正例区域 。 如果  

一个区域和所有标签区域的 ＩＯＵ都小于 ０ ．３ ， 该区域为负例区域 。  

在测试过程中 ， 根据置信度分数 ， 使用非极大值抑制 （Ｎｏｎ

－ｍａｘｉｍｕｍ  

Ｓｕｐｐｒｅｓｓｉｏｎ ， ＮＭＳ ）方法选取出Ｌ ＝５０个区域 ， ＮＭＳ的实质是对局部极大值进  

行搜索 ，通过若干轮迭代选出置信度高且相互重叠度小的若干区域 。该部分输出  

坐标组成的ＬＸ４张量和置信度组成的ＺＪＩ张量 。  

双线性插值给大小有变化的区域生成固定大小的特征表示 ，得到ｉｘｅｘＸｘｙ  

的输出特征张量 。  

识别网络由全连接前馈神经网络组成 ，将每个区域特征压缩为

一维向量  

表示 。 通过两个后接ＲｅＬＵ激活函数 、 并带有Ｄｒｏｐｏｕｔ正则化的全连接层 ， 每个  

区域表示为 ４０９６维的向量 ，最终 ，该部分的输出为 ５０Ｘ４０９６的特征集 ， 表示为  

｛ｖｖｖ２ ｈ）

，将作为区域注意力模块的输入 。 对特征集做按位最大池化操作 ，  

得到全局表示Ｖ ｐ

， 作为句子ＣＮＮ的输入 。  

４．１ ．３融合区域注意力的句子ＣＮＮ  

以％为输入 ， 对于第 ／个句子 ， 句子ＣＮＮ首先按 ３ ．２ ．３介绍的流程生成门控  

卷积层的输出ｓａ 。接下来 ， 区域注意力模块将视觉特征 作为  

４２  

第四章 融合区域注意力的段落式图像描述模型  

输入 ，计算第 ｉ个句子的注意力区域特征 。 我们将此过程公式化为以下两个  

公式 ：  

＿ ｅｘ Ｔｐ（（Ｓ〇 ｉ）

ＴＷｔＶ ｉ）   Ｓ ｌ１  

ｓｎｖ ｔ （４ － ６）  

ｉ＝ｉ  

其中 ， 表示区域ｔ；在第 ｚ

‘ 个句子的注意力分数 ， ％表示可学习的权重参  

一步 ， 根据义？

？和汗 《中的语义 ， 计算出具有区域注意力的多模态语义向  

量 ：  

６严 ＝ 对 《

］＋ｂａ５）（４ － ７）  

其中 ， 是可学习权重 ， ６叫是可学习偏置 ， ｆ表示ＲＥＬＵ函数 。 中蕴  

含了生成第 ／个句子所需的感兴趣区域特征 。 以６纟 《为语义沟通桥梁 ， 实现图像  

语义和段落中句子的细颗粒度对齐 。  

最后 ， 词ＣＮＮ解码器在Ｇｆ ？的指导下生成段落 ， 过程同 ３ ．２ ．４ 。  

４．２实验对比与分析  

以上介绍了Ｄｕａｌ －ＣＮＮ的详细结构 ， 为验证Ｄｕａｌ

－ＣＮＮ的性能 ， 同样在斯坦  

－段落数据集上实验 ， 进行指标的评测和对比 ， 并通过三种方式进

一步验  

证模型的优势 ： （ １ ）提出了

一种段落内句子多样度的衡量指标 ； （２ ）对区域注意  

力模块的效果进行可视化分析 ； （３ ） 对模型生成的段落进行主观的定性分析 。  

４．２．１基线方法介绍  

除上 一章所比较的六个基线方法外 ， 本章还将对比ＲＴＴ －ＧＡＮＷ和ＤＣ

１）ＲＴＴ －ＧＡＮ方法建立在包括段落ＲＮＮ 、句子ＲＮＮ和词ＲＮＮ的三层次ＲＮＮ  

解码器上 ， 在句子＿ 中结合了注意力机制 ， 并引入 ＧＡＮ构建对抗框架以增  

强段落的连贯性 。其中 ，

一个句子判别器评估句子的可读性 ，

一个主题转换判别  

器评估句子之间主题的转换连贯性 。 为了对比的公平性 ， 我们和不加ＧＡＮ设置  

的ＲＴＴ －ＧＡＮ进行比较 。  

２）ＤＣ方法建立在句子ＲＮＮ和词ＲＮＮ的层次ＲＮＮ解码器上 ， 提出了两个  

向量 ： 全局主题向量和连贯性向量来增强段落连贯性 。  

以上两个方法属于 ３ ．３ ．２中的Ｈｉｅｒａｒｃｈｙ方法 ，本章对比的所有基线方法分类  

－３所示 。  

４３  

第四章 融合区域注意力的段落式图像描述模型  

Ｓｅｎｔｅｎｃｅ

Ｃｏｎｃａｔ  

Ｃｏｎｃａｔ类 ）

Ｓｅｎｔｅｎｃｅ －  

ＬＣｏｎｃａｔ  

Ｉｍａｇｅ －  

Ｆｌａｔ （ＲＮＮ ）  

ｆ本节对比的＾）／ ＼

１   ｖ基ｕＳ（

ｉ— 僕 ）

Ｊ  ｜Ｆ ；：Ｎ ）  

ＤＡＷ  

Ｈ ｉｅｒａｒｃｈ ｉｃａ ｌ  

－ＲＮＮ   Ｌ （

Ｈ ｉｅｒａｒｃｈｙ＾ ）

＜ＲＴＴ ＿ＧＡＮ  

ＬＤＣ  

图 ４ －３基线方法分类示意图  

４ ．２ ．２评测指标对比与分析  

本小节通过ＢＬＥＵ －１ 、 ＢＬＥＵ －２ 、 ＢＬＥＵ －３ 、 ＢＬＥＵ －４、 ＣＩＤＥｒ和ＭＥＴＥＯＲ六  

个指标对Ｄｕａｌ

－ＣＮＮ和基线方法的性能进行评测 。表 ４

－ １所示为评测指标结果 。  

得益于全局主题向量和连贯性向量 ， ＤＣ取得了最佳的结果 ， 其ＣＩＤＥｒ得分  

比ＲＴＴ －ＧＡＮ高出４ ．９ ，比Ｄｕａｌ －ＣＮＮ高出２ ．６ 。当移去连贯性向量的模块后 ，ＤＣ（ｗ＼ｏ  

ＣＶ）的ＣＩＤＥｒ得分为 １６ ．４ ，比Ｄｕａｌ －ＣＮＮ低出 ０ ．５ ，这显示了卷积结构的有效性 。  

同时 ， Ｄｕａｌ

－ＣＮＮ的ＣＩＤＥｒ得分比Ｈ ｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ高出３ ．９ ， 比ＲＴＴ －ＧＡＮ高出  

２ ．３ 。  

在ＢＬＥＵ和ＭＥＴＥＯＲ指标上 ， Ｄｕａｌ －ＣＮＮ取得了和ＲＴＴ

－ＧＡＮ 、ＤＣ可比的  

结果 。ＲＴＴ －ＧＡＮ融入了ＤｅｎｓｅＣａｐ中的区域描述 ，并加入了在区域描述上的文本  

注意力 ， 因此更容易捕获频繁的 ｎ － ｇｍｍ短语 ， 这可能导致更高的 ＢＬＥＵ 和  

ＭＥＴＥＯＲ得分 。 然而 ， 根据ＢＬＥＵ和ＭＥＴＥＯＲ的计算方法 ， 与 ＣＩＤＥｒ指标相  

比 ，这两个指标与人类评估的相关性较低 ，在某种程度上不能准确反映段落的质  

量 ， ＣＩＤＥｒ更适合评估 。  

当不加区域注意力模块时 ， 不出意料 ， Ｄｕａｌ

－ＣＮＮ （ｗ＼ｏａｔ）的 ＣＩＤＥｒ得分比  

－ＣＮＮ低 ０ ．５ ， 四个ＢＬＥＵ指标的得分也都低于Ｄｕａｌ －ＣＮＮ 。这在

一定程度上  

显示了区域注意力模块的作用 。  

综上 ，我们的Ｄｕａｌ

－ＣＮＮ在ＣＩＤＥｒ指标上优于除ＤＣ外的所有基线方法 。在  

ＢＬＥＵ和ＭＥＴＥＯＲ上 ， Ｄｕａｌ

－ＣＮＮ取得了和ＲＴＴ

－ＧＡＮ 、 ＤＣ可比的结果 ， 并且  

优于其他基线方法 。  

４４  

第四章 融合区域注意力的段落式图像描述模型  

表 ４ － １ 模型评测结果对比  

模型ＣＩＤＥｒＢＬＥＵ －１ＢＬＥＵ －２ＢＬＥＵ －３ＢＬＥＵ －４ＭＥＴＥＯＲ  

Ｓｅｎｔｅｎｃｅ

－Ｃｏｎｃａｔ６ ．８３ １ ． １１５ ． １７ ．６４ ．０ １２ ． １  

ＤｅｎｓｅＣａｐ

－Ｃｏｎｃａｔ１２ ．５３３ ．２１７ ．０８ ．５４ ．５ １２ ．７  

ｌｍａｇｅ －Ｆ ｌａｔ（ＲＮＮ ）

１ １ ． １３４ ．０２０ ．０１２ ．２７ ．７ １２ ．８  

Ｉｍａｇｅ －Ｆｌａｔ（ＣＮＮ ） １５ ．２３５ ．０１９ ．４１０ ．７５ ．９ １３ ．３  

ＤＡＭ １７ ．３３５ ．０２０ ．２ １ １ ．７６ ．６ １３ ．９  

Ｈ ｉｅｒａｒｃｈ ｉｃａｌ －ＲＮＮ １３ ．５４ １ ．９２４ ． １ １４ ．２８ ．７ １６ ．０  

ＲＴＴ －ＧＡＮ １５ ． １４ １ ．９２４ ．３ １４ ．６９ ．０ １６ ．６  

ＤＣ （ｗ＼ｏＣＶ ）

１６ ．４４２ ．０２４ ．８ 】４ ．５８ ．８ １６ ．９  

ＤＣ （ｗ＼ＣＶ ）２０ ．０４２ ． １２５ ．２１４ ．７９ ． １１７ ．８  

Ｄｕａｌ －ＣＮＮ（ｗ＼ｏａｔｔ） １６ ．９４ １ ．２２４ ．３１４ ． １８ ．４ １５ ．８  

－ＣＮＮ （ｗ＼ａｔｌ）

１７ ．４４ １ ．６２４ ．４１４ ．３８ ．６ １ ５ ．６  

人类２８ ．６４２ ．９２５ ．７１５ ．６９ ．７ １９ ．２  

４．２．３多样度指标对比与分析  

Ｅ域注意力机制在句子ＣＮＮ中生成更富变化性的多模态语义向量 ， 我们的  

一是据此生成更低重复度 、更高多样度的句子 。 在本小节 ，我们提出了

种衡量段落内句子间多样度的指标 ， 来验证区域注意力机制的作用 。  

一个段落 ， 其多样度定义为每两个句子对之间的加权ＢＬＥＵ

－ｎ分数 。使  

用ＢＬＥＵ的原因是 ， 相对于ＣＩＤＥｒ ， ＢＬＥＵ －ｎ直接计算 ｎ元语法的共现度 ， 当两  

句话之间的 ＢＬＥＵ得分高时 ， 说明这两句话之间的 ｎ元词组重复度高 ， 更直观  

反映出两句话的重复度较高 。  

一个段落有ｗ句话 ， 则句子对数共有ｍ（ｍ － ｌ）／２对 。 对于其中

一个句  

子对 ， 其多样度心计算方式如下 ：  

知 ＝ ｌ － Ｊ＾

ｒＡ（４ －８）  

ｎ＝ｌ  

其中 ， 表示ＢＬＥＵ －ｎ值 ， 为对应的权重 。 权重满足以下基本条件 ：  

ｙｎ＾〇 （４ －９）  

＝１ （４ － １〇）  

ｎ＝ｌ  

此外 ， 我们启发式地增加以下两个式子来进

一步确定权重 ：  

４５  

第四章 融合区域注意力的段落式图像描述模型  

Ｖｉ ＝ Ｖ４

Ｙ３（４ － １１）  

－ Ｖ２ ＝ ２Ａ（４ － １２）  

有４＝０．０５ ， 四个权重｛ｙＴｌ｝ｆ＝１ 分别为｛０ ． １５ ，０ ．２０ ，０ ．３０ ，０ ．３５｝ 。  

对段落内所有句子对的Ｓｄ值做简单平均 ，得到该段落的句子多样度 。在实验  

中 ，我们记录了在第２０个至第 ４０个轮次之间 ，由Ｄｕａｌ －ＣＮＮ和Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ  

在测试集上生成的段落的平均多样度 ， 由图 ４

－４ 所示 。 两个曲线分别代表  

Ｄｕａｌ －ＣＮＮ和Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ的多样度分数 。水平线代表人类表现 ，得分为９４ ．８ 。  

经过４０个轮次的训练后 ，Ｄｕａｌ

－ＣＮＮ和Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ分别取得了９３ ．７和 ９０ ．６  

的分数 。 与 Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ相比 ， Ｄｕａｌ

－ＣＮＮ与人类表现之间的差异减少了  

７３ ．８％ 。 因此 ， 我们得出的结论是 ， 我们的模型能在段落中生成更多样的句子 ，  

表现也更接近人类水平 。  

 — ￣－ １  

■ ＂  ？—Ｏｕｒ ｍｏｄｅｌ   ９８一一一  

— ？Ｈｕｍａｎ  

ｇ ９４  

§ ９２  

Ｑ８６  

， ＂＾  

８２  

  

２０２２２４２６２８３０３２３４３６３８４０  

Ｅｐｏｃｈ  

－４ 多样度得分随训练轮次变化   — — — —■Ｍ－ｓｓｓｉａ    

１   ■ｍ—  

Ａ ｔｒａｉｎ  ｉｓ ｏｎ ｔｈｅ ｔｒａｃｋｓ ．１７ ｉｅ ｔｒａ ｉｎ  ｉｓ

ｙｅｌ ｌｏｗａｎｄ ｂｌａｃｋ  ｉｎ ｃｏ ｌｏｒＴｈｅｒｅ ａｒｅ ｔｗｏ ｗ ｉｎｄｏｗｓ ｏｎ ｔｈｅ ｆ ｒｏｎｔ ｏｆＴｈｅｒｅ ａｒｅ  ｔｈ ｒｅｅ ｒ ａ ｉ ｌｓ ｖ ｉｓｔ ｏｔｅ ａｌｏｎｇｓ ｉｄｅＴｈｅ ｓｋｙ 

ｉｓ ｂｔ ｅｕ ｗ ｉｔｈ ｗｈ ｉｔｅ ｃ ｌｏｕｄｓ

ｔ＞ｅ  ｔｒａ ｉｎ． ｔｈｅ ｆａｒ ｏｆ ｔｈｅ ａｒｅａ ．  

Ａ ｍａｎ  ｉｓ ｓｕｒｆ ｉｎｇ ｏｎ ａ ｓｕｒｆｂｏａｒｄ ．Ｈｅ  Ｉｓ ｈｏ ｌｄ ｉｎｇ ａ ｗａｖｅ ａｎｄ  ｉｓ ｓｔａｎｄ ｉｎｇ 

ｉｎＴｈｅ ｍａｎ ｉｓ ｗｅａｒ ｉｎｇ ａ ｗｅｔｓｕ ｉｔ ．Ｔｈｅ ｗａ ｔｅｒ  ｉｓ ｂｒ ｉｇｈｔ ａｎｄ  ｔｈｅ ｒｅ ａｒｅｓｍａ ｌ ｌ  

ｆ ｒｏｎｔ ｏｆ ｗａｔｅｒ． ｗａｖｅｓ ｈ ｉｇｈ ｕｐ  ｔｏ  ｔｈｅ ｒ ｉｇｈｔ ｏｆ ｔｈｅ  

ｓｕｒｆｂｏａｒｄ ．  

－５ 区域注意力可视化  

４６  

第四章 融合区域注意力的段落式图像描述模型  

４．２．４区域注意力机制效果分析  

一小节 ，我们通过计算段落内句子多样度 ， 定量分析了区域注意力机制  

的效果 。在本小节 ，我们将区域注意力 果可视化 ，把每个句子的注意区域调高  

亮度反映显示在图上 ， 如图 ４ －５所示 。  

一幅图中 ， 在生成前三句话时 ， Ｄｕａｌ

－ＣＮＮ对包含火车 （Ｔｒａｉｎ） 的区域具  

有强烈的关注 ， 对应地 ， 前三句话描述了火车及其细节 。 第四句话描述了铁轨  

（Ｔｒａｃｋ ） ， 模型关注的重点转向包含铁轨的区域 。在生成最后

一句话时 ， 模型开  

始关注天空 （Ｓｋｙ ） ， 生成的句子描述了图中天空的画面 。  

第二幅图中 ， 前三句话描述了

一个男人 （Ｍａｎ）在冲浪以及相关的细节 ， 模  

型关注的区域集中在该男子及其周围的区域上 。 第四句话描述了水面 （Ｗａｔｅｒ ） ，  

模型也将关注点转向水面 。  

通过以上分析 ， 区域注意力机制使我们的Ｄｕａｌ

－ＣＮＮ在生成不同句子时 ， 能  

够合适地 、 选择性地关注不同的区域 ，关注的顺序也呈现出先关注主要对象 、 再  

关注次要对象的趋势 。通过更有目的性的关注 ， 生成的句子也更富变化 ， 描述也  

更细颗粒度 。  

４．２．５生成段落定性分析  

图 ４ －６展示了Ｄｕａｌ －ＣＮＮ和Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ在从测试集中随机选取的若干  

张图片的段落生成结果 。  

一幅图中 ，针对Ｄｕａｌ

－ＣＮＮ生成的段落 ，第

一句话首先识别出了该图片  

所在的整体场景 ： 城市 （Ｔｈｅｒｅｉｓａｐ ｉｃｔｕｒｅｏｆａｎａｎｃ ｉｅｎｔｃｉｔｙ

． ） 。 接下来两个句子介  

绍了图中最突出的对象公共汽车 （Ｔｈｅｒｅｉｓ ａｂｕｓ ｏｎｔｈｅｓｔｒｅｅｔ ． ） ， 并描述了其相关  

特征 ： 双层巴士 （Ｔｈｅｂｕｓｉｓａｄｏｕｂ丨ｅｄｅｃｋｅｒｂｕｓ ． ） 。接下来三个句子描述了图片中  

其它对象 。 第四句话点明了建筑物及其位置 （Ｔｈｅｒｅｉｓａｌａｒｇｅｂｕｉｌｄｉｎｇｂｅｈｉｎｄｔｈｅ  

ｂｕｓ ． ） 。第五句话介绍了人行道上的行人 （Ｔｈｅｒｅｉｓａ ｌａｄｙｓｔａｎｄｉｎｇｏｎｔｈｅｓｉｄｅｗａｌｋ ． ） ，  

由于人行道上的行人较为模糊 ， 人眼分辨也有困难 ， 因此性别描述稍不准确 。最  

一句话描述了

一棵树和它的位置 （Ｔｈｅｒｅｉｓａｌａｒｇｅｔｒｅｅｔｒｕｎｋｔｏｔｈｅｒ ｉｇｈｔｏｆｔｈｅ  

ｂｕｓ ． ） 。而针对Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ生成的段落 ，第

一句话和第三句话描述了相同的  

内容 ， 重复度较高 ， 第五句话和第六句话完全相同 。  

在第二幅图中 ，针对Ｄｕａｌ

－ＣＮＮ生成的段落 ，第

一句话描述了该图片中发生  

的主要事件 ：

一位女士在网球场上 （Ａｗｏｍａｎｉｓｓｔａｎｄｉｎｇｏｎａｔｅｎｎｉｓｃｏｕｒｔｏｎａ  

ｓｕｎｎｙｄａｙ

． ） ，第二句话描述了她的衣着 （Ｓｈｅｉｓｗｅａｒｉｎｇａｗｈｉｔｅｖｉｓｏｒ ，ａｗｈｉｔｅｓｈｏｒ ｔ  

ｓｌｅｅｖｅｓｈｉｒｔ ，ａｎｄａｂｌａｃｋｓｋｉｒ ｔ ． ）且这些描述都完全正确 ， 第三句话介绍了她的动作  

４７  

第四章融合区域注意力的段落式图像描述模型  

〇ｕｒｍｏｄｅｌ ：  

： ：  ＾  ￣ ７

Ｔｈｅｒｅ ａｒｅ ｔｗｏ

ｉｒａｆｆｅｓ ｉｎ  ｔｈｅ ｐ

ｉｃｔｕｒｅ ． Ｔｈｅ ｇ

ｉｒａｆｆｅｓ ａｒｅ ｖｅｒｙ 

ｔａ ｌｌ Ｔｈｅ ｇ

ｉｒａｆｆｅ ｏｎ  ｔｈｅｒ ｉｇｈｔ  ｉｓｓｔａｎｄ ｉｎｇ  

二ｓｔｒａ ｉｇｈｔ ｕｐ ａｎｄ ｌｏｏｋ ｉｎｇａｔ ｔｈｅ ｃａｍｅ ｒａ ． Ｔｈｅ

ｉｒａｆｆｅｈａｓ ｌｏｎｇｈｏｒｎｓ ． Ｔｈｅ ｇ

ｉｒａｆｆｅ ｈａｓａ ｌｏｎｇｎｅｃｋ ．  

Ｔｈｅ ｒｅ  ｉｓ ａ ｐａｔｈｗａｙ 

ｔｏ  ｔｈｅ ｌｅｆ ｔｏｆ  ｔｈｅ

ｉｒａｆｆｅ ．  

Ｈ ｉｅｒａｒｃｈ ｉｃａ ，

了ｈｅｍａ ｉｎ  ｆｏｃｕｓｏｆ  ｔｈｅ ｐ

ｉｃｔｕｒｅ  ｉｓａ ｔａｌ ｌ

ｉ ｒａｆｆｅ ． Ｔｈｅ ｒｅ ａｒｅｔｗｏ ｇ

丨 ｒａｆｆｅｓ ｉｎｔｈｅ ｐｈｏｔ ｏ ． Ｉｔ ｉｓ ｃｒｅａｍ   ｍＨＭ＾３

｜Ｅ ＞ ｗｒ ｔｈ ｂｒｏｗｎ ｓｐｏｔｓ ． Ｔｈｅｒｅａｒｅ ｔｒｅｅｓ  ｉｎ  ｔｈｅｂａｃｋｇ ｒｏｕｎｄ ． Ｔｈｅ

ｉｒａ ｆｆｅ  ｉｓｔａ ｌ ｌｅ ｒ ｔｈａｎ  ｔｈｅｔｒｅｅｓ ａｎｄ  

＜ｕｎｋ＞  ｔｏ ｓｅｅ ｉｔＴｈｅ

ｇ ｒａｓｓ ｉｓ ｖｅｒｙ ｇ ｒｅｅｎａｎｄ ＜ｕｎｋ＞  ｌｏｏｋ ｉｎｇ

了ｈｅ ａｒｅ ｔｗｏ ｇ

ｉｒａｆｆｅｓ ｉｎ  ｔｈｅｆｏｒｅｓＬＯｎｅ ｇ

ｉ ｒａｆｆｅ  ｉｓ ｓｍａ ｌ ｌｅｒ ｔｈａｎ  ｔｈｅ ｏ ｔｈｅｒ ．Ｔｈｅ ｇ

ｉｒａｆｆｅｓｈａｖｅ  

乂 ｈｏｒｎｓ ． Ｔｈｅ ｉｒ ｅａｒｓａｒｅ ｐｏ ｉｎｔｙ ａｎｄ ｗｈ ｉｔｅ Ｔｈｅｙｈａｖｅ ｂｒｏｗｎｓｐｏｌｓ ． Ｔｈｅ ｉｒｎｅｃｋｓ ａ ｒｅ  ｌｏｎｇ

．Ｔｈｅ ｉｒ   ＾

ｌｅｇｓ ａｒｅ  ｌｏｎｇ

．Ｔｈｅ ｅｎｄｏｆ ｔｈｅ ｉｒ  ｔａ ｉ ｌ  ｉｓ ｂｌａｃｋ．Ｂｅｈ ｎｄ  ｔｈｅｍａｒｅ  ｔｒｅｅｓ ａｎｄｂｕｓｈｅｓ Ｏｎｔｈｅ ｇ ｒｏｕｎｄ  

＇ 二 、 、／（

、 ｉ至，

ｒａｓｓ ， ｔｈｅ ｇ ｒａｓｓ ａｒｅ ｄｒｙ

． Ｔｈｅ ｌａｃｅ ｏｆ  ｔｈｅ

ｉｒａｆｆｅｓａｒｅｂｒｏｗｎ ．  

Ｉ — Ｗ＾ＺＺ＾ＴＨＷｉＷ  

｜Ｊ ＊ ５５ Ｏｕ ｒ ｍｏｄｅｌ

＾＾ Ｔｈ ｉｓ

ｉｃｔｕｒｅ ｉｓ ｔａｋｅｎ ｏｕｔｓ ｉｄｅ ｏｎ ａ ｓｕｎｎｙ ｄａｙ

．Ｔｈｅｒｅ  ｉｓａｔａｌ ｌ ｂｕ ｉ ｌｄ ｉｎｇｗ ｉ ｔｈｍａｎｙ ｗ ｉｎｄｏｗｓ ｏｎ ｔｈｅ  

： ｓ ｉｄｅ ｏｆ ｔｈｅ ｓｔｒｅｅｔ ． Ｔｈｅ ｒｅ

ｉｓａ ｗｈ

ｉｔｅｂｕｓｗ ｉｔｈ ａ ｒｅｄ ｓｔｒ ｉｐｅｗａｌｋ ｉｎｇ ｏｎ  ｔｈｅｓｔｒｅｅｔＴｈｅｒｅａｒｅ ｍａｎｙ   二 ｔａＢ ｂｕ ｉ ｌｄ ｉｎｇｓｏｎ  ｔｈｅ ｓ ｉｄｅ ｏ ｆ ｔｈｅｒｏａｄ Ｔｈｅ ｒｅａｒｅ ｍａｎｙｃａｒｓｏｎ  ｔｈｅ ｓｔｒｅｅｔ

＾ＳｈＪＳＳＨ ｉｅｒａ ｒｃｈ ｉｃａ ｌ

－ＲＮＮ ：  

Ｔｈｅ ｒｅａｒｅｔｗｏ ｂｕｓｅｓ ｄ ｒ ｉｖ ｉｎｇ ｃＪｏｗｎ  ｔｈｅｓｔｒｅｅ ｔ ．Ｔｈｅ ｒｅ ｉｓａｂｕｓ

ｇｏ ｉｎｇｄｏｗｎ  ｔｈｅ ｒｏａｄ ．Ｔｈｅｒｅａｒｅ ａ  

ｌｏ ｔ ｏ ｆ  ｔｒｅｅｓｏｎ ｔｈｅ ｏ ｔｈｅｒｓ ｉｄｅ ｏｆ ｔｈｅ ｂｕｓ Ｔｈｅ ｒｅ ａ ｒｅ ａｂｕｎｃｈ ｏｆ

ｐｅｄｅｓ ｔ ｒ ｉａｎｓ ｗａ ｌｋ ｎｇｄｏｗｎ  ｔｈｅ  

ｓｔｒｅｅｔＴｈｅｒｅａ ｒｅ ｓｅｖｅｒａ ｌ ｂｕ ｉ ｌｄ ｉｎｇｓ ａ ｌｏｎｇ

ｔｈｅ ｓ ｉｄｅ ｏｌ ｔｈｅｒｏａｄ Ｏｎ  ｔｈｅｏｔｈｅ ｒ ｓ ｉｄｅｏｆｔｈｅ ｂｕｓ ．  

ｔｈｅ ｒｅ  ｉｓａｍａｎｗａ ｌｋ ｉｎｇｄｏｗｎ ａ  ｒｏａｄ ．   獨

Ｇ ｒｏｕｎｄ Ｔｒｕｔｈ ：  

Ｉ Ａ ｄｏｕｂ ｌｅｄｅｃｋｅ ｒ ｂｕｓ  ｉｓｄｒ ｉｖ ｉｎｇｄｏｗｎ ｔｈｅｓｔｒｅｅ ｔ Ｔｈｅ ｔｏｐｈａｌｆ ｏｆ  ｔｈｅｂｕｓｈａｓ ｍａｎｙ ｗ ｉｎｄｏｗｓ ａｎｄ  

？＠１％二

ｔｈｅ ｓ

ｉｄｅｓａｒｅｂ ｌｕｅ ．Ｔｈｅｂｏｔｔｏｍｈａ ｌｔ

ｏｆ ｔｈｅｂｕｓ  ｉｓ ｗｈｒ ｔｅ ．Ｕｎｄｅｒ  ｔｈｅ ｂｕｓ ｉｓ ａ ｐａｖｅｄａｒｅａ ｗｒ ｔｈ  

｜騸麟 ｍａｎ ｙ ｙｅ ｌｌｏｗ ｌ ｉｎｅｓ ｐａ

ｉｎ ｔｅｄ ｏｎ ｒ ｔ ．Ｂｅｈ ｉｎｄ ｔｈｅ ｂｕｓ ａｒｅ  ｔａｌ ｌ ｇ

ｒｅｙ ｓｋｙｓｃｒａｐｅ ｒｓ ．Ｎｅｘｔ  ｔｏ ｔｈｅｂｕｓ  ｉｓ ａ  

ｗｈ ｉ ｔｅ ｖａｎ ｗ ｉｔｈｓ ｉ ｌｖｅ ｒｈｕｂｃａｐｓ ．Ｔｈｅｒｅａ ｒｅａ  ｆｅｗ

ｇ ｒｅｅｎ ｔｒｅｅｓ

＊ ， Ｏｕ －ｍｏｄｅ． ：  

＊ Ａ ｍａｎ  ｉｓ ｒ ｉｄ ｉｎｇ ｈ ｉｓ ｓｕｒｆｂｏａ ｒｄ ｏｎ  ｔｈｅ ｗａｔｅ ｒ ．Ｈｅ  ｉｓ  ｒ ｉｄ ｉｎｇａ ｗａｖｅ ．Ｔｈｅｗａｔｅｒ ｈａｓ ｓｍａｌ ｌ ｗａｖｅｓ ．  

＊ ＇Ｔｈｅ ｓｕｒｆｂｏａｒｄ  ｉｓｗｈｒ ｔｅ ｗｒ ｔｈ ａ ｂｌａｃｋ ｄｅｓ ｉｇｎ ｏｎ  ｉｔ Ｔｈｅｒｅ ｉｓ ａ ｓｈａｄｏｗｏｆ ｔｈｅ ｍａｎ ｏｎ ｔｈｅ   ｓｕ ｒｆｂｏａ ｒｄ ．Ｔｈｅ ｗａｔｅｒ  ｉｓａ

ｇ ｒｅｅｎ ｉｓｈ ｃｏ ｌｏｒ ．  

Ｈ ｉｅｒａ ｒｃｈ ｉｃａ ｌ

－ＲＮＮ ：  

Ａ ｍａｎ  ｉｓ ｓｕ ｒｆ ｉｎｇ 

ｉｎ ｔｈｅｗａｔｅｒＴｈｅ ｍａｎ ｉｓｗｅ？ ｉｎｇ ａｂ ｌａｃｋ ｗｅ ｔ ｓｕ ｉｔＴｈｅｒｅ  ｉｓ ａ  ｌａｒｇｅｗａｖｅ  

ｂｅｈ ｉｎｄ ｔｈｅｓｕｒｆｅ ｒ Ｔｈｅｒｅ ｉｓ ａ

ｐｅｒｓｏｎ ｓｕｒｆ ｉｎｇ ｏｎ ｔｈｅ ｗａｖｅ ｉｎ  ｆｒｏｎｔ ｏｔｔｈｅ ｐｅｒｓｏｎ Ｔｈｅｒｅ ｉｓ ａ  

＇ ＇＾Ｚｐｅ ｒｓｏｎ ｓｒ ｔｔ ｉｎｇ ｏｎ  ｔｈｅｏｔｈｅｒ ｓ ｉｄｅ ｏｔ  ｔｈｅｗａｔｅ ｒ  ｌｏｏｋ ｉｎｇ

．   二 ＧｒｏｕｎｄＴｒｕｔｈ ：  

―＾ Ａ ｍａ ｌｅ ｉｓｓｕｒｆ ｉｎｇ ｍ  ｔｈｅｂ ｌｕｅ ｏｃｅａｎ ．Ｔｈｅｒｅ  ｉｓａ ｗａｖｅｂｅｈ ｉｎｄ ｈ ｉｍ ｗ ｉｔｈｗｈｒ ｔｅ ｆｏａｍｓｕ ｉｌａｃ ｉｎｇ ｏｎ  

￣ 、 一 ’二 —  ＜ｔｈｅ ｗａ ｔｅ ｒ ．Ｔｈｅｍａｌｅ ｓｕ ｒｆｅ ｒ ｉｓ  ｌａｙ

ｉｎｇ ｏｎ ｔｈｅｓｕ ｒｆｂｏａｒｄ ｉｎ ｐ ｒｅｐａｒａｔ ｉｏｎｔｏ ｒ ｉｄｅ ａ Ｎｇｗａｖｅ ．Ｈｅ  ｉｓ   一

…ｗｅａ ｒ ｉｎｇ ａｂ ｌａｃｋ ｗｅ ｔ ｓｕ ｉｔ ｔｈａｔ ｃｏｖｅｒｓｈ ｉｓ ｅｎ ｔ ｉｒｅ ｂｏｄｙ

．Ｔｈｅ ｓｕｒｆｅ ｒ ｈａｓｄａｒｋ ｂｒｏｗｎｈａ ｉ ｒ ａｎｄ ｔｈｅ   ｎ：

． ？ 二＿

：二 — ｄ ．  

。一  

Ａ  ｔｒａ ｉｎ  ｉｓｏｎ ｔｈｅ ｔｒａ ｉｎ ｔｒａｃｋｓ ． Ｔｈｅ  ｔｒａ ｉｎ ｉｓ ｂｌａｃｋ ａｎｄｗｈ ｉｔｅ ．Ｔｈｅ ｔｒａ ｉｎｈａｓａ ｎｕｍｂｅｒ ｏｎ  ｔｈｅ  ｆｒｏｎｔ   麗 〇＜  ｉｌ ． Ｔｈｅｒｅ ｉｓ ａ  ｌａｇｅｍｅｔａｌ ｂｕ ｉ ｌｄ

ｉｎｇ ｏｎ ｔｈｅ ｏｌｈｅｒ ｓ ｉｄｅｏｆ  ｔｈｅ  ｔｒａｎ ｎｅａｒ  ｔｈｅ ｔｒａ ｉｎ ． Ｔｈｅｒｅ ａｒｅ  

ｍａｎｙ  ｔｒｅｅｓ ｏｎ  ｔｈｅ ｓ ｉｄｅｏ ｆ ｔｈｅ  ｔｒａ

Ｈ ｉｅｒａ ｒｃｈ ｉｃａｌ

Ｔｈｅ ｒｅ  ｉｓａｔｒａ ｉｎ ｏｎ  ｔｈｅｔｒａｄｅ Ｔｈｅ  ｔｒａ ｉｎｈａｓ ａ  ｌａｒｇｅｈｅａｄ ｌ ｉｇ ｈｔ 丁ｈｅ ｒｅａｒｅｗ ｉｒｅｓａｂｏｖｅ  ｔｈｅ  ｔｒａｃｋｓ

Ｔｈｅ ｐ

ｌａｔｆｏｒｍ  ｉｓ ｃｏｖｅｒｅｄ ｉｎ ｓｎｏｗ ａｎｄ ｔｈｅｒｅ  ｉｓ ｓｎｏｗｏｎ ｉｔ Ｔｈｅｒｅ ｉｓａ ｐ

ｌａｔｆｏｒｍ ｏｎ ｔｈｅ ｏｔｈｅｒ ｓ ？ｄｅ  

ｏｆ  ｔｈｅ  ｔｒａ ｉｎ ｗ ｉｔｈ ａ ｂｒｏｗｎｒｏｏｆ ｏｎ  ｉｔ Ｉｔ ｉｓ ａ ｓｕｎｎｙ ｄａｙ

ＧｒｏｕｎｄＴｒｕｔｈ ：  

！ Ｔｈ ｉｓ  ｉｓ ａ ｌａ ｒｇｅ ｂｌａｃｋａｎｄ ｒｅｄ  ｔｒａ ｉｎ ． Ａ

 ｊｅ ｔｏｆ ｓ ｔｅａｍ ｃｏｍｅｓ ｏｕｔ  ｔｈｅ ｓ ｉｄｅ ａｎｄ ｈ ｉｔｓｔｈｅ ｇ

ｒｏｕｎｄ ． Ｔｈｅ  

ｔｒａ ｉｎｈａｓｔｈｒｅｅｈｅａｄ ｌ ｉｇｈｔｓ ｏｎ  ｔｈｅ ｆｒｏｎｔ ａｓ ｗｅ ｌ ｌ ａｓ ａｎ ｉｄｅｎ ｔ ｉｆ ｉｃａｔ ｉｏｎｎｕｍｂｅｒ ． Ｔｈｅｄｏｏｒ  ｔｏ  ｔｈｅ ｆｒｏｎｔ  

， ：ｃａｒ ｉｓ ｓ ｌ ｉｄｏｐｅｎ ａｎｄａｍａｎ ｓｔａｎｄｓａｔｔｈｅ ｒｅａｒ ｏｆ  ｔｈｅｃａｒ ｄｏｉｎｇ ｓｏｍｅｔｈ ｉｎｇ

． Ｔｈｅｒｅａｒｅ  ｔｒｅｅｓ ｉｎ ｔｈｅ   Ｗｂａｃｋｇ ｒｏｕｎｄ ｂｅｈ ｉｎｄ ｈｅ ｔｒａ ｉｎ ．  

＊ ｉ  

－６Ｄｕａｌ －ＣＮＮ和Ｈ ｉｅｒａｒｃｈｉｃａ ｌ －ＲＮＮ的生成段落对比  

（Ｓｈｅｉｓｈｏｌｄｉｎｇａｂｌａｃｋａｎｄｗｈｉｔｅｔｅｎｎｉｓｒａｃｋｅｔ． ） ，最后

一句话将网球场的细节加以  

描述 （Ｔｈｅｔｅｎｎｉｓｃｏｕｒ ｔｉｓｂｒｏｗｎｗｉｔｈａｉｄｅｎｔｉｃａｌｗｈｉｔｅｌｉｎｅ ． ） 。 针对Ｈｉｅｒａｒｃｈｉｃａｌ －  

ＲＮＮ 生成的段落 ， 其第二句话和第三句话描述出现了重复 ， 且第四句话描述准  

确度很低 。  

在第三幅图中 ， 针对Ｄｕａｌ

－ＣＮＮ生成的段落 ，第

一句话 、第四句话、第五句  

话 、 第六句话描述有较大重复 ，这也是选取的四个例子中Ｄｕａｌ

一生成了  

较为重复的段落的图片 。对于Ｈｉｅｒａｒｃｈｉｃａｌ

－ＲＮＮ生成的段落 ，第

一句话 、第三句  

话有较大重复 。  

４８  

第四章融合区域注意力的段落式图像描述模型  

在第四幅图中 ，针对Ｄｕａｌ

－ＣＮＮ生成的段落 ， 第

一句话描述了图片的主要对  

象飞机 （Ａ ｐ ｌａｎｅｉｓｏｎｔｈｅｒｕｎｗａｙ

． ） ，第二句话至第四句话描述了飞机的细节特征 ，  

一句话描述了天空 。而对于Ｈｉｅｍｒｃｈｉｃａｌ －ＲＮＮ生成的段落 ，第二句话和第三  

句话 、 第五句话和第六句话之间均有重复描述出现 。  

综上分析 ， Ｄｕａｌ －ＣＮＮ生成的段落具有以下优势 。 第

， 从注意力机制中受  

益 ，Ｄｕａｌ －ＣＮＮ生成了更细粒度的描述段落 ，其中的句子更加多样化 。作为对比 ，  

Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ生成的段落是冗余的且较粗粒度的 ， 其中许多句子重复相同的  

内容 。第二 ，得益于区域提议网络和区域注意力机制结合的强图像理解 ， 段落的  

描述更准确 ， 图像和段落的语义对齐程度更高 。 第三 ， Ｄｕａ丨 －ＣＮＮ可以发现

一些  

对象之间的位置关系 ， 例如

。此外 ， Ｄｕａｌ －ＣＮＮ 习  

惯于金字塔式的描述 ， 这延续了全卷积段落解码器的优点 。  

４ ．３本章小结  

本章将区域提议网络 、 区域注意力机制和全卷积段落解码器结合 ， 提出了  

Ｄｕａｌ －ＣＮＮ模型 。我们详细介绍了Ｄｕａｌ －ＣＮＮ的结构 ， 主要包括区域提议网络 、  

融合区域注意力的句子ＣＮＮ 。  

在实验验证部分 ，通过评测指标得分 、 多样度指标得分 、 区域注意力效果分  

析以及主观评价四个方面综合证明了Ｄｕａｌ －ＣＮＮ的优势 。  

４９  

第五章 总结与展望  

第五章总结与展望  

５．１工作总结  

本文对段落式图像描述任务开展研宄 。段落式图像描述任务旨在为给定图像  

生成连贯的段落描述 ， 当前的最佳方法基于层次性ＲＮＮ解码器 ， 其存在两个问  

题 ： （ ｌ ） ＲＮＮ长时记忆能力有限限制了生成段落的连贯性 ； （２ ） ＲＮＮ的时间序  

列结构导致模型训练的时间复杂度较高 。  

针对以上问题 ，本文的第

一项研究成果是提出了

一种全卷积段落解码器 ，利  

用了ＣＮＮ 的可并行化能力提高了训练效率 ， 并将门控模块引入

一个层次性的  

ＣＮＮ解码器中 ， 增强了解码器的长时记忆能力 。该解码器由句子ＣＮＮ解码器和  

词 ＣＮＮ解码器组成 。 句子 ＣＮＮ建模段落的整体关系 ， 为段落中的每句话生成  

一个多模态语义向量 ， 在多模态语义向量的指导下 ， 词ＣＮＮ为每句话生成其中  

的单词 。  

在实验验证部分 ， 本文在最新的斯坦福图像

－段落数据集上通过以下四种评  

判手段与若干基线方法进行对比与分析 ： （ １ ） 计算评测指标ＣＩＤＥｒ和 ＢＬＥＵ的  

得分 ； （２ ）提出了

一种衡量连贯性的指标 ，并根据指标得分衡量段落连贯性 ； （３ ）  

分析对比了全卷积段落解码器和Ｈｉｅｒａｒｃｈｉｃａｌ －ＲＮＮ的训练时间复杂度 ，记录并对  

比了训 和收敛所需的时间 ； （４ ）主观评定段落的连贯性 。经评测指标得分 、连  

贯性指标得分以及主观评测三项实验 ，我们得出结论 ，所提出的全卷积段落解码  

器较传统方法能够生成更连贯 、更类人的描述段落 ， 同时 ， 根据训练时间复杂度  

分析和实验 ， 可看出我们的方法拥有更短的训练时间 。  

本文的第二项研宄内容是增强模型对图像的理解能力 ，提高段落描述的详细  

程度和与图像语义的对齐程度 ，研宄成果是将区域提议网络 、区域注意力机制和  

全卷积段落解码器结合 ，提出了Ｄｕａｌ －ＣＮＮ模型 ，并同样通过四种实验方法证实  

了模型的有效性 ： （ １ ）计算评测指标ＣＩＤＥｒ、 ＢＬＥＵ和ＭＥＴＥＯＲ的得分 ； （２ ）  

一种计算段落内句子多样性的指标 ； （３ ）对区域注意力的效果进行可视化 ；  

（４ ）对段落进行主观质量评测 。 经分析 ， Ｄｕａｌ －ＣＮＮ提高了段落描述的详细程  

度 ， 生成了更高质量的段落 。  

５．２未来工作展望  

５０  

第五章 总结与展望  

段落式图像描述是

一项新兴的任务 ，除本文关注的问题之外 ， 仍有许多有趣  

而又充满挑战的方向值得探索 ，总的来说归结为两类探索 ，第

一类探索是增强图  

像理解 ，提高段落的描述颗粒度 ， 以及图像和段落的语义对齐程度 。第二类探索  

是增强段落的连贯性 。 我们未来的工作将集中于以下四个问题 ：  

（ １ ）考虑加入更多图像监督信息指导段落的生成 ， 如位置关系等 ， 以加强  

图像和段落的语义对齐 ， 提高描述的准确性。  

本文的Ｄｕａｌ ＿ＣＮＮ中的编码器采用区域提议网络 ，保证了图像中的许多对象  

都能被检测到 ，生成的段落较为详细 。然而 ， 图像中

一种重要的语义 ：对象间的  

关系 ， 不能被这种区域提议网络刻画出来 。 因此 ， 在描述中 ， 对于

一些物体间的  

位置关系描述不够准确 。近年来 ，

一种用深度学习方法表示传统数据结构

一一图  

的网络 ： 图神经网络 （ＧｒａｐｈｉｃＮｅｕｒａｌＮｅｔｗｏｒｋ ， ＧＮＮ）得到了广泛的应用 。 ＧＮＮ  

有较好的可解释性和表征性能 。 当ＧＮＮ对图像建模时 ， 可以通过边结构表示位  

置关系 。因而 ，我们将考虑使用ＧＮＮ ，增加更多监督信息输入到段落解码器中 ，  

以此提高段落中对位置关系的描述 。  

（２ ）增强段落连贯性 ， 例如学习判断两句话是否为连续的两句话 。  

在Ｄｕａｌ －ＣＮＮ中 ， 我们通过层次性的ＣＮＮ解码器对段落建模 ， 得到的段落  

已有较好的连贯性 。但

一些段落中 ，还出现有不连贯的情况下 ， 比如相邻的两句  

话读起来不像是两句相邻的话 。受此启发 ，我们考虑学习判断两句话是否为连续  

的两句话 。在训练时 ，从数据集中选取正例相邻句 ， 并从两个独立的段落中各抽  

一句话作为负例相邻句 ，通过让二分类的交叉熵损失函数学习两句话是否相邻 ，  

增强模型生成段落的连贯性 。  

（３ ）将强化学习方法与全卷积段落解码器结合 。  

本文所使用的损失函数为交叉熵损失 ，存在着优化自标和评价指标不

一致的  

问题 。 已经有工作将改进的策略梯度算法应用到段落式图像描述任务上 ， 证明了  

强化学习方法在该任务的有效性 。在接下来的工作中 ，我们也将进

一步尝试将策  

略梯度算法应用于我们的全卷积段落解码器上 ， 直接对 ＣＩＤＥｒ指标进行优化 ，  

一步提升模型的效果 。  

（４ ）如何全面量化衡量段落的连贯性  

衡量模型生成的段落的质量 ，最普遍的方法是用ＢＬＥＵ 、ＭＥＴＥＯＲ和ＣＩＤＥｒ  

等评价指标 ，但这些指标和人类评价仍存在着

一定的鸿沟 。有时得分高的段落的  

连贯性却很差 。如何量化段落的连贯性是自然语言处理中的

一个难题 ，虽然本文  

一种量化的方法且有

一定的说服力 ，但该衡量方式仍较为片面 ，仅从指代  

的角度进行了分析 。影响段落的连贯性的因素是多样的 ， 因此 ， 在接下来的研究  

中 ， 我们将研宄从更全面的角度分析段落的连贯性 。  

５ １  

参考文献  

参考文献  

［ １ ］ＤｅｎｇＪ， ＤｏｎｇＷ，Ｓ ｏｃｈｅｒＲ，ｅｔ ａｌ．Ｉｍａ ｇｅｎｅｔ：Ａｌａ ｒｇｅ－ｓｃａｌｅ ｈｉｅｒａｒｃｈｉｃａｌｉｍａｇｅｄａｔａ ｂ ａ

ｓｅ［Ｃ］／／２ ００ ９ＩＥＥＥｃｏｎｆｅｒｅｎｃｅｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａｔｔｅｒｎｒ ｅｃｏｇｎｉｔｉｏｎ．Ｉｅｅｅ ， ２

００９： ２４８－２５ ５．［

２］Ｈｅ  Ｋ ，

Ｚｈ ａｎｇＸ， ＲｅｎＳ，ｅｔ ａｌ．Ｄｅｅｐ ｒｅｓｉｄｕ ａｌｌｅａｒｎｉｎｇｆｏｒｉｍａｇｅｒｅｃｏｇｎｉｔｉｏｎ［Ｃ］／／Ｐｒｏｃｅｅ ｄｉ ｎ ｇｓ  ｏ

ｆｔｈｅＩＥＥＥｃｏｎｆｅｒｅｎｃｅｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａｔｔｅｒｎｒｅｃｏ ｇｎｉｔｉｏｎ．２０１６：７７０－７ ７ ８ ．

 ［３ ］Ｖａｓｗ

ａｎｉ Ａ ， Ｓ

ｈａ ｚｅｅｒＮ，Ｐａｒｍ ａｒＮ，ｅｔａｌ． Ａｔｔｅｎｔｉｏｎ ｉｓａｌｌ ｙｏｕｎｅｅｄ［Ｃ］／／Ａｄｖａｎｃｅｓｉｎｎ ｅｕ ｒａｌｉｎｆｏｒｍａ ｔ ｉ

ｏｎｐｒｏｃｅｓｓｉｎｇｓｙｓｔｅｍｓ ．２０１７：５９９８－６００８．［ ４］国务 院．新一

代人工  智 

能 发  展  规 

划  ［ Ｅ Ｂ ／ Ｏ Ｌ ］ ． ｈｔｔｐ ：

ｏｖ．ｃｎ／ｚｈｅｎｇｃｅ／ｃｏｎｔｅｎｔ／２０１７－０７／２０／ ｃｏ

ｎｔｅｎｔ＿５２１１９９６．

ｈｔｍ ． ２０ １７－７ － ２ ０

 ［５ ］Ｓ

ｔａｎ ｆ ｏ

ｒｄ Ｕｎｉｖｅｒｓｉｔｙ．＂Ａｒｔｉｆｉｃｉ

Ｉｎｔｅｌ ｌｉｇｅｎｃｅａｎｄＬｉｆｅｉｎ２０３０．＂ＯｎｅＨｕｎｄ ｒ

ｅ ｄＹｅａｒＳｔｕｄ ｙ 

ｏｎＡｒｔｉｆｉｃｉａｌＩｎｔｅｌ ｌｉｇｅｎｃｅ：Ｒｅｐｏｒｔｏｆ ｔｈｅ２０１５－２０１６Ｓｔｕｄ ｙ

Ｐａｎ ｅｌ［Ｃ／ＯＬ］．ｈｔｔ ｐ ：

／／ａｉ１ ０

０．ｓｔａｎ

ｆｏｒｄ． ｅｄｕ ／２０１６－ｒｅｐ ｏｒｔ．２０１ ６－

９－６．［ ６］Ｖｉ ｎｙ

ｓ Ｏ ， Ｔ

ｏｓ ｈｅｖＡ，Ｂｅｎｇｉ ｏＳ，ｅｔａｌ． Ｓｈｏｗａ ｎｄｔ ｅｌｌ：Ａｎ ｅｕｒａｌｉｍａｇｅｃａ ｐ ｔｉｏｎｇｅｎｅｒａｔｏｒ［Ｃ］／／Ｐｒｏｃ ｅ

ｄｉｎｇｓｏｆ ｔｈ ｅ ＩＥＥＥｃｏｎｆｅｒｅｎｃｅｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａｔｔｅｒｎｒｅｃｏｇｎｉｔｉｏ ｎ ．

２０１５：３１５６－３１６４．［７ ］Ｘｕ Ｋ， Ｂａ Ｊ，Ｋ

ｉｒ ｏｓ Ｒ ， ｅ

ｔ ａｌ．Ｓｈｏ ｗ，ａｔｔｅ ｎｄａｎｄｔｅ ｌｌ：Ｎｅｕｒ ａｌｉｍａ ｇｅｃａｐｔｉｏｎｇｅｎｅｒ ａｔｉｏｎｗｉｔｈｖｉｓｕａｌ ａｔｔｅ ｎ ｔ

ｉｏｎ［Ｃ］／／Ｉｎｔｅｒｎａｔｉｏｎａｌｃｏｎ ｆｅｒｅｎｃｅ ｏ ｎ ｍａｃｈｉｎｅｌｅａｒｎｉｎｇ．２０１５：２０４８－２０５７． ［ ８

］ＬｕＪ，Ｘｉ

ｏｎｇ Ｃ， Ｐａｒｉｋｈ

Ｄ，ｅｔ  ａ ｌ

．Ｋ ｎｏｗｉｎｇ ｗｈｅｎｔｏ ｌｏｏｋ：Ａｄａｐｔ ｉｖｅａｔｔ ｅｎｔｉｏｎｖｉａａｖｉｓｕａｌｓ ｅｎｔｉｎｅ ｌｆｏｒｉｍａｇｅｃａｐｔｉｏｎｉ ｎ ｇ

［Ｃ］／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥｃｏｎｆｅｒｅｎｃ ｅ ｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａｔｔｅｒｎｒｅｃｏｇｎ ｉ ｔ

ｉｏｎ．２０１７：３７５－３８３． ［９］ＭａｏＹ，ＺｈｏｕＣ，Ｗａｎｇ Ｘ，ｅ ｔ ａｌ．Ｓｈ ｏｗａ ｎ ｄ 

Ｔｅ ｌｌＭｏｒｅ ：Ｔｏｐｉｃ－Ｏ ｒｉｅｎｔｅｄ Ｍｕｌｔｉ－ ＳｅｎｔｅｎｃｅＩｍａｇｅＣａｐｔｉ ｏｎｉｎｇ ［Ｃ

］／／ＩＪＣＡＩ． ２ ０

１８：４２ ５８－４２６４．［１０］ＹｏｕＱ ，ＪｉｎＨ，Ｗａｎ ｇＺ，ｅｔ ａｌ．Ｉｍａ ｇｅｃａｐ ｔｉｏｎｉ ｎ ｇ 

ｗ ｉｔ ｈｓｅｍａｎ ｔｉｃａｔ ｔｅｎｔｉｏｎ［ Ｃ］／／Ｐｒｏ ｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ ｃｏｎｆｅｒｅｎｃｅ ｏ ｎ

ｃｏｍｐｕｔｅｒ ｖ ｉ ｓｉｏｎａｎｄｐａｔｔｅｒｎｒｅｃｏｇｎｉｔｉｏｎ．２０１６：４６５１－４６５９．［１１］Ｋａｒｐａｔｈｙ Ａ，Ｆｅｉ－Ｆ ｅ ｉ

Ｌ．Ｄｅｅｐｖｉｓ ｕａｌ－ ｓｅ ｍａｎｔｉ ｃ ａｌｉｇ ｎ ｍ ｅ

ｎ ｔ ｓ ｆｏｒｇｅｎｅｒａｔ ｉｎｇｉ ｍａｇｅ ｄｅｓｃｒｉｐｔｉｏｎｓ［ Ｃ］／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥｃｏｎｆｅｒｅｎ ｃｅｏｎ  ｃ

ｏｍｐｕｔｅｒ ｖｉｓｉ ｏｎ  ａｎｄｐａｔｔｅｒｎｒｅｃｏｇｎｉｔｉｏｎ．２０１５：３１２８－３１３７．

５２  

参考文献  

［ １２ ］ＡｎｄｅｒｓｏｎＰ， ＨｅＸ，Ｂ ｕｅｈｌｅｒＣ，ｅｔ ａｌ．Ｂｏｔ ｔｏｍ－ｕ ｐａ ｎｄｔｏｐ－ｄｏｗｎ

ａｔｔｅｎｔｉｏｎｆｏｒｉｍａｇｅｃａｐ ｔ ｉ

ｏｎｉ ｎｇａｎｄｖｉｓｕａｌｑｕｅｓｔｉｏｎａｎｓｗｅｒｉｎｇ［Ｃ］／／Ｐｒ ｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥｃｏｎ ｆ ｅ

ｒｅｎｃｅｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａｔｔ ｅｒｎｒｅｃｏｇｎｉｔｉｏｎ．２０１８ ：６０７ ７－ ６０８６．

［１３］ Ｃ ｈ ｅ

ｎ Ｌ ，ＺｈａｎｇＨ

，ＸｉａｏＪ，ｅ ｔａｌ．Ｓｃａ －ｃｎｎ：Ｓｐ ａｔｉａｌ ａｎｄ ｃｈａｎｎｅｌ－ｗｉｓｅａｔｔｅｎｔｉ ｏｎｉｎｃｏｎｖｏｌｕｔｉｏｎ ａ ｌ

ｎｅｔｗｏｒｋｓｆｏｒｉｍａｇｅｃａｐｔｉｏｎｉｎｇ［Ｃ］／／Ｐ ｒｏｃｅｅｄｉｎｇ ｓ ｏｆｔｈｅＩＥＥＥｃｏｎｆｅｒｅｎｃｅ ｏ ｎ

ｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａｔｔｅｒｎｒｅｃｏ ｇｎｉｔｉｏｎ．２０１７：５６５９－５６ ６７． ［ １４］Ｒｅｎ ｎｉｅＳ  Ｊ ，

Ｍ ａｒ ｃｈｅｒｅｔＥ，Ｍｒｏ ｕｅｈＹ，ｅｔａｌ．Ｓ ｅｌｆ－ｃｒｉｔｉｃ ａｌｓｅｑｕ ｅｎｃｅｔ ｒａｉｎｉｎｇｆｏｒｉｍａｇｅｃａｐｔｉｏｎｉｎｇ［Ｃ ］ ／

／Ｐｒｏｃｅｅｄｉ ｎｇｓｏｆｔｈ ｅ ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎ ｉ ｔ

ｉｏｎ．２０１７：７００８－７０２４．［１ ５］Ｅｌ ｌｉ ｏｔｔＤ， Ｋｅｌｌｅ ｒ  Ｆ

． Ｉｍ ａｇｅｄ ｅｓｃｒｉｐ ｔｉｏｎｕｓｉｎｇｖｉｓｕａｌｄｅｐｅｎ ｄｅ ｎｃｙｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ［Ｃ］／／Ｐｒｏ ｃ ｅ

ｅｄｉｎｇｓｏｆｔｈｅ２ ０１ ３ＣｏｎｆｅｒｅｎｃｅｏｎＥｍｐｉｒｉｃａ ｌＭｅｔｈｏｄｓｉｎＮａｔｕｒａ

ｌＬａｎｇｕａｇｅＰｒｏ ｃ ｅ

ｓｓｉｎｇ．２０１３：１２９２－１３０２．［１６］Ｋｕｌ

ｋａｍｉ Ｇ ，Ｐｒｅｍｒ

ａ ｊＶ， Ｏ ｒ ｄ

ｏ ｎｅ ｚＶ，ｅｔａｌ．Ｂａｂｙｔａｌｋ： Ｕｎｄ ｅｒｓｔａｎｄｉｎｇ

ａｎｄｇｅ ｎｅｒａｔｉ ｎｇｓ ｉｍｐｌｅｉｍａｇｅ ｄｅｓｃｒｉｐ ｔ ｉ

ｏｎｓ［Ｊ］．ＩＥＥＥＴｒａ

ｎｓａｃｔｉｏｎｓｏｎＰａｔ ｔｅｒｎ Ａｎ ａ

ｌｙｓｉｓａｎｄＭａｃｈｉｎｅＩｎｔｅｌｌｉ ｇｅｎｃｅ，２０１３，３５ （ １

２）：２８９１－２９０３．［１７ ］Ｋｕｚｎｅｔｓｏｖ ａ Ｐ，Ｏｒｄ ｏｎｅ ｚＶ，Ｂ ｅ ｒｇＴ Ｌ ， ｅ

ｔ ａ ｌ．Ｔｒｅｅｔａｌｋ：Ｃｏｍｐｏｓｉｔｉｏｎａｎ ｄｃｏｍｐｒｅｓ ｓｉｏｎｏｆ ｔｒｅｅｓｆｏｒ ｉｍａｇｅｄｅｓｃｒｉｐｔｉｏ ｎ ｓ

［Ｊ］．ＴｒａｎｓａｃｔｉｏｎｓｏｆｔｈｅＡｓｓｏｃｉａｔｉｏｎｆ ｏｒＣｏ ｍｐ ｕ

ｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ，２０１４，２：３５１－３ ６ ２

．［１８］ＭｉｔｃｈｅｌｌＭ，Ｈ ａｎＸ，Ｄｏｄｇｅ Ｊ，ｅ ｔａｌ． Ｍｉｄｇ ｅ ：Ｇｅｎ ｅ ｒ ａ

ｔ ｉｎ ｇｉｍａｇｅｄ ｅｓｃ ｒｉｐｔｉｏｎ ｓｆｒｏｍｃ ｏｍｐｕｔｅｒ ｖｉ ｓｉｏｎ ｄｅｔｅｃｔｉｏｎｓ［Ｃ

］／／Ｐｒｏｃｅｅｄｉ ｎｇ ｓｏｆｔｈｅ１ ３ ｔ

ｈＣｏｎｆｅｒｅｎｃｅｏｆｔｈｅＥｕｒｏｐ ｅａ ｎ ＣｈａｐｔｅｒｏｆｔｈｅＡｓｓｏｃｉａｔｉｏｎｆｏｒＣｏｍｐｕｔａｔｉｏｎ ａ ｌ

Ｌｉｎｇｕｉｓｔｉｃｓ． ＡｓｓｏｃｉａｔｉｏｎｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇ ｕｉｓｔｉｃｓ，２０１２：７４７－ ７５６．［ １９］Ｙａｎ ｇ 

Ｙ，ＴｅｏＣＬ，ＤａｕｍｅⅢＨ ，ｅｔａｌ．Ｃｏｒ ｐｕｓ－ ｇｕ ｉｄｅｄ ｓｅｎｔ ｅ ｎ ｃ

ｅ ｇ ｅｎｅｒａｔｉｏ ｎｏｆｎａｔｕｒａｌｉｍａｇｅ ｓ［Ｃ ］／／Ｐｒｏｃ ｅｅｄｉｎｇｓ ｏ ｆｔｈｅＣｏｎｆｅｒｅｎｃｅｏｎＥｍｐ ｉｒｉｃａｌ  Ｍ

ｅｔｈｏｄｓｉｎＮａｔ ｕｒ ａ ｌＬａｎｇｕａｇ ｅＰｒｏｃｅｓｓｉｎｇ．Ａｓｓｏｃｉａｔｉｏｎｆｏｒ ＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎ ｇ ｕ

ｉｓｔｉｃｓ，２０１］：４４４－４５４．［２０

］Ｆａｒｈａｄ ｉＡ，ＨｅｊｒａｔｉＭ，ＳａｄｅｇｈｉＭＡ，ｅｔａｌ．Ｅｖｅｒ ｙｐｉ ｃｔｕ ｒ ｅ 

ｔｅｌ ｌｓａ  ｓ ｔ

ｏｒｙ ：Ｇｅｎｅｒａｔｉｎｇ ｓｅｎｔｅｎｃｅｓ ｆｒｏｍｉｍａｇｅｓ［ Ｃ］／／Ｅｕｒ ｏｐｅａｎｃｏｎ ｆｅｒｅｎｃｅｏｎｃｏｍｐｕｔｅｒ

ｖｉｓｉｏｎ．Ｓｐｒｉｎ ｇ ｅ

ｒ，Ｂｅｒｌｉｎ，Ｈｅｉｄｅｌｂｅｒｇ ，２ ０１０：１５－２９．［２１］ＨｏｄｏｓｈＭ，ＹｏｕｎｇＰ，Ｈｏｃｋｅｎｍａ ｉｅｒＪ．Ｆｒａｍ ｉ ｎ ｇ

ｉｍａｇｅ ｄｅｓｃｒｉｐｔｉｏｎａｓ ａ ｒａｎｋ

ｉｎｇ   ｔ

ａｓ ｋ ：Ｄａｔａ，ｍｏｄｅ ｌｓａｎｄｅｖ ａｌｕａｔｉｏｎｍｅｔｒｉｃ ｓ［Ｊ］．Ｊｏｕｒｎ ａｌｏｆＡｒｔｉｆｉｃｉａｌＩｎｔｅｌｌｉｇｅｎｃｅ  Ｒ

ｅｓｅａ ｒｃｈ，２０ １３，４７：８５３－８９９．

５３  

参考文献  

［２２ ］ＳｏｃｈｅｒＲ， ＫａｒｐａｔｈｙＡ，Ｌ ｅＱＶ，ｅｔ ａｌ．Ｇｒｏ ｕｎｄｅｄｃｏｍｐｏｓｉｔｉｏｎａｌｓｅｍａｎｔｉｃｓｆｏｒｆｉｎ ｄ ｉ

ｎｇａｎｄｄｅｓｃｒｉｂｉｎｇｉｍａｇｅ ｓｗｉｔｈｓｅｎｔｅｎｃｅｓ［Ｊ］．Ｔ ｒａ ｎ

ｓａｃｔｉｏｎｓｏｆｔｈｅＡｓｓｏｃｉａｔｉｏｎｆｏｒ Ｃ ｏ

ｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ，２０１４， ２：２０ ７－ ２１ ８．［

２３ ］Ｇ ｏ ｎ ｇ

Ｙ， ＷａｎｇＬ，ＨｏｄｏｓｈＭ，

ｅｔａｌ．Ｉｍｐｒ ｏｖｉｎｇｉ ｍａｇｅ－ｓｅｎｔｅｎｃ ｅｅｍｂ ｅｄｄｉｎｇｓｕｓｉｎｇｌａｒｇｅｗｅａｋｌ ｙ 

ａｎｎｏｔａｔｅｄｐｈｏｔｏｃｏｌｌｅｃ ｔｉｏｎｓ［Ｃ］／／Ｅｕｒｏｐｅａｎ ｃ ｏ ｎｆｅｒｅｎｃｅｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎ．Ｓｐｒｉ ｎ ｇ

ｅｒ，Ｃｈａ ｍ，２０１ ４：５２９ －５４５．

［２４ ］Ｏ ｒｄｏｎｅ ｚＶ， Ｋ ｕ ｌ

ｋａｒ ｎｉＧ，ＢｅｒｇＴ

Ｌ．Ｉｍ２ｔｅｘｔ： Ｄｅｓｃｒｉｂｉｎｇ ｉｍａｇｅｓｕ ｓｉｎｇ１ｍｉｌｌｉｏ ｎｃａｐｔｉｏｎｅｄ ｐｈｏｔｏ ｇｒａｐ ｈ ｓ

［Ｃ］ ／／Ａｄｖａｎｃｅｓｉｎｎｅｕｒ ａｌ ｉｎｆｏｒｍａｔｉｏｎｐｒｏｃｅｓｓｉｎｇｓｙｓｔｅｍｓ．２０１１：１１４３－１１５１．［ ２ ５ ］

Ｒｅｎ  Ｓ，Ｈ ｅＫ ， Ｇ ｉｒ ｓ ｈ ｉ ｃ

ｋＲ ，ｅｔａｌ． Ｆａｓｔｅｒ ｒ－ ｃｎｎ：Ｔｏｗａｒ ｄｓｒｅａｌ －ｔｉｍｅｏｂｊｅ

ｃｔｄ ｅｔｅｃｔｉｏｎｗｉｔｈ ｒｅｇｉｏｎ ｐｒｏｐｏｓａｌｎｅｔｗｏ ｒ ｋ

ｓ［Ｃ］／／Ａｄ

ｖａｎｃｅｓｉｎｎｅｕｒａｌｉｎｆｏ ｒｍ ａ ｔｉｏｎｐｒｏｃｅｓｓｉｎｇｓｙｓｔｅｍｓ．２０１５：９１－９９．［２６］Ｐ ａ ｐ

ｉｎｅｎｉＫ ，Ｒｏｕ ｋｏ ｓＳ ，

Ｗａｒ ｄ  Ｔ

，ｅｔ ａｌ．Ｂ

ＬＥＵ：ａｍ ｅｔｈｏｄｆｏｒ ａｕｔｏｍａｔｉ ｃｅｖａｌｕ ａｔｉｏｎ ｏｆｍａｃｈｉｎｅｔｒａｎｓｌａｔｉｏｎ［Ｃ］／／Ｐｒｏｃｅｅｄ ｉ ｎ

ｇｓｏｆｔｈｅ４０ｔｈａｎｎｕａｌ ｍｅ ｅ ｔｉｎｇｏｎａｓｓｏｃｉａｔｉｏｎｆｏｒｃｏｍｐｕｔａｔｉｏｎａｌｌｉｎｇ ｕ ｉ

ｓｔｉｃｓ．ＡｓｓｏｃｉａｔｉｏｎｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇ ｕｉｓｔｉｃｓ，２００２：３１１－３１８．［２７］Ｄｅｎｋ ｏ ｗ

ｓｋｉＭ，Ｌａｖｉｅ Ａ．Ｍｅｔ ｅｏｒ  ｕ

ｎｉ ｖｅ ｒ ｓ ａ

ｌ：Ｌ ａｎｇｕａｇｅｓｐｅｃｉ ｆｉｃｔｒａｎｓ ｌａｔｉｏｎｅｖａｌｕａｔｉｏｎ ｆｏｒａｎｙｔａｒｇｅｔｌ ａｎｇｕａｇｅ［Ｃ］／／Ｐｒ ｏ ｃ

ｅｅｄｉｎｇｓｏｆｔｈｅｎｉｎｔ ｈｗｏｒｋｓｈｏｐｏｎ ｓｔ ａｔｉｓｔｉｃａｌｍａｃｈｉｎｅｔｒａｎｓｌａｔｉｏｎ．２０１４：３７６－ ３ ８

０．［２８］ＶｅｄａｎｔａｍＲ，ＬａｗｒｅｎｃｅＺｉｔ ｎｉｃｋ Ｃ ，Ｐａｒｉ ｋｈＤ ． Ｃ ｉ

ｄｅｒ ：Ｃｏｎｓｅｎｓｕｓ－ｂ ａｓｅｄｉｍａｇｅｄｅｓｃｒｉｐｔ ｉｏｎｅｖａｌｕａ ｔｉｏｎ［Ｃ］ ／／Ｐｒｏｃｅｅｄｉｎ

ｇｓｏｆｔｈｅＩＥ

ｃｏｎｆｅｒ ｅｎｃｅｏｎｃｏｍｐｕｔｅ ｒ ｖｉｓｉｏｎａｎｄｐａｔｔｅｒｎｒｅｃｏｇｎｉｔｉｏｎ．２０１５：４５６６－４５７５． ［ ２

９］Ｊｏｈｎｓｏｎ Ｊ，Ｋａ ｒｐａｔｈｙＡ，Ｆｅｉ－Ｆｅｉ Ｌ．Ｄｅｎ ｓｅｃａｐ：

Ｆｕｌｌｙ  ｃ ｏ

ｎｖｏ ｌｕｔｉｏｎａｌｌｏ ｃａｌｉｚａｔｉｏｎ ｎｅｔｗｏ ｒｋｓｆｏ ｒｄｅｎｓｅｃａ

ｐｔｉｏｎｉｎｇ［Ｃ］／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥ

ＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ  ａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ．２０１６：４５６５－４５７４．  

［３０］ＫｒａｕｓｅＪ，ＪｏｈｎｓｏｎＪ， ＫｒｉｓｈｎａＲ，ｅｔａｌ． Ａｈｉ ｅｒ ａｒｃｈｉｃ

ａｌａｐ ｐ ｒ ｏ

ａｃｈ ｆｏｒｇｅｎｅｒ

ａｔｉｎｇｄｅｓｃ ｒｉｐｔｉｖｅｉｍａ ｇｅｐａｒａ ｇｒａｐｈｓ［Ｃ］／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥｃｏｎｆｅ ｒ ｅ

ｎｃｅｏｎ ｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄ

ｐａｔ ｔ ｅｒｎｒｅｃｏｇｎｉｔｉｏｎ．２０１７：３１７－３２５．［３１］Ｓｉｍｏ ｎ ｙ

ａｎＫ，ＺｉｓｓｅｒｍａｎＡ．Ｖｅ ｒｙｄ ｅｅｐｃｏｎｖｏｌｕｔｉｏｎａ ｌｎｅ ｔｗ ｏｒｋ ｓ ｆｏｒ ｌ ａ ｒ

ｇｅ － ｓｃａｌｅｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ［ Ｊ］．ａｒＸｉｖｐｒｅｐｒｉｎｔａｒＸｉｖ：１４０９．１５５６，２０１４［３２］

Ｌｉａｎｇ Ｘ ，

ＨｕＺ，ＺｈａｎｇＨ ，ｅｔａｌ． Ｒ

ｅｃｕｒｒｅｎ ｔｔｏｐｉｃ－ｔｒａｎｓｉｔ ｉｏｎｇａ ｎ ｆｏｒ ｖｉｓ ｕａ ｌ 

ｐａ ｒａｇｒａｐｈｇ ｅｎｅｒａｔ ｉ ｏｎ［Ｃ］／／ Ｐｒｏｃｅｅｄ ｉｎｇｓｏｆｔｈｅＩＥＥ Ｅ

Ｉ ｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏ ｎ 

ＣｏｍｐｕｔｅｒＶｉｓｉｏｎ．２０１ ７： ３３６２－３３７１．

５４  

参考文献  

［３３ ］ＧｏｏｄｆｅｌｌｏｗＩ， Ｐｏｕｇｅｔ－Ａ ｂａｄｉｅＪ，Ｍ ｉｒｚａＭ，ｅｔ ａｌ．Ｇｅｎ ｅｒａｔｉｖｅａｄｖｅｒｓａｒｉａｌ ｎｅｔ ｓ ［

Ｃ］／／ Ａｄ ｖａｎｃｅｓｉｎｎｅｕｒａｌｉｎｆｏｒｍａｔｉｏｎｐｒｏｃ ｅｓｓｉｎｇｓｙｓｔｅｍｓ．２０１４ ：２６７２－ ２６８０． ［３４］ Ｃ ｈ ａ

ｔｔｅ ｒｊｅｅＭ，Ｓｃ ｈｗｉｎｇ ＡＧ．Ｄｉｖｅｒｓｅ ａｎｄｃｏｈｅｒｅｎｔｐａｒａｇｒａｐｈｇｅｎｅｒａｔｉｏｎｆｒｏｍｉｍａｇｅｓ［Ｃ ］ ／

／Ｐｒｏｃｅ ｅｄ ｉ ｎｇｓｏｆｔｈｅＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ（ＥＣＣＶ）．２ ０ １

８：７２９－

７４４．  ［３５］Ｗ ａｎｇ Ｚ ， Ｌ

ｕｏ Ｙ，ＬｉＹ，ｅ ｔａｌ．Ｌｏ ｏｋｄｅｅ ｐｅｒｓｅｅ ｒｉｃｈｅｒ：Ｄｅｐｔｈ－ａｗａｒｅｉｍａｇ ｅｐａｒａ

ｇｒａｐｈｃａｐｔｉｏ ｎ ｉ

ｎｇ［Ｃ］／／Ｐｒｏｃｅｅ ｄｉｎｇｓｏｆ ｔ ｈｅ２６ｔｈＡＣＭｉｎｔｅｒｎａｔｉｏｎａｌｃｏｎｆｅｒｅｎｃ ｅｏｎＭｕｌｔｉｍｅｄｉａ．２０ １ ８

：６７２－６８０．［３ ６］Ｃｈ ｅ Ｗ，Ｆａｎ Ｘ，Ｘ ｉ ｏ ｎ

ｇＲ ，ｅｔａｌ． Ｐａｒａｇｒａ ｐｈｇｅｎｅｒａ ｔｉｏｎｎｅ ｔｗｏｒｋｗｉｔｈｖｉｓｕａｌｒｅｌａｔｉｏｎｓｈｉｐｄｅｔｅｃｔｉｏｎ［ Ｃ ］

／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２ ６ｔ ｈ ＡＣＭｉｎｔｅ ｒｎａｔｉｏｎａｌｃｏｎｆｅｒｅｎｃｅｏｎＭ ｕｌｔｉｍｅｄｉａ．２０１８：１４３５ － １

４４３．［３７］Ｍｅｌ ａｓ－Ｋ ｙｒ ｉａｚｉＬ ， Ｒｕｓｈ  Ａ 

Ｍ，Ｈ ａｎＧ．Ｔｒ

ａｉｎｉｎｇｆｏｒ ｄｉｖｅｒｓｉｔｙ ｉｎｉｍａ ｇｅｐａｒａ ｇｒａｐｈｃａｐｔｉｏｎｉｎｇ［

Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆ  ｔ

ｈｅ ２０１８Ｃｏｎｆ ｅ ｒｅｎｃｅｏｎＥｍｐｉｒｉｃａｌＭｅｔｈ ｏｄｓｉｎＮａｔｕｒａｌＬａｎｇ

ｕａｇｅＰｒｏｃｅｓｓｉｎｇ．２ ０ １

８：７５７－７６１．［３８］Ｈｏｃｈｒｅｉｔｅｒ

Ｓ，Ｓｃ ｈｍ ｉｄｈｕｂ ｅｒ Ｊ ． Ｌ ｏ

ｎｇ ｓｈｏｒｔ－ｔｅｒｍｍｅｍ ｏｒｙ［Ｊ］ ．Ｎｅｕｒａｌｃ ｏｍｐｕｔａｔｉｏｎ， １９９７，９（８）：１ ７３ ５

－１７８０．［３９］ＣｈｏＫ，Ｖａｎ  Ｍ

ｅｒｒｉ ｅｎｂ ｏｅ ｒ

Ｂ，Ｇｕｌ

ｃ ｅｈｒｅ  Ｃ ，

ｅｔ ａｌ．Ｌｅａｒ ｎｉｎｇｐｈｒａｓ ｅｒｅｐｒｅｓｅ ｎｔａｔｉｏｎｓｕｓ ｉｎｇＲＮＮ ｅｎｃｏｄｅｒ－ｄｅｃｏｄｅｒｆｏｒｓｔａｔｉｓｔｉｃａｌ ｍ ａ

ｃｈｉｎｅｔｒａｎｓｌａｔｉｏｎ ［Ｊ］．ａｒＸｉｖｐｒｅｐｒｉｎｔａｒＸｉｖ：１４０６．１０７８，２０１４．［４０

］ＬｅＣｕ ｎＹ，Ｂｏｔｔｏｕ Ｌ ，

Ｂｅｎ ｇｉ ｏＹ，ｅｔ  ａｌ．Ｇ ｒａｄｉ ｅｎ ｔ － ｂ

ａｓｅ ｄｌｅａｒｎｉｎ ｇａｐｐｌｉｅｄ ｔｏｄｏｃ

ｔｒｅｃｏ ｇｎｉｔｉｏｎ［Ｊ］ ．Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ

 ＩＥＥＥ，１９９８，８６（１１ ） ：

２２７８－２ ３２４． ［ ４

１］Ｋｒｉｚｈｅｖ ｓｋｙＡ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｈｉｎｔ ｏｎＧ  Ｅ ． Ｉ ｍａｇｅｎｅ ｔｃｌａ ｓ ｉ

ｆｉ ｃ ａｔｉｏｎｗｉｔｈｄｅｅ ｐｃｏｎｖｏｌｕｔｉｏ ｎａｌ ｎｅｕｒａｌｎ ｅｔｗｏｒｋｓ［Ｃ］／／Ａｄｖａｎｃ ｅｓｉｎｎｅｕ ｒａｌｉｎｆｏ ｒ ｍ

ａｔｉｏｎｐｒｏｃｅｓｓｉｎｇｓｙｓｔｅｍｓ．２０１ ２： １０９７－１１０５．［４２］ＳｚｅｇｅｄｙＣ，ＬｉｕＷ，Ｊｉａ Ｙ，ｅｔ ａｌ． Ｇ ｏ

ｉｎｇｄｅｅ ｐｅｒ ｗｉ ｔｈｃｏｎ ｖ ｏ ｌｕｔ ｉ ｏ ｎ

ｓ［Ｃ ］／／Ｐｒｏｃｅｅｄｉ ｎｇｓｏｆ ｔｈ ｅＩＥ ＥＥｃｏｎｆ ｅｒｅｎ ｃｅｏｎｃｏｍｐｕｔｅｒｖｉｓｉｏｎａｎｄｐａ ｔｔ ｅ ｒｎｒｅｃｏｇｎｉｔｉｏ ｎ ．

２０１５：１－９．［４３］ＧｌｏｒｏｔＸ，ＢｏｒｄｅｓＡ，ＢｅｎｇｉｏＹ．Ｄｅｅ ｐｓｐ ａｒｓｅｒｅｃｔｉｆｉｅｒｎ ｅｕｒａ ｌ ｎｅ

ｔｗ ｏ ｒ ｋ

ｓ［Ｃ ］／／Ｐｒｏｃｅｅｄ ｉｎｇｓｏｆｔｈ ｅｆｏｕｒ ｔｅｅｎｔｈｉｎｔｅｒｎａｔｉｏｎａｌｃｏｎ ｆｅｒｅｎｃｅｏｎ  ａ

ｒｔｉｆｉｃｉａ ｌ  ｉｎｔｅｌｌｉｇｅｎｃｅａｎｄｓｔａｔｉｓｔｉｃｓ．２０１１：３１５－ ３２３．［４４］ＢａｈｄａｎａｕＤ，ＣｈｏＫ，Ｂ ｅｎｇｉｏ  Ｙ

．Ｎｅｕｒａ ｌｍａｃｈｉｎｅｔｒａｎｓｌａｔｉｏｎ ｂｙ ｊ ｏ ｉｎｔ ｌｙ

ｌｅａ ｒ ｎ ｉ

ｎｇ ｔｏａｌｉｇｎａｎ ｄｔｒａｎｓ ｌａｔｅ［Ｊ ］．ａｒＸｉｖｐｒｅｐｒｉｎｔａｒＸｉｖ：１４０９．０４７３，２０１４．［４５］

ＬｕｏｎｇＭＴ ，Ｐ ｈ ａ

ｍＨ，ＭａｎｎｉｎｇＣＤ．Ｅｆｆｅｃ

ｔｉｖｅ ａｐ ｐｒｏａｃｈｅｓｔｏａｔｔ ｅｎｔｉｏｎ －ｂａｓｅｄｎ ｅｕ ｒ ａ ｌ

ｍａ ｃｈｉｎｅｔｒａｎｓ ｌａｔｉｏｎ［Ｊ ］．ａｒＸｉｖｐｒｅｐｒ ｉｎｔａｒＸｉｖ：１５０８．０４０２５，２０１５．

５５  

参考文献  

［４６ ］ＫｒｉｓｈｎａＲ， ＺｈｕＹ，Ｇ ｒｏｔｈＯ，ｅｔ ａｌ．Ｖｉｓ ｕａｌｇｅｎｏｍｅ：Ｃｏｎｎ ｅｃｔｉｎｇｌａｎｇｕａ ｇｅａｎｄｖｉｓｉ ｏ ｎ

ｕｓｉｎｇｃｒｏｗｄｓｏｕｒｃｅｄｄｅｎｓｅｉｍａｇｅａｎｎｏｔａｔｉｏｎｓ［Ｊ］．Ｉｎ ｔｅ ｒ

ｎａｔｉｏｎａｌＪｏｕｒｎａｌｏｆＣｏｍｐｕ ｔ ｅ

ｒＶｉｓｉｏｎ，２０１７，１ ２３（１ ）： ３２－７３ ．  

Ｃｈｅ ｎ  Ｘ

，Ｆａ ｎｇＨ，Ｌｉｎ ＴＹ，ｅｔ ａｌ．Ｍｉｃｒｏｓ ｏｆｔｃｏｃ ｏｃａｐｔｉｏｎｓ ：Ｄａｔａｃｏｌｌ ｅｃｔｉｏ ｎａｎｄｅｖａ ｌｕａｔｉｏｎｓｅｒ ｖ ｅ

ｒ［Ｊ］．ａｒＸｉｖｐｒｅｐｒｉ ｎｔ 

ａｒＸｉｖ：１ ５０４．００３２５，２０１５． ［４８］ Ａｎｅｊａ Ｊ ，Ｄ ｅｓ ｈ ｐ ａ

ｎｄｅ Ａ，Ｓｃ ｈｗｉｎ ｇＡＧ．Ｃｏｎｖｏｌｕ ｔｉｏｎａｌｉｍａｇｅ ｃａｐｔｉｏｎｉｎｇ［Ｃ］／／Ｐｒｏｃｅ ｄ

ｉｎｇ ｓｏｆｔｈ ｅＩＥ ＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ．２ ０ １

８：５６１－５５７０．［４９］Ｗ ａｎｇＱ， Ｃｈａｎ Ａ Ｂ．Ｃｎ ｎ ＋ ｃ

ｎｎ： Ｃｏｎｖｏｌｕｔ ｉｏｎａｌｄｅｃｏ ｄｅｒｓｆｏｒｉ ｍａｇｅｃａｐｔｉｏｎｉｎｇ［Ｊ］．ａｒＸｉｖｐｒｅｐｒｉｎｔａｒＸｉｖ：１８０５． ０

９，２ ０１８．［５０］Ｄａｕｐｈｉｎ  ＹＮ， ＦａｎＡ， ＡｕｌｉＭ ， ｅ ｔ

ａｌ ．Ｌａｎｇｕａｇｅｍｏｄ ｅｌｉｎｇｗ ｉｔｈｇａｔｅ ｄｃｏｎｖｏ ｌｕｔｉｏｎａｌｎｅｔｗｏｒｋｓ［Ｃ］／／Ｐ ｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ３４ ｔ ｈ

Ｉｎｔｅｒｎａ ｔｉ ｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＭａｃｈｉｎｅＬｅａｒｎｉｎｇ－Ｖｏｌｕｍｅ７０．ＪＭＬＲ．ｏｒｇ，２０１７：９ ３

－９４１．［

５１］Ｐａｓｚｋｅ Ａ，Ｇｒｏｓ ｓＳ，Ｃ ｈｉｎｔａｌ ａＳ，ｅ ｔａｌ ． Ａ ｕ

ｔｏ ｍ ａｔｉｃｄｉｆｆｅ ｒｅｎｔｉａｔｉｏ ｎｉｎｐｙｔｏｒｃｈ ［Ｊ］．２ ０１７．

５６  

致谢  

致谢  

天波易谢 ，寸暑难留 。伴随着二〇二〇年夏天的到来 ，我也即将要向学生生  

涯和北京邮电大学说

一声再见 。 北邮不仅是我攻读硕士学位 、 努力奋斗的地方 ，  

一个温暖的家 。三年前 ，我带着些许彷徨孤身

一人来到北京求学 ，面对我的  

是无限的未知和可能性 。 在这期间 ， 我成长了许多 、收获了许多 ， 也留下了无限  

美好的回忆 。在此 ， 我谨向教育 、帮助 、鼓励过我的人们 ，表达我最诚挚的感谢  

和最深切的祝福 。  

首先 ，感谢我的导师李睿凡老师 ， 您严谨的治学态度 、渊博的专业知识 、开  

阔的科研思路无时无刻地影响着我。在初入学术大门时 ，您教会我科研的思路和  

方法 ， 让我快速进入到跨模态研宄的轨道上 。在决定选题方向时 ，您给予我自由  

的研究空间 ， 让我选择自己感兴趣的方向 。在课题研究陷入瓶颈时 ， 您给我继续  

前进的鼓励 。 在撰写英文小论文时 ， 您告诉我论文的要领 ，还逐字逐句地和我交  

流论文的修改 ，您对科研的投入和认真深深折服了我 。您是我学习和科研的导师 ，  

更是我生活的老师 。在生活中 ，您风趣幽默 、平易近人 ，对我们无微不至地关怀 ，  

并时常以点带面告诉我们人生的经验和道理 。 再次向老师表达我最诚挚的感谢 ！  

感谢王小捷老师 ，您始终把我们当成自己的学生

一样看待 ，在科研和生活上  

毫无保留地帮助我们 。在您的计算语言学课程上 ， 您用生动的讲述带我们进入  

ＮＬＰ的世界 。 在认知组会上 ， 您指导我完善论文的实验分析 ， 让我理清思路 。  

您学术上的高深造诣让我受益匪浅 ， 谢谢您 ！  

感谢智能实验室的老师和同学 。 感谢石祎晖师弟 ， 在图像描述任务研宄上 ，  

和你的交流帮助了我许多 。感谢我的舍友们 ， 感谢你们对我的帮助 ， 我们

一起度  

过了美好的研宄生时光 。  

一直互相陪伴的侯俊旭同学 ， 感谢你对我的支持和帮助 。  

谁言寸草心 ，报得三春晖 。感谢我的父亲母亲对我的养育之恩和对我学业的  

支持 。母亲常说 ：

“ 我们是你最坚强的后盾

。有了这句话 ，我便义无反顾地前行 。  

人生接下来的日子 ， 我会努力报答你们 ， 让你们幸福 。  

５７  

攻读学位期间取得的研究成果  

攻读学位期间取得的研究成果  

［ １ ］ＬｉＲ ，Ｌ ｉａｎｇＨ

，ＳｈｉＹ ，ＦｅｎｇＦ ，ＷａｎｇＸ ．Ｄｕａｌ －ＣＮＮ ：ＡＣｏｎｖｏｌｕｔｉｏｎａｌＬａｎｇｕａｇｅ  

ＤｅｃｏｄｅｒｆｏｒＰａｒａｇｒａｐｈＩｍａｇｅＣａｐ ｔｉｏｎｉｎｇ［Ｊ ］

．Ｎｅｕｒｏｃｏｍｐｕｔｉｎｇ ，ＤＯＩ ：  

１０ ． １０ １６／ ｊ

．ｎｅｕｃｏｍ ．２０２０ ．０２ ．０４ １ ， ２０２０ ．０２（ＳＣＩ期刊 ）  

［２ ］ 李睿凡 ，梁昊雨 ， 冯方向 ，张光卫 ， 王小捷 ．基于全卷积神经结构的段落式  

图像描述算法 ［Ｊ ］

． 北京邮电大学学报 ， ２０ １９ ，４２（６ ）

－ １６ＬＤＯＩ ：  

０ ． １０ ． １３ １９０／ｊ

． ｊｂｕｐ ｔ ．２０ １９ －０５７ ，２０ １９ ． １２（ＥＩ期刊 ）  

５８  