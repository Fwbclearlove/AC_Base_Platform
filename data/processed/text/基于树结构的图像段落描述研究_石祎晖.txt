密级
：
保密期限
：


嫌意，翁夂壤


硕士学位论文


题目
：
基于树结构的图像段落描述研究


学号
：２０１９１１０６６０


姓名
：
石祎晖


专业
：智能科学与技术


导师
：
李睿凡


学院
：人工智能学院


２０２２年
６
月
１
曰


中屆
■北京


密级
：保密期限
：


分丈却索大聲


硕士学位论文


義


题目
：
基于树结构的图像段落描述研究


学号
：
２０１９１１０６６０


姓名
：
石祎阵


专业
：
智能科学与技术


导师
：
李睿凡


学院
：
人工智能学院


２０２２年
６月
１
日


ＳｅｃｒｅｔＬｅｖｅｌ
：ＣｏｎｆｉｄｅｎｔｉａｌｉｔｙＰｅｒｉｏｄ
：


Ｂｅｉ
ｊ
ｉｎｇＵｎｉｖｅｒｓｉｔｙｏｆＰｏｓｔｓａｎｄ


Ｔｅｌｅｃｏｍｍｕｎｉｃａｔｉｏｎｓ


ＴｈｅｓｉｓｆｏｒＭａｓｔｅｒＤｅｇｒｅｅ


ＴＩＴＬＥ
：ＩＭＡＧＥＰＡＲＡＧＲＡＰＨＣＡＰＴＩＯＮＩＮＧ


ＢＡＳＥＤＯＮＴＲＥＥＳＴＲＵＣＴＵＲＥＳ


ＳｔｕｄｅｎｔＩＤ
：２０１９１１０６６０


Ｃａｎｄｉｄａｔｅ
：ＹｉｈｕｉＳｈｉ


Ｓｕｂ
ｊｅｃｔ
：ＩｎｔｅｌｌｉｇｅｎｃｅＳｃｉｅｎｃｅａｎｄＴｅｃｈｎｏｌｏｇｙ


Ｓｕｐｅｒｖｉｓｏｒ
：ＲｕｉｆａｎＬｉ


Ｉｎｓｔｉｔｕｔｅ
：ＳｃｈｏｏｌｏｆＡｒｔｉｆ
ｉｃｉａｌＩｎｔｅｌｌｉｇｅｎｃｅ


Ｊｕｎｅ１
，２０２２


基于树结构的图像段落描述研究


摘
要


图像段落描述任务旨在为给定图像自动生成描述性段落
，是对传


统的图像单句描述研宄的进
一步深入
，属于多模态人工智能的新兴研


究方向之
一
。随着生成目标从单个句子拓展到多句子段落
，
图像段落


描述对模型的视觉线索梳理和文本逻辑建构能力提出了更高的要求
。


此外
，
自动生成能够承载更多信息的段落具有更广阔的应用前景
。


目前
，
主流研究存在以下问题亟待解决
：
首先
，
主流方法缺乏对


段落句子结构信息的建模
，容易导致生成段落出现内容冗余和上下文


不连贯问题
。此外
，
主流方法也缺乏对图像区域结构关系的建模
，
简


单地将图像表示为
一个无结构的区域集合
，容易导致模型对图像理解


不充分
，进而导致描述不全面
。为此
，
本文提出利用树结构显式建模


段落结构以及图像区域关系
，
并将树结构引入图像段落描述模型中
。


具体而言
，
本文开展的研宂工作如下
：


一
、针对句子结构缺失问题
，本文设计了
一种用于构建段落句子


树结构的层次建模方法
。将句子树结构作为监督信息
，本文提出了
一


种新颖的树结构段落解码框架
Ｓ２ＴＤ（Ｓｐ
ｌｉｔｉｎｇｔ
ｏＴｒｅｅＤｅｃｏｄｅｒ
）
。
该框


架将段落生成过程建模为
一棵自顶向下不断扩展的二叉树结构
。从图


像全局特征开始
，父节点特征被逐步划分成左右子节点
。最终
，
叶节


点特征被解码成句子并组成段落
。


二
、针对区域关系缺失问题
，本文设计了
一种图像区域树结构的


启发式构建方法
。将区域树结构作为指导信息
，本文提出了
一种新颖


的树结构增强的编码器网络ＴＥＥ（ＴｒｅｅＥｎｈａｎｃｅｄＥｎｃｏｄｅｒ
）
。
该编码器


网络利用区域树分组结果逐层约束多头自注意力机制
，使模型对图像


内容的理解更加全面和准确
。


本文在图像段落描述基准数据集上开展了实验
。通过定量分析和


定性对比
，
验证了所提方法的可行性与有效性
。实验结果表明
，
在图


像段落描述模型中引入树结构有助于生成质量更高的描述段落
。


关键词
：
多模态人工智能深度学习
图像段落描述树结构


Ｉ


ＩＭＡＧＥＰＡＲＡＧＲＡＰＨＣＡＰＴＩＯＮＩＮＧ


ＢＡＳＥＤＯＮＴＲＥＥＳＴＲＵＣＴＵＲＥＳ


ＡＢＳＴＲＡＣＴ


Ｉｍａｇｅ
ｐａｒａｇｒａｐｈｃａｐｔｉｏｎｉｎｇａｉｍｓｔｏｇｅｎｅｒａｔｅｄｅｓｃｒｉｐ
ｔｉｖｅ
ｐａｒａｇｒａｐｈｓ


ａｕｔｏｍａｔｉｃａｌｌｙｆｏｒａ
ｇ
ｉｖｅｎｉｍａｇｅ
．Ｉｔｉｓｍｏｒｅｃｈａｌｌｅｎｇｅｔｈａｎｔｒａｄｉｔｉｏｎａｌｉｍａｇｅ


ｃａｐｔｉｏｎｉｎｇ
ｔａｓｋ．Ｉｔｂｅｌｏｎｇｓｔｏｏｎｅｏｆｔｈｅｅｍｅｒｇ
ｉｎｇｒｅｓｅａｒｃｈｔｏｐ
ｉｃｓｏｆ


ｍｕｌｔｉｍｏｄａｌａｒｔｉｆｉｃｉａｌｉｎｔｅｌｌｉｇｅｎｃｅ
．Ａｓｔｈｅ
ｇｅｎｅｒａｔｉｏｎｔａｒｇｅｔｅｘｐａｎｄｓｆｒｏｍａ


ｓｉｎｇ
ｌｅｓｅｎｔｅｎｃｅｔｏａｍｕｌｔｉ
－ｓｅｎｔｅｎｃｅｐａｒａｇｒａｐｈ
，ｈｉｇｈｅｒｄｅｍａｎｄｓｏｆｔｈｅ


ｍｏｄｅｌ
＇
ｓｖｉｓｕａｌｃｕｅｏｒｇａｎｉｚｉｎｇａｎｄｔｅｘｔｌｏｇ
ｉｃｃｏｎｓｔｒｕｃｔｉｎｇｃａｐａｂｉｌｉｔｉｅｓａｒｅ


ｒｅｑｕｉｒｅｄ
．Ｉｎａｄｄｉｔｉｏｎ
，ｔｈｅａｕｔｏｍａｔｉｃ
ｇｅｎｅｒａｔｉｏｎｏｆｓｅｍａｎｔｉｃ
－ｒｉｃｈ
ｐａｒａｇｒａｐｈｓ


ｈａｓｂｒｏａｄｅｒａｐｐ
ｌｉｃａｔｉｏｎ
ｐｒｏｓｐｅｃｔｓ
．


Ｃｕｒｒｅｎｔｍａｉｎｓｔｒｅａｍｓｔｕｄｉｅｓｓｈａｒｅｔｈｅｆｏｌｌｏｗｉｎｇｐｒｏｂｌｅｍｓ
：Ｆｉｒｓｔｌｙ，


ｓｔｒｕｃｔｕｒｅｓｗｉｔｈｉｎｔｈｅｐａｒａｇｒａｐｈａｒｅｉｇｎｏｒｅｄ
，ｗｈｉｃｈｃｏｕｌｄｅａｓｉｌｙ
ｌｅａｄｔｏ


ｃｏｎｔｅｎｔｒｅｄｕｎｄａｎｃｙａｎｄｉｎｃｏｈｅｒｅｎｃｅ
．Ｍｏｒｅｏｖｅｒ
，ｒｅｌａｔｉｏｎｓｈｉｐｓｂｅｔｗｅｅｎ


ｒｅｇ
ｉｏｎｓｏｆｔｈｅｉｍａｇｅａｒｅｎｅｇ
ｌｅｃｔｅｄ．Ａｎｕｎｓｔｒｕｃｔｕｒｅｄｃｏｌｌｅｃｔｉｏｎｏｆｒｅｇ
ｉｏｎｓ


ｉｓｕｓｅｄｔｏｍｏｄｅｌｔｈｅｉｎｐｕｔｉｍａｇｅ
，ｗｈｉｃｈｉｓｉｎｓｕｆｆｉｃｉｅｎｔｔｏｃａｐ
ｔｕｒｅｔｈｅｏｖｅｒａｌｌ


ｄｅｔａｉｌｓａｎｄｌｅａｄｓｔｏａｎｉｎｃｏｍｐ
ｌｅｔｅｄｅｓｃｒｉｐ
ｔｉｏｎ
．Ｔｏｔｈｉｓｅｎｄ
，ｗｅ
ｐｒｏｐｏｓｅｔｏ


ｅｘｐ
ｌｉｃｉｔｌｙｍｏｄｅｌｐａｒａｇｒａｐｈｓｔｒｕｃｔｕｒｅｓａｎｄｒｅｇ
ｉｏｎｒｅｌａｔｉｏｎｓｈｉｐｓｂｙ
ｔｒｅｅ


ｓｔｒｕｃｔｕｒｅｓ
．Ｔｒｅｅｓｔｒｕｃｔｕｒｅｓａｒｅｔｈｅｎｉｎｔｒｏｄｕｃｅｄｉｎｔｏｔｈｅｉｍａｇｅｐａｒａｇｒａｐｈ


ｃａｐ
ｔｉｏｎｉｎｇｍｏｄｅｌｓ
．


Ｓｐｅｃｉｆｉｃａｌｌｙ，ｏｕｒｗｏｒｋｓａｒｅａｓｆｏｌｌｏｗｓ
．


Ｆｉｒｓｔｌｙ，ｆｏｒｔｈｅｌａｃｋｏｆ
ｐａｒａｇｒａｐｈｓｔｒｕｃｔｕｒｅｓ
，ｗｅｄｅｓｉｇｎａｈｉｅｒａｒｃｈｉｃａｌ


ｃｏｎｓｔｒｕｃｔｉｎｇｍｅｔｈｏｄｔｏｂｕｉｌｄｔｒｅｅｓｔｒｕｃｔｕｒｅｓｆ
ｒｏｍｔｈｅ
ｐａｒａｇｒａｐｈ
．Ｔｈｅｔｒｅｅ


ｓｔｒｕｃｔｕｒｅｓａｒｅｕｓｅｄａｓｓｕｐｅｒｖｉｓｉｏｎｓｉｇｎａｌｓ
．Ｉｎａｄｄｉｔｉｏｎ
，ｗｅ
ｐｒｏｐｏｓｅａｎｏｖｅｌ


ｔｒｅｅ
－ｓｔｒｕｃｔｕｒｅｄｖｉｓｕａｌ
ｐａｒａｇｒａｐｈｄｅｃｏｄｅｒｎｅｔｗｏｒｋ
，ｃａｌｌｅｄＳｐｌｉｔｔｉｎｇ
ｔｏＴｒｅｅ


Ｄｅｃｏｄｅｒ
（Ｓ２ＴＤ）
．Ｓ２ＴＤｍｏｄｅｌｓｔｈｅ
ｐａｒａｇｒａｐｈｄｅｃｏｄｉｎｇｐｒｏｃｅｓｓａｓａｔｏｐ
－


ｄｏｗｎｂｉｎａｒｙ
ｔｒｅｅｅｘｐａｎｓｉｏｎ
．Ｓｔａｒｔｉｎｇｆ
ｒｏｍｔｈｅｇ
ｌｏｂａｌｉｍａｇｅｆｅａｔｕｒｅ
，ｔｈｅ


ｐａｒｅｎｔａｌｎｏｄｅｉｓｉｔｅｒａｔｉｖｅｌｙｓｐ
ｌｉｔｉｎｔｏｌｅｆ
ｔａｎｄｒ
ｉｇｈｔｃｈｉｌｄｎｏｄｅｓ
．Ｌｅａｆｎｏｄｅｓ


ａｒｅｄｅｃｏｄｅｄｉｎｔｏｓｅｎｔｅｎｃｅｓｆｏｒｍｉｎｇａｃｏｈｅｒｅｎｔ
ｐａｒａｇｒａｐｈ
．


ｎ


Ｓｅｃｏｎｄｌｙ，ｆｏｒｔｈｅｌａｃｋｏｆｒｅｇ
ｉｏｎａｌｒｅｌａｔｉｏｎｍｏｄｅｌｌｉｎｇ，ｗｅｄｅｓｉｇｎａ


ｈｅｕｒｉｓｔｉｃｃｏｎｓｔｒｕｃｔｉｎｇｍｅｔｈｏｄｔｏｂｕｉｌｄｒｅｇ
ｉｏｎｔｒｅｅｓｔｒｕｃｔｕｒｅｓ
．Ｔｈｅｔｒｅｅ


ｓｔｒｕｃｔｕｒｅｓａｒｅｉｎｐｕｔａｓｇｕｉｄａｎｃｅ
．Ｗｅｆｕｒｔｈｅｒｐｒｏｐｏｓｅａｎｏｖｅｌｅｎｃｏｄｅｒ


ｎｅｔｗｏｒｋ
，ｃａｌｌｅｄＴｒｅｅＥｎｈａｎｃｅｄＥｎｃｏｄｅｒ（ＴＥＥ）
．Ｂｙｕｔｉｌｉｚｉｎｇｇｒｏｕｐｅｄ


ｒｅｓｕｌｔｓｏｂｔａｉｎｅｄｆｒｏｍｔｈｅｒｅｇ
ｉｏｎｔｒｅｅｓ
，ＴＥＥｃｏｎｓｔｒａｉｎｓｔｈｅｍｕｌｔｉ
－ｈｅａｄｓｅｌｆ
？


ａｔｔｅｎｔｉｏｎｍｅｃｈａｎｉｓｍｌａｙｅｒｂｙ
ｌａｙｅｒ．Ｔｈｉｓｒｅｓｕｌｔｓｉｎａｍｏｒｅｃｏｍｐｒｅｈｅｎｓｉｖｅ


ａｎｄａｃｃｕｒａｔｅｕｎｄｅｒｓｔａｎｄｉｎｇｏｆｔｈｅｉｍａｇｅＣｏｎｔｅｎｔ－


Ｅｘｐｅｒ
ｉｍｅｎｔｓａｒｅｃｏｎｄｕｃｔｅｄｏｎＩｍａｇｅＰａｒａｇｒａｐｈＢｅｎｃｈｍａｒｋＤａｔａｓｅｔ
．


Ｔｈｒｏｕｇｈｑｕａｎｔｉｔａｔｉｖｅａｎａｌｙｓｉｓａｎｄｑｕａｌｉｔａｔｉｖｅｃｏｍｐａｒ
ｉｓｏｎ
，ｔｈｅｆｅａｓｉｂｉｌｉｔｙ


ａｎｄｅｆｆｅｃｔｉｖｅｎｅｓｓｏｆｏｕｒｐｒｏｐｏｓｅｄｍｅｔｈｏｄｓａｒｅｖｅｒｉｆｉｅｄ
．Ｅｘｐｅｒ
ｉｍｅｎｔａｌ


ｒｅｓｕｌｔｓｓｈｏｗｔｈａｔｉｎｔｒｏｄｕｃｉｎｇ
ｔｒｅｅｓｔｒｕｃｔｕｒｅｓｉｎｔｏｔｈｅｉｍａｇｅｐａｒａｇｒａｐｈ


ｃａｐｔｉｏｎｉｎｇｍｏｄｅｌｉｍｐｒｏｖｅｓｔｈｅ
ｐａｒａｇｒａｐｈ
ｇｅｎｅｒａｔｉｏｎ
ｑｕａｌｉｔｙ
．


ＫＥＹＷＯＲＤＳ
：ｍｕｌｔｉｍｏｄａｌａｒｔｉｆｉｃｉａｌｉｎｔｅｌｌｉｇｅｎｃｅ
，ｄｅｅｐ
ｌｅａｒｎｉｎｇ，
ｉｍａｇｅ


ｐａｒａｇｒａｐｈｃａｐｔｉｏｎｉｎｇ，ｔｒｅｅｓｔｒｕｃｔｕｒｅ


ｍ


目
录


第
一章绪论
１


１
．１研宄背景及其意义
１


１
．２研究现状及分析
２


１
．２
．１
图像单句描述
３


１
．２
．２
图像段落描述
５


１
．２
．３树结构弓图文多模态
７


１
．３研究内容和贡献
８


１
．３
，１现存问题
８


１
．３
．２研宄内容
８


１
．３
．３贡献及创新点
９


１
．４本文的组织结构
９


第二章基础知识
１１


２
．
１编码器
－解码器框架
１１


２
．２视觉编码器
１１


２
．２
．
１卷积神经网络
１２


２
．２
．２
目标检测模型
１３


２
．３
文本解码器
１４


２
．３
．１循环祌经网络
１４


２
．３
．２变压器网络
１５


２
．４数据集及评测指标
１７


２
．４
．１
图像段落描述基准数据集
１７


２
．４
．２
图像段落描述任务评价指标
１７


２
．５本章小结
２０


第三章基于文本树结构的图像段落描述算法研究
２１


３
．
１本章引论
２１


３
．２段落文本树结构建模方法
２２


３
．３面向段落生成的自顶向下树结构解码框架
２５


３
．３
．１框架总览
２５


３
．３
．２划分模块
２５


３
．３
．３打分模块
２７


３
．３
．４词级另
丨
ＪＲＮＮ
２８


３
．３
．５模型训练
２９


３
．３
．６段落解码牛成算法
３０


３
．４实验对比弓分析
３０


３
．４
．１实验参数与设置
３０


３
．４
．２评测指标对比与分析
３１


３
．４
．３消融实验
３４


３
．４
．４定性分析
３７


３
．５木章小结
３９


第四章
引入视觉树结构的图像段落描述算法研究４１


４
．
１本章引论
４１


４
．２
图像区域树结构建模方法
４２


４
．３编码视觉树结构的图像段落描述模型
４５


４
．３
．１模型总览
４５


４
．３
．２树结构增强的编码器网络
４６


４
．３
．３基于概率分布衰减的段落解码策略
４８


４
．４实验对比与分析
５０


４
．４
．１实验参数与设置
５０


４
．４
．２评测指标对比与分析
５１


４
．４
．３消融实验
５３


４
．４
．４定性分析
５５


４
．５本章小结
５７


第五章
总结与展望
５９


５
．
１
工作总结

５９


５
．２未来工作展望
６０


参考文献
６１


第
一章绪论


第
一章绪论


１
．
１研究背景及其意义


近年来
，
深度学习
［
１
］等相关人工智能技术的快速发展
，
在计算机视觉
、
自然


语言处理
、语音信号处理等领域实现了革新式的突破
，取得了良好的社会和经济


效益
，
包括但不限于高精度的图像识别安防系统
、无人驾驶感知模组
、媲美专业


人员的机器翻译工具以及智能语音助理
。深度学习技术也逐渐成为其他自然学科


开展研宄的新兴工具手段
，
例如预测地震发生时间地点
、
推理蛋白质结构等
。


尽管深度学习在涉及图像
、文本或语音等单
一模态的任务上取得了令人鼓舞


的成绩
，但是如何处理多模态异构信息仍是
一个极具挑战性且亟待解决的课题
［２
］
。


一方面
，
不同模态的数据在表征形式上是不
一致的
，
不能简单地应用单
一领域


的解决方案
。
例如
，
图像数据
一般通过的长
、
宽
、通道三个维度上的像素点进行


建模
，而文本数据利用字词组成句
、段
、篇章
。相比图像数据的基本单位像素点
，


文本数据的基本单位字词具有更明确且丰富的语义
。然而
，不同像素点组合而成


的整体图像往往比文本包含更多细节信息
。因此
，适用于文本模态的方案往往无


法直接应用于图像模态
，
反之亦然
。另
一方面
，
多模态信息处理需要解决不同模


态数据之间的对齐
、融合和生成
（转换
）
问题
。例如
，
通过图像检索文本或者利


用文本检索视频
，
需要实现跨模态信息的对齐
；联合图文进行舆情分析
，
依赖语


音字幕和图像画面进行视频分类
，
需要完成多模态的信息融合
；从启发图像到连


贯视频
，
从图像到对应的描述性文本
，
需要实现模态到模态的生成
。跨模态的表


征
，
对齐
，
融合和生成在处理实际多模态任务时相互交叉
，
需要综合考虑
。


此外
，
随着移动互联网等信息技术产业的发展
，
在大量用户产出了更加丰富


的多模态数据的同时
，也对现有智能系统的多模态信息处理能力提出了更高的要


求
。例如基于多模态信息的推荐搜索
，
具备图文推理能力的知识图谱引擎
。综上


所述
，
开展多模态人工智能技术的研宄具有重要的学术和社会价值
。


多模态人工智能技术的代表任务之
一是图像描述
（
ＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ
）
。
图像


描述任务要求设计
一种计算模型
，该模型以图像视觉信息作为输入
，生成类似于


人类对图像内容描述的自然语言文本
，从而实现图像模态到文本模态的转换
，是


对人类在幼儿早期对环境认知和语言习得的模拟
。如何让模型实现对图像中物体


的类别
、属性特征
、物体对象间关系的综合理解
，并能使用更为抽象的文本准确
、


流畅且有逻辑地描述出来
，连接图像和文本的通路
，是图像描述任务的核心挑战
。


因此研宄图像描述任务
，有助于进
一步探索多模态人工智能和人类认知机制
。同


１


北京邮电大学工学硕士学位论文


时
，
在可预期的未来
，
终端计算设备的升级和
５Ｇ网络的全面铺开将进
一步推动


图像描述技术研宄向工业界落地
［３Ａ５
，６
］
，应用于盲人语音导航
、施工安全提示
、商


品广告优化
、
景区智能导游和医疗图像报告自动生成等
，具有良好的应用前景
。


句子级别描述
（Ｓｅｎｔｅｎｃｅ
－
丨ｅｖｅ
ｌＣａｐｔ
ｉｏｎ
）


１
．Ａ
ｐ
ｉｚｚａ
ｉｓｔｏｐｐｅｄｗ
ｉｔｈｍｕｓｈｒｏｏｍｓａｎｄｈａｍ
．


园稼
２
．Ａｐ
ｉｚｚａｏｎａｃｕｔｔ
ｉｎｇｂｏａｒｄ
ｉｓｈａ
ｌｆ
ｇｏｎｅ
．



３
．Ａ
ｐａｎｗ
ｉｔｈａｐ
ｉｚｚａｏｎ
ｉｔｗ
ｉ
ｔｈａｓｐｏｏｎａｎｄａｐ
ｉｚｚａｃｕｔｔｅｒ
．


４
．Ｍｏｒｅｔｈａｎｈａ
ｌｆｏｆａｍｕｓｈ
ｒｏｏｍｐ
ｉｚｚａｒｅｍａ
ｉｎｓ
ｉｎａｄ
ｉｓｈ


ｔｈａｔａ
ｌｓｏｈｏ
ｌｄｓａｐ
ｉｚｚａｃｕｔｔｅｃａｎｄｓｐａｔｕ
ｌａ
．


＾
５
．Ｔｈ
ｉｓｐ
ｉｚｚａ
ｉｓｈａ
ｌ
ｆｅａｔｅｎａｎｄｈａｓｍｕｓｈｒｏｏｍｓａｎｄｈａｍ
．


段落级别描述
（Ｐａｒａｇｒａｐｈ
－
丨ｅｖｅ
ｌＣａｐｔ
ｉｏｎ
）


Ｔｈｅｒｅ
＇
ｓａｇ
ｌａｓｓｄ
ｉｓｈｏｎｔｈｅｔａｂ
ｌｅ
．Ｔｈｅｇ
ｌａｓｓｐ
ｌａｔｅｈａｓ


ｐ
ｉｚｚａｏｎ
ｉｔ
．Ｈａ
ｌｆｏｆｔｈｅｐ
ｉｚｚａ
ｉｓｇｏｎｅ
．Ｔｈｅｐ
ｉｚｚａｈａｓ


；
ｖ
ｍｕｓｈ
ｒｏｏｍｓｏｎｉｔ
．Ｔｈｅｐ
ｉｚｚａａ
ｌｓｏｈａｖｅａｍｅａｔｏｎ
ｉｔ
．Ｔｈｅ


耋
ｃｒｕｓｔｏｆｔｈｅｐ
ｉｚｚａ
ｉｓｇｏ
ｌｄｅｎｂｒｏｗｎ
．Ｔｈｅｒｅ
＇
ｓａｓｐａｔｕ
ｌａｏｎｔｈｅ


ｐ
ｌａｔｅ
．Ｔｈｅｓｐａｔｕ
ｌａ
ｉｓｍａｄｅｏｆｍｅｔａ
ｌ
．Ｔｈｅ
ｌ
ｉｇｈｔ
ｉｓｒｅｆｌｅｃｔ
ｉｎｇ


ｏｆｆｏｆｔｈｅｂａｃｋｏｆｔｈｅｓｐａｔｕ
ｌａ
．


图
１
－
１
图像单句描述与图像段落描述任务的对比


当前的图像描述研宄主要以生成单个描述句子为主
，
然而
“
一图胜千言
”
，


仅使用单个句子难以全面的描述图像中丰富的内容
，并且包含多个句子的段落更


符合实际应用需求
。为了弥补上述缺陷并进
一步探究视觉和文本两个模态之间的


关系
，
Ｋｒａｕｓｅ等人
［７
］于
２０
１７年首次提出图像段落描述任务
（
ＩｍａｇｅＰａｒａｇｒａｐｈ


Ｃａｐ
ｔｉｏｎｉｎｇ）并提供了基准数据集和基线模型
。
“ 段落由阐述同
一主题紧密相关的


若干不同句子组成
”
。
图像段落描述任务相比传统的单句描述任务更具挑战性
，


如图
１
－１所示
，
单句描述任务的生成目标为
一个篇幅在三十词以内的单个句子
。


较短的篇幅使得模型在学习和推理过程局限于图像中少量的物体及其细节
，而缺


乏对图像细节的理解和刻画
。与此相反
，段落描述任务的生成目标为
一个包含六


个句子左右的段落文本
，其要求生成的段落句子内容多样
、句子间上下文语义连


贯
，
符合视觉观察和写作逻辑
。
同时
，段落的多样和连贯受到图像内容的指导和


约束
。
这对图像描述模型的设计和训练推理提出了更高的要求
。


综上所述
，
本文开展的图像段落描述研究具有重要的研究意义和应用价值
。


１
．２研究现状及分析


本节将主要介绍图像描述任务的研宄现状
，并补充与本文研宄内容相关的树


状结构在图文多模态领域的相关工作
。


根据生成目标文本篇幅的不同
，可以将现有的图像描述研宄划分为图像单句


描述研究和图像段落描述研宄两大类
。图像单句描述的相关研宄是开展段落描述


研宄的基础
，
相关研宄奠定了图像到文本生成的基本框架和计算范式
，
然而
，
正


２


第
一章
绪论


如后文将提到的
，
当生成目标从句子扩展到段落
，现有的单句描述模型无法很好


的解决生成段落的冗余问题
。从而引出了图像段落描述研宄中两大主流的解决方


案
：
层次解码结构和非层次解码结构
。
两大类结构从不同的段落建模视角出发
，


采用不同的技术方案提升图像描述模型生成段落文本的质量
。


树结构是
一种常见的数据结构
，
用于模拟具有树状结构性质的数据集合
，
是


由多个有限节点组成的
一个具有层次关系的集合
，通常由父节点和子节点单向连


接构成
。
图像中的对象间关系
，
观察顺序可以利用自顶向下的树结构进行刻画
，


而文本无论是段落中句子的结构
，还是句子中词级别的句法结构均能利用树结构


实现建模
。
因此
，
在图文多模态领域
，
不少研宄者开始关注如何在现有的跨模态


问题中引入树状结构的归纳偏置
，
提升模型的任务性能表现和解释性
。


１
．２
．
１图像单句描述


图像单句描述早期的研宄工作主要是利用模板填空＾？＾＾或检索匹配


［
｜３
，
１４
，
１５
，
１６
，
１
７啲方法实现图像到文本的生成
。
基于模板填空的方法首先提取图像中


传统的机器视觉特征
，并利用提取的特征获取对应的物体信息
，然后将对应的信


息填入预先设定好的模板
，最终得到描述的句子
。基于检索匹配的方法依赖于
一


个预先收集的描述文本数据库
，并通过模型将图像和库中的描述文本投影到同
一


个语义空间
，使得具有相似语义的图像和文本表示距离更小
。生成时选取距离最


小的文本作为描述输出
。尽管上述方法局限于其预设的模板或文本库
，
导致得到


的文本描述在流畅性或者准确度上有其局限性
，但模板填空和匹配检索的思想仍


在未来的研究中受到重视
。


随着互联网产业的发展
，大量图文对齐的多模态数据不断积累
，使得通过数


据驱动解决图像描述问题成为可能
。模型可以利用深度神经网络学习到语义更加


丰富的图像和文本模态的表亦
。受到基于循环神经网络
（ＲｅｃｕｒｒｅｎｔＮｅｕｒａｌＮｅｔｗｏｒｋ
，


ＲＮＮ）的序列到序列
（Ｓｅｑｕｅｎｃｅ
－
ｔｏ
－Ｓｅｑｕｅｎｃｅ
）架构在自然语言领域中机器翻译任


务成功应用的启发
，
Ｖｉｎｙａｌｓ
等人
［
１８
］进
一步抽象
，
提出利用编码器
－解码器


（Ｅｎｃｏｄｅｒ
－Ｄｅｃｏｄｅｒ
）框架建模图像单句描述任务
，
并提出了相应的模型
ＮＩＣ


（ＮｅｕｒａｌＩｍａｇｅＣａｐ
ｔｉｏｎ）
。
具体而言
，
他们利用已预先训练的深度卷积神经网络


（ＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｕｒａｌＮｅｔｗｏｒｋ
，ＣＮＮ
）作为编码器提取稠密的图像特征表示
，
并


采用循环神经网络作为解码器建模语言模型
，解码提取到的图像特征生成描述文


本
。
与模板匹配和匹配检索方法相比
，
数据驱动的
ＮＩＣ模型通过学习大量的图


像文本对数据并利用梯度下降方法优化模型参数
，在文本生成质量上取得了显著


的优势
。随后
，主流的图像描述研究开始围绕编码器
－解码器框架进行探索改进
。


一个重要的改进方向是借鉴和模拟人类视觉系统中的注意力机制
，注意力机


制的特点是有目的性地
、不断调整关注的目标对象
。
Ｘｕ等人
在ＮＩＣ模型的基


３


北京邮电大学工学硕士学位论文


础上
，
提出将视觉编码网络中卷积层的特征图谱
（Ｆｅａｔｕｒｅｍａｐｓ
）
作为上下文信


息
（Ｃｏｎｔｅｘｔ
）
，
将文本解码器在解码过程中的中间表示作为查询信息
（Ｑｕｅｒｙ
）
，


计算给定查询时不同上下文信息的权重
，最终加权融合或决策选取
，使文本解码


器有能力在生成不同单词时关注到图像中的不同内容
。
Ｌｕ等人
从文本角度出


发
，
区分生成句子中具有视觉含义的词语
（例如
“
ｐｅｒｓｏｎ
”
，
“
ｓｋｙ
”
，
“
ｄｏｇ
” 等
）


和语法辅助的词语
（例如
“
ａｔ
”
，
“
ｏｆ
”
，
“
ｔｈｅ
” 等
）
，
在图文注意力机制屮引入视


觉哨兵
（ＶｉｓｕａｌＳｅｎｔｉｎｅｌ
）
，
使得解码器有能力在生成非视觉词时不受图像内容的


干扰
，
提升描述句子的质量
。
Ａｄｅｒｓｏｎ等人
［２
１
］进
一步将图文注意力机制扩展为自


顶向下和自底向上两种注意力
，
传统的图文注意力机制属于自顶向下的注意力
。


自底向上的注意力通过
Ｆａｓｔ
ｅｒＲ
－ＣＮＮ
［２２
］目标检测模型获取图像中区域级别的特


征表示
。
目标检测模型通过在预训练阶段引入了目标对象的属性信息
，使抽取得


到的图像特征能够包含更多的细节信息
，
极大提升了描述句子的生成质量
。


另
一个重要的改进方向是研宄如何缓解训练阶段和评测阶段的不
一致问题
，


也称为暴露偏差问题
（Ｅｘｐｏｓｕｒｅｂｉａｓ
）
。在训练阶段
，
ＮＩＣ等图像描述模型采用教


师强制学习方法
（ＴｅａｃｈｅｒＦｏｒｃ
ｉｎｇ）
，利用交叉熵损失优化每个时间步的输出词表


分布
，
使标签句子中的对应词的选取概率越大越好
。在评测阶段
，
图像描述模型


通过随机米样
（Ｇｒ
ｅｅｄｙＳｅａｒｃｈ
）或集束搜索
（ＢｅａｍＳｅａｒｃｈ
）实现句子生成
，
采用


ＢＬＥＵ％
，ＣＩＤＥｉ＾Ｉ等指标评估生成句子与标签句子的相似程度
。
采样方法和优


化目标的不
一致
，意味着训练阶段表现较好的模型无法保证其在评测阶段的性能
。


为此
，Ｂｅｎｇ
ｉｏ等人
１２５
：
１提出了
一种在训练阶段使用的计划采样
（ＳｃｈｅｄｕｌｅｄＳａｍｐ
ｌ
ｉｎｇ
）


方法
。该方法是对教师强制学习的改进
，在训练中逐步将预先给定的标签句子中


的词
，
替换为上
一个时间步采样输出的词
，
减小训练阶段和测试阶段的差异
。


Ｒｅｎｎｉｅ等人
提出
一种基于强化学习的优化方案
，
自我评判序列训练
（
Ｓｅ
ｌｆ
－


Ｃｒ
ｉｔｉｃａｌＳｅｑｕｅｎｔｉａｌＴｒａｉｎｉｎｇ
，ＳＣＳＴ
）
。该方案利用策略梯度方法
，
将文本生成过程


中词的抽样视为动作选择
，将解码器循环神经网络的中间表示建模为状态
，将不


可求导的评测阶段的指标作为环境交互后的奖励
，
进行直接的优化
。
ＳＣＳＴ技术


的提出使模型能够生成更为多样和准确的描述句子
，
缓解了暴露偏差问题
。


近年来
，
变压器网络结构
［２７
］（Ｔｒａｎｓｆ
ｏｒｍｅｒ）在自然语言领域的兴起
，
并逐渐


替代饱受梯度消失和梯度爆炸问题困扰的循环神经网络
，成为了文本建模的新范


式
。变压器网络结构利用层叠的多头注意力机制
（Ｍｕ
ｌｔｉ
－ＨｅａｄＡｔｔｅｎｔｉｏｎ
）
，
能够更


好地捕捉序列上下文间的依赖关系
，也激发了新
一轮的图像描述模型的探索和改


进
。
Ｈｅｒｄａｄｅ等人
在朴素变压器网络的编码器结构中引入了图像区域特征的空


间几何信息
，
使得多头注意力机制能够更好的建模特征之间的关系
。
Ｈｕａｎｇ等人


［２９
］针对图像描述任务的特点
，对多头注意力机制进行了改进
，提出了
一种利用门


４


第
章
绪论


控机制过滤注意力计算的结果
，提升了模型的性能
。
Ｃｏｒｎｉａ等人
进
一步提出
一


种网状的
、多级连接的变压器网络用于解决图像单句描述问题
。该模型通过可学


习的门控机制
，动态连接编码器和解码器不同的层级信息
。除了在传统的编码器


－解码器框架上探索
，
图文大规模预训练方法
［３
１
，３２
］也开始受到研究者的重视
。
这


类方法仅利用变压器网络的编码器部分
，并在庞大的训练数据上进行预训练
，最


终迁移到下游的图像描述任务
。这类方法通常将图像区域与文本词向量输入到同


一个多头注意力机制层进行注意力计算
，而大规模预训练使得模型能够泛用到更


为复杂的场景中
。


综上
，
图像单句描述的研究主要围绕编码器
－解码器框架展开
，
一方面探索


如何在编码器端引入更好的视觉编码网络
，提升图像特征的表达能力
。另
一方面


研宄在解码器端如何更好的利用视觉上下文信息生成文本
，并缓解暴露偏差问题
。


１
．２
．２图像段落描述


当图像描述研宄逐渐实现
“ 从
０到
１
”
，
从模板方法到数据驱动
，
研宄者们


开始着眼于更上
一层楼
，将模型的生成目标从单个粗粒度的句子逐渐推广到生成


多个独立的描述短句
，
乃至生成语义连贯
、
内容多样的段落长文本
。


针对图像多句描述问题
，
Ｊｏｈｎｓｏｎ和Ｋａｒｐａｔｈｙ等人
开创性地提出了
一种基


于目标检测模型改进的密集描述方法
（ＤｅｎｓｅＣａｐ
ｔｉｏｎｉｎｇ
）
。
首先
，
收集区域对齐


的图像文本对作为训练数据
，端到端训练目标检测器中的区域提议网络和文本解


码器
，
使得模型能够同时完成兴趣区域的检测和对应区域的描述句子生成
。
Ｍａｏ


等人
［３４
］提出了
一种文本主题驱动的图像多句描述方法
，
通过隐式狄利克雷分布


（ＬａｔｅｎｔＤ
ｉｒｉｃｈｌｅｔＡ
ｌ
ｌｏｃａｔｉｏｎ
，ＬＤＡ
）建模描述句子的文本主题分布
，
并利用祌经


网络学习图像到文本主题的映射函数
，实现主题与图像特征的融合
，从而生成多


样的描述句子
。


针对图像段落描述问题
，根据段落文本的不同建模视角
，相关方法可以划分


为两大类模型
：层次结构模型和非层次结构模型
。层次结构模型将段落生成建模


为多个句子的顺序生成
，
即逐句生成段落
。该类方法会在解码之前显式计算用于


指导句子生成的特征表示
（也称为句子主题表示或句子视觉表示）
，
不同的句子


由不同特征解码得到并最终组成段落
。非层次结构模型将段落的生成建模为单个


长句子的生成
，
即逐词生成段落
。该类方法对段落内的句子不做显式划分
，
直接


利用得到的视觉表示解码生成段落中的词
，
不引入句子级别的特征表示
。


２０
１７年
，
Ｋｒａｕｓｅ等人Ｄ首次提出图像段落描述任务
，提供了基准评测数据集


和最早的层次结构模型ＲＨ（Ｒｅｇ
ｉｏｎ
－Ｈ
ｉｅｒａｒｃｈｉｃａｌ
）
。该模型由
一个句子ＲＮＮ和
一


个词
ＲＮＮ组成
。
句子ＲＮＮ解码图像视觉信息生成多个主题表示
，
这些主题表


示进
一步输入词
ＲＮＮ解码生成句子
，
从而完成段落中多个句子的生成
。
其中
，


５


北京邮电大学工学硕士学位论文


句子ＲＮＮ隐式建模和推理了段落间句子关系
。
实验发现
，
相比直接利用传统图


像单句描述的模型或拼接密集描述模型的生成结果
，具有层次结构的ＲＨ模型能


够生成逻辑更连贯
、
更符合阅读习惯的描述段落
。


为了建模语义更丰富
、上下文转换更连贯的句子主题表示
，不同的层次结构


模型被相继提出
。
Ｌｉａｎｇ等人
［３５
］提出的
ＲＴＴ
－ＧＡＮ模型引入了段落级
ＲＮＮ
以及


对抗生成网络的思想
，通过句子质量和主题迁移连贯两个判别网络
，提升段落生


成模型的句子的准确度以及句子间的连贯程度
，
辅助句子主题特征的学习
。


Ｃｈａｔｅｉｊｅｅ等人
［３６
］提出的ＣＡＰＧ
－ＶＡＥ模型
，
在ＲＨ的基础上引入全局主题表示和


连贯主题表示对句子间的连贯性进行显式的建模
，并利用变分自编码器训练框架


进
一步优化段落解码器参数
，提升段落生成的多样性
。Ｗａｎｇ等人
提出的ＣＡＥ
－


ＬＳＴＭ模型采用卷积自编码器结构替换句子
ＲＮＮ
，
在计算出句子主题特征的同


时进行约朿
，使其能重构图像特征表示
，使句子主题能够捕捉更完整的图像信息
。


Ｗｕ等人
提出了
一种受到多层次奖励和评估值监督的策略
－估值网络
ＤＨＰＶ
。


通过利用强化学习
，将奖励分为句子级和词级别
，进
一步提升了层次结构模型的


性能
。
Ｌｉ等人
１３９
，叫提出的Ｄｕａｌ
－ＣＮＮ模型
，通过将循环神经网络替换为层次卷积


解码结构
，缓解了己有的层次结构模型的计算复杂度高
、梯度易消失等问题
。
同


时引入了区域级别的注意力机制
，
辅助模型从图像中更好地挖掘句子主题表示
。


除了直接针对句子主题表示进行建模和约束
，另
一个改进方向是增强模型对


图像信息的利用
。
Ｃｈｅ等人提出显式引入视觉对象间的关系信息
，
相继设计了


ＶＲＤ模型
以及ＶＲＥＮ模型
模型在目标检测网络基础上进
一步预测物体间


的关系
，
抽取并加权融合主体
、客体和主客体所处环境的图像特征
，
最终输入到


解码器中进行段落生成
。
Ｚｈａ等人％提出了
一种感知上下文的视觉策略网络


ＣＡＶＰ
，
它将生成过程中的视觉注意力权重作为视觉上下文信息
，
并基于当前的


视觉注意力权重决定是否将该上下文信息用于生成当前的词和句子
。
Ｘｕ等人
［４４
］


提出的
ＩＭＡＰ模型
，采用了
一种新颖的交互式键值记忆增强的注意力机制
，
该机


制使得模型能够在生成句子中词的过程中同时关注多个图像区域
，并利用可读写


的记忆模块缓解冗余内容生成问题
。
Ｙａｎｇ等人
［４５
］提出的层次结构模型ＨＳＧＥＤ
，


在编码器端引入图像场景图
（ＳｃｅｎｅＧｒａｐｈ）信息
，增强了模型对图像内物体及物


体间关系的编码能力
。具体而言
，
场景图中节点为图像中物体对象类别
，对象的


视觉属性作为节点的属性
，
对象与对象之间的关系类别作为节点的边
。


非层次结构模型相关研究的主要目标是解决段落文本长距离依赖带来的冗


余生成问题
，使得能够更好地应用图像单句描述研宄成果
。因缺乏对单个句子表


示显式建模
，将段落视为单个长句子的容易导致重复的描述的出现
。Ｍｅｌａｓｋｙｒ
ｉａｚｉ


等人
［４６
］提出在Ａｄｅｒｓｏｎ等人
［２
１
］工作的基础上引入三元词组
（
ｔｒ
ｉ
－
ｇｒａｍ
）重复性惩


６


第
一章
绪论


罚
，在对下
一时刻生成词进行采样时
，对可能重复形成的三元词组的选项进行降


权
，
鼓励模型生成更多样的描述
。
Ｗａｎｇ等人
［４７
］提出的ＤＡＭ模型
，
通过在编码


器端引入深度估计图
，
使模型有能力关注到处于不同深度的物体对象
，隐式提升


段落生成内容多样性
。模型通过无监督方法获取图像的相对深度估计
，使用注意


力机制融合图像语义和深度信息作为解码器的输入从而生成段落
。Ｌｕｏ等人
■
是


出的
ＣＲＬ模型引入了时序差分算法
，
并在传统评测指标的外部奖励上加入了基


于内部状态估计的内部奖励
。鼓励模型探索少见或不熟悉的状态
，减少文本冗余
。


Ｙａｎｇ等人
［４９
］在Ｍｅ
ｌａｓｋｙｒｉａｚｉ工作的基础上
，
引入了
一种新颖的对象关系注意力


机制ＯＲ
－ＡＴＴ
，
尝试解决模型关系建模不准确导致的描述不准确的问题
。


综上
，图像段落描述的研宄主要围绕如何提升段落生成的连贯性和多样性展


开
。针对不同的段落建模视角
，相关研宄可以划分为层次结构和非层次结构两大


类模型
。
本章的
１
．３节将进
一步讨论和分析已有模型存在的问题和缺陷
。


１
．２
．３树结构与图文多模态


最近
，图文多模态领域的不同研究者开始关注树结构的建模能力和应用价值
。


在视觉接地
（ＶｉｓｕａｌＧｒｏｕｎｄｉｎｇ
）任务中
，
Ｈｏｎｇ等人
［Ｍ）
］提出利用将输入的接地文


本递归地剖析为
一棵二叉树结构
，并在建树的过程中实现文本节点与视觉内容的


对齐
。通过利用树结构连接图像和文本模态
，相关方法取得了当时最佳的性能表


现
。
Ｌｉｕ等人％提出利用文本的依存句法树
，
从叶节点对应的词
，
递归地实现图


像区域对齐
，
提升了模型的性能表现和可解释性
。
在视觉问答任务
（Ｖｉｓｕａｌ


ＱｕｅｓｔｉｏｎＡｎｓｗｅｒｉｎｇ
）中
，
Ｃａｏ等人
［５２
］将问题文本剖析为依存句法树
，并在叶节点


逐步遍历到根节点的过程中
，利用注意力机制有针对性地挖掘图像中对应的
、可


以用于解决问题的线索信息
。
Ｔａｎｇ等人
提出
一种动态构建图像中物体间的树


结构的方法
，使得模型可以更好的理解图像中物体间关系
，该方法也可以用于构


建场景图
。在图像描述相关的领域
，Ｙａｏ等人
将图像进行剖析成包含图像全局
、


区域
、
实例三层的树结构
，
并递归地融合不同粒度的信息增强句子的生成质量
。


Ｍａ等人
提出
一种应用于单句描述的树结构解码器
。
该方法将标签句子的依存


树结构转换为
一棵三叉树
，每个节点对应
一个句子中的词或特殊的符号
，句子中


越重要的词在依存树中距离根节点越近
，使得模型可以优先生成重要的描述内容
。


Ｗａｎｇ等人
在图像到食谱文本的生成过程中引入了树结构信息
，
用以缓解菜品


图像因缺乏预训练的目标检测器导致的图像特征语义不丰富的问题
。
具体而言
，


该方法利用无监督方法从食谱文本中剖析出句子间树结构并利用该标签进行监


督学习
，为输入图像预测出树结构并编码
，增强食谱文本生成的准确性和连贯性
。


７


北京邮电大学工学硕士学位论文


可以看到
，在上述引入树结构的图文多模态任务的研究中
，核心挑战在于如


何建模与任务相关的树结构
。
当前主要思路是利用文本模态的句子依存树结构
，


构建图像模态中物体间的关系树结构
，或通过树结构实现两个模态的融合或对齐。


１
．３研究内容和贡献


尽管研宄者们面对图像段落描述任务的语义连贯性、
内容多样性等挑战
，进


行了积极的探索并取得了阶段性的成果
，但是当前模型生成的段落文本仍与人类


认知观察并描述的结果有较大的差距
。


１
．３
．
１现存问题


通过对相关研究工作的梳理
，
可以发现以下亟待解决的问题
：


１
）图像段落描述模型缺乏对段落句子结构信息的建模和利用


段落不是多个句子或者词语的简单顺序拼接
，总分结构
、上下文的内容指代


都是段落中存在丰富结构信息的体现
。当前图像段落描述研宄忽略了段落句子间


存在的关系结构
，简单地将段落生成过程建模为
一个顺序解码的过程
。其中
，非


层次结构模型将段落生成建模为词序列顺序生成
，而层次结构将段落生成建模为


句子序列顺序生成
。这类模型在段落生成时有
一定的局限性
：
例如
，
由于模型在


生成当前句子或词的同时会使用注意力机制选取图像区域信息
，顺序解码会导致


图像观察利用过程同样呈线性
。解码器会从图像中
一个包含显著物体的区域开始
，


基于已生成的结果不断更新到下
一区域
。因缺乏对文本结构的建模
，解码器很难


学习到如何基于图像内容进行梳理和规划
，容易过度依赖己生成部分
，导致解码


器反复选取相同区域进行解码生成
，
最终导致生成内容冗余以及上下文不连贯
。


２
）图像段落描述模型缺乏对图像区域结构信息的建模和利用


人类对图像的观察和描述不是杂乱无章的
，通常会参考图像中物体间关联关


系
，有组织地选取待描述对象
。因此
，
空间相邻或具有从属关系的不同目标对象


往往容易在相邻的段落上下文中提及
。然而
，主流的图像段落描述模型中
，编码


器将抽取到的图像区域特征作为
一个无结构的特征集合输入到解码器
。图像区域


特征之间的关联关系缺乏显式地编码与利用
，例如空间关系
、从属关系
。缺乏对


结构信息进行编码
，
在
一定程度上损害了生成段落的准确性和连贯性
。


１
．３
．２研究内容


为了解决上述问题
，本论文开展了基于树结构的图像段落描述研宄
，其主要


目的是在主流的图像段落描述模型的基础上
，探索如何通过建模并引入图文模态


中蕴含的树结构
，
提升模型的段落生成质量。


８


第
一章绪论


本文的主要研究内容如下
：


１
）基于文本树结构的图像段落描述算法研宄


针对问题
１
，
本文将其进
一步拆解为
，
研究如何获取段落句子间蕴含的树结


构以及研究如何利用树结构指导段落描述生成
。为此
，本文首先设计了
一种段落


句子树结构层次无监督构建方法
，该方法基于大规模预训练语言模型和层次聚类


实现
。将建模的树结构信息作为监督信号
，本文进
一步提出了
一种新颖的树结构


段落解码框架
，
用于缓解顺序结构解码容易导致的冗余生成和不连贯问题
。


２
）
引入视觉树结构的图像段落描述算法研宄


针对问题２
，
本文将其进
一步拆解为
，
研宄如何建模图像区域间蕴含的树结


构以及研究如何在现有模型中引入树结构信息提升生成质量。为此
，本文首先设


计了
一种图像区域树结构的启发式构建方法。基于构建的图像区域树结构
，本文


在非层次结构模型的视觉信息编码过程引入树结构信息进行了尝试
。
实验发现
，


引入区域树结构的模型能够生成内容更加丰富和准确的描述段落
。


１
．３
．３贡献及创新点


本文的主要贡献以及创新点总结如下
：


１）在图像段落描述任务中
，
首次提出利用树结构进行图文模态的建模
，
并


结合建模后的树结构进行模型改进
。提供了
一种与传统思路不同的
、用于解决段


落连贯性和多样性挑战的研究新视角
。


２
）提出了
一种新颖的树结构段落解码框架以及对应的段落句子树层次建模


方法
，创新性的将段落生成过程建模为
一棵自顶向下不断划分扩展的二叉树结构
。


所提方法利用基于标签段落剖析得到的句子树作为监督信息
，使模型能够显式学


习到段落间句子关系
，
实现了段落连贯性和多样性的提升
。


３）提出了
一种新颖的树结构增强的编码器组件以及对应的图像区域树启发


式构建方法
，
创新性的将图像区域集合逐层分组为符合人类观察习惯的
“ 上下
”


或
“ 左右
” 子部分
，
利用分组信息指导注意力机制
，从而増强模型对图像观察的


理解和建模的能力
，
实现了描述段落生成质量的提升
。


１
．４本文的组织结构


本论文总共包含五个章节
，章节结构如图
１
－２所示
，每
一章的重点内容如下
：


第
一章
，绪论
。首先介绍了图像段落描述任务的研宄背景和应用价值
，并对


相关工作进行了综述
。进
一步分析了当前图像段落描述任务面临的问题
，最后对


本文的研宄内容与主要贡献进行了总结
。


９


北京邮电大学工学硕士学位论文


第二章
，基础知识
。简要介绍了本文涉及的基础理论知识
。首先介绍了编码


器
－解码器框架
，
并对主流的视觉编码器和文本解码器基础算法进行了梳理和介


绍
。
最终对图像段落描述基准数据集与评测指标进行了总结
。


第三章
，基于文本树结构的图像段落描述算法研宄
。首先介绍了本文设计的


一种段落句子树结构的层次建模方法
，并介绍了所提出的树结构解段落解码框架


细节
。
最终通过实验分析
，
验证了所提出的框架的有效性
。


第四章
，
引入视觉树结构的图像段落描述算法研究
。首先介绍了本文提出的


一种图像区域树结构的启发式构建方法
。进
一步介绍了在非层次结构模型中引入


视觉树结构的技术细节
。
最终通过实验分析
，
验证了方法的有效性
。


第五章
，
总结与展望
。对本文的研究工作进行了总结
，
并对未来工作进行了


展望
，
提出了可以进
一步开展的研宄方向
。


第
一章绪论


＾


第二章翻知识


挑战１
：
上下文连贯性
挑战２
：
内容多样性
挑战３
：
描述准确性


问题
１
：
缺乏对段落句子问题２
：
缺乏对图像区域


结构信息的建模和利用结构信息的建模和利用


Ｖ
＼
Ｊ



＞
ｊ
ｒ



第三章基于文本树结构的图像
｜第四章引入视觉树结构的图像


段離述算挪究
段雛述算法研究


第五章总结与展望


图
１
－２
本论文的组织结构


１０


第二章基础知识


第二章基础知识


２
．
１编码器
－解码器框架


编码器
－解码器框架
（Ｅｎｃｏｄｅｒ
－ＤｅｃｏｄｅｒＡｒｃｈｉｔｅｃｔｕｒｅ）是
一种通用的
，
用于解


决实际问题的计算框架
。
顾名思义
，
框架主要由编码器和解码器两个模块构成
。


编码器负责将输入编码为中间状态
，
解码器负责将中间状态解码并输出
。


框架的输入输出定义会随着任务不同发生变化
。机器翻译任务中
，输入为源


语言
，输出为目标语言
；
自动文摘任务中
，输入为长文档
，输出为摘要
；
图像分


割任务中
，输入为原始图像
，输出为包含轮廓的分割掩码
；
语音识别任务中
，输


入为语音信号
，
输出为文本
；
图像生成任务中
，
输入为描述文本
，
输出为图像
。


图像单句
（段落）描述任务中
，
输入为图像
，
输出为描述句子
（段落）
。


利用编码器
－解码器框架解决实际问题的关键
，
在于有针对性地选取和设计


合适的神经网络结构处理输入和输出
。随着深度学习的发展
，前馈神经网络
（多


层感知机）
、
卷积神经网络、
循环神经网络和变压器
（Ｔｒａｎｓｆ
ｏｒｍｅｒ）等基础结构


被相继提出
，成为了编码器
－解码器框架的重要组成部分
。机器视觉、
自然语言处


理等领域的研宄也为编码和解码图像
、文本等数据积累了宝贵的理论和实践经验
。


因此
，
本文开展的图像段落描述研究
，
本质上是围绕编码器
－解码器框架展


开的
。给定图像输入
／
，
可以将图像段落任务的编码
－解码过程抽象如下
：


ｒＶ＝Ｅｎｃｏｄｅｒ（／）


ｈｔ
＝Ｄｅｃｏｄｅｒ（
／ｉｔ
＿１＃Ｋ）
（２
－
１）


Ｊ
＞ｗ〇ｒｄ
＝Ｓｏｆｔｍａｘ
（ＭＬＰ（ｈ
ｔ））


其中
，
Ｖ编码得到的视觉特征表示
，
／ｉｔ代表
ｔ时刻解码器网络的隐藏状态
，


包含解码过程的历史信息
。ＭＬＰ为多层感知机
，
为词表中的词作为当前输


出的概率
，
最终通过采样得到文本输出
。


本章节的后续内容安排如下
：


首先分别介绍图像段落描述任务中编码器与解码器的理论基础和常见模型


组件
。
最后介绍图像段落描述任务的基准数据集以及采用的评测指标
。


２
．２视觉编码器


视觉编码器负责图像的预处理以及信息提取
，实现从原始像素信号中提取视


觉语义信息
。视觉编码器的理论主要依托于机器视觉方法的发展
，从早期的手工


特征设计
，
逐渐发展到由深度学习理论主导的特征表示学习
。


１
１


北京邮电大学工学硕士学位论文


本节主要介绍两种常用于图像描述任务的编码器组件
：卷积神经网络和目标


检测模型
。


２．２
．
１卷积神经网络


卷积神经网络是
一类深度学习模型
，因采用共享的卷积操作替代全连接的矩


阵运算而得名
。卷积神经网络适用于处理网状类型的数据输入
，包括但不限于语


音信号
（
一维时间序列
）和图像数据
（二维像素矩阵）
，
其最早被应用于解决图


像分类问题
，
后逐渐成为目标检测
、语义分割模型的重要组成部分
。


随着训练数据量和计算能力的不断提升
，卷积神经网络的架构经历了从早期


经典的ＬｅＮｅｔ
－５
［５＇到深度学习时代在
ＩｍａｇｅＮｅｔ＾大规模视觉识别竞赛大放异彩


的Ａｌｅｘｎｅｔ
［５９］
，ＶＧＧ
［６（）
］
，ＧｏｏｇＬｅＮｅｄ
６
１
］
，ＲｅｓＮｅｔ
［６２】
，ＳＥＮｅｔ
［６３
］以及后继者ＲｅｓＮｅＸｔ
［６４］
，


Ｅｆ
ｉＣｉｅｎｔＮｅｔ
［６５
］等
。尽管如此
，卷积神经网络的架构仍在快速迭代更新中
，数月甚


至数周内就会有新的改进方案被提出
，提升卷积神经网络的性能表现或计算效率
。


尽管不同网络结构有着不同的设计
，
但都包含相似的基础组件
：
卷积操作
、


池化操作和非线性激活函数
。
简要说明如下
：


１
）卷积操作


卷积操作又称为卷积层
（ＣｏｎｖｏｌｕｔｉｏｎａｌＬａｙｅｒ）
，
是
一种特殊的线性运算
。卷


积操作利用卷积核模板
（Ｋｅｒ
ｎｅｌ）以预设的步长
（Ｓｔｒ
ｉｄｅ）滑动
，对特征图
（Ｆｅａｔｕｒｅ


Ｍａｐ）进行特征提取
，
得到新的特征图
。特征图为三维张量
，
初始的特征图为预


处理后的图像像素矩阵
，
每
一维分别对应长、
宽和ＲＧＢ通道信息
。卷积核模板


是参数共享的
，与全连接的矩阵运算相比
，
一方面减少了计算量
，使处理分辨率


更高的图像成为可能
；另
一方面
，有助于模型捕捉输入图像中的平移不变形特征


（ＳｈｉｆｔＩｎｖａｒ
ｉａｎｃｅ）
，
提升模型的泛化能力
。


以二维图像
Ｊ输入为例
，给定二维的卷积核模板Ｘ
，卷积操作计算如下


ＳＣ
ｉ
．ｊ）
＝
〇
＊＝
ＶＶ／（ｉ＋ｍ
，ｊ＋ｒｉ）Ｋ（ｍ
，ｎ）（２
－２）


ｉｎ


２
）池化操作


池化操作又称为池化层
（ＰｏｏｌｉｎｇＬａｙｅｒ）
，是
一种下采样运算
。池化操作通过


利用特征图相邻区域的统计量的作为采样结果
，对卷积操作过后的特征图进行特


征选择和信息过滤
。
一个显著特点是在模型进行池化操作后
，特征图的长和宽通


常会缩小
。与卷积操作相同
，池化操作也需要预先设定进行操作的范围和移动的


步长
。常用的池化操作包括最大池化（ＭａｘＰｏｏｌｉｎｇ）和平均池化
（ＭｅａｎＰｏｏｌｉｎｇ）
。


最大池化计算相邻矩阵区域内
（例如
２ｘ
２
）
的最大值作为新的特征图在该位置


的输出
，
而平均池化则计算相邻矩阵区域内的平均值作为输出
。


１２


第二章基础知识


３）非线性激活函数


非线性激活函数
（Ｎｏｎ
－ＬｉｎｅａｒＡｃｔｉｖａｔ
ｉｏｎＦｕｎｃｔｉｏｎ）
，
在网络结构中通常位于


卷积操作之后
、池化操作之前
，
用于增强模型对复杂特征的建模能力
。常用的非


线性激活函数包括
ｓｉｇｍｏｉｄ函数
，双曲正切函数
，线性整流函数
（Ｒｅｃｔｉｆ
ｉｅｄＬｉｎｅａｒ


Ｕｎｉｔ
，ＲｅＬＵ
）
以及ＲｅＬＵ的改进。


ｓｉｇｍｏｉｄ激活函数通常用
ａ符号表示
，
其表达式如下
：


ｓｉｇｍｏｉｄ〇）＝〇
？〇）
＝
（２
－３）


１＋ｅ
ｘ


双曲正切函数通常使用
ｔａｎｈ表示
，
其表达式如下
：


ｔａｎｈ〇）
＝
６
Ｘ
Ｂ
Ｘ
（２
－４）


ｅｘ
＋ｅ
ｘ


ＲｅＬＵ激活函数的计算公式如下
：


ＲｅＬＵ
（ｘ）＝ｍａｘ
（ａｔ
，０）（２
－５）


在早期的图像描述任务研宄工作中
［１８
，
１９
，２（）
］
，研宄者首先在大规模图像分类数


据集上预训练卷积神经网络
，并用最后
一层卷积层的特征图输出作为编码器的输


出
。在训练图像描述模型时
，往往会冻结卷积神经网络的参数
，优先对解码器的


进行训练
。有的研究者会在训练的最后阶段
，使用非常小的学习率对编码器和解


码器进行联合微调
（Ｆｉｎｅ
－ｔｕｎｅ）
。通过将上游任务
（图像分类任务）学习到的图像


信息提取能力泛化到下游任务
（图像描述任务
）
，
使模型能够在数据量更小
、任


务更复杂的场景下取得好的性能表现
。


２
．２
．２目标检测模型


目标检测模型是
一类用于同时解决图像中物体的定位和类别预测的神经网


络模型
。
目标检测模型的输入为
一张图像
，输出为
一个检测目标集合
，集合中的


每个元素包含
一个矩形边界框
（ＢｏｕｎｄｉｎｇＢｏｘ）的空间坐标以及框内对象的类别


预测结果
。其中
，边界框是对检测目标所在空间位置的描述。经典的目标检测模


型包括
一阶段模型ＹＯＬＯ
［６７
］系列模型以及两阶段模型ＦａｓｔｅｒＲ
－ＣＮＮ
［２２］
，
ＭａｓｋＲ
－


〇１１＃
８
］等
。以ＦａｓｔｅｒＲ
－ＣＮＮ模型为例
，卷积神经网络作为骨干网络提取特征图
，


利用区域提议网络
（Ｒｅｇ
ｉｏｎＰｒｏｐｏｓａｌＮｅｔｗｏｒｋ
，
ＲＰＮ）基于锚点框
（Ａｎｃｈｏｒ）进行


预测
，保留可能存在物体的候选区域
，并在特征图的基础上进行Ｒ〇ｒ池化（Ｒｅｇ
ｉｏｎ


ｏｆｌｎｔｅｒ
ｅｓｔ）
。
区域的特征最终输入到分类器中
，
完成边界框回归和类别分类
。


相比于通过图像分类训练得到卷积神经网络
，
目标检测模型能够提供更加细


粒度的图像信息
，
有助于图像描述模型解码生成更准确的描述文本
。具体而言
，


在图像描述任务中
，
因经过多轮卷积和池化操作
，卷积神经网络抽取得到特征图


的分辨率往往是原图像的
１／１６甚至更低
，
因此只能对图像中形状较大的
、特征


１３


北京邮电大学工学硕士学位论文


明显的对象实现有效的响应并提取信息
。而将目标检测模型作为特征提取器
，有


助于缓解上述问题
，
获取区域级别
、语义更为丰富和准确的图像特征表示
。


在图文多模态研究领域
，
由Ａｄｅｒｓｏｎ等人
［２
１］在ＶｉｓｕａｌＧｅｎｏｍｅ数据集
［６９］上预


训练的
ＦａｓｔｅｒＲ
－ＣＮＮ模型被广泛用于图像特征抽取
。预训练阶段
，
该模型在学


习目标检测的同时
，
需要对图像内物体的颜色、
状态等属性进行预测
。例如
，


“
ｗｈｉｔｅｈａｔ
”
，
“
ｇｒｅｅｎｇｒａｓｓ
” 等
。通过对物体属性的监督学习
，该模型进
一步提升


了图像区域特征的编码质量
，
极大地提升了下游任务的表现。


此夕卜
，
Ｊｏｈｎｓｏｎ等人
［３３］提出的密集描述方法模型Ｄｅｎｓｅｃａｐ也常被应用于特征


抽取
。
Ｄｅｎｓｅｃａｐ在ＦａｓｔｅｒＲ
－ＣＮＮ的基础上
，
将边界框中物体类别预测任务拓展


为描述句子生成任务
。
值得
一提的是
，
图像段落描述研宄的部分工作
［７
，３５
，４（）
］是基


于Ｄｅｎｓｅｃａｐ检测的区域特征和对应生成的描述句子开展的
。


２
．３文本解码器


文本解码器负责文本序列的建模以及生成
，完成从编码器得到的中间表示到


输出文本的转换
。
文本解码器的理论基础源于计算语言学中对神经语言模型


（ＮｅｕｒａｌＬａｎｇｕａｇｅＭｏｄｅｌ
，
ＮＬＭ）的研究
。
随着深度学习的发展
，
相关方法在词


表示学习
、机器翻译等任务中得到了广泛应用
，成为了建模文本序列的重要范式
。


在训练阶段
，
给定编码器得到的中间表示Ｖ
／
，
文本解码器的模型参数为０
，


优化目标为最大化标签文本Ｓ＝
｛叫
，
．
．
．
，
；＾
；｝的似然函数
：


６
＊
＝ａｒｇｍａｘ
Ｉ
＼ｏｇｐ（Ｓ
＼Ｖ
ｊ
－
，ｄ）（２
－６）


（
．ｖ＾ｓ）


利用链式法则
，
可以将联合概率分布拆分如下
：


Ｔ


ｌ〇ｇｐ（５
｜Ｖ
／；＾
ｌｏｇｐ（＾
ｔ
｜Ｖ
／，ＷＸ，
ｗ
ｔ
＿ｘ
；９）（２
－７）


ｔ＝ｌ


文本解码器需要通过神经网络完成对ｐ（ｗ
ｔ
｜ｈ叫
，
，ｗ
ｔ
＿１
；６〇的建模和学习
。


在测试阶段
，文本解码器通过选取概率最大的值作为输出
（贪婪解码）或依据预


测的概率分布随机选取
（随机采样）
，
从而实现文本的生成
。
本节主要介绍两种


常用于图像描述任务的解码器组件
：
循环神经网络和变压器网络
。


２
．３
．
１循环神经网络


循环神经网络是
一类深度学习模型
，因循环利用同
一个网络更新隐状态表示


（ＨｉｄｄｅｎＳｔａｔｅ）而得名
。循环神经网络适用于处理序列形式的输入和输出
，包括


但不限于文本、语音、时序信号等数据类型
。循环神经网络与卷积神经网络类似
，


１４


第二章
基础知识


也具有参数共享的特点
。此外
，
循环神经网络每个时间步均有输出
，
且循环神经


网络当前时刻的输出与当前时刻的输入以及历史信息有关
。


具体而言
，设
ｔ时刻模型输入为
，存储历史信息的隐状态表示为
。朴


素的循环神经网络的前向过程如下所示
：


ｈ
ｔ
＝ｔａｎｈ（
ｌ４／
ｘｘ
ｔ＋Ｗｈｈ
ｔ＾＋ｂ）（２
－８）


其中
，
和
为可学习的参数矩阵
，
６为可学习的偏置向量
。随着序列输


入的改变
，隐状态表示将被不断更新
。循环神经网络通过ＢＰＴＴ
（Ｂａｃｋｐ
ｒｏｐａｇａｔｉｏｎ


Ｔｈｒ
ｏｕｇｈＴｉｍｅ
）方法实现误差反传和模型参数更新
。


然而
，朴素的循环神经网络在训练时容易遇到梯度消失和梯度爆炸问题
，导


致网络参数难以得到有效的更新
。此外
，朴素的循环神经网络难以利用历史较远


的信息
，
长距离的序列信息捕捉能力有限
。


为此
，Ｈｏｃｈｒｅｉｔｅｒ等人
［７
１
］提出了长短期记忆网络
（ＬｏｎｇＳｈｏｒ
ｔ
－ＴｅｒｍＭｅｍｏｒｙ
，


ＬＳＴＭ）
。
ＬＳＴＭ利用门控机制
，
对输入
、
历史信息和输出进行有选择性的更新
。


设
ｔ时刻输入为ｘ
ｔ
，隐状态表示为
ｈ
ｔｙ
，额外引入的内部状态
（ＣｅｌｌＳｔａｔｅ
）为
Ｃｐｉ
，


ＬＳＴＭ的前向过程如下所示
：


ｒ
ｆｔ
＝ａ（Ｗ
ｆｘ
ｔ＋Ｕ
ｆｈ
ｔ
＿ｔ＋ｂｆ）


ｉ
ｔ
＝ａ（Ｗ
ｔｘｔ＋Ｕ
ｉｈ＾＋


＾ｏ
ｔ
＝ａ（Ｗ０ｘ
ｔ＋Ｕｏｈ＾＋ｂ０）（２
－９）


ｃ
ｔ
＝ｔ＾ｎｈ（Ｗｃｘ
ｔ＋ｔ／ｃ
／ｉ
ｔ
＿！＋ｂｃ）


ｃ
ｔ
＝
ｆｔＱｃ
ｔ
＿！＋ｉ
ｔＱ
ｃ
ｔ


＜ｈ
ｔ
＝ｏｔＱｔａｎｈ（ｃ
ｔ）


其中
，
队和Ｒ均为可学习的参数矩阵
，
匕均为可学习的偏置向量
，
Ｇ
＞代表


逐元素乘积
。
／ｔ
，和
ｏ
ｔ分别对应遗忘门控
，输入门控和输出门控向量
。可以看


至
ｌ
ｊ
，ＬＳＴＭ
的内部状态
ｃ
ｔ由两部分组成
，
一部分为前
一时刻的内部状态
经


过／ｔ后遗忘部分无关信息
，
另
一部分为利用力筛选的当前时刻有效的输入信息
。


通过有选择的遗忘和更新
，
ＬＳＴＭ能够更好的处理长序列数据带来的依赖性挑战
。


２
．３
．２变压器网络


变压器网络
（Ｔｒａｎｓｆｏｒｍｅｒ）
是由Ｖａｓｗａｎｉ等人
［２７吁
２０
１７年提出的新
一代神


经网络架构
，最早用于解决机器翻译问题
，包含
一套完整的编码器和解码器设计
。


与前馈神经网络
、卷积神经网络不同
，循环神经网络计算时依赖于前
一时刻的输


出
，
因此无法进行并行化计算
，
训练效率成为了瓶颈
。此外
，
ＬＳＴＭ等循环神经


网络结构依然存在梯度消失和爆炸问题
。为此
，变压器网络提出利用多头注意力


机制实现序列上下文间的依赖关系的捕捉和编码
，极大的降低了训练复杂度
，使


得训练阶段能够进行并行计算加速训练
，
逐渐成为了文本建模的新范式
。


本节主要介绍变压器网络的解码器组件
：


１５


北京邮电大学工学硕士学位论文


１）多头注意力机制
（Ｍｕｌｔｉ
－ＨｅａｄＡｔｅｎｔｉｏｎ）


首先
，
定义注意力操作Ａｔｅｎｔｉｏｎ如下
：


Ａｔｔｅｎｔｉｏｎ
（Ｑ，Ｋ
，Ｖ）＝Ｓｏｆｔｍａｘ
（＾
＿
）
Ｖ（２
－
１０）


其中
，
＜３Ｇ尺
ｅ和
１／ｅ分别代表查询向量
（Ｑｕｅｒｙ）
、键


值向量
（Ｋｅｙ）
以及值向量
（Ｖａｌｕｅ）
。
Ｌ为序列长度
，
ｄｆ
ｃ和勾分别为查询向量


和键值向量的维度
。将原始的
（？
，
欠
，
Ｆ先投影到维度ｄｍ
，分别进行ｈ个独立注


意力操作
，
将最终得到的结果拼接
，
便得到了多头注意力机制如下
：


ＭｕｌｔｉＨｅａｄ（Ｑ
，Ｋ
，Ｖ）＝ＣｏｎｃａｔＣ
／ｉｅａｄｉ，
．
．
．
，ｈｅａｄ
ｆ＾Ｗ
０（２
－
１
１）


ｗｈｅｒｅｈｅａｄ
ｊ
＝ＡｔｅｎｔｉｏｎＣＱＭ＾
３
，ｉｆ


其中
，ｗ／
３
ｅ＜ｅＭ
ｄｍＸｄ＊
，岭ｅＥ
ｄｍＸ知以及ｅＤ＾
ｄｐＸｄｍ
。


在文本解码器中
，多头注意力需要引入
一个掩码矩阵
（Ｍａｓｋ）实现在ｒ时刻预测


时
，使其只能进行历史时刻
（ｔ＜ｒ
）的输入的注意力计算
。
引入掩码的多头注意


力机制记为
１＾＾１（６￡１１＾１１行他３（１（
（３义
１〇
。此外
，如果
（２
，
尺
，
７为相同的输入特征


则将该注意力称为多头自注意力机制
。


２
）位置编码
（ＰｏｓｉｔｉｏｎＥｎｃｏｄｉｎｇ）


变压器网络通过在词向量中引入额外的位置编码
，解决由于多头注意力无法


建模序列数据的顺序信息的缺陷
。
位置编码定义如下
：


ｒ
ＰＥ
（ｐｏｓ．２〇
＝ｓｉｎ（ｐｏｓ／１００００
２
ｌ
＇
／ｄ－
）


ＰＥ
（ｐｏｓ＞２
ｉ＋ｉ）
＝ｃｏｓ（ｐｏｓ／１００００
２ｉ／ｄ－
）
ＣＪ


其中
，
ｐｏｓ为词向量在序列中的下标值
，
ｉ为词向量对应维度的下标值
。


３）解码过程


输入为编码器得到的中间表示
文本序列的词向量矩阵
ｓ
ｅ


Ｊ＾
ｓＸｄｅ
，
变压器网络解码器组件的前向过程如下所示
：


Ｓ＝ＰＥ（５）
（２
－
１３）


Ｓ
ｓｅｌｆ＝ＭａｓｋｅｄＭｕｌｔｉＨｅａｄ（５
，Ｓ
，Ｓ）（２
－
１４）


Ｓ
ｄｅｃ＝ＭｕｌｔｉＨｅａｄ＾＾Ｋ
；
，＾）（２
－
１５）


Ｓ
＇
＝
（ＲｅＬＵ（Ｓ
ｄｅｃＷ〇＋ｉｏ））＾＋ｂｘ（２
－１６）


Ｐ＝Ｓｏｆｔｍａｘ（ＭＬＰ（５
，
））（２
－１７）


其中
，为了清晰展示
，每
一层操作均采用了残差连接
［６２］并采用ＬａｙｅｒＮｏｒｍ方


法
［７２
］进行归
一化
，
即
；ｔ＝ＬａｙｅｒＮｏｒｍ（ｘ＋Ｓｕｂｌａｙｅｒ（
；ｃ））
。公式２
－
１４、
２
－１５和２
－１６


１６


第二章
基础知识


定义的
一组计算称为
一层解码网络
，实际使用时会层叠多个参数独立的解码网络
，


提升模型的深度
，
从而增强模型的建模能力
。


此外
，最终输出为Ｐ
ｅＭｋｘ？
，说明可以同时为序列每个位置预测的词概率


分布
，实现了训练阶段并行化计算
。然而在文本生成阶段
，变压器模型的解码器


仍需要逐步抽样上
一时间步的输出
，更新输入矩阵
，才能得到当前时间步的输出
。


值得
一体的是
，在图像单句描述的研究中
，变压器网络逐渐替代ＬＳＴＭ成为


首选的解码器组件
。然而在图像段落描述研宄中
，变压器网络作为解码器的探索


仍处于早期阶段
，
ＬＳＴＭ仍是段落描述生成的主流解码器组件
。


２
．４数据集及评测指标


２
．４
．
１图像段落描述基准数据集


当前图像段落描述研宄的基准数据集为斯坦福图像段落数据集
（Ｓｔａｎｆｏｒｄ


ＩｍａｇｅＰａｒａｇｒａｐｈＤａｔａｓｅｔ
）
，
由Ｋｒａｕｓｅ等人
［７
】于
２０
１７年收集并开源
。
段落基准数


据集从ＭＳ
ＣＯＣＯ
［７３
］和ＶｉｓｕａｌＧｅｎｏｍｅ
［６９＾据集中选取了１９５５
１张图像
，
交由数


据众包平台进行人工标注
，为每
一张图像标注了对应的描述段落文本
。基准数据


集将图像进
一步划分为训练集
、验证集和测试集
，分别包含
１４５７５
、
２４８７和
２４８９


个图像和段落描述对
。
平均每个标注段落的长度为
６７
．５个词
，
包含约
５
．７个句


子
，
每个句子包含
１
１
．９个词
。


对比来看
，
图像单句描述基准数据集ＭＳＣＯＣＯ每张图像包含
５个描述句


子
，其句子的平均长度为
１
１
．３个词
。单句描述和段落描述基准数据集中名词
、形


容词
、
动词和代词的比例差异也反映出段落描述更为内容丰富
、
生成难度更高
，


具体统计结果展示在图
２
－
１中
。


ＢＮｏｕｎｓ３３
．４５
（３３
．５％
）■Ｎｏｕｎｓ２５
．８
１（２５
８％
）


＾Ａｄ
ｊｅｃｔ
ｉｖｅｓ２７
．２３

（２７
．２％
）＾Ａｄ
ｊｅｃｔ
ｉｖｅｓ２７
．６４
（２７
．６％
）


＿＿Ｖｅｒｂｓ１０
．７２（
１０
．７％
）醻Ｖｅｒｂｓ１５
．２
１（
１５
．２％
）


—
Ｐｒｏｎｏｕｎｓ１
．２３
（
１
．２％
）
Ｐｒｏｎｏｕｎｓ２
．４５
（２
．５％
）


Ｏｔｈｅｒｓ２７
．３７
（２７
．４％
）
Ｏｔｈｅｒｓ２８
．８９
（２８
．９％
）


图
２
－
１
单句描述数据集
（左
）
与段落描述数据集
（右
）
统计对比


２
．４
．２图像段落描述任务评价指标


在图像段落描述任务中
，模型的性能由其生成的段落文本质量反映
，生成的


段落文本越准确
、上下文逻辑越连贯以及内容越丰富
，
则模型的性能越好
。人工


评价由于不同研究的标准不统
一且难以横向比较
、耗时费力等客观条件限制
，逐


１７


北京邮电大学工学硕士学位论文


渐被自动化评价指标替代
。基于
“ 模型生成的文本与人类给出的标准文本越接近
，


则生成的文本质量越高
”
［２３］的前提假设
，
自动化评价指标通常遵循如下范式
：


Ｍｅｔｒ
ｉｃ＝Ｓｉｍ（Ｃ
，Ｒ）
（２
－
１８）


其中
，
Ｃ为模型生成的待评测文本
（Ｃａｎｄｉｄａｔｅｓ）
，
为人工标注的
、
用于参


考的标准文本
（Ｒｅｆｅｒｅｎｃｅｓ或Ｇｒｏｕｎｄｔｒｕｔｈ）
。
本节将对图像段落描述研究中广泛


采用的ＢＬＥＵ
，ＭＥＴＥＯＲ
，ＣＩＤＥｒ三类自动化评价指标进行说明
。


１）ＢＬＥＵ
（ＢｉｌｉｎｇｕａｌＥｖａｌｕａｔｉｏｎＵｎｄｅｒｓｔｕｄｙ）


ＢＬＥＵ指标是由
Ｐａｐ
ｉｎｅｎｉ等人
于
２００２年提出
，
最早用于机器翻译模型的


自动化评测
。
ＢＬＥＵ是首个与人工评价具有高相关程度、计算开销低且简单易用


的自动化评价指标
，
被广泛应用于各类与文本生成相关的任务评测中
。


ＢＬＥＵ指标是对文本匹配精确率
（ＰｒｅｃｉｓｉｏｎＲａｔｅ）
的改进
。首先
，
ＢＬＥＵ在


文本匹配统计时引入了不同粒度Ｎ元组
（ｎ
－
ｇｒａｍ）的匹配
，包括对应单个词的
一


元组
（ｕｎｉｇｒａｍ）
、对应词组的二元组
（ｂｉｇｒａｍ）等。
同时
，
ＢＬＥＵ对待评测文本


Ｎ元组的统计上限进行约束
，
使其不超过标准文本中对应Ｎ元组的最大值
。
最


后
，ＢＬＥＵ考虑了长度对评测的影响
，引入了过度简短惩罚（ＢｒｅｖｉｔｙＰｅｎａｌｔｙ，ＢＰ）
。


具体而言
，针对待评测的生成文本ｑ
，给定对应的
、包含Ｍ个标准文本的集


Ｒ
ｔ
＝｛ｒ
ｔｌ
，ｒ
ｉ２
ｒ
ｉＭ｝
。
首先统计匹配的Ｎ元组个数
，
得到匹配程度ｐｎ
：


２ｋｍｉｎ
＾
Ｃｏｕｎｔｋ（Ｃ
ｉ）
，ｍａｘＣｏｕｎｔｋ（ｒ
ｉ；）
ｊ


Ｐｎ
＝Ｉ￡Ｓｆ
ｃＣｏｕｎｔｋ（Ｑ）
（２
＂１９）


其中
，
Ｃｏｕｎｔｋ（Ｃ
ｉ）和Ｃｏｕｎｔｋ（ｒ
ｉ７
．
）是
和ｒｙ文本中第ｆ
ｃ个Ｎ元组的统计量
。


进
一步依据生成文本的长度
和参考文本的有效长度＾
，
计算惩罚项ＢＰ
：


（
１，
ｌｃ＞ｌｓ


ＢＰ
＝ｘ
＿ｋ
（２
－２０）


（ｅ
ｌｃ，
ｌｃ＜
ｌｓ


最终
，
通过引入几何平均
，
得到ＢＬＥＵ评测结果
：


ＢＬＥＵｎ
＝ＢＰＸｅｘｐｗｎ
ｌｏｇｐｎ
＾
（２
－２１）


其中
，
％为权重值
，
通常取％
＝１／＾
。
由于当Ｎ大于４时
，
相应的Ｎ元


组会非常稀疏
，
因此通常采用Ｎ
ｅ
｛ｌ
，２
，３
，４｝
，
对应ＢＬＥＵ
－
｛
１
，２
，３
，４
｝指标
。


２）ＭＥＴＥＯＲ
（ＭｅｔｒｉｃｆｏｒＥｖａｌｕａｔｉｏｎｏｆＴｒａｎｓｌａｔｉｏｎｗｉｔｈＥｘｐ
ｌｉｃｉｔＯｒｄｅｒ
ｉｎｇ）


ＭＥＴＥＯＲ指标是由Ｂａｎｅｒｊｅｅ等人
［７４
］于
２００５年提出
，
是对ＢＬＥＵ指标的改


进
。
ＢＬＥＵ指标仅采用了准确率
，且要求Ｎ元组完整匹配
，没有考虑同义词等语


义相似的情况。为此
，ＭＥＴＥＯＲ指标在计算时同时考虑了精确率和召回率（Ｒｅｃａｌｌ


１８


第二章基础知识


Ｒａｔｅ）
，
并给予召回率更大的权重
。
ＭＥＴＥＯＲ进
一步将词干相同
、
同义词等情况


纳入匹配统计
，
使其与人工评价更为相关
。


具体而言
，给定待评测的生成文本
ｃ以及参考用标准文本ｒ
。ＭＥＴＥＯＲ首先


进行
一元组的匹配
，
计算相应的精确率和召回率
，
并釆用调和平均进行加权
：


ｍ
，、


Ｐ＝—
（２
－２２）


Ｃｏｕｎｔ（ｃ）


ｍ
，


Ｒ＝ｔ
－ｔ
（２
－２３）


Ｃｏｕｎｔ（ｒ）


１０ＰＲ
，、


＾ｒｎｅａｎ
＝
＆＋９尸
（２
－２４）


其中
，
ｍ为待评测文本
ｃ和标准文本
ｒ最优匹配下的
一元组匹配数
，


Ｃｏｕｎｔ（ｃ）和
Ｃｏｕｎｔ（ｒ）分别为待评测文本
ｃ和标准文本ｒ中
一元组总个数
。词干相


同
、
同义词等情况将计入匹配数
。如果存在多种
一元组匹配的方案
，选取匹配连


线交叉最少的作为指标计算的依据
。


为了对更长的Ｎ元组匹配情况进行评估
，
ＭＥＴＥＯＲ引入了惩罚项ｐ
，
待评


测文本和标准文本中不相邻的匹配越多
，则惩罚越大
。首先要将匹配好的
一元组


划分到尽可能少的文本块
（Ｃｈｕｎｋ）
中
，
文本块越少
，
则说明待评测文本和参考


文本中相邻的
一元组匹配越长
。如果待评测文本和参考文本完全相同
，则相应的


文本块数则为
１
。
统计得到文本块数ｙ后
，
计算惩罚项如下
：


ｐ
＝０
．５ｘ
（Ｓ）
（２
－２５）


最终
，
得到ＭＥＴＥＯＲ指标如下
：


ＭＥＴＥＯＲ＝Ｆｍｅａｎｘ
（ｌ
－
ｐ）（２
－２６）


３）ＣＩＤＥｒ
（Ｃｏｎｓｅｎｓｕｓ
－ｂａｓｅｄＩｍａｇｅＤｅｓｃｒ
ｉｐ
ｔｉｏｎＥｖａｌｕａｔｉｏｎ）


ＣＩＤＥｒ指标是由Ｖｅｄａｎｔａｍ等人
ｔ２４
］于２０
１５年提出
，是专门针对图像描述任务


设计的自动化评测标准。ＣＩＤＥｒ采用ＴＦ
－ＩＤＦ加权
，即词频
－逆文本频率指数（Ｔｅｒｍ


Ｆｒｅｑｕｅｎｃｙ
－ＩｎｖｅｒｓｅＤｏｃｕｍｅｎｔＦｒｅｑｕｅｎｃｙ）
，为不同的词赋予不同的权重
。直观来看
，


重复出现在描述句子中的词通常视觉信息量更少
，因此在利用标准文本评测生成


的文本时
，
应当赋予这类词更低的权重
。
由此
，
在图像描述任务评测中
，
ＣＩＤＥｒ


能取得相比ＢＬＥＵ和ＭＥＴＥＯＲ与人工评测更为
一致的结果
。


具体而言
，
给定基于图像
／
￡生成的文本
Ｃ
ｉ
，
以及对应的参考文本集


并且将文本中的词映射到对应的原始词根或词干形式
。
定义Ｎ


元组为叫
，统计其出现在文本￣和文本Ｃ
ｉ中的次数
，分别记为
和
／ｉｆ
ｃ（ｑ）
。


计算Ｎ元组Ｗｆ
ｃ的ＴＦ
－ＩＤＦ权重仇
如下
：


１９


北京邮电大学工学硕士学位论文


Ｉｗ
ｚｅｎ
１〇Ｓ
（ｓ／ｐｅ／ｒ
ｎｉｎ
（ｌ
，
ｈｋ｛ｒ
ｐｑ））ｊ
（２２７）


ｆ
ｔ为包含所有Ｎ元组的词表
，
ｆ为数据集中所有图像的集合
。随后
，
基于平


均余弦相似度计算Ｎ元组对应的ＣＩＤＥｒ值如下
：


ＣＩＤＥ
咖母
（２
－２８）


其中
，
＾
ｎ
（Ｃ
ｉ）和５
ｎ
（ｒｙ）为文本
和文本％对应的ＴＦ
－ＩＤＦ权重向量
。通常


采用多个不同长度的Ｎ元组捕捉不同粒度的信息
：


Ｎ


ＣＩＤＥｒ＝
＾
ＡｎＣＩＤＥｒｎＣｃ
ｆ
．
ｉ？
，
－
）（２
－２９）


ｎ＝ｌ


默认米用Ｗ＝４
，
加权权重为
＝１／
ｉＶ。


２
．５本章小结


本章主要介绍了开展图像段落描述研究所涉及的基础知识
。本章以编码器
－


解码器框架为线索
，首先简要介绍了框架的基本范式
，进
一步介绍了卷积神经网


络和目标检测模型两大类视觉编码器
，以及循环神经网络和变压器网络两大类文


本解码器
。
最后
，
本章介绍了图像段落描述基准数据集和相应的指标。


２０


第三章
基于文本树结构的图像段落描述算法研宄


第三章基于文本树结构的图像段落描述算法研究


当前主流的图像段落描述研究忽略了段落句子间存在的关系结构
，简单地将


段落生成过程建模为
一个顺序解码的过程
。因此
，本章对基于文本树结构的图像


段落描述算法进行研宄
，提出了
一种新颖的树结构解码框架
。该框架将段落生成


过程建模为
一棵自顶向下不断扩展的二叉树
，显式建模段落句子间的树结构关系
。


同时
，提出了
一种段落句子树结构的层次建模方法和
一种新颖的树结构损失函数
。


实验结果表明
，与主流的顺序解码方案相比
，在显式建模文本树结构后
，模型能


够生成质量更高的描述段落并且生成过程具有更好的可解释性
。


３
．
１本章引论


首先
，
给出图像段落描述任务的定义
：
输入待描述的图像
图像段落描述


的目标为生成
一个含有Ｍ个句子的描述段落Ｐ＝
｛＆，
每个句子包


含恥个单词
，即
＝将图像输入到预训练的目标检测器


模型中
，抽取图像中欠个区域级图像特征表示
，记为Ｐ＝。将检测得


到的区域特征表示为通过逐元素的最大池化
（Ｍａｘｐｏｏｌｉｎｇ）计算得到全局图像特


征表示
，
记为


由于图像段落模型采用编码器
－解码器框架
，当得到编码后的图像特征７
，可


以将主流的层次结构方法的解码过程抽象如下
：


（
Ｔ
ｉ
＝Ｒｍｓ（Ｔ
ｉ
＾１
，Ｖ）


）
Ｋｊ
＝
（３
－
１）


［ｗ
ｉｊ
＝Ｓｏｆｔｍａｘ
（ＭＬＰ（ｈ
ｉｊ）＾


其中Ｔ
ｉ为利用句子ＲＮＮＳ得到的句子主题特征表示
，
；
？为循环神经网络的


隐藏单元
，
ＭＬＰ为多层感知机
，
即全连接前馈神经网络
。
可以看到
，
层次结构


将段落生成建模为两个阶段
：顺序推理出句子主题
，再基于句子主题生成词
。
由


于句子主题是逐步推理得到
，使得模型只能建模
一种简单的
，类似于
“ 流水账式
”


的段落结构
，
限制了段落生成的多样性和连贯性
。


类似的
，
可以将非层次结构方法的解码过程抽象如下
：


；
ｈ
ｔ
＝ＲＮＮｗ（Ｖｉ＾）
（＾


ｗ
ｔ
＝Ｓｏｆ
ｔｍａｘ（ＭＬＰ（ｈｔ））


２１


北京邮电大学工学硕士学位论文


可以看到
，非层次结构方法进
一步简化了段落结构
，将段落生成直接建模为


词序列顺序生成
。句子间的关系被进
一步弱化
，模型主要依赖图像模态生成描述
，


使得生成内容冗余且缺乏连贯性
。


本章提出采用树结构作为桥梁
，显式连接图像和文本模态
。与顺序解码不同
，


树结构解码方法的生成过程抽象如下
：


ｆｖ
ｌ
，ｖ
ｒ＝ＴｒｅｅＮＮ（ｖｐ
，


（３
－３
）


ｗ
ｉ
ｔｊ
＝Ｓｏｆｔｍａｘ
＾
ＭＬＰ
（ｈ
ｌＪ）ｊ


其中
，
｛ｖｐ
，ｉ／
，ｕ
７
＂
｝分别对应通过ＴｒｅｅＮＮ逐步划分的父节点
、左节点和右节


点特征
，初始根节点为图像全局特征Ｖ５
，最终解码叶节点
实现句子生成
。可


以看到
，树结构解码从图像全局表示开始
，逐步细化到叶节点得到生成最后的段


落
。通过自顶向下逐步细化的过程
，模型能够更全面的理解图像信息
，减少冗余
，


并通过在同
一子树下生成相关主题的描述句子提升生成段落的连贯性
。图
３
－
１形


象地展示了顺序解码和树结构解码的特点和差异
。


？
？１
描述段落
：


〇Ａｂｕｓ
ｉｓｇｏ
ｉｎｇｄｏｗｎｔｈｅｒｏａｄ
．


；
Ｔｈｅｒｅａ
ｒｅａ
ｌｏｔｏｆｂｒ
ｉｇｈｔｇ
ｒｅｅｎｔ
ｒｅｅｓ
．


（ａ
＞顺序解码范式
（ｂ
）树结构解码范式


图
３
－
１
顺序解码与树结构解码的差异展示


本章节的后续内容安排如下
：


首先介绍如何从无标签的段落描述文本中获取树结构作为监督信息
，进
一步


详细介绍本文提出的树结构解码框架细节
，最终通过实验验证所提方法的有效性
。


３
．２段落文本树结构建模方法


当前对自然语言文本中结构的分析
，主要针对句子内部的结构
，
即词或短语


之间的关系展开
，
例如句法成分分析
（ＣｏｎｓｔｉｔｕｅｎｃｙＰａｒｓ
ｉｎｇ
）
、
依存结构分析


（ＤｅｐｅｎｄｅｎｃｙＰａｒｓｉｎｇ
）
。
面向段落间句子结构的分析工作开展较少
，
也缺乏明确


统
一的计算语言学理论
。另外
，
由于段落文本是生成目标
，无法像传统句法分析


方法那样可以在任务输入阶段获取完整的文本
，只能在标注的数据上进行解析并


２２


第三章
基于文本树结构的图像段落描述算法研究


尝试将解访得到的树结构作为标签监督信号
。为此
，需要研究如何从段落文本中


无监督的获取树结构信息
，
并将得到的树结构作为模型设计和训练的辅助信息
，


实现更好的图像段落描述生成效果
。


考虑如下描述段落
（选自图像段落描述基准数据集
［７
］
）
：Ａ
ｌ
ｉｔｔ
ｌｅ
ｇ
ｉｒｌｉｓｓｔａｎｄｉｎｇ


ｂａｒｅｆｏｏｔｉｎｔｈｅｇｒｅｅｎｇｒａｓｓ（０
）
．Ｓｈｅｉｓｈｏｌｄｉｎｇａｂｌｕｅｆｒ
ｉｓｂｅｅｉｎｈｅｒｒ
ｉｇｈｔｈａｎｄａｎｄｈｅｒ


ｌｅｆｔｈａｎｄｉｓ
ｐ
ｌａｃｅｄｏｎｈｅｒｈｉｐ（
１
）
．Ｓｈｅｈａｓｄａｒｋｈａｉｒａｎｄｂｒｏｗｎｅｙｅｓａｎｄｓｈｅｉｓｗｅａｒ
ｉｎｇ


ａｎｏｒａｎｇｅｔａｎｋｔｏｐａｎｄｙｅｌ
ｌｏｗｓｈｏｒｔｓ（２
）
．Ｔｈｅｒｅａｒｅｔａｌｌｔｒｅｅｔｒｕｎｋｓｉｎｔｈｅｂａｃｋｇｒｏｕｎｄ


ａｓｗｅｌｌａｓｂｒｉｇｈｔｃｏ
ｌｏｒｅｄｆ
ｌｏｗｅｒｓｉｎａｆｌｏｗｅｒｂｅｄｏｆｆｔｏｔｈｅｓｉｄｅ（３
）
．段落由４个句子


组成
，采用（ｘ
）的记号对句子进行编号
，方便举例分析
。段落包含两个最主要的主


题
，
女孩和背景环境
，
对应的句子集合为
｛（０
），
（
１
）
，
（２）｝和
｛（３
）｝
。
对女孩的描述可


以进
一步划分为概括描述和细节描述
，分别对应
｛（０
）｝和？
１
），
（２
）｝
。基于上述分析
，


可以将上述描述段落建模为图
３
－２中的二叉树结构
：


ｄ


Ｉ〇
，
丨
－）


图
３
－２段落文本树结构示例


其中
，蓝色节点中的数字与段落中的句子编号对应
。与女孩相关的句子被划


分到了根节点左子树
｛（〇）
，（
１
）
，（２）｝
，
与背景中树和花朵相关的句子被划分到了根


节点的左子树
｛（３
）｝
。
通过对数据集中的描述段落进行类似的分析
，
发现如下
：


１
）主题相关
（例如描述相同对象
）
的句子处于同
一棵子树下
。


２
）人工标注的段落连贯性强
，
句子主要与前后相邻的句子组成子树
。


基于上述分析
，
本文设计了
一种基于
Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ
［７６
］和层次聚类的


段落树结构自动建模方法
，对段落中句子关系进行挖掘并建模为树结构
，更好的


服务后续章节中图像段落描述模型的设计和监督学习
。


具体而言
，所设计的段落文本树构建方法分为两个阶段
：句子语义特征提取
、


自底向上的树结构构建
。首先在句子语义特征提取阶段
，采用预训练的句子编码


网络
Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ提取句子的语义特征ｘｅ，
将输入的描述段落文本


■Ｐ＝
｛５＾
，
…
，心
表不为
一个语义特征序列
｛Ｘｉ
，
…


Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ是在文本预训练模型
（例如
ＢＥＲＴ模型
［７５
］
）
的基础上


运用孪生网络架构和度量学习技术在句子蕴含任务等句子级别数据集上微调训


练得到的句子特征编码网络
。
Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ能够将输入的句子转换为
一


个Ｄ维的语义向量表示
，
满足语义越相似的句子对的特征间余弦相似度越大
。


２３


北京邮电大学工学硕士学位论文


Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ模型的训练框架如图
３
－３所；＾：
，训练时以
一对句子作为


输入
，如果该句子对语义相似
，则记为正例
，反之则记为负例
。利用同
一个ＢＥＲＴ


对句子分别进行编码
，通过多层的多头自注意力机制得到对应位置上每个词的向


量表示
，并采用平均池化得到最终的句子表示
，通过计算句子表示对的余弦相似


度
，
使得正例句子对间的相似度越大越好
，
负例句子对间的相似度越小越好
。构


造树结构时
，模型能够实现对描述段落中句子对进行相似度计算
，描述主题相似


的句子间的相似度更大
，
能够作为下
一阶段合并叶节点或子树的依据
。


－１
．
．
．１


１


ｃｏｓ
ｉｎｅ
－
ｓ
ｉｍ
ｔｕ
，ｖ）


Ｏ


ｕｖ


Ａ
—專
￣


ｐｏｏ
ｌ
ｉｎｇｐｏｏ
ｌ
ｉｎｇ


车车


ＢＥＲＴＢＥＲＴ


ｆ＾


ＳｅｎｔｅｎｃｅＡＳｅｎｔｅｎｃｅＢ


图３
－３Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ模型的训练框架
［７６
］


随后
，
在自底向上的树结构构建阶段
，将段落中的句子视为叶节点
，
则非叶


子节点对应的是叶节点的父节点或子树的父节点
。利用层次聚类的思想
，逐步合


并语义相似度最大的节点对
。同时
，基于句子主要与前后相邻的句子组成子树的


特点
，
约束位置为
ｔ的节点只能与前后相邻的
ｔ
－
ｉ以及
ｔ＋ｉ位置上的节点合


并
。
以构造图
３
－２
中的树结构为例
，
叶节点
｛
１
｝在首次合并时只能考虑合并叶节


点
｛０
｝或０｝
。
当叶节点
｛
１
｝和
因语义相似度最大优先被合并后
，得到的非叶子


节点在下
一轮构建时只能选择叶节点
｛０
丨或
进行合并
。


为了更好的说明树结构构建过程
，
展示图
３
－２中树结构的构造步骤如下
：


步骤
１
：将段落中的四个句子编码为语义向量
｛１。
，１１
，＾２
，１３｝并将其初始化为


树中的叶子节点
。


步骤
２
：
计算相邻节点间两两余弦相似度
｛Ｓ
（）１
，ｓ１２
，Ｓ２３｝
，
选择最相似的节点


对合并成新的子树
，例子中为
５
：１２
＝ｍａｘ
（
｛ｓｏｈＳｕｈｄ）
，即合并叶节点
和
｛２
｝
，


记为新的非叶子节点
｛４
丨
，通过平均得到新节点的语义表示
；ｃ４
＝ｍｅａｎ（丨ＸｐＸｊ）
。


此时语义向量序列为｛ｘＱ
，ｘ４
，ｘ３｝


步骤
３
：计算剩余节点间两两余弦相似度
｛ｓＱ４
，ｓ４３｝
，选择相似度最大的节点


对合并
，
例子中为
即合并叶子节点
｛０
｝和非叶子节点
｛４
｝


组成新的子树
。


步骤
４
：
仅剩余两个节点
，
无需计算距离
，
合并得到最终树结构的根节点
，


完成树结构的自底向上的构建过程
。


２４


第三章
基于文本树结构的图像段落描述算法研究


３
．３面向段落生成的自顶向下树结构解码框架


３
．３
．
１框架总览


为了充分利用描述段落中的句子树结构
，本文提出了
一种面向段落生成的自


顶向下的树结构解码框架
，该框架能够显式建模段落间句子树结构
，其主要部分


可以灵活地替换为其他神经网络组件
。本文进
一步设计了
一种树结构损失
，作为


图像段落描述的中实现树结构拓扑预测的辅助优化目标
。


具体而言
，本文提出了
一种新颖的图像段落描述模型
，称为划分为树的解码


器（Ｓｐ
ｌ
ｉｔｔｉｎｇ
ｔｏＴｒｅｅＤｅｃｏｄｅｒ
，Ｓ２ＴＤ
）
，
该模型将段落生成建模为
一棵二叉树自顶向


下划分的过程
，
Ｓ２ＴＤ的流程总框架如图
３
－４所示
。
Ｓ２ＴＤ由三个模块组成
：划分


模块（３卩价
］＼／［〇（１１１１（；
）
，打分模块
（８￡：£ ＾
１＾０（１１１１６）和词级别
１１１
＇朴＾（
＇
＼￥（＾（１
－
１６￥６１
１＾１＾
）
。


Ｓ２ＴＤ首先通过预训练的目标检测器
ＦａｓｔｅｒＲ
－ＣＮＮ获取输入图像中的区域


图像表示
。将最大池化后的区域特征作为根节点
，进
一步通过划分模块中的门控


机制迭代地将父节点划分为左右子节点
。通过打分模块控制是否划分特定节点获


得最终的树结构
。树结构构建完成后
，将叶节点依次输入词级别ＲＮＮ生成句子
，


组成最终的描述段落并输出
。


由于基准数据集
ＳｔａｎｆｏｒｄＩｍａｇｅＰａｒａｇｒａｐｈＤａｔａｓｅｔ中缺乏相关的树结构标签
，


故将通过
３
．２节中提出的段落文本树结构建模方法得到
，
并有针对性地设计了
一


种新颖的树结构损失来进行端到端的监督学习
。


＾
ｐａｒａｇ
ｒａｐｈ


ｄ

？＾

Ｉｓｅｎｔｅｎｃｅ＃
１

｜


ｉｍａｇｅ
ｉ
，ｂｐｖ＜ｎ幽ｐ
ｉ


？ｗ馨骨
一
Ｊ
；
ｓｅｎｔｅｎｃｅ＃３
｜


Ｒｅｇ
ｉｏｎ
－
ｌｅｖｅ
ｌ
丨
ｉ


Ｆｅａｔｕ
ｒｅｓ
－？
：ｓｅｎｔｅｎｃｅ＃４
：


图
３
－４树结构解码器
Ｓ２ＴＤ框架总览


３
．３
．２划分模块


二叉树自顶向下划分构造的核心操作是将
一个节点
一分为二
，该过程由划分


模块负责实现
。
划分的首个对象为树的根节点
，
根节点为图像的全局特征表示
。


通过分析
，
设计节点划分操作时应满足如下的特点
：


１
）划分得到的新节点应当与父节点相关
，
即新节点是基于父节点计算得到


的
。最理想的情况下
，利用子节点能够重构父节点特征
。满足该特点有助于实现


在同
一棵子树下
，
描述的主题相关联
，
提升描述段落上下文的连贯性
。


２５


北京邮电大学工学硕士学位论文


２）划分计算时应当避免引入噪声
，
即减少引入与父节点无关的信息
。
满足


该特点有助于避免引入未出现的图像信息
，
生成不准确的描述句子
。


３）划分得到的左右子节点有差异性
，
即左右节点应当尽可能建模有差异的


信息
。满足该特点有助于让同
一棵子树下
，左右子树对应的句子能够描述同
一主


题的不同方面
，
提升描述段落中句子内容的多样性
。


为此
，
划分模块采用了门控机制的设计
。
给定父节点特征表示Ｗ
，利用


ＬａｙｅｒＮｏｒｍ
［７２
］方法
，
计算门控向量没
ｓ如下
：


ｇ
ｓ＝ａ（Ｗｓ
－
ＬａｙｅｒＮｏｒｍ（ｖｐ
）＋ｂｓ）（３
－４）


其中
，
代表
ｓｉｇｍｏｉｄ激活函数
，呎
ｅＲＤ” Ｘ？以及圮
ｅ属于可学习的神


经网络参数
。
门控向量炉维度与节点特征维度相同
，
由于釆用了ｓｉｇｍｏｉｄ激活


函数
，
门控向量的每
一维在０到
１之间
，用于控制父节点的信息向左子节点的流


动程度
。为了鼓励左右子节点显式建模图像特征的不同方面
，实现父节点特征的


有效划分
，
左右子节点的计算方式如下
：


ｆｖ
ｌ＝ｖｐＱｇ
ｓ


ｌｖ
ｒ＝ｖＰ〇（ｌ
－
ｇ
ｓ
）
＾Ｊ


其中
，
？代表逐元素乘积
。
可以看到
，
当门控向量
某
一维度的值越接近


１
，则该维度的信息主要由左子节点获得
；值越接近０
，则该维度的信息主要由右


子节点获得。上述特点使得划分模块能够在监督训练时学习到差异性
。
同时
，
公


＊式
３
－５满足父节点等于左右子节点的加和
，
减小了引入噪声的可能性
。


实际上
，任何由
一个特征表示计算得到两个特征表示的方法都可以应用于划


分模块
，例如直接使用多层感知机或者利用卷积神经网络完成
。后续实验发现基


于门控的划分机制简单且有效
，故
Ｓ２ＴＤ最终釆用上述节点划分方式
。其他可采


用的划分模块设计如下
：


１
）基于两个独立的门控向量


ｒ
ｇ
ｌ＝ａ（Ｗ
ｔ
■
ＬａｙｅｒＮｏｒｍ（ｖｐ
）＋ｂ
ｉ）


ｇ
ｒ＝ｃｘ（Ｗｒ
＊
ＬａｙｅｒＮｏｒｍ（ｖｐ
）＋ｂｒ），
、


，＝ＶＰＱｇ
ｌ
（３
＿６）


，ｖ
ｒ＝ｖＰＱｇ
ｒ


２
）基于多层感知机直接计算左右子节点


（
ｖ
ｌ＝ＭＬＰ
ｉｅ／ｔ（ｉ；Ｐ
）


１
＝ＭＬＰｒｉｇｈｔ（ｖｎ
＾Ｊ


２６


第三章基于文本树结构的图像段落描述算法研宄


３
．３
．３打分模块


如果模型只包含划分模块
，那么树结构将会无休止地扩展下去
，无法从图像


和段落数据中学习到如何生成合适的
、有利于段落生成的句子树结构
。
因此
，
需


要使模型具备停止节点划分的能力并能够从数据集中学习如何决策
。


为此
，本文提出利用打分模块对划分结果进行评价
，完成对树结构扩展的控


制
，学习段落句子树的拓扑结构
。具体而言
，给定
一组由划分模块得到的节点划


分提议集合
｛ｖｐ
，Ｖ
７
＂
｝
，
打分模块基于余弦相似度计算得到决策分数ｓｐ
：


，（ｖ
ｌ
）
Ｔ
（ｖ
ｒ
）


ｓｐ
＝
ｃｏ＜ｖ
＇ｖｎ
＝
ｌ＾
ｌ
（３
－８）


当
ａ时
，打分模块将保留当前节点划分结果
，否则拒绝划分
。其中
，决


策阈值ａ为０和
１之间的超参数
，需要通过验证集来确定
。采用余弦相似度进行


度量，具有较好的可解释性
：
决策分数越大
，
则说明划分得到的左右子节点的向


量表示越相似
，更有可能导致冗余的描述句子生成
，应当拒绝这次划分
；决策分


数越小
，
则说明划分的质量越高
，
应当采用本次划分结果
。


为了有效监督打分模块
，首先通过３
．２节中提出的段落文本树结构建模方法
，


基于段落Ｐ构造出对应的树结构ｒ作为标签。树结构标签的学习
，可以转换为对


决策分数的学习
。为此
，本文提出了
一种新颖的树结构损失来实现对决策分数的


有效监督
，
具体计算方式如下所示
：


，
（ｓｐ＞．＝｛
ｍａｘ（〇？ｃｏｓ（ｖ
ｚ
，ｖ
ｒ
））
，ｐｇＬ


Ｔ
‘ｍａｘ（０
，ａ
—
ｃｏｓ（ｖ
ｚ
，ｖ
ｒ
））
，
ｐｅＬ


其中
，
Ｌｃｒ代表所有叶子节点的集合。对于非叶子节点
，
即打分模块的决


策为划分的情况
，
损失Ｌ
ｔ
？的鼓励左右节点的差异越明显越好
。对于叶子节点
，


即打分模块的决策为不划分的情况
，损失
鼓励左右节点的差异略大于阈值ａ
。


相比直接利用二分类损失
，
例如二元交叉熵损失
，
上述树结构损失ｈ可以鼓励


打分模块学习到更平滑的打分策略
，从而实现更好的段落生成效果
。另外
，
训练
、


过程中
，
模型保持与给定标签相同的划分决策
，
测试时则无需预先给定标签
。


与划分模块相同
，打分模块设计亦可采用不同的计算方式和优化目标
，例如


直接使用多层感知机加上
ｓｉｇｍｏｉｄ激活函数作为打分模块
，或者采用其他距离函


数
。后续实验发现
，采用余弦相似度打分机制可解释性更强
，简单有效
，故
Ｓ２ＴＤ


最终采用上述打分设计
。其他可采用的打分模块设计如下
：


１）基于二分类决策


打分模块可以基于父节点的表示进行决策
，
即给定当前父节点
，通过
一个二


分类器决定是否划分该节点
，
计算公式如下
：


ｓｐ＝
■
ＲｅＬＵ（ＶＶ〇
？
ｖｐ
＋ｂ〇）＋ｂｔ）（３
－
１０）


２７


北京邮电大学工学硕士学位论文


如果决策分数小于
０
．５
，
即分类结果为
０则决策划分该节点
，
同时说明该节


点为非叶子节点
。训练时利用二元交叉熵损失训练
。二分类器可以进
一步基于预


划分的子树三元组进行决策
，
计算公式如下
，
其中符号
［；
］为拼接操作
：


ｓｐ＝ａ（Ｗｘ
■
ＲｅＬＵ（ＶＫ０
？
［ｖｐ
；ｖ
ｌ
；ｖ
ｒ
］＋ｂ〇）＋ｂ± ）（３
－
１
１）


２）基于回归拟合节点深度


打分模块也可以通过预测节点的深度实现树结构划分的控制
，同样利用
一个


多层前馈神经网络预测当前父节点ｖＰ的深度分数ｓ
，
计算公式如下
：


５（ｖＰ
）
＝＜ｔ（ＶＫ
ｘ
■
ＲｅＬＵ（ｌＶ〇
■＋ｂ〇）＋ｂｘ）（３
－
１２）


给定
一组节点划分提议集｛ｖｐ
，Ｖ
，ｖ
”
｝
，划分的决策交由以下不等式进行判别
：


ｓ（ｖ
１
＇
）＋ｓ（ｖ
ｒ
）


ｓ（ｖＰ
）＜
Ｊ
２
ＫＪ
＋ａ（３
－１３）


即如果满足该条件则接受该划分提议
，
否则拒绝
。其中
，决策阈值
ｃｒ为
０和


１之间的超参数
。
ａ越大
，
打分模块越倾向于拒绝
。
该设计的动机是
，
新增节点


的平均分数应当大于已有父节点
。训练时
，分数的回归目标设计为ｄ／Ｄ
，其中
ｄ


为节点到根的跳数
，
Ｄ为预设最大深度
。


３
．３
．４词级别ＲＮＮ


树结构构造完成后
，
词级别ＲＮＮ模块负责将叶节点解码得到描述句子
，
约


定从最左边的叶节点开始解码到最右边的叶节点结束
，将依次解码得到的句子组


成最后的描述段落
。
由于利用了划分模块和打分模块
，从图像全局特征开始
，
自


顶向下不断对全局信息进行拆解
，完成了从图像整体到局部的理解
。
因此
，
与主


要利用循环神经网络的顺序解码相比
，
Ｓ２ＴＤ采用的树结构解码能够更好对图像


内容进行理解和规划
。值得注意的是
，
词级别ＲＮＮ可以对树结构中任意
一个节


点表示实现解码
，故可以通过解码树结构中的不同节点
，展示模型生成段落的过


程
，
增强模型的可解释性
。


具体而言
，
给定
一个叶节点表示
，
利用Ｈｉｇｈｗａｙ神经网络
［７７
］将其映射


为句子主题表示
ｅ


Ｇ
＝Ｈｉｇｈｗａｙ。（ｖ
丨
ｅａｆ
）
（３
－１４）


Ｈｉｇｈｗａｙ神经网络在传统的前馈神经网络的基础上
，通过门控机制
，增加了


额外的梯度反传通路
，
缓解模型训练时存在的梯度消失问题
，
前向过程如下
：


ｆｇ
＝
＜ｗ
ｇ
－ｘ
－ｈｂ
ｇ）


ｌｙ
＝
ｇＱＲｅＬＵ（Ｍ／ｈｗ
？
ｘ＋ｂｈｗ）＋（ｉ
￣
ｇ）〇（Ｗｃ
？
ｘ）
Ｋ｝


其中
，
Ｈｉｇｈｗａｙ网络的输入为
；ｃ
，
输出为ｙ
。
当输入和输出维度相同时
，
参


数
可以省略
。得到句子主题表示后
，
进
一步利用
ＬＳＴＭ网络构建语言模型
：


２８


第三章基于文本树结构的图像段落描述算法研宄


ｈ
ｔｊ
＝ＬＳＴＭｉＷｅＷ
ｉｊ＾
．ｈ
ｔｊ＾）（３
－１６）


其中
，％ｅ为可学习的词嵌入矩阵
，ｗ＋ｉｅ为输入词的独热编


码
（Ｏｎｅ
－ｈｏｔＣｏｄｉｎｇ）
，
ｅ为时间步／的隐状态表示
。基于每个时间步的隐


状态表示
，可以通过前馈祌经网络得到当前时间步的词表分布
，最终利用逐步采


样或贪婪解码可以得到叶节点对应的描述句子
：


ｐｕ
＝Ｓｏｆｔｍａｘ
（Ｍ
４
，
［
／ｉ
ｆＪ
；ｔ
ｆ］＋ｂ
ｐ）（３
－
１７）


其中
，
［；
］为特征拼接操作
，
ｎ？以及
是可学习的参数
。


与划分模块、
打分模块相同
，
词级别ＲＮＮ可以进
一步根据使用场景采取不


同的单句描述解码器
。简单起见
，
Ｓ２ＴＤ采用了上述语言模型建模方式
。


３
．３
．５模型训练


模型训练分为监督训练以及强化学习优化两个阶段
。


为了监督训练所提出的
Ｓ２ＴＤ模型
，除了３
．３
．３节提出的树结构损失Ｌ
ｔ
■
，
同


样需要对词级别ＲＮＮ的输出分布进行监督
。具体而言
，基于得到的叶节点表示
，


为了监督语言模型学习如何生成文本
，
本文采用被广泛采用的多元交叉熵损失


进行监督学习
。对单个词分布
，
定义
如下
：


Ｌｗ（Ｐｉ
．ｊ
，Ｗ
ｉｊ）
＝－
ｌｏｇＣｐｗ）（３
－１８）


其中
，
设
ｉｊ是段落标签对应的目标词
，
即当前时刻的生成目标
。
为目标词


由词级别ＲＮＮ计算得到的生成概率值
。


通过联合学习树结构划分和文本生成
，
最终得到如下的联合损失函数Ｌ
：


ｍＮ
ｉ


Ｌ＝
＾
ＬＴＱＳＰ
）＋
＾
Ｌｗ｛ｐｉ
ｔｊ
，ｗ
ｔＪ）（３
－１９）


ｐｅｒ
ｉ＝ｉｊ＝ｉ


利用基于强化学习的
ＳＣＳＴ技术＾，＾可以进
一步优化
Ｓ２ＴＤ模型生成的段


落文本
。该方法将模型视为智能体
，循环神经网络部分的隐藏状态作为智能体的


状态
，将选择和生成词的过程视为智能体在完成动作选择
，对应的动作集合则是


整个词表
。环境的奖励为抽样得到的段落与标签段落的相似程度
，该相似程度利


用评测指标完成计算
。
具体而言
，
ＳＣＳＴ是
一种策略梯度方法
，
利用评价指标作


为奖励
，
计算并优化如下的期望梯度
：


Ｖｇ￡（ｅ）
＝－＾－ｐＪＣｒＣｗ
５
）
－
ｒ（ｗ３
））Ｖｅ
ｌｏｇｐｇ（ｗ
ｓ
）］（３
－２０）


其中＃和？分别代表逐词抽样或贪婪解码的段落文本
。
ｒ〇）为基于指标计


算的奖励函数
，符号ｐ０代表描述模型的所有可学习参数
。
ｒ（ｗｓ
）被称为基线奖励


（Ｂａｓｅｌｉｎｅ）
，不会对期望梯度方向造成影响
，
主要用于稳定强化学习过程
。期望


２９


北京邮电大学工学硕士学位论文


梯度
一般采用马尔科夫采样进行近似估计
，可以利用单次或多轮求平均计算
。此


外
，在进行
ＳＣＳＴ优化前
，
模型需要进行
一定轮次的监督学习作为初始化
，
用以


稳定动作采样
。
需要说明
，
Ｓ２ＴＤ在
ＳＣＳＴ优化阶段不进行树结构划分的学习
。


３
．３
．６段落解码生成算法


为了更好的说明
Ｓ２ＴＤ模型的前向过程
，即测试推理阶段的计算过程
，
Ｓ２ＴＤ


实现树结构扩展生成的算法过程总结在图
３
－５中
。


可以看到
，
图
３
－５中总结的算法类似于树的层次遍历
。划分模块和打分模块


的设计使得Ｓ２ＴＤ可以灵活的选取不同的扩展方式
，例如将算法中的队列替换为


栈结构
，
即可得到类似于树的深度遍历的扩展方式
。


算法
１
：
测试时树结构扩展生成步骤


输入
：
全局图像特征ｖ５
，
句子最大生成个数Ｍ
，
决策分数阈值ａ


初始化
：
空队列
＜３
，
空树结构
：Ｔ


输出
：
扩展完成的树结构
：Ｔ


１将Ｗ加入队列
＜３并将Ｍ登记为ｒ的根节点
；


２ｗｈｉｌｅ非空且ｒ的叶节点个数少于Ｍｄｏ


３出队
中的队首节点ｖＰ
；


４利用划分模块将＃划分为Ｖ
１和ｆ
；


５利用打分模块计算决策分数ｓｉ


６ｉｆｓｐ＜ａｔｈｅｎ


７和
■
依次入队Ｑ
；


８将Ｗ和，登记到Ｔ中
；


９ｅｎｄｉｆ


１０ｅｎｄｗｈｉｌｅ


１
１ｒｅｔｕｒｎＴ
；


图
３
－５
測试时树结构扩展生成算法


３
．４实验对比与分析


３
．４
．
１实验参数与设置


针对提出的
Ｓ２ＴＤ模型
，
为了验证其有效性
，
本文采用开源深度学习框架


Ｐｙ
ｔｏｒｃｈ开发和训练模型并在基准数据集上进行了定性和定量实验
。实验环境为


Ｕｂｕｎｔｕ１６
．０４服务器
，
ＧＰＵ为单张１２ＧＢ显存的ＮＶＩＤＩＡＧｅＦｏｒｃｅ１０８０Ｔｉ显卡
。


３０


第三章
基于文本树结构的图像段落描述算法研究


首先采用预训练的目标检测网络
ＦａｓｔｅｒＲ
－ＣＮＮ— 检测并抽取图像区域特征
。


保留目标检测结果前
３６个框
，
每个框抽取的特征为
２０４８维
。随后
，
利用
一个单


层的
Ｈ
ｉｇｈｗａｙ
网络将图像区域特征的维度投影到
＝１０２４维
。
在训练和测试


阶段
，
目标检测网络的参数保持固定
。


段落文本预处理阶段
，
对于段落标签
，
每个段落保留最多
６个句子
，每个句


子保留最多
３
１个词
。统计词频后
，将出现少于两次的低频词用特殊的符号
“ ＜ｕｎｋ＞
”


替换
。
在每个句子的首尾分别加入特殊符号
“
＜ｂｏｓ＞
” 和
“ ＜ｅｏｓ＞
”
，
用以表明句


子开始和结朿
。
最终得到的词表大小ＳＤＷ
＝６７３０
。


实验中
，
词级别ＲＮＮ采用双层的ＬＳＴＭ网络实现
。词嵌入表示以及网络中


隐藏层的维度均设为Ｄｅ
＝５１２
。在推理阶段时
，采用贪婪解码从输出的词分布中


选择输出的词
。
打分模块和树结构损失采用的阈值ａ设为
０
．３
。


在监督训练阶段
，
采用
Ａｄａｍ优化器
［７９
］
，
学习率为
ＳＸ１０—
，
数据批量大


小为
１６的配置
。
每当训练
５个轮次
（ｅｐｏｃｈ
）
后
，
学习率降低为原本的
０
．８倍
。


在每个轮次结束后
，
为验证集的图像生成段落进行验证
，
采用
ＢＬＥＵ
－４
和


ＭＥＴＥＯＲ指标的平均值作为评测标准
，
如果连续
２０个轮次模型性能未得到提


升
，
则提前结束模型训练
，
将验证集上性能最佳的模型作为最终的训练结果
。


在强化学习阶段
，遵循
ＳＣＳＴ优化过程的基本流程进行
。首先选取监督训练


３０个轮次后的模型作为起始模型
。将ＢＬＥＵ
－４和ＭＥＴＥＯＲ指标的平均值作为环


境奖励
，
学习率固定为
３Ｘ
１０
－５
，
微调至多
５０个轮次
，
同样在验证集上进行验


证和模型选择
。


需要说明
，
上述模型的结构和超参数设置均通过验证集的表现进行选择
。


３
．４
．２评测指标对比与分析


本节选取了近年的图像段落描述模型进行定量的性能对比
，并将其进
一步划


分为层次结构模型组ＲＨ
［７
］
，
ＲＴＴ
－ＧＡＮ
［３５
］
，
ＣＡＰＧ
－ＶＡＥ
［３６
］
，ＣＡＥ
－ＬＳＴＭ
［３７
］
，Ｄｕａｌ
－


ＣＮＮ
［４Ｑ
］
，
ＤＨＰＶ
［３８
］
，ＩＭＡＰ
［４４
］以及非层次结构模型组ＤＡＭ
－ＡＴＴ
［４７］
，
ＳＣＳＴ
［４６
］
，


ＣＲＬ
［４８
］
，
ＯＲ
－ＡＴＴ
［４９
］
。
与上述研宄保持
一致
，
通过采用ＢＬＥＵ
－
｛
１
，２
，３
，４
｝
［２３
］
（Ｂ
）
，


ＭＥＴＥＯＲ
［７４
］
（Ｍ
）
，ＣＩＤＥｒ
［２４
］
（Ｃ
）指标来评价模型的段落生成质量
。


简要说明进行对比的模型结构如下
：


１
）ＲＨ模型
：该模型采用了层次ＲＮＮ网络作为解码器
，
与本文提出的
Ｓ２ＴＤ


模型的主要差异在于
，
ＲＨ模型采用基于句子级
ＲＮＮ来建模和获取句子主题表


示
，而
Ｓ２ＴＤ采用基于划分模块和打分模块的树结构解码来建模和获取句子主题
。


在所有基线模型中
，
ＲＨ模型与
Ｓ２ＴＤ模型的训练和输入最为相似
。


２
）ＲＴＴ
－ＧＡＮ模型
：
该模型是ＲＨ模型的改进
，
其在句子级
、词级ＲＮＮ的基


础上额外引入了段落级
ＲＮＮ
，
并且采用对抗生成网络的思想进行学习
。
此外
，


３
１


北京邮电大学工学硕士学位论文


模型利用预训练的图像密集描述模型
１３３
１生成对应的区域文本描述作为输入
，
故


该模型的输入包含图像区域特征和区域描述句子两部分
。


３
）ＣＡＰＧ
－ＶＡＥ模型
：该模型在ＲＨ模型的改进
，
引入了句子主题间的
“ 连贯


特征向量
” 和
“ 全局特征向量
”
，
并且利用变分自编码器进行额外的优化
。


４
）ＣＡＥ
－ＬＳＴＭ模型
：
该模型将ＲＨ模型的句子级ＲＮＮ替换为
一个卷积自编


码器网络
，通过重构图像特征来学习更好的主题表述
。此外
，
模型在强化学习阶


段采用了额外的奖励信号
，
用以反馈生成段落内容提及图像中物体的包含程度
。


５
）Ｄｕａｌ
－ＣＮＮ模型
：
该模型将ＲＨ模型中的ＲＮＮ网络替换为ＣＮＮ网络
，
利


用卷积神经网络降低模型训练难度
、提升训练效率并增强段落生成的连贯性
。模


型进
一步引入了区域级别的注意力机制
，
用以增强其对图像内容的理解
。


６
）ＤＨＰＶ模型
：
相较于ＲＨ模型
，
该模型采用了更复杂的层次ＲＮＮ结构设


计
，
并采用了
一种受到多层次奖励反馈的策略
－估值优化方法
，
使模型在强化学


习阶段能够接受来自句子级别和词级别的反馈信号
。


７
）
ＩＭＡＰ模型
：
该模型是对ＲＨ模型的改进
，
在层次ＲＮＮ结构中引入了
一


种交互式键值记忆增强的注意力机制
。
该模型采用了与
ＲＴＴ
－ＧＡＮ类似的输入
，


除了图像区域特征外还包括区域对应的描述句子文本
。


８
）ＤＡＭ
－ＡＴＴ模型
：
在图像单句描述模型ＮＩＣ
［
１８
】的基础上
，
该模型首先利用


无监督的方法获取图像相对深度估计
。然后利用解码器中的注意力机制融合图像


语义和信息进行段落生成
。


９
）ＳＣＳＴ模型
：
该模型基于图像单句描述模型ＢＵＴＤ＾ｈ
通过在解码时引入


三元词组重复性惩罚
（Ｔｒ
ｉ
－
ｇｒａｍＲｅｐｅｔｉｔｉｏｎＰｅｎａｌｔｙ，ＲＰ
）
，
降低段落中的句子冗余


内容的生成
，
并进
一步将ＲＰ引入强化学习阶段作为基线奖励
。


１０
）ＣＲＬ模型
：
该模型同样是对ＢＵＴＤ模型的改进
，
主要是对强化学习阶段


的改进
，采用了时序差分算法
，在传统的外部指标反馈的基础上加入了基于内部


状态估计的内部奖励反馈
。


１
１
）ＯＲ
－ＡＴＴ模型
：
该模型是对
ＳＣＳＴ模型的改进
，
引入了
一种新颖的对象


关系注意力机制
，
通过图像物体对象特征两两交互
，
融合提升特征编码质量
。


表
３
－
１和表
３
－２分别展示了相关模型方法在非强化学习和强化学习设置下的


性能结果
。需要说明的是
，
由于大部分研究工作模型设计复杂且缺少有效的开源


代码
，
因此
，
难以在与
Ｓ２ＴＤ相似的实验环境下重复相关实验并评测
，
故表中的


性能结果均沿用相关研宄论文中的指标进行汇报展示
。


表
３
－
１
为非强化学习条件下的评测结果
。
可以看到
，
所提
Ｓ２ＴＤ
的方法在


ＢＬＥＵ
—
１和ＢＬＥＵ
—２指标上取得了最优的效果
，
并且在ＭＥＴＥＯＲ和ＣＩＤＥｒ指标


上取得与最新方法可比较的性能
。


３２


第三章基于文本树结构的图像段落描述算法研究


具体分析来看
，以ＲＨ模型为基础的层次结构模型在绝大多数指标下均显著


优于非层次结构模型
。通过显式建模句子主题表示
，层次结构模型可以更好地建


模段落前后句子的关系
。相关实验结果验证了建模段落句子结构的重要性
，
即更


好地建模段落内句子结构
，
将有助于模型生成更高质量的段落
。


与经典的层次结构模型ＲＨ相比
，
Ｓ２ＴＤ通过引入简洁的树结构解码替换原


有的句子ＲＮＮ结构
，
极大的提升了模型性能表现
，
尤其是在ＢＬＥＵ
－
１和ＣＩＤＥｒ


指标上
。
上述结果验证了树结构解码的可行性且有效性
。


表
３
－
１
非强化学习训练设置下不同模型的评测结果对比


Ｂ
１Ｂ２Ｂ３Ｂ４Ｍ
Ｃ


ＲＨ４１
．９０２４
．１
１１４
．２３８
．６９１５
．９５１３
．５２


ＲＴＴ
－ＧＡＮ４１
．９９２４
．８６１４
．８９９
．０３１７
．
１２１６
．８７


ＣＡＰＧ
－ＶＡＥ４２
．３８２５
．５２１５
．
１５９
．４３１８．６２２０
．９３


Ｄｕａｌ
－ＣＮＮ４１
．６０２４
．４０１４
．３０８
．６０１５
．６０１７
．４０


ＤＨＰＶ４０
．３５２４
．４５１５
．４１１０．０３１６
．
１０２０
．７０


ＩＭＡＰ４２
．３８２５
．８７１５．５１９
．４２１６
．５６２０
．７６


ＤＡＭ
－ＡＴＴ３５
．０２２０
．２４１
１
．６８６
．５７１３
．９１１７
．３２


ＳＣＳＴ３２
．７８１９
．００１
１
．４０６
．８９１３
．６６１２
．８９


ＳＣＳＴ＋ＲＰ３５
．６８２２
．４０１４
．０４８
．７０１５
．
１７２２
．６８


ＯＲ
－ＡＴＴ３４
．９７２０
．
１７１２
．２１７
．４６１３
．５８１６
．２７


ＯＲ
－ＡＴＴ＋ＲＰ３７
．５０２３
．３４１４
．６３９
．００１５
．４３２２．８５


ＯｕｒＳ２ＴＤ４４
．３２２５
．８６１４
．８０８
．３３１６
．８９２１
．４１


ＯｕｒＳ２ＴＤ＋ＲＰ４４．５９２６．０６１４
．９３８
．３５１７
．００２１
．９２


表
３
－２为强化学习条件下的评测结果
。可以看到
，
通过采取强化学习优化
，


所提出的
Ｓ２ＴＤ模型可以进
一步提升指标性能
。尽管强化学习优化使非层次结构


取得最好的指标效果
，弥补了缺乏结构建模带来的性能差距
，但这类方法严重依


赖重复性惩罚降低生成的冗余程度
，例如
ＳＣＳＴ和ＯＲ
－ＡＴＴ模型
，去掉重复性惩


罚后
，
指标性能严重下滑
。
相较而言
，
Ｓ２ＴＤ方法性能表现更稳定
，
也在
一定程


度上说明
Ｓ２ＴＤ模型的生成冗余性更低
。此外
，
即使与ＤＨＰＶ和ＣＲＬ等采用了


复杂的强化学习技术的模型方法相比
，Ｓ２ＴＤ在没有增加额外优化开销的情况下
，


取得了相似的性能表现
，验证了树结构建模的有效性
。尽管本文提出的
Ｓ２ＴＤ在


强化学习设置下
，与最优的模型仍有差距
，潜在的原因是由于目前采用的强化学


习优化方法主要是针对主流的顺序解码设计
，在优化过程中因无法同时实现树结


构的优化
，
在
一定程度上限制了Ｓ２ＴＤ模型性能
。


３３


北京邮电大学工学硕士学位论文


总的来说
，通过定量实验
，通过引入句子树结构
，
所提出的方法在强化学习


和非强化学习条件下取得了与现有最新方法可比较的指标性能
，并在段落生成的


多样性上具有
一定的优势
。


表
３
－２
强化学习训练设置下不同模型的评测结果对比


Ｂ
１Ｂ２Ｂ３Ｂ４Ｍ
Ｃ


ＣＡＥ
－ＬＳＴＭ
－
－－９
．６７１８．８２２５
．
１５


ＤＨＰＶ４３
．３５２６
．７３１６
．９２１０．９９１７．０２２２
．４７


ＩＭＡＰ４４
．４５２７
．９３１７
．
１４１０
．２９１７
．３６２４．０７


ＳＣＳＴ２９
．６７１６
．４５９
．７４５
．８８１３
．６３１３
．７７


ＳＣＳＴ＋ＲＰ４３
．５４２７
．４４１７
．３３１０
．５８１７
．８６３０
．６３


ＣＲＬ４３
．
１２２７
．０３１６
．７２９
．９５１７
．４２３
１
．４７


ＯＲ
－ＡＴＴ３２
．８４１８
．３０１０．６７６
．２
１１３
．４４１４
．８８


ＱＲ
－ＡＴＴ＋ＲＰ４３
．７６２８．０８１７．８８１０
．９５１７
．８２３３．３８


ＯｕｒＳ２ＴＤ４３
．７０２６
．６７１６
．３０９
．７９１７
．３２２２
．８４


ＯｕｒＳ２ＴＤ＋ＲＰ４４．４７２７
．３８１６
．８７１０
．
１７１７
．６４２４
．３３


３
．４
．３消融实验


为了进
一步验证Ｓ２ＴＤ模型设计的有效性
，本节从模型组件设计
、树结构推


理策略和损失函数三个方面分别进行了定量实验和对比分析
。


模型组件消融实验的结果展示在表
３
－３中
，
对比的模型说明如下
：


１）Ｓｐ
ｌｉｔ
－Ｈ将划分模块中的门控组件替换为两个参数独立Ｈｉｇｈｗａｙ网络
，
基


于父节点表示直接计算出左右节点表示
。


２）Ｓｐ
ｌｉｔ
－Ｇ将划分模块中的互补门控组件替换为两个参数独立的门控组件
，


前向计算过程如公式
３
－６所示
。


３）Ｓｃｏｒｅ
－Ｃ采用了
一种二分类的打分模块组件
，
具体而言采用多层感知机和


二分类损失的组合替换余弦相似度和树结构损失的组合
，
即公式
３
－
１０。推理时
，


如果打分模块的输出小于
０
．５
，
即二分类预测结果为０则对节点进行划分
。


４）Ｓｐ
ｌｉｔ
－Ｒ利用随机生成的标签树结构作为监督信息
，即未利用
３
．２节提出的


段落文本树结构建模方法剖析的树结构作为标签
，而是随机合并相邻叶节点或子


树结构并将结果作为监督训练阶段的标签
。


５）
｛ＢＦＳ
，ＤＦＳ｝
－
｛Ｌ
，Ｒ
｝
：
由于打分模块的设计
，
Ｓ２ＴＤ支持采用不同的树结构


推理策略进行生成
。具体而言
，可以修改推理算法过程中的数据结构使用
（先入


先出的队列结构或先入后出栈结构
）
，
并且修改扩展后子节点入队或入栈的顺序


（优先左节点或右节点
）
。
队列结构等价于采用宽度优先遍历
，
栈结构等价于深


３４


第三章
基于文本树结构的图像段落描述算法研究


度优先遍历
。
因此
，
如果将原始的
Ｓ２ＴＤ记为ＢＦＳ
－Ｌ（即宽度优先遍历并优先扩


展左子节点
）
，可以依次得到三个不同的推理策略变形
：
ＢＦＳ
－Ｒ（宽度优先遍历并


优先扩展右子节点
）
，
ＤＦＳ
－Ｌ（深度优先遍历并优先扩展左子节点
）
，
ＤＦＳ
－Ｒ（深


度优先遍历并优先扩展右子节点
）
。


表
３
－３
采用
Ｓ２ＴＤ模型组件设计和推理策略的消融实验结果
Ｂ
１Ｂ２Ｂ３Ｂ４
Ｍ
Ｃ


Ｓｐ
ｌｉｔ
－Ｈ４２
．８３２４
．４６１３
．７４７
．５８１６
．３８１９
．００


Ｓｐ
ｌ
ｉｔ
－Ｇ４２
．８７２４
．９９１４
．６
１８
．４６１６
．３７１９
．５０


Ｓｃｏｒｅ
－Ｃ３７
．３７２１
．２
１１
１
．８２６
．４４１４
．７４１６
．２７


Ｓｐ
ｌｉｔ
－Ｒ

４３
．６９２５
．０７１４
．
１３７
．８４１６
．５５１９
．７０


ＢＦＳ
－Ｒ４４
．３０２５．９１１４
．８０８
．２８１６
．８３２０
．５
１


ＤＦＳ
－Ｌ４４
．０２２５
．５７１４
．６０８
．
１９１６
．７
１２０
．８２


ＤＦＳ
－Ｒ

４３
．３４２５
．０４１４
．４２１
．９９１６
．４５１９
．５３


ＦｕｌｌＳ２ＴＤ

４４
．３２２５
．８６１４
．８０８
．３３１６
．８９２１
．４１


从表
３
－３中的结果可以看到
，
ＳｐＨｔ
－Ｇ优于
Ｓｐ
ｌｉｔ
－Ｈ而
Ｓ２ＴＤ进
一步优于
Ｓｐ
ｌｉｔ
－


Ｇ
，
说明门控机制优于直接进行节点表示生成
，
而互补的门控机制进
一步提升了


模型的性能
，
这
一结果验证了基于互补门控机制的划分模块设计的有效性
。


此外
，
可以观察到
Ｓｃｏｒｅ
－Ｃ存在明显的指标降低
。这是因为二分类损失的学


习目标在非叶节点和叶节点切换时会发生从
０到
１的剧烈变化
，而
Ｓ２ＴＤ采用的


树结构损失能够通过计算相对距离
，
更为平滑地学习到针对树结构的打分策略
。


本节进
一步对
Ｓ２ＴＤ和
Ｓｃｏｒｅ
－Ｃ在不同阈值ａ下的指标表现进行评测
，并将对应


的结果绘制在图
３
－６中
。
为了更好的对比展示
，
Ｓ２ＴＤ是采用
ａ＝０
．Ｓ的设置训


练和评测的
。
图中
，
随着阈值从
０
．
１扩大到
０
．５
，Ｓ２ＴＤ的ＣＩＤＥｒ指标在不断上


２５
！
ｉ
ｉ
ｉ
ｉ
Ｉ
ｉ
ｉ
ｉ


－ｅｅ—ｅ—ｅ
—〇


２０
－＾


８
１０
／
＇
：
－


５
－
／
—？
—Ｓ２ＴＤ


／
—Ａ
— Ｓｃｏｒｅ
－Ｃ


０＾


００
．１０
．２０
．３０
．４０
．５０
．６０
．７０
．８０
．９１


Ｐａｒａｍｅｔｅｒａ


图
３
－６基线模型
Ｓｃｏｒｅ
－Ｃ与
Ｓ２ＴＤ模型在不同参数ａ下性能表现对比


３５


北京邮电大学工学硕士学位论文


升
，
说明模型生成了不同的段落且质量在不断提升
，而
Ｓｃｏｒ
ｅ
－Ｃ模型的指标


基本保持平稳
，无明显变化
，说明
Ｓ２ＴＤ的打分模块和损失函数使打分过程更为


平滑
。


Ｓ２ＴＤ的性能表现好于
Ｓｐ
ｌｉｔ
－Ｒ说明
，质量更高的段落文本树结构作为监督信


息将有助于训练得到更好的模型
，同时验证了所提出的利用
Ｓｅｎｔｅｎｃｅ
－Ｔｒａｎｓｆｏｒｍｅｒ


编码句子语义并层次聚类的段落句子树结构构造方法的有效性
。


进
一步考察不同的树结构推理策略
，从评测结果中可以看到
，
宽度优先策略


优于深度优先策略
，该结果符合预期的
。相比于深度优先遍历会倾向于扩展同
一


棵子树的节点
，形成不平衡的二叉树
，宽度优先遍历能够辅助模型更好的囊括更


丰富的图像内容主题
，
提及更多的主要实体对象
，
从而提高性能表现。


另外
，
优先扩展左子节点略好于优先扩展右子节点
，
观察生成结果后发现
，


这是由于根节点的左子节点主要描述图像中的前景对象
，例如人
、动物等
，而根


节点的右子节点将主要关注点放在背景信息上
，
例如天空
、街道等。
因此
，对于


给定标准段落的评测方法而言
，左子节点优先的策略能够更好的匹配标准段落的


内容
，
进而反应在性能指标上
。


总的来说
，采用不同树结构推理策略存在差异性
，反映了Ｓ２ＴＤ模型框架的


灵活性
，
相关实验结果符合预期
，验证了方法的有效性
。
同时
，较小的性能差异


也在
一定程度上反映出
Ｓ２ＴＤ模型的树结构解码的鲁棒性
。


表
３
－４采用
Ｓ２ＴＤ模型损失函数设计的消融实验结果


Ｂ
１Ｂ２Ｂ３Ｂ４Ｍ
Ｃ


Ｌｏｓｓ
－Ｂ３６
．０３２０
．７５１
１
．９２６
．８０１４
．３３１５
．８７


Ｌｏｓｓ
－Ｒ３９
．６５２２
．７７１３
．０１７
．３２１５
．２３１７
．
１９


Ｌｏｓｓ
－Ｄ４０
．９１２３
．５０１３
．３７７
．６３１６
．６１１８
．５７


ａ＝０
．
１４３．２５２４．７０１３
．８７７
．５９１６
．６１２０
．０４


ａ
＝０．３４３
．
１２２４．９２１４．２６８．０６１６．７１２０．６４


ａ＝０
．５４３
．０４２４．７２１３
．９７７
．７５１６
．７５２０
．３６


ａ＝０
．７４２
．９４２４．７２１４
．０３７
．８４１６
．５８２０
．０９


ａ＝０
．９４２
．６１２４．３２１３
．８２７
．７４１６
．３３１８
．７２


本节进
一步开展了对树结构损失设计和超参数的实验验证
。相关实验结果展


示在表
３
￣４中
。
除额外说明
，
对比的模型均采用相同的设计
、
训练和推理配置。


１
）Ｌｏｓｓ
－Ｂ
：
打分模块采用多层感知机计算
，
并使用二元交叉熵训练。


２）Ｌｏｓｓ
－Ｒ
：
打分模块采用多层感知机计算
，
采用回归损失Ｌ２距离训练。


３）Ｌｏｓｓ
－Ｄ
：
是采用回归拟合节点深度的方案进行训练
，


３６


第三章
基于文本树结构的图像段落描述算法研宄


４
）ａ＝
｛０
．１
，
．
．
．
，０
．９
）
：
采用不同的决策阈值ａ训练和评测的
Ｓ２ＴＤ模型
。
其


中
，
ａ＝０
．３为
Ｓ２ＴＤ最终采用的超参数设置
。


考察不同的打分策略和对应的损失函数
，可以看到
，打分机制和损失计算越


平滑
，模型的性能指标越高
。
Ｌｏｓｓ
－Ｒ优于Ｌｏｓｓ
－Ｂ
，Ｓ２ＴＤ进
一步优于Ｌｏｓｓ
－Ｒ
，
性


能差异
一方面是由于模型能够更平滑地学习到打分策略
，
另
一方面是由于
Ｓ２ＴＤ


采用的树结构损失基于余弦相似度
，能够更好监督划分模块学习
，使其能够划分


得到差异性更大的左右子节点
，从而生成更加丰富多样的段落句子
，验证了本文


设计的树结构损失的有效性
。此外
，从对不同的决策阈值ａ的实验结果中
，
可以


看到模型在
０
．３取得最优性能
，
过大的决策阈值会影响模型的性能表现
，
该结果


符合预期
，这是因为决策阈值越大
，树结构损失函数和二分类使用的交叉熵损失


的效果越接近
，
即模型要在非叶子节点过渡到叶子节点时完成突变式的预测
。


综上
，通过模型组件设计
、树结构推理策略和损失函数三个方面的消融实验
，


本节进
一步验证了所提
Ｓ２ＴＤ模型各个模块组件
、推理策略和训练方法的有效性
。


３
．４
．４定性分析


本节将从生成的段落
、段落对应的句子树以及划分过程可视化三个方面来定


性展示本文所提出的
Ｓ２ＴＤ模型的特点
，
以及树结构解码带来的可解释性
。


ＳＣＳＴ＊ＲＰ
Ｓ２ＴＤ
（Ｏｕｒｓ）Ｓｅｎｔｅｎｃｅ
Ｔｒｅｅｂｙ
Ｓ２ＴＯ


！Ａｗｏｍａｎ
ｉｓｓｔａｎｄ
ｉｎｇｏｎａｔｅｎｎ
ｉｓ
｜Ａｗｏｍａｎ
ｉｓｓｔａｎｄ
ｉｎｇｏｎａｔｅｎｎ
ｉｓＨ
ｉｓ
ｓｕｎｎｙ
ｏｕ
ｔｓｉｄｅ
ａｎｄ
ｔｈ？
ｔｅｎｎ
ｉｓ
ｃｏｕｒｔ

ｉｓｓｕｎｎｙ


ｉｃｏｕｒｔＳｈｅ
ｉｓｗｅａ
ｒ
ｉｎｇａｗｈ
ｉｔｅｖ
ｉｓｏｒ
ｊ
ｃｏｕｒ
ｔｐ
ｌａｙ
ｉｎｇ
ｔｅｎｎ
ｉｓＳｈｅ
ｉｓ
１
—
；
ｗｃ
ｉｎ＾ｒ
ｉ

：
４ｏｎ
ａ
ｌｏｎｎ
ｉ
ｒ．
＜〇ｕ
？
？


！ａｎｄａｗｈ
ｔｅｓｋ
ｉｒ
ｔＴｈｅｗｏｍａｎ
丨ｓ
ｉｗｅａｒ
ｉｎｇａｖ／ｈ
ｉｔｅｓｈ
ｉ
ｒｔａｎｄｗｈ
ｉｔｅ
ｉ
＼
—
ａ
ｗｏ
ｒｒｔａｎ

ｔ＞
ｓｔａｎｄ
－ｎｇ
ｏｎａ
ｔｅｎｎ
ｉｓ
ｃｏｕ
ｒ
ｔｐ
ｌａｙ
ｉｎｇ
ｒｅｎｍｓ


Ｓ
１ｈｏ
ｌｄ
ｉｎｇａｔｅｎｎ
ｉｓｒａｃｋｅｔ
Ｔｈｅｗｏｍａｎｓｈｏｒｔｓ
．Ｓｈｅｉｓｗｅａｒ
ｉｎｇｄｗｈｉｔｅ
｜
［＼
￣


，
，ｓ
ｈ
＾
ｄ
ｉｎ９
ａ＾ｋｅｔ
ｉｎ
ｆ
＾
ｒｈａｎｄｓ
Ｔｈｅ

；
ｖ
ｉ＾
ａ
ｖ＾
ｉｔｅｓｋ
ｉｒｔａｎｄａｗｈ
ｉｔｅ
，：ｈｏ
ｌ＾

，
＾


（
－
ｉ
ｃｏｕｒＴ
ＪＳｇ
ｆｅｅｎａｎｄｗｈ
ｉｔｅ
Ｔｈｅｃｏｕｒｔ
，ｓｋ
ｉｒｔＳｈｅ
ｔｓｈｏ
ｌｄ
ｉｎｇａｔｅｎｎ
ｔｓ
ｊ
＿

ｗ


ｆ
．
＜
ｉｓｍａｄｅｏｆ
ｇ
ｒｅｅｎ
Ｔｈｅｔｅｎｎｉｓｃｏｕｒｔ
ｉｓ
ｊ
ｒａｃｋｅｔ
ｉｎｈｅｒｈａｎｄ
Ａｃｈａ
ｉｎ
ｌ
ｉｎｋ
ｊ
ｓ


變
＾
！ｗｈ
ｉｔｅ
．Ｔｈｅ
ｒｅａ
ｒｅｐ？＞ｐ
ｌｅｓ
ｉｔ
ｔ
ｉｎｇｏｎ
ｉｆｅｎｃｅ
ｉｓｂｅｈ
ｉｎｄｔｈｅｗｏｍａｎ
ｉ—
ｂ？
＞ｈ
ｉｎｄｆｅｎｃｅａ
＞ｅ
ｍ＾ｎｙ
ｐ
？Ｋ：ｐ
；ｔ
＞
ｗ＾
ｔｃｈ
：ｎｃ
ｊ


ｖ
ｉ｜
！
化？ｃｏｕｒｔＴｈｅｍａｎ
ｉｓｗｅａ
ｒ
ｉｎｇａ
｜
Ｔｈｅｒ
ｅａｒｅｍａｎｙｐｅｏｐ
ｌｅｓｉｔｔ
ｉｎｇ
ｉｎｈ
—
，
ｉｂ
ｌａｃｋｓｈ
ｉ
ｒｔ
．
？ｔｈｅ
ｓｔａｎｄｓｗａｔｃｈ
ｉｎｇ
ｔｈｅ
ｐｅｏｐ
ｌｅ
．
１—
：
？
－
＊
？

ｔｈｔ
＜
＾
－ｖ

ｉ
－
；
：
：

：

；
，
＇ｈ
ｆ

；
－
；

；
：
絕
Ａｐ
丨ａｔｅｏｆｆｏｏｄ
丨…
ａｐ
ｌａ
ｔｅｍｅ

｜
Ｔｈ二
ｉｓａａｗｈ
ｉｔ
：


｜ｐ
ｌａ
ｔｅ
ｉｓｗｈ
ｉ
ｔｅＴｈｅｐ
ｌａ
ｔｅ
ｉｓｗｈ
ｔｅ
．
；
ｔａｂｌｅｄｏｔｈｏｎ
ｉｔ
．Ｔｈｅｒｅ
ｉｓａｒｏｕｎｄ
ｊ
｜
＿＿
ｕ？￥

，ｓ
ａ
ｙ
：ａ
｛
？
＞
〇？
ｌｏｏｄ


＾霸Ｔｈｅｒｅ
ｉｓａｐ
：ａ
：ｅｃｎｔｈｅｐｂｔｅＴｈｅ
ｒｅ
？ｐ
ｉａ
ｔｅｏｎｔｈｅｔａｂ
ｌｅ
Ｏｎｔｈｅｐ
ｌａｔｅ
ｉｓ
｜



ｉ
ｓａ
ｆｏｒｋｏｎｔｈｅ
ｐ
ｌａｔｅ
Ｔｈｅ
ｐ
ｌａ
ｔｅｈａｓ
丨ａｐ
ｌａ
ｔｅｏ
ｆｆｏｏｄｔｈａ
ｔｈａｓａｗｈ
ｉ
ｔｅ
！
Ｉ
＇
—


斷绞ｆＪ｜｜Ｃ？
｜＾Ｋａｖｖｉ
ｉ
ｉ
ｔｅｐ
ｌａｔｅｏｎ
ｉ
ｔ
．Ｔｈｅｒｅａ
ｒｅｔｗｏ
＇ｓａｕｃｅｃａ
ｒｖｅｄ
ｉｎ
ｔｏ
ｉｔ
Ｔｈｅｋｎ
ｉｆｅｈａｓ
Ｉ
１—


ｐ
ｉｅ＜ｅｓｃ
ｆｆｏｏｄｏｎｔｈｅｔａｂ
ｌｅＴｈｅ
ｒｅ
ｉｂｅｅｎｃｕｔ
ｉｎ
ｔｏａｂｕｎＴｈｅ＾ｅａ
ｒｅ
Ｌ—
ｆ〇ｃｄ
〇ｎ

？
：
＞〇
〇
＊

ｔ
ｉ
ｖｐ
ｔ＾ｂｕ
．


＼罵菜＾
ａ
ｒｅａｆｏｒｋｏｎｔｈｅｐ
ｌａｔｅＴｈｅｒｅ
．ｓａ
；ｐ
？？ｅｓｏ
ｆｆｏｏｄｏｎｔｏｐｏｆｔｈｅｔａｂ
ｌｅ
ａｋｒｒ
ｆｅｆｏ
ｒｋ
ｏｎ
ｔｈｅ

ｔａｂ＾


識
ｗｈ
ｉｔｅｂｏｗｌｏｎｔｈｅｔａｂ
ｌｅＴｈｅｔａｂ
ｉｅ
ｉｓ
ｉＴｈｅｒｅａｒｅｐｅａｓａｎｄｃａｒｒｏｔｓｏｎＬＺ


ｍｍｍｒ
ｎｔｍｍｗｈ
ｉｔｅａｎｄ
ｗｈ
ｉｔｅ
［
ｔａｂ
ｌｅ

ｉｎｆｒｏｎｔｏｆ
ｔｈｅ
ｐ
ｌａ
ｔｅ
．
ｔ


Ｍ
！ＡｎｆＡＨ〇
，ｃ
＜ｎａＴｈｏ
！Ａ
ｇ
ｉｒａｆｆｅ
ＩＳＳｔａｎｄ
ｉｎｇ
ｉｎｆｒｏｎｔｏｆ
ａ？
ｇ
ｉ
ｒ
？
ｉ？ｅ
ｗ
ｉｔｈｂｒｏ
％＊ｎ
ｓｐｏｔ
ｓ

ｉｓ
ｓｔａｎｄ
ｉｎｇｎ＊＊
ｔ
ｔｈ？ｆ
？？ｎｃｅ


么
＇＼
；
＂
ＩＴＫｏ
ｔｒｏａ
＜
ｍ
＊心
＇ｐ
ｌａｎｔｓ
Ｔｈｅｓｕｎ
ｉｓｓｈ
ｉｎ
ｉｎｇｏｎｔｈｅｈ
—
＜


，Ｔｈｅ
ｔｒｅ？
ｉｓｍａｄｅ
ｏｆ
ｄ
ｉｒ
ｔ
．
｜ｅｎｄｏｓｕ
ｒｅａｎｄｔｈｅ
ｅｎｃｌｏｓｕ
ｒｅ
．
１￣
ｉ
；
图
３
－７模型生成的描述段落以及对应的句子树结构展示


输入图像以及对应的生成段落展示在图
３
－７中
，
可以观察到
，
相比基线方法


ＳＣＳＴ＋ＲＰ
，
本文所提出的
Ｓ２ＴＤ模型生成的段落冗余程度更低
。如图
３
－６中的第


一个例子所不
，
ＳＣＳＴ＋ＲＰ方法反复生成与
“
ｔｅｎｎｉｓ
ｒａｃｋｅｔ
” 和
“
ｔｅｎｎｉｓｃｏｕｒｔ
” 有关


的句子
。
相比之下
，
Ｓ２ＴＤ模型通过在解码过程中显式引入树结构
，
生成的内容


更为多样
。段落对应的句子树结构进
一步验证了上述优势
，
由于同
一子树下的句


子主题相关但关注不同方面
，从而有效降低描述内容的冗余程度
。此外
，
通过引


入树结构
，
Ｓ２ＴＤ能够捕捉到更丰富的图像内容并能生成更连贯的上下文
，
如图


３７


北京邮电大学工学硕士学位论文


３
－７中的第二个例子所示
，
基线方法
ＳＣＳＴ＋ＲＰ较为杂乱地对
“
ｐ
ｌａｔｅ
”
，
“
ｔａｂｌｅ
” 进


行描述
，
而
Ｓ２ＴＤ能够通过
“
ｏｎ
ｔｈｅｐ
ｌａｔｅ
ｉｓ
．
．
．
”
，
“
ｉｎ
ｆｒｏｎｔｏｆ
” 等句式完成连贯的


描述对象转换
，同时也描述了对更多的图像细节
，如
“
ｋｎｉｆｅ
”
，
“
ｐｅａｓ
” 和
“
ｃａｒｒｏｔｓ
”
。


进
一步观察生成段落过程中扩展得到的完整句子树
。构建过程为
：在解码时
，


将根节点以及所有划分得到子节点
，
包括非叶子节点和组成段落的叶节点表示
，


输入到词级ＲＮＮ中
，
生成对应句子并保留原有的拓扑关系
。


生成的句子树与预期相符
，根节点生成的句子有效地捕捉了图像全局的信息
，


实现了对图像内容概括性的描述
。而且
，树中每
一棵子树对应的节点划分都与图


像语义相关
，
与人的观察逻辑相符
，
从而验证了引入句子树的有效性
。
如图
３
－７


中的第三个例子所示
，
Ｓ２ＴＤ在首次划分时
，
根的左子树的主要描述对象为


“
ｇ
ｉｒａｆｅ
”
，根的右子树的主要描述对象是背景中的
“
ｅｎｃｌｏｓｕｒｅ
” 和
“
ｒｏｃｋｗａｌｌ
”
。


对根的右子节点划分时
，模型将内容进
一步拆分成
“
ｒｏｃｋａｎｄｐ
ｌａｎｔｓ
” 和
“
ｓｕｎａｎｄ


ｅｎｃｌｏｓｕｒｅ
”
。可以看到
，树结构的引入
，使得模型具有良好的可解释性
，能够观察


到模型从整体到局部的描述生成过程
。同时补充不同解码策略生成得到的句子树


结构
，
结果如图
３
－８所示
，
相关生成结果进
一步验证了３
．４
．３节中的定性分析
。


ＥｘｐａｎｄＬｅｆｔＮｏｄｅＦ
ｉｒｓｔ
ＥｘｐａｎｄＲ
ｉｇｈｔＮｏｄｅＦ
ｉｒｓｔ


二
ｉ
ｔ

ｉｓ
ｓｕｎｎｙｏｕｔｓ
ｉｄｅ
ａｎｄｔｈｅ
ｔｅｎｎ
ｉｓｃｏｕ
ｒｔ

ｉｓ
ｓｕｎｎｙ
＊
ｈ
ｎ
ｓｕｎｎｙ
ｏｕｔｓｉｄｅ
ａｎｄ
ｔｂ？
ｔｅ
ｒｍｉｔｃｏｕｒｔ

ｉｓｓｕｎｎｙ


ａ
ｉ

ａ
ｗｏｆｒａｒ
ｉｓ
ｐ
ｌａｙ
ｉｎｇ
ｔｅｎｎｉｉ
ｄｒ
ａ
ｔｅｎｎｉｓ
ｃｏｕｒｔ
＼
！

ａ
ｗｏｍａｎ
ｂ
ｐ
ｌａｙｋ
ｓｇ

ｔｅｒｍｂ
ｏｎ
ａ
ｔｅ？
？ｎｉｓ
ｃｏｕｒｔ


３
１
｜

ａｗｏｍａｎ

ｉｓ
ｓｔａｎｄ
ｉｎｃ
ｏｎ
ａｔｅｎｒ
ｉｓ
ｃｏｕ
ｒｔ
ｐ
ｆａ
＞
＊
ｉｎｇ

ｔｅｎｎ
ｉｓ
，
１｝
—
－
：ｖ
＊
：


ｊ
｜

．
１
！
１
．
－
？
－
：
：
；


Ｋ
ｊ
１
ｆｈ
ｓ
：＾
ｗｈｆ
ｃｃ
＼
１
ｂｅｈ
ｉｎｄ
ｔｎｅ
ｆｅｎｃｅ
ｔｈｅ？ｅ
ａｒｅ
ｍａｎｙ
ｐｅｏｐ
ｌｅ
ｗａ
ｔｃｈ
ｉｎｇ


広
１
ｓ＾
－ｅ
１５ａ
ｔｅｎｎ
ｉｓ
ｒａｃｋｅｔ

ｉｎ
ｈｅｒ
ｈａｎｄ
＊
Ｉ
—
ａ
ｃｈａ
ｉｎ
Ｒｎ
ｋ
ｆｅｎｃｅ

ｉｓ
ｂｅｈ
ｉｎｄ
ｔｈｅ
ｗｏｍａｎ


ＪＺ
Ｉ
Ｉ


ｒ
／
．
＾＾ｖｉ
：
ｒ＾
－
：
－

－
ｉｒ

？＊
１
ｉ

＾
：
；
：
：
；
；
：
；

Ｉ
ｖｊ
ｃ
：

＇
｝
■

ｏ
：ｊ
ｌ

？
：
？
；
－Ｖ
＾


■
？
；〇
：
．
：


ｉｊｙａｇ＾ｐＭＫ＃＾ｇ
：—
ｂｅｈ
ｉｎｄ
ｍｅ
ｆｅｎｃｅ
ｔ＾ｅｒ？
ａｒｅ
ｍａｎｙ
ｐｅｏｐ
ｌｅ
ｗａ
ｔｃｈ
ｉｎｇ
＊ｔｈｅ
ｒｅ
ａｒｅ
ｍａｎｙ
ｐｅｏｐ
ｌｅ
ｓｉｔｔｉｎｇ

ｉｎ
ｔｈｅ
ｓｔａｎｄｓ
ｖ／ａ
ｔｃｈ
ｉ
ｒ
？ｇ
ｔｈｅ
ｐｅｏｐ
ｌｅ


Ｍ＾
ｉ
—
．
Ｉ
ｉｔ

ｉｓ
ｓｕｎｎｙ
ｏｕｔｓｉｄｅ
？ｎｄｔｈｅ
ｔｅｎｎ
ｉｓ
ｃｏｕｒｔ

ｉｓ
ｓｕｎｎｙ
＜
ｉｔ

ｉｔ
ｓｕｎｎｙ
ｏｕｔｓｉｄｅ
ａｎｄ
ｔｈｅ
ｔｅｎｎｉｓ
ｃｏｕｒｔ
？ｔｕｎｎｙ


＊
５
ｊ

ａｗｏｍａｎ
ｉｓ
ｐ
ｌａｙ
ｉｎｇ

ｔｅｎｎｉｓ
ｏｎ
ａ
ｔｅｎｎ
ｉｓ
ｃｏｕｒｔ
１
Ｉ

－
ｖ＾ｖ
：
？
？
：
，

：
：
＞

ｉ
：
ｖ

：
＇＇
产
＊ｆ
？ｑ
｜
｜

ａ
ｗｏｍａｎ

ｉｓｓｔａｎｄ
ｉｎｇｏｒ．
ｚ
ｔｗ＾ｎ
：ｓ
ｃｏｕｒｔ
ｐｔ
ｅｙｍｇ
ｔｅｎｎ
ｉｓ
ｊ
１
ｂｅｈ
ｒ
＞ｄ
ｔｈｐ
ｆｅｎｃｅ
ｊｈ？ｅａ
ｒｅｍａｎｙ
ｐ？；ｐ
！ｅ
ｗａ
ｔｃｈ
ｉｎｇ


＾ＳＸ
＇
＇
ｆ％戈
ｊ
Ｉ

１
—
ａ
ｃｈａ
ｉｎ
ｌ
ｉｎｋ
ｌｅｎ＜ｅ？
ｂｅｈｉｎｄ
ｔｈｅ
ｗ〇ＴＶ＊ｎ


—
ｊ
ｊ
１
ｓｈｅ
ｉｓ
ｘｗｅａｒ
ｉ
ｒ＞ｇ
ａ
ｗｈ
ｉｔｅ
ｓｈ
ｉ
ｒｔ
ａｎｄ
ｗｈ
ｉ
ｔｅ
ｓｈｏｎｓ
Ｊ
Ｉ
｜
－
；
ｒ
＾
：
：
；
？
：
■
：
？
ｖ
：
．
；
＂
＂
．ｂ
！
Ｉ｛
ｓｈｅ

ｉｓ
ｗｅａｒ
ｉｎｇａ
ｗｈｉｔｅ
ｖ
ｉｓｏ
ｒ
ａ
ｗｈ
ｉｔｅ
ｓｎ
ｉ
ｒｔ
ａｎｄ
ｂ
ｌａｃｋ
ｓｈｏｒｔｓ
ｊ
ｊ
１
Ｊ广
－
－
－
：ｃｒ＇
：
ｔｗ：
．ｖ＾
：ｃｃｗ
ｔｅｃ


十
ｉ
ｉ
ｆ
￣

ｓ
ｉｈｅ

：
：
＞
ｔ
ｗｈ
ｉｔｓ；

■

＾
：

；

＞
１
１—
ｔｈｅｒｅ
ａ
ｒｅ
ｍ３ｎｙｐｅｏｐ
ｌｅ
ｓｉｔｔ
ｉｎｇ

ｉｎ
ｔｈｅ
ｓｔａｎｄｓ
ｗａｔｃｈ
ｎｇｐｅｏｐ
ｌｅ


￡
ｊ
ｊ
１—
ｖ
？＾ｓ〇
ｖ
／
＞

：
－
ｒ
：
｜
１
—
＼
■

－
Ｉ
！
－
＊
－
－
？
：
：
＾
：
：
；

■
— Ｖ
－


§
■
ｊ
＊—
－
ｈ
－＊
ｗ
ｒ
ｒ
－
；
：＾
￥
■
■＞＜
＞
＞
！
：
：
：
？ａ
－
Ｍ
ｆ
：
）
■￣
ｔｈ？ｙ？
ｌ
ｌ
ｗ＾ａｎｏｇ
ｗｈ
ｉｔｅ
ｓｈｏ
ｒｔｓ
ａｎｄ
？
ｗｈ
ｉｔｅ
ｓｈ
ｉｒｔ


Ｑ
ｊ



：？
ｒ；ｎ
］
，
＇＊
，

＞
？
（

；
ｊ
：

ｒｈｓｖ＾
－
！
：
？ｖ？Ｋ
＞Ｍｒ
：〇
ｖ－＞
：
ｉｊｒ
．
：ｆ〇ｆｒｕ


１
！
：？

：ｖ！
ｉ
ｒ
．
ｉ
．
＾ｒ
ｃｘ
ｔ
－
ｉ
ｖ
ｖ
ａ
ｒｅ
ｒ
＞
ｉ＾ｓ＆ｏｐ
ｉｓ
｜
１—
巾ｅ
－
，
ｉ
ｒ
＜？
ａｆ
；
ｗ
ｔｆｉｎｎｇ
ｋ
－ｗＵ
ｔｆｔ
；
图
３
－８由
Ｓ２ＴＤ采用不同解码策略生成的句子树结构


最终
，
为了更好的验证
Ｓ２ＴＤ模型在节点划分时的有效性
，
本节对节点划分


过程中门控向量的累计变化进行了可视化展示
。可视化过程如下
，首先初始化根


节点对应的累计门控向量全部维度为
１
，将划分时对应节点的门控输出与父节点


的累计门控向量对应维度相乘
，得到当前节点的累计门控向量
。
门控向量的含义


是
，
当前节点在该维度保留了多少根节点的信息
，
如果为
０则完全不保留
，
为
１


则完全保留
。结果如图
３
－９中右侧的颜色矩阵所示
，
该矩阵每行为对应编号节点


的累计门控向量
，
一共有
１０２４列对应
Ｓ２ＴＤ设置的
１０２４维
，
数值越接近于
１其


颜色越深
，
数值越接近
０则颜色越浅
。
图像对应的句子树结构在图
３
－９的下方
。


３８


第三章
基于文本树结构的图像段落描述算法研究


可以观察到
，左右子节点的划分比较平衡
，
没有出现只划分父节点信息到特


定子树的情况
。
另外
，
左右子节点划分门控上有明显差异性
，说明对应的树结构


损失能实现预期的监督
，
验证了树结构解码框架设计的有效性
。


■
ｉＷＰｉｉ
ｌ
：


ｏｎｅｏｆｔｈｅｗｏｍｅｎｉｓｅａｔ
ｉｎｇｆｏｏｄｆｒｏｍａｔａｂ
ｌｅ［０
］


Ｉ
—
ｔｗｏｗｏｍｅｎａｒｅｓ
ｉｔｔ
ｉｎｇａｔａｔａｂ
ｌｅ［１
】



｜
—
ａｗｏｍａｎａｎｄｔｗｏｗｏｍｅｎａｒｅｅａｔ
ｉｎｇ
ｆｏｏｄ
ｉｎａｒｏｏｍ［Ｂ
］



Ｉ
｜

ｔｗｏｙｅｏｍｅｎａｒｅｓ
ｉ
ｔｔ
ｉｎｇａｔａｔａｂ
ｌｅ
＝ｎａｒｅｓｔａｕｒａｎｔ［７
］


Ｉ
ｊ
１
ｓｈｅ
ｉｓｅａｔ
ｉｎｇ
ｆｏｏｄｏｕｔｏｆａ
ｐ
ｉａｔｅｏｆｆｏｏｄ［８
］



１—
ｓｈｅｈａｓｏｎａｂ
ｌａｃｋａｎｄｗｈ
ｉｔｅｓｔｒ
ｉｐｅｄｓｈ
ｉｒｔａｎｄａｂ
ｌａｃｋｐｕｒｓｅ［４］



｜

ｓｈｅ
ｉｓｗｅａ
ｒ
ｉｎｇａａ
ｒｉｄｗｈ
ｉｔｅｓｔｒ
ｉｐｅｄｓｈ
ｉｒｔｗ
ｉｔｈａｂ
ｉａｃｋｓｃａｒｆｏｎｈｅｒｈｅａｄ［９
】


Ｉ
１
ｔｈｅ曼ｅｈａｓａｖｖｈ谂ｅｓｈｅｅｔｏｎ
ｉｔａｎｄａｒｅｄａｎｄｗｈ
ｉｔｅｓｔ
ｉｉｐｅｄｐ
ｉａｔｅｏｎｔｈｅｆｓｂ
ｉｅ
【１０】


１
ｔｈｅｔａｂ
ｌｅ
ｉｓｍａｄｅｏｆｗｏｏｄａｎｄｈａｓａｃｏｕｐ
ｌｅｏｆ
ｐ
ｌａｔｅｓｏｎ
ｉｔ［２
］


｜

ｔｈｅｗａ
ｉ
ｌｂｅｈ
ｉｎｄｔｈｅｗｏｍａｎ
ｉｓｒｅｄ［５
］


１
ｔｈｅｔａｂ
ｌｅ
Ｉｓｍａｄｅｏｆｗｏｏｄａｎｄｈａｓａｗｈ
ｉｔｅｔａｂ
ｌｅｃ
ｌｏｔｈ［６
］


图
３
－９
节点划分过程中门控向量的累计变化展示


综上
，通过对生成的段落
、段落句子树以及划分过程可视化三个方面的定性


展示
，
本节进
一步验证了树结构解码在段落生成过程的优势及其可解释性
。


３
．５本章小结


本章开展了基于文本树结构的图像段落描述算法的研究工作
。本章首先提出


了
一种用于构建段落句子树结构的层次建模方法
。随后
，本章详细介绍了
一种新


颖的树结构解码框架
Ｓ２ＴＤ用于解决图像段落描述任务
。该框架将段落生成过程


建模为
一棵自顶向下不断扩展的二叉树
。本章进
一步介绍了Ｓ２ＴＤ的三个核心模


块
：
划分模块
、
打分模块以及词级别
ＲＮＮ
，
并提出了
一种新颖的树结构损失函


数用于监督
Ｓ２ＴＤ学习段落句子树的拓扑结构
。最终
，
总结了
一个基于
Ｓ２ＴＤ的


树结构段落解码生成算法
。在实验验证部分
，
本章通过定量性能比较
、消融实验


对比验证以及定性生成展示
，
验证了所提方法的可行性与有效性
。


３９


北京邮电大学工学硕士学位论文


４０


第四章
引入视觉树结构的图像段落描述算法研究


第四章引入视觉树结构的图像段落描述算法研究


当前主流的图像段落描述模型中
，编码器网络将抽取到的图像区域特征作为


一个无结构的特征集合输入到解码器
，缺乏对特征间关系的显式建模
。
因此
，本


章对引入视觉树结构的图像段落描述算法进行研究
，提出了
一种图像区域树结构


的启发式构建方法以及树结构増强的编码器网络
。提出的方法是对人类观察图像


时对信息梳理的模拟
，首先启发式地将图像区域集合迭代划分为
“ 上和下
”
、
“ 左


与右
” 子部分
，得到对应的图像区域树结构
。进
一步改进多头自注意力机制
，
使


得编码器网络能够得到更好的建模图像特征
，提升段落生成质量。此外
，研宄过


程中也对非层次结构模型的解码推理过程做出了改进
。实验结果表明
，在模型中


引入视觉树结构信息
，
有助于提升描述段落的生成质量
。


４
．
１本章引论


首先
，
本章沿用
３
．１节中给出的图像段落描述任务的定义
。
补充定义如下
，


给定图像
／
，通过目标检测器模型抽取
，将图像中
Ａ：个区域级图像原始特征表示


记为Ｋ
？
°ｆ＝ｉ以及对应的坐标Ｃ＝
｛ｃｆ
ｃ｝ｆ＝１
，
其中ｑ


（Ａ
，ｙＱ）和
（Ａ
，ｙｉ）分别代表左上和右下坐标
。经过编码器处理后得的视觉特征记


为
｛／＝
｛叫垃＝１
。
随后
，
解码器利用处理后的特征
进行段落生成
。


主流的图像段落描述模型的编码过程可以抽象如下
：


（Ｖ，Ｃ＝Ｄｅｔｅｃｔｏｒ（Ｚ）


（ｕｋ
＝ＭＬＰ〇产
°
”
（４
＿１）


其中
，
ＭＬＰ代表前馈神经网络
，其主要目的是对原始区域特征
进行维


度变换和信息抽取
。
可以看到
，
主流的编码过程是对区域特征的操作是独立的
，


没有考虑到区域特征之间的关联
。然而
，
区域特征间存在丰富的空间关系
、从属


关系
，
这类关系的缺失将造成模型段落生成性能的下降
。


为了缓解上述问题
，有的研宄
ｔ４
１
，４２
，４５］通过额外的标注数据训练图像关系分类


器作为编码器的
一部分
，
这类方法的编码过程可以抽象如下
：


ｒＶ
，Ｃ＝Ｄｅｔｅｃｔｏｒ（Ｚ）


？Ｔ
ｉｊ
— Ｓｏｆｔｍａｘ
＾ＭＬＰ
（［ｖｆ
ｂ０；ｃ
；ｖ
ｆ
ｂｏａｒ
］））
，ｉｆ
Ｉ〇Ｕ（ｃ
￡，Ｃ
ｊ）＞０
．５（４
－２）


、Ｕ＝Ｆｕｓｉｏｎ（Ｆ
，Ｒ）


其中
，
［；
］代表向量拼接操作
，
为图像区域两两预测的关系矩阵
，


Ｆｕｓｉｏｎ代表信息融合的操作
。
丨ｏＵ为交并比函数
（ＩｎｔｅｒｓｅｃｔｉｏｎｏｖｅｒＵｎｉｏｎ）
，
用于


４１


北京邮电大学工学硕士学位论文


计算两个区域框之间的重叠程度
，
即只有在框重叠比较高时
，
才进行关系预测
。


尽管上述方法在
一定程度上提升了编码器对关系信息的利用
，但关系预测的准确


性依赖于人工预先定义与额外标注数据
，缺少或预测错误的关系结果会引入噪声
，


影响模型的性能表现。


结合上述分析
，本章提出采用树结构来建模图像区域特征间的关系
，并利用


多头自注意力机制融合编码原始视觉特征和对应的图像区域树结构
，
过程如下
：


｛
Ｖ
，Ｃ＝Ｄｅｔｅｃｔｏｒ（Ｚ）


Ｔ＝Ｐａｒｓｅｒ（Ｃ）
（４
－３）


Ｕ＝ＭｕｌｔｉＨｅａｄ（Ｆ
，ｒ）


其中
，
Ｐａｒｓｅｒ为本章提出的启发式树结构建模方法
，其利用图像区域的坐标


信息剖析得到区域树结构Ｔ。进
一步利用改进后的多头自注意力机制ＭｕＷＨｅａｄ
，


实现区域特征Ｋ和树结构Ｔ的融合
。可以看到
，
引入树结构的编码方案充分利用


了区域坐标信息
，在编码区域关系信息的同时
，无需额外的标注和训练开销
。此


夕卜
，
区域树结构是对人类观察图像时对信息梳理的模拟
，相较于直接引入高度抽


象的关系类别
，
更具可解释性
。


本章节的后续内容安排如下
：


首先介绍如何利用区域坐标信息启发式地构建区域树结构
，进
一步详细介绍


本文提出的树结构增强的段落描述模型
，
最终通过实验验证所提方法的有效性
。


４
．２图像区域树结构建模方法


针对同
一张图像
，相比单个句子
，
想用
一个内容丰富的段落进行描述
，
需要


对图像内容进行更深入的观察理解。人类在处理复杂的图像信息时
，
一种简单有


效的规划策略便是对图像内容进行
“
一分为二
”
。
区别于直接关注到图像中的每


一个细节
，
人类往往将图像先分为
“ 左右
”
，
“ 上下
” 等子区域
，
逐步地理解子区


域中的内容
，建立子区域内外的关联。这种
“
一分为二
” 的观察过程可以利用二


叉树结构进行建模
。因此
，本文提出在图像段落描述任务中引入区域树结构信息
。


具体而言
，
区域树为
一棵完美二叉树
（Ｐｅｒ
ｆｅｃｔＢｉｎａｒｙＴｒｅｅ）
，
即
一个深度为


ｄ（ｄ２０）且有
２
（ｒ
ｆ＋１）－
１个节点的二叉树
。树Ｔ中的每
一个节点对应
一个包含


恥个图像区域的分组
以｝因此
，第ｄ层的
一共有＂个区域分


组
，
记为
Ｚ／ｄ
＝并满足如下条件
：


（ＪＡ
＝Ｃ
（４
－４）


Ｉｄ


ＶＧ
ｊ，Ｇ
ｊＥＬ＾，Ｇ
（ｎＧ
ｊ
＝
０（４
－５）


４２


第四章
引入视觉树结构的图像段落描述算法研宄


其中
，
公式
４４和
４
－５要求图像中任意区域仅出现在ｄ层的某
一个分组中
，


不同分组间没有交叉
。根据定义
，
区域树的根节点即为未划分的图像区域全集
。


由此
，
区域树的构建过程抽象如下
：


ｆ
－Ｃ
—
｛ｃ＼
，〇２
，
．
．
．
，Ｔ＝
｛Ｌ０，Ｌ
－
ｙ
．
．
．Ｌ＾｝（４
－６）


为了实现上述变换／
，本章提出了
一种基于图像区域的空间坐标
，将图像区


域集合启发式地划分为
“ 上和下
”
、
“ 左与右
” 子部分的区域树结构建模方法
。建


模步骤详细说明如下
：


首先
，
给定父节点分组
＝目标是将其划分为两个新的子节点分组


以和
（Ｔ
。计算父节点分组整体对应的最大区域


Ｃ二
＝？
，ｙ〇
Ｐ
，沭ｙｆ）
７
＂
＝
（裳Ｖ
。
，裳
ｎ
ｐｙ〇
，
ｃ
ｒ
ｘ
ｐｙｉ
）
（４
－７）


父节点分组区域４１＆给出了
“ 上下
”
、
“ 左右
” 划分的最大范围
。进
一步基


于４ａ计算变化需要的基准框ｙ和ｄ如下
：


＾＝
（
ｘ
〇
，ｙ〇
，ｘｌ
，ｙ＾＋Ａｘ
（ｙｘ
ｐ－
（４
－８）


ｃ
ｌ＝
（ｘ＾
，ｙ＾，ｘ＾＋
２．Ｘ
（ｘｆ
－
ｘｌ）
，ｙｌ）
Ｔ（４
－９）


其中
，
；ｌ为放缩的比例
。随后
，计算父节点分组中某个图像区域ｃｆ属于
“ 上


下
” 划分中上方区域的置信度如下
：


ｐｆ
＝Ｍｅｒｓｅｃｔｉｏｎ（ｃｆ
，ｃ〇（４
．
１０）


Ａｒｅａ
（ｑ）


其中
，
Ｉｎｔｅｒｓｅｃｔｉｏｎ函数用于两个坐标框相交面积的大小
，
Ａｒｅａ函数用于计


算坐标框的面积
。
ｐｆ的含义为图像区域框Ｃｆ与基准框夕的重合程度
，值在０到


１之间
。
如果
２０
．５则将该框记入新的
、
代表
“ 上方
” 的分组中
，
ｐｆ＜０
．５则


记入
“ 下方
” 的分组中
。
至此
，
完成了
一轮放缩比例为
；Ｉ的
“ 上下
” 分组划分
。


相似的
，
可以得到区域ｃｆ属于
“ 左右
” 划分中左方区域的置信度
：


ｐｌ
＝Ｌ
ｎｔｅｒｓｅｃｔｉｏｎ（ｃｆ
，ｃ〇（４
．ｎ）


Ａｒｅａ
（ｑＪ


如果ｐ丨２ｏ
．ｓ则将该框记入新的
、代表
“ 左方
” 的分组中
，
ｐ｜＜ｏ
．ｓ则记入


“ 右方
” 的分组中
。
至此
，
完成了
一轮放缩比例为
；Ｉ的
“ 左右
” 分组划分。


采用不同的
；Ｉ以及不同方向
（
“ 上下
” 或
“ 左右
”
）可以得到多个不同的新分


组
，
需要对这些新分组进行筛选。
为此
，
本文提出优先选取候选集Ｒｅ
／
，
中


区域数量最为均衡的作为最终结果
，
即计算分值
ｓ
ｙ如下
：


＿
ａｂｓ（２ｘ
｜Ｇ
／卜
｜ＧＰ
｜）


巧
―ｍ
（４
＿１２）


４３


北京邮电大学工学硕士学位论文


其中
，
ａｂｓ为绝对值函数
，
丨
？
丨代表集合元素数量
。分值＆越小
，
则说明对应


的新分组更平衡
。优先选取
５
；最小的新分组
，
如果存在多组分值相同
，
则选取Ａ


最接近
０
．５的新分组
。由于最终目标是得到
一棵完美二叉树
，因此只需要遍历
ｄ
－


１层的父节点
，
并逐
一采用上述的划分方法
，
即将树结构扩展到ｄ层
。实际应用


时
，采用
；Ｉｅ｛０
．１
，０
．２
，０
．３
，０
．４
，０
．５
，０
．６，０
．７
，０
．８
，０
．９｝与两种方向
（
“ 上下
”
、
“ 左右
”
）


的组合
，
共计
１８种情况
，
原始图像区域总数为Ｋ＝３６
，
建模深度为ｄ＝２
。


通过引入上述图像区域树结构
，
能够辅助建模两类区域关系
：
组内关联
，
层


次关联
。组内关联
，指位于同
一个节点对应的分组下的所有区域是空间相邻或处


于同
一观察逻辑的
；层次关联
，指父节点对应的分组与子节点对应的分组间具有


由整体向局部过度的特点
。


在图
４
－
１和图
４
－２中
，
可视化了由所提方法构建出的区域树结构
。
其中
，
图


像中的红色框为目标检测模型抽取的区域图像特征
。


園





Ｗ／


？ｔ，

Ｉｈ，


□ｉ
＾厂
．


图
４
－
丨
区域树结构剖析结果示例
１


１
：邊瀾


ｗ圈


Ｉ
ｉ
ｌ
ｉＭＩ


图
４
－２
区域树结构剖析结果示例
２


４４


第四章
引入视觉树结构的图像段落描述算法研究


４
．３编码视觉树结构的图像段落描述模型


４
．３
．
１模型总览


本文将变压器网络架构
［２７
］应用于图像段落描述任务中
，
并在编码器端引入


了区域树结构信息
，提出了
一种新颖的树结构增强的编码器网络
（Ｔｒｅｅ
－Ｅｎｈａｎｃｅｄ


Ｅｎｃｏｄｅｒ
，ＴＥＥ
）
。
此外
，
本文提出了
一种基于概率分布衰减的段落解码策略
，
延


迟终止
（ＥｎｄｉｎｇＤｅｌａｙ）解码策略
，
用于改善朴素的变压器网络在解决段落描述


问题时存在的解码缺陷
，
使得变压器架构能够获得与最新方法可比较的性能
。


模型总体框架如图
４
－３所示
，
由树结构增强的编码器网络
、解码器网络以及


基于概率分布衰减的段落解码策略三个重要组件构成
。计算流程如下
：首先将图


像输入到
ＴＥＥ的目标检测模块中
，
得到区域的原始特征和边界框坐标
，
并通过


ＴＥＥ的树结构剖析模块得到区域树结构
。随后
，
ＴＥＥ通过改进的多头自注意力机


制编码区域的原始特征和区域树结构
，得到最终的视觉特征表示
。进
一步将视觉


特征表示输入到解码器网络中
，
得到段落中词的概率分布
。在推理测试阶段
，模


型采用由延迟终止和重复性惩罚组成的
、基于概率分布衰减的段落解码策略
，对


词的概率分布进行优化
，
从而得到最终的描述段落并输出
。


Ｄｕｒ
ｉｎｇ
Ｉｎｆｅｒｅｎｃｅ


Ｏｕｔｐｕｔ
；


Ｐｒｏｂａｂ
ｉ
ｌ
ｉｔｉｅｓ
！


■个
■
｜


（
Ｓｏｆｔｍａｘ
｜
；


．个
ｉ


｜Ｌｉｎｅａｒ｜
；


ｉ
、
｜


、ｒｖ


［
Ａｄｄ＆Ｎｏｒｍ
ｊ＜
￣］Ｅｎｄ
ｉｎｇ


＿
Ｆｅｅｄ
ｌ
Ｄｅ
ｌａｙ


Ｆｏｒｗａｒｄ
，Ｒｅｐｅｔ
ｉ
ｔ
ｉｏｎ


，
、
ｙ

Ｐｅｎａ
ｌ
ｔｙ


Ａｄｄ＆Ｎｏｒｍ
｜ｊ
｜Ａｄｄ＆Ｎｏｒｍ
ｈ
＾
；
’


＾ｅｄＭｕ
ｌｔ
ｉ
－Ｈｅａｄ１
；


ｌ
．
ｆＰ＾
ａｒｄＪＭｅｎｔ
ｉｏｎＮｘＲｅｆ
ｉｎｅｄ


￣￣
ｆ
—
Ｉ
，

个
个
个Ｏｕｔｐｕｔ


Ｎｘ
｜
－＾
ｊＡｄｄ＆Ｎｏｒｍ
［
ｉ
￣
１Ｐｒｏｂａｂ
ｉ
ｌ
ｉｔｉｅｓ


Ｅｎｈａｎｃｅｄ］
ＩＡｄｄ＆Ｎｏｒｍｋ
—
，


Ｍｕ
ｌｔ
ｉ
－Ｈｅａｄ
．卜
■
，Ｊ


Ａｔｔｅｎｔ
ｉｏｎ
；Ｍａｓｋｅｄ


Ａ
Ａ
ＡＭｕ
ｔｔｉ
－Ｈｅａｄ


Ａｔｔｅｎｔ
ｉｏｎ


Ｖｙ
、
个
不
个
Ｊ


Ｔｒｅｅ＾」


Ｐａ
ｉ
￣
ｓｅｒ〇ｆＺ＼Ｐｏｓ
ｉｔ
ｉｏｎａ
ｌ


个＾
￣
Ｅｎｃｏｄ
ｉｎｇ


Ｒｅｇ
ｉｏｎＷｏｒｄ


ＤｅｔｅｃｔｏｒＥｍｂｅｄｄ
ｉｎｇ


ＩｍａｇｅＰａｒａｇ
ｒａｐｈ


图
４
－３
引入视觉树结构的图像段落描述模型总览


４５


北京邮电大学工学硕士学位论文


４
．３
．２树结构増强的编码器网络


树结构增强的编码器网络ＴＥＥ是对朴素的变压器编码组件的改进
。
ＴＥＥ由


三个模块组成
：
目标检测器模块、区域树剖析模块以及树结构增强的注意力编码


模块
（Ｔｒｅｅ
－ＥｎｈａｎｃｅｄＡｔｅｎｔｉｏｎＭｏｄｕｌｅ
，
ＴＥＡＭ）
。
区域树剖析模块基于４
．２节提


出的图像区域树结构建模方法实现
，
利用目标检测的结果构建区域树结构
。


ＴＥＡＭ在朴素的多头自注意力机制的基础上
，
融合了剖析得到的区域树结构信


息
，
使得编码器ＴＥＥ能够更好的利用区域间关系
，
从而得到更好的视觉表示
。


首先回顾朴素的变压器编码组件
，
简记为ＡＭ（ＡｔｅｎｔｉｏｎＭｏｄｕｌｅ）
。输入的


原始图像区域特征为Ｋ
，
其前向过程抽象如下
：


ｖ
ｓｅｉｆ＝ＭｕｌｔｉＨｅａｄ（
ｌ／
，Ｖ
，Ｖ）（４
－１３）


Ｖ＝
（
ＲｅＬＵ（Ｖ
ｓｅｌｆＷ〇＋６〇）
）Ｗ
ｘ＋ｂｘ（４
－
１４）


其中
，
每
一层操作额外采用了残差连接
［６２
］并采用了ＬａｙｅｒＮｏｒｍ方法％进行


归
一化
，
即
；ｃ＝ＬａｙｅｒＮｏｒｍ
（ｘ＋ＳｕｂＩａｙｅｒ〇ｃ））
。
ＭｕｌｔｉＨｅａｄ函数即为公式２
－
１
１定


义的多头自注意力操作
。
实际使用时会层叠多个参数独立的编码组件
。


可以看到
，
ＡＭ采用的多头自注意力操作是全连接的
，
即输入特征可以与所


有的特征进行注意力计算
。全连接的注意力计算在机器翻译任务中
，
即用于编码


源语言的文本
，是合理的
。这是因为文本是符号化的信号
，其蕴含着规律性的结


构
，
即语法结构
。通过监督学习
，
全连接的注意力计算可以通过文本语义隐式的


获取结构
。然而
，
图像与文本不同
，
图像中物体对象的空间关系是随机的
，并不


遵循类似于文本语法的约束
。
因此
，在解决图像描述任务
，尤其是更为复杂的图


像段落描述任务时
，
需要引入额外的区域信息关系进行指导或约束
。


为此
，本文提出在ＡＭ的基础上引入区域树结构信息
，对注意力计算过程进


行约束
。
回顾４
．２节中对区域树结构的定义
，
区域树ｒ＝为
一棵完


美二叉树
，
其中
Ｌｄ
＝以及
定义为图像区域的
一个分


组集合。即Ｔ的每
一层Ｌｄ将所有的图像区域划分为了２ｄ个子集合
，每个集合内


的区域是空间相关
。基于上述特点
，通过将朴素的全连接方式改进为只允许对子


集中的区域进行注意力计算
，区域树结构可以被用于约束多层注意力机制
。由此
，


得到了ＴＥＡＭ的基础架构
，
展示在图冬４中
，
剖析得到的区域树结构将被逐层


的输入到编码组件中对多头自注意力进行约束
。


需要说明的是
，
图
４
－４中展示的只是
一种引入区域树结构的策略
。在图
４４


中
，
区域树结构的第ｄ层被优先输入到编码组件ＴＥＡＭ中
，
最终输入根节点
。


这种从局部到整体的树结构引入方式
，定义为自底向上的约束策略
（Ｂｏｔｏｍ
－ｕｐ）
。


同理
，
可以优先输入根节点
，最终输入第ｄ层节点
，这中从整体到局部的树结构


４６


第四章
引入视觉树结构的图像段落描述算法研究


引入方式
，
定义为自顶向下的约束策略
（Ｔｏｐ
－ｄｏｗｎ
）
。
此外
，
树结构的同
一层节


点可以重复使用
，
对连续的多层独立参数的ＴＥＡＭ组件进行约束
。


Ｖｉｓｕａ
ｌ


Ｆｅａｔｕｒｅｓ


￣？
｜
Ａｏｄ＆ｈｌｏｆｍ

Ｉ


｜
Ｆｅｅ＾
１Ｌａｙｅｒ０


氣Ｆｏｒｗａ
ｒｄＪ＾
——
－－
－－
－－
－
－
－－
－－
－－
－
－
－
－
－
－
－
－
－－
－－
－
－— －
－
－
－
－
－
－—
－
—
－－
－
－
－
－
－
－
－
－
－
－—
－


＜ｒ
－？
ｊＡｄｄ
＆
Ｎｏｉｍ
Ｉ
丨
，
ｊ
）
！


Ａ
ｔｉｅｎ
ｔｉｏｆ


ｖ
Ｊ
ｊ
ｊ



、
＊？





—










－


广
－￣？
［
￣
ＡｄｄＫ
Ｎｏｒｍ
＾
＇
？
？
、
？
？


ＦｅｃｄＬａｙｅｒ１


［
Ｆｏｒ
ｗ
ａｒｄ
）


－－
．７
、


２ｒＫ＾
＆ＮｃｘＴＴ
，
］
：
＾Ｘ
．
；


、
ｊ








＊

＇




二二、





／


＼，
＇
＇


：，ｖ
－／
：
■
…
—
．
．
．
＿
；ｗ
＇
．


２
个
＊ｅ
－
－
－

－

？



．
— 

、


＾
ｒ
－＞
｛Ａｄｄ
＆Ｎｏｒｍ

］
Ｊｇ
ｉ卜
｝
＿
？
ｖ？
！


Ｋ
ｉＬ
１＾５

：


Ａｒ＾
ｓｏｒｆ
？
＞


中
‘
Ｉ國
：


Ｖ
１Ｊ
＊
？


：
．
＾？＾
：
＾
令
，
一
？
、
．胺
ｉ


＼

＾
￣


—
Ｔ

—

－


＊
＊

：
－

＂
＂
＊
一
：
＇
ｕ
，


ｒ＾ｒｊ


Ｔ

＇


＾Ｐａｒｓｅｒ


ＩＲｅ
＾ｐｏｎ


［
Ｄｅｔｅｃｔｏｒ


Ｊ
Ｉｍａｇｅ


图
４
＊４树结构增强的注意力编码模块示意图


得到由区域树结构提供的分组信息
Ｌｄ后
，需要将利用集合表示的
Ｌｄ转换成


矩阵表示
，
方便后续计算
。
定义分组矩阵於
￡１Ｇ为
一个仅包含
０和
１的方


阵
。依据
Ｌｄ给出的区域特征分组
，如果区域特征
ｉ和区域特征ｙ属于同
一个节点


（即同
一个分组
）
，
则矩阵Ｍｄ对应位置的
＝１
，
反之则
＝０
。


由此
，输入的原始区域特征Ｆ
，对应
的组件ＴＥＡＭ的前向过程抽象如下
：


ｙ
ｓｅ
ｉｆ＿
ＥｎｈａｎｃｅｃｉＭｕｌｔｉＨｅａｄ（Ｋ
，Ｖ
，Ｖ
，Ｍｄ）（４
－
１５）


＝
（
ＲｅＬＵ
（
Ｖ＾
ｅｉ／Ｍ／
〇＋６〇））
Ｖ／ｘ＋ｂ
ｘ（４
－
１６）


与组件ＡＭ
—致
，
每
一层均采用了ｘ＝ＬａｙｅｒＮｏｒｍ
（ｘ＋Ｓｕｂｌａｙｅｒ〇〇）操作
。


其中
，
ＥｎｈａｎｃｅｄＭｕｌｔｉＨｅａｄ函数在传统多头自注意力机制的基础上额外引入了编


码分组信息的矩阵Ｍｄ
。
本文提出并尝试了下述的几种改进方案
：


１
）硬掩码方案
（ＨａｒｄＭａｓｋｉｎｇ
）


硬掩码方案通过硬性约束注意力对象
，不允许非同组的特征进行注意力计算
。


具体而言
，
考虑公式
２
－
１０中定义的注意力操作
，
其中未归
一化的注意力矩


阵与分组矩阵Ｍｄ的维度大小是相同的
，
矩阵下标的物理含义分别对应特征
ｉ与


特征）的注意力强度以及是否处于同
一分组
。
因此
，
改进后的计算公式如下
：


４７


北京邮电大学工学硕士学位论文


ＡｔｅｎｔｉｏｎＨ
（
（３
ｆＫ
，Ｖ
，Ｍｄ）＝Ｓｏｆｔｍａｘ＋（１
－
Ｍ〇）ｘＣ
－〇〇
）
ｊ
Ｖ（４
－
１７）


其中
，
－〇〇代表负无穷
。
公式
４
－
１７的含义为将不在同
一分组的注意力分值


置为负无穷
，
归
一化后即为０
，
从而对关注区域的约束
。
多头自注意力的计算沿


用公式２
－
１
１
，
将对应的注意力计算从公式
２
－
１０替换为４
－
１７即可
。


２
）软加权方案
（Ｓｏｆ
ｔＷｅｉｇｈｔｉｎｇ）


软加权方案通过加权朴素的多头自注意力机制和硬掩码方案
，实现对区域分


组信息的引入
。
结合公式
２
－１０和
４
－１７
，
具体计算过程如下
：


Ａｔｅｎｔｉｏｎ
５＝ａｘＡｔｔｅｎｔｉｏｎＨ
＋（１
—
ａ）ｘＳＧ（Ａｔｅｎｔｉｏｎ）（４
－１８）


其中
，
ａｅ（０
，１）为预设的超参数常量
，用于平衡两类注意的计算结果
，如果


ａ＝〇则本方案退化为朴素的多头自注意力机制
，
若ａ＝１则本方案等价于硬掩


码方案
。
ＳＧ函数表示在反向传播时取消梯度反传
，
实验中发现只保留硬掩码单


方向的梯度有助于提高性能表现
。


３
）
中心偏移方案
（ＣｅｎｔｅｒＳｈｉｆ
ｔｉｎｇ）


中心偏移方案基于相同分组内注意力分值应当更高的假设
，首先计算不同分


组的键值向量均值作为键值中心
，
然后计算键值向量与各组中心的相似度分值
。


理论上
，
同组内的分值会更高。最终将该分值与原始的注意力权重相加
，从而约


束注意力计算更倾向于同组的区域
。相应的计算过程如下所示
：


１


Ｋ
ｃ＝
－ｘＭｄＫ
（４
－１９）


Ｋ


Ａｔｔｅｎｔｉｏｎ
ｃ
（Ｑ，Ｋ
，Ｖ，Ｍｄ）＝Ｓｏｆｔｍａｘ
（
—土Ｖ（４
－２０）


Ｖ２ｘ具
；


综上
，本节介绍了树结构增强的编码组件ＴＥＡＭ
，并阐明了引入区域树结构


的编码器网络ＴＥＥ的各个组件以及区域树结构的引入策略
。


４
．３
．３基于概率分布衰减的段落解码策略


在所提模型的解码端
，本文沿用变压器网络的解码器组件进行段落生成
，相


关计算过程见
２
．３
．２节
。
尽管理论上
，
相较于循环神经网络
，
变压器网络能够更


好地对文本序列上下文进行理解并生成
。然而实验发现
，在图像段落描述任务中
，


由于变压器网络的解码组件仍属于非层次结构的模型
，无法显式区分和利用段落


中句子层次的信息
。
因此
，
受到Ｍｅｌａｓｋｙｒ
ｉａｚｉ等人
【４６１研究工作的启发
，
需要在解


码推理阶段
，采用额外的后处理
，才能使模型更好地解码生成描述段落
。进
一步


实验发现
，已有的段落解码后处理策略都是针对以循环神经网络为组件的解码器


网络设计的
，
同样的方法直接应用于变压器网络反而会导致性能下降
。


４８


第四章
引入视觉树结构的图像段落描述算法研究


为此
，本文提出了
一套基于概率分布衰减的段落解码策略用于增强变压器解


码组件在段落生成时的性能表现
。顾名思义
，
概率分布衰减的策略是指
，在解码


网络输出的词概率分布的基础上
，有策略地调整部分词概率分布的强度
，使解码


过程更加充分
，
从而生成质量更高的描述段落
。


具体而言
，
所提策略包含两个主要步骤
，
延迟终止和重复惩罚
。在解码生成


的每个时间步
，首先对输出词分布进行延迟终止的调整
，再对潜在的重复内容生


成进行罚分
，
得到优化后的词分布进行采样生成
，
最终组成输出段落
。


相关技术细节说明如下
：


１
）延迟终止
（ＥｎｄｉｎｇＤｅｌａｙ）


针对变压器网络的最新研宄工作
［７９］指出
，
变压器网络存在序列长度过拟合


的问题
，
即模型的性能表现受到训练集序列长度分布的影响
。在本文幵展的实验


中
，观察到了类似的过拟合问题
，
由于训练集段落长度方差较大加上非层次结构


无法显式表征句子
，变压器解码组件会过早结束段落生成
，导致生成的段落长度


显著不足
，
从而极大地影响段落内容的丰富程度
，
降低评测指标
。近期的图像单


句描述工作
［８（）
］也开始对相关问题进行研究
，
使生成的描述句子长度可控
。


受到上述研宄的启发
，本文提出在解码阶段
，对模型输出的词概率分布进行


调整
，通过渐进式的罚分衰减
，
鼓励模型生成段落
。设表示段落终止的特殊词为


“
＜ｅｏｓ＞
” 以及表示句子终止的句号为
“
．
”
。
需要提前设定期望生成的句子数
ｉＶ
ｅ


以及惩罚因子５ｅ（０
，１
］
。在段落解码过程中的第
ｔ时刻
，基于句号对己生成的句


子个数进行统计
，
记为
／Ｖ
ｔ
ｓ
，
对词
“
＜ｅ〇ｓ＞
”
的概率输出调整如下
：


ｌｏｇｐｆ
ｏｓ＝ｌｏｇｐｆ
ｏｓ
＋｛Ｎ
ｅ—ｘｌｏｇ５（４
－２
１）


其中
，
ｐｔ
ｅ° ｓ为调整前的概率值
，戽
° ｓ为进行延迟终止更新后的概率值
。
５越


小则越倾向于鼓励模型继续生成段落
，
直到
“
＜ｅｏｓ＞
” 被采样生成
。
公式４
－２
１会


随着段落中已生成的句子数量逐渐增多
，
逐步降低对词
“
＜ｅｏｓ＞
”
的概率输出的


影响直到满足预设的期望句子生成个数
，
实现平滑的转换
。


２
）重复性惩罚
（ＲｅｐｅｔｉｔｉｏｎＰｅｎａｌｔｙ）


重复性惩罚是由Ｍｅｌａｓｋｙｒ
ｉａｚｉ等人
【４６
］提出的
，
用于降低非层次结构模型段落


生成的冗余度的解码策略
。该策略通过在解码过程中统计己生成的段落中的三元


组
，
降低可能导致重复三元组的词的概率
，
从而增加段落文本内容的多样性
。


然而该方法是基于循环神经网络解码器设计的
，实验发现
，该方法不能直接


应用于变压器解码组件
。进
一步研宄后
，发现变压器解码组件需要先利用所提出


的延迟终止策略进行解码增强
，
随后重复性惩罚策略才能被有效地实施
。


重复性惩罚策略对词ｗ概率值的调整如下所示
：


ｌｏｇｐｆ
＝ｌｏｇｐｆ
—Ｘａ（４
－２２）


４９


北京邮电大学工学硕士学位论文


其中
，所
＾代表
ｔ时刻
，
以词ｗ结尾的
、
己生成的三元组个数
。
ａ￡
［０
，＋〇〇
）


为惩罚强度
，
ａ越大则对重复的惩罚越大
。


综上所述
，
本节介绍了本文提出的由延迟终止和重复惩罚组成的解码策略
。


该策略被用于提升变压器网络中的解码组件在段落生成上的性能表现
。


４
．４实验对比与分析


４
．４
．
１实验参数与设置


针对本章提出的模型方法和解码策略
，为了验证其有效性
，本文采用开源深


度学习框架Ｐｙｔ
ｏｒｃｈ开发和训练模型
，并在基准数据集上进行了定性和定量实验。


实验环境为搭载
１２ＧＢＮＶＩＤＩＡＧｅＦｏｒｃｅ１０８０Ｔｉ显卡的Ｕｂｕｎｔｕ１６
．０４服务器。


编码器网络中的目标检测器组件同样采用预训练的
ＦａｓｔｅｒＲ
－ＣＮＮ
［２
１
］检测并


保留目标检测结果前
３６个框
，
每个框抽取的特征为
２０４８维
。在训练和测试阶


段
，
参数保持固定
。
随后
，
利用多层感知机网络将特征投影
＝５１２维
。
区


域树剖析模块遵循４
．２节
，
采用Ａｅ｛０
．１
，０
．２
，０
．３
，０
．４
，０
．５
，０
．６
，０
．７
，０
．８
，０
．９｝与两种


方向
（
“ 上下
”
、
“ 左右
”
）
，
最终得到的区域树共计
３层
。


模型中采用变压器网络实现遵循Ｒｕｓｈ
［８
１ｌ开源的变压器网络基准实现和超参


数配置。模型釆用了６层树结构增强的编码网络ＴＥＥ和
６层变压器解码网络的


配置
。
依据不同
ＴＥＡＭ组件设计
，
剖析得到的区域树结构将采用不同的方式引


入组件中
，将在模型对比部分详细说明
。词表釆用与
３
．４
．
１节中相似的流程处理
，


但不区分句子而是将段落作为
一个长序列
，
段落的预设生成最长长度为
１７５个


词
，其中包含标点符号
。在监督训练阶段
，模型采用Ａｄａｍ优化器
数据批量


大小为
１０的配置
。
并采用如下的公式
［２７］对学习率
Ｚｒ进行调整
：


ｌｒ＝ｄ＾
－５
ｘｍｉｎ
ｉＮ
￣
ｔ＾
，ＮｓｔｅｐｘＮ
￣＾ｕｐ）（４
－２３）


其中
，
队ｔｅｐ为当前训练步数
，
ＭｖａｒｍｕＰ
＝
２〇〇〇〇为预热步数
。此外
，
遵循


变压器网络训练的惯例
，
采用强度为
０
．
１
的标签平滑策略
ｔ８２
】
（ＬａｂｅｌＳｍｏｏｔｈｉｎｇ）


进行训练
，避免多元交叉熵损失导致过于自信的预测
，从而提升模型的泛化性能
。


在测试推理阶段
，模型采用的解码策略的超参数设置为
：期望生成的最少句


子数
＝７
，
惩罚因子５＝０
．２以及重复性惩罚强度ａ＝２１ｎ２
。
上述超参数是


基于模型在验证集上的性能表现选择的
。


因受限于实验环境的算力
，模型没有釆用
ＳＣＳＴ等强化学习技术＾进行进
一


步优化
。这是由于在每个时间步的强化学习进行的釆样
，均需要重新计算
一次对


历史信息的多头注意力机制
，
因此需要存储的梯度信息远多于循环神经网络
，过


大的显存和时间开销使得利用
ＳＣＳＴ技术优化变压器结构的模型极为困难
。


５０


第四章
引入视觉树结构的图像段落描述算法研究


４
．４
．２评测指标对比与分析


本节选取了近年的图像段落描述模型进行定量的性能对比
，并将其进
一步划


分为建模了未建模区域关系组ｒｎｎ＋ｒｐ
［４６
］
，
ｄａｍ
－ａｔｔ
［４７
］
，ｒｈ
［７
］
，ｒｔｔ
－ｇａｎ
［３５］
，


ＣＡＰＧ
－ＶＡＥ
［３６
］
，Ｄｕａｌ
－ＣＮＮ
［４。
］
，
ＤＨＰＶ
［３Ｓ
］
，
ＩＭＡＰ
［４４
］以及建模区域关系组ＶＲＤ
［４
１
］
，


ＶＲＥＮ
［４２
］
，
ＣＡＶＰ
［４３
］
，
ＯＲ
－ＡＴＴ
［４９
］
，
ＨＳＧＥＤ
［４５
］
。
为保持
一致
，
通过采用
已１＾１；
－


｛
１
，２
，３
，４ｐ
］
（Ｂ
）
，ＭＥＴＥＯＲ
［７４
］
（Ｍ
）
，ＣＩＤＥｒ
［２４
］
（Ｃ
）指标来评价模型的段落生成质量
。


对未在
３
．４
．２节介绍的相关模型补充说明如下
：


１
）ＲＮＮ＋ＲＰ模型
：
该模型基于图像单句描述模型
［２
１
］
，
解码器组件为循环神


经网络
，通过监督学习训练模型
，
解码时采用重复性惩罚策略进行优化
，
属于最


简单的基线方法之
一
。


２
）ＶＲＤ模型
：该模型基于经典的段落描述模型ＲＨ
。其在目标检测模型结果


的基础上
，对区域关系进行显式的预测
，并将有效的区域关系对输入到循环神经


网络解码组件中进行段落生成
。


３
）ＶＲＥＮ模型
：
该模型是对ＶＲＤ的改进
，
利用提出的关系对预测模块替换


目标检测模型
，
该模块基于对抗生成网络实现
，
同样进行显式的关系标签预测
。


４
）ＣＡＶＰ模型
：
该模型由多个感知上下文的视觉策略组件构成
，
通过将己完


成的注意力结果作为上下文信息
，
隐式的完成对图像区域关系的捕捉和利用
。


５
）ＨＳＧＥＤ模型
：
该模型在层次结构模型ＲＨ的基础上引入了场景图
，
需要


预先进行场景图的预测和生成学习
。该模型显式建模并引入了图像区域关系信息
。


同时
，该模型采用了复杂的训练和采样手段提升性能指标
，是当前最先进的方法
。


６
）
ＴｒａｎＳｆ〇ｒｍｅｉ
？模型
：
该模型是直接采用目标检测模型和变压器网络实现的


图像段落描述模型
，未引入本章提出的编码器和解码策略的改进
，
同样属于最简


单的基线方法之
一
。


７
）Ｏｕｒｓｗ／ｏＴｒｅｅ
：
该模型是基于Ｔｒａｎｓｆｏｒｍｅｒ的实现
，
未引入区域树结构和


树结构增强的编码器组件的改进
，只引入了本文提出的基于概率分布衰减的解码


策略
，
包括终止延迟和重复性惩罚
，
属于基线方法
。


８）０ｕｒｓ
：
即本章提出的引入视觉树结构的完整模型
，包括对编码器组件和解


码策略的改进
。
树结构增强的编码器中的
ＴＥＡＭ组件采用了硬掩码策略
，
即公


式４
－
１７
。区域树结构引入的策略是前
３层ＴＥＡＭ组件采用自底向上的约束策略
，


后
３层采用自顶向下的约束策略
。


表４
－
１中展示了相关模型方法的性能结果
。
由于大部分研究工作模型设计复


杂且缺少有效的开源
，表中结果沿用论文提供的指标
。需要说明的是
，为了公平


比较
，表中尽可能汇报相关模型进行监督学习后的性能表现
。其中
，
ＲＴＴ
－ＧＡＮ
，


ＣＡＰＧ
－ＶＡＥ和ＨＳＧＥＤ模型采用了额外的方法进行优化
。


５
１


北京邮电大学工学硕士学位论文


表４
￣
１
不同糢型的评測结果对比


Ｂ１Ｂ２Ｂ３Ｂ４Ｍ
Ｃ


ＲＮＮ＋ＲＰ３５
．８６２２
．４０１４
．０４８
．７０１５
．
１７２２
．６８


ＤＡＭ
－ＡＴＴ３５
．０２２０
．２４１
１
．６８６
．５７１３
．９１１７
．３２


ＲＨ４
１
．９０２４
．
１
１１４
．２３８
．６９１５
．９５１３
．５２


ＲＴＴ
－ＧＡＮ４１
．９９２４
．８６１４．８９９
．０３１７
．
１２１６
．８７


ＣＡＰＧ
－ＶＡＥ４２
．３８２５
．５２１５
．
１５９
．４３１８．６２２０
．９３


Ｄｕａｌ
－ＣＮＮ４１
．６０２４
．４０１４．３０８
．６０１５
．６０１７
．４０


ＤＨＰＶ４０．３５２４
．４５１５
．４１１０
．０３１６
．
１０２０
．７０


ＩＭＡＰ４２
．３８２５
．８７１５
．５１９
．４２１６
．５６２０
．７６


ＶＲＤ４
１
．７４２４
．９４１４
．９４９
．３４１７
．３２１４
．５５


ＶＲＥＮ４
１
．９４２４
．９９１５
．０１９
．３８１７
．４０１４．７１


ＣＡＶＰ４２
．４９２５
．８０１５
．０４９
．００１７
．
１４１９
．６３


ＯＲ
－ＡＴＴ＋ＲＰ３７
．５０２３
．３４１４
．６３９
．００１５
．４３２２
．８５


ＨＳＧＥＤ

４４
．２２２６
．９３１７．３１１０．３５１７
．４５２５
．５２


Ｔｒａｎｓｆｏｒｍｅｒ３５
．２７２１
．００１２．８１７
．８３１４
．７８２２
．４０


Ｏｕｒｓｗ／ｏＴｒｅｅ４４
．４８２７
．０４１６
．５２９
．９６１７．６８２６
．５５


Ｏｕｒｓ
４４．６４２７．５０１６
．８８１０
．２５１７．６５２７．７８


由表４
－１
，
可以看到
，
引入区域信息分组内的模型性能与同期的模型相比
，


都具有性能上的优势
：
例如早期的方法ＶＲＤ和ＶＲＥＮ都相较于基线ＲＨ模型有


提升
，近期的方法例如ＣＡＶＰ和ＨＳＧＥＤ相较于
ＩＭＡＰ模型有优势
。相关实验结


果表明
，
引入图像区域关系等信息是有助于提升段落生成质量
。


本文提出的引入视觉树结构信息的方法取得了良好的性能表现
，指标结果普


遍优于基线模型
，
并与最先进的方法ＨＳＧＥＤ可比较
，
在评测指标上各有优劣
。


此外
，同样是非层次结构模型的ＲＮＮ＋ＲＰ和
Ｔｒａｎｓｆｏｒｍｅｒ基线模型
，在性能


指标上差异不明显
，并且在监督训练设置下性能大幅度低于层次结构模型
。然而
，


在采用本文提出的基于概率分布衰减的段落解码策略进行优化后
，变压器网络的


性能得到了极大的提升
，优于利用了重复性惩罚策略的最新ＯＲ
－ＡＴＴ＋ＲＰ模型的


性能
，甚至好于大部分层次结构模型
。这验证了本文提出的延迟终止策略的有效


性
，
即能够有效的增强变压器网络在段落生成任务上的表现
。在进
一步引入树结


构后
，
所提模型在ＢＬＥＵ和ＣＩＤＥｒ指标上均得到了提升。
其中
，
在ＣＩＤＥｒ指标


上提升明显
，
与未引入树结构的基线模型相比提升了约
４．６％
。
相关结果验证了


本文提出的树结构增强的编码器ＴＥＥ组件的可行性和有效性
。


５２


第四章
引入视觉树结构的图像段落描述算法研究


４
．４
．３消融实验


为了进
一步验证本章提出的引入视觉树结构的段落描述模型的有效性
，本节


从区域树结构剖析方法的设计
、区域树结构信息的引入机制以及所提段落解码策


略三个方面进行了定量实验和分析对比
。


针对区域树结构剖析方法的对比结果展示在表
４
－２中
，
对比方法说明如下
：


１）ｗ／ｏＴｒ
ｅｅ为未引入任何树结构信息的基线模型
。


２
）ｗ／ＢＢｏｘ为在ｗ／ｏＴｒｅｅ的基础上
，
将区域边界框信息
（坐标
，
长宽
，
面


积）作为新増维度直接拼接在对应的区域特征上作为输入
，交由多头自注意力机


制自行完成关系隐式计算
。
与其他方法相比
，
该模型引入了额外的参数量
。


３）ＲａｎｄＴｒｅｅ为采用了随机平均划分剖析策略得到的基线模型
。
具体而言
，


剖析流程与
４
．２节提出的剖析方法相似
，但划分不同分组时不依赖于区域边界框


坐标进行划分
，而是将当前父节点分组中的区域随机划分成两个大小相等的集合
。


除此之外
，
其他配置保持
一致
。


４
）ＨＡＣＴｒｅｅ采用的是自底向上构建视觉树结构的策略
，
核心流程是计算区


域间的距离
，然后利用层次聚类方法（ＨｉｅｒａｒｃｈｉｃａｌＡｇｇ
ｌｏｍｅｒａｔｉｖｅＣｌｕｓｔｅｒｉｎｇ
，ＨＡＣ
）


完成树结构的构建。区域间距离计算基于图像区域特征表示间的余弦相似度和空


间坐标交并比的加权值
。在树结构自底向上构建完成后
，进行剪枝只保留
３层的


树结构并转换为对应的矩阵表示
，
最终引入编码器中
。其他配置保持
一致
。


５
）Ｒｅｇ
ｉｏｎＴｒｅｅ即利用
４
．２节提出的构建方法得到的区域树结构
。
值得
一提


的是
，
编码器端采用的ＴＥＡＭ策略为硬掩码
，
该方案没有引入额外的参数量
。


表
４
－２采用区域树结构剖析方法的消融实验结果


Ｂ１Ｂ２Ｂ３Ｂ４Ｍ
Ｃ


ｗ／ｏＴｒｅｅ４４
．４８２７
．０４１６
．５２９
．９６１７．６８２６
．５５


ｗ／ＢＢｏｘ４４
．３
１２７
．０４１６
．５８１０
．００１７
．４５２６
．７６


ＲａｎｄＴｒｅｅ４２
．５３２６
．
１６１６
．
１０９
．７７１６
．９５２７
．
１０


ＨＡＣＴｒｅｅ
４３
．２８２６
．０５１５
．７０９
．３６１７
．
１２２５
．５７


Ｒｅｇ
ｉｏｎＴｒｅｅ

４４．６４２７．５０１６．８８１０．２５１７
．６５２７．７８


从表４
－２中可以看到
，
采用Ｒｅｇ
ｉｏｎＴｒｅｅ的模型取得了最佳的性能表现
。
对


比ＲａｎｄＴｒｅｅ和ｗ／ｏＴｒｅｅ
，
发现应用随机剖析得到的树结构会损害模型的表现
，


这说明Ｒｅｇ
ｉｏｎＴｒｅｅ中采用的区域划分策略是有价值的
，远好于随机划分
。
对比


ＨＡＣＴｒｅｅ和ＲａｎｄＴｒｅｅ
，
可以看到尽管ＨＡＣＴｒｅｅ采用了语义和空间关系混合打


分的方法进行建模
，
但是其表现甚至差于随机划分
。
一方面是因为ＨＡＣＴｒｅｅ采


用的层次聚类方法会导致剖析得到的树结构不平衡
，即不同分组内区域数量差异


５３


北京邮电大学工学硕士学位论文


大
；
另
一方面是因为ＨＡＣＴｒｅｅ基于的图像语义距离是基于目标检测模型原始特


征得到的
，
该特征是粗粒的
，
容易将不同位置相似的物体聚类在
一起
，
引入额外


的噪声
。
而仅基于空间信息构建的Ｒｅｇ
ｉｏｎＴｒ
ｅｅ能够为模型补充额外的信息而非


干扰
。最后
，对比不同的引入区域关系的方案
，
隐式方案ｗ／ＢＢｏｘ对性能的提升


并不明显
，
Ｒｅｇ
ｉｏｎＴｒｅｅ更好的性能表现验证了引入区域树结构的有效性
。


进
一步考察不同的树结构约束方案和
ＴＥＡＭ组件设计对模型性能的影响
。


相关结果展示在表４
－３中
。本节实验了三种ＴＥＡＭ设计
，
硬掩码方案
（ＨＭ）
、


软加权方案
（ＳＷ）
以及中心偏移方案
（ＣＳ）
，
以及四种引入树结构约束方案
：


１
）
自顶向下
（ＴＤ）
：
区域树结构引入顺序为从根节点层到叶节点层
，每
１层


分组用
２层独立的ＴＥＡＭ组件编码
。


２）
自底向上
（ＢＵ）
：
区域树结构引入顺序为从叶节点层到根节点层
，
每
１


层分组用
２层独立的ＴＥＡＭ组件编码
。


３
）
自顶向下再自底向上
（ＴＤＢＵ）
：
区域树结构引入顺序为从根节点层到叶


节点层
，
叶节点层再到根节点层
。每
１层分组用
１层独立的ＴＥＡＭ组件编码
。


４
）
自底向上再自顶向下
（ＢＵＴＤ）
：
区域树结构引入顺序为从叶节点层到根


节点层
，
根节点层再到叶节点层
。每
１层分组
＿用
１层独立的ＴＥＡＭ组件编码
。


表４
－３采用不同树结构编码方案的消融实验结果


Ｂ１Ｂ２Ｂ３Ｂ４Ｍ
Ｃ


ｗ／ｏＴｒｅｅ

４４
．４８２７
．０４１６
．５２９
．９６１７
．６８２６
．５５


ＨＭ＋ＴＤ４４．１０２６
．６５１６
．２２９
．８０１７
．４２２８
．０８


ＨＭ＋ＢＵ４３
．６４２６
．５０１６
．
１０９
．７０１７
．２６２７
．６７


ＨＭ＋ＴＤＢＵ４４
．１８２６
．７２１６
．２４９
．７５１７
．３４２６
．９０


ＨＭ＋ＢＵＴＤ４４
．６４２７．５０１６．８８１０．２５１７
．６５２７
．７８


ＳＷ＋ＴＤ４４
．３２２７
．１
１１６
．６９１０
．
１８１７．８４２８．８５


ＳＷ＋ＢＵ４２
．５４２５
．８５１５
．６５９
．３８１６
．９７２７
．０６


ＳＷ＋ＴＤＢＵ４３
．６２２６
．５４１６
．２０９
．７４１７
．２６２６
．
１６


ＳＷ＋ＢＵＴＤ４３
．５９２６．４９１６
．３２９
．９１１７
．３
１２６
．２７


ＣＳ＋ＴＤ４４
．２９２６
．６５１６
．
１９９
．７０１７．４７２７
．
１０


ＣＳ＋ＢＵ４４．６９２７
．３６１６
．７２１０
．
１７１７
．４９２７
．８０


ＣＳ＋ＴＤＢＵ４４
．００２６
．５４１６
．０５９
．５９１７
．３８２６
．５２


ＣＳ＋ＢＵＴＤ４４
．２８２７
．０９１６
．４９９
．９６１７
．２４２６
．８３


从表
４
－３中可以看到
，
不同的
ＴＥＡＭ组件设计方案需要采用合适的树结构


约束方案
，才能取得比基线ｗ／ｏＴｒｅｅ更好的性能表现
。例如
，ＨＭ＋ＢＵＴＤ
，
ＳＷ＋ＴＤ


５４


第四章
引入视觉树结构的图像段落描述算法研究


以及ＣＳ＋ＢＵ的组合
。从ＨＭ、
ＳＷ到ＣＳ
，
相关设计对注意力机制的约束程度是


从严格约束逐步放松
，
到完全交由模型自行学习
。


可以发现
，
ＨＷ和
ＳＷ采用ＢＵＴＤ和ＴＤ的效果普遍较好
，原因是最后阶段


的引入是从整体到局部
，能够增强最终输入到解码器组件中视觉表示间的区分度
，


并且能让图像边缘非核心对象的特征获得增强
。
而
ＴＤＢＵ和
ＢＵ的约束策略效


果普遍较差
，
是因为最后
一层采用根节点层对应的全连接
，
等价于放弃了约束
。


不同的是
，
学习型的ＣＳ的设计
，
采用ＢＵ策略更好
，
这是因为ＣＳ基于键值的


中心表示对注意力进行调整
，故先从叶节点层开始编码有助于获取到更好的中心
。


总的来说
，
结合表４
－２和表４
－３的实验结果
，
剖析有效的区域树结构并采用


合适的方式引入
，
将有助于提升模型在图像段落描述任务上的性能表现
。


表４
￣４采用不同解码策略的消融实验结果


Ｂ
１Ｂ２Ｂ３Ｂ４
Ｍ
Ｃ


Ｔｒａｎｓｆｏｒｍｅｒ３５
．２７２１
．００１２
．８１７
．８３１４
．７８２２
．４０


＋ＲＰ３４
．７０２１
．００１２
．８２７
．７５１４
．９３２５
．３２


＋ＥＤ４１
．２１２４
．３２１４
．７７９
．０３１７
．００２２
．６４


＋ＥＤ＋ＲＰ

４４．４８２７．０４１６．５２９．９６１７．６８２６．５５


针对所提的基于概率衰减的段落解码策略
，
本节在基线模型Ｔｒａｎｓｆｏｒｍｅｒ上


进行了实验对比验证
。
延迟终止策略简记为ＥＤ
，
重复性惩罚策略简记为ＲＰ
。


相关结果展示在表４
－４中
。可以看到
，
直接在变压器解码时采用ＲＰ并没有


同循环神经网络解码那样对性能指标有
一致性的提升
，甚至会导致部分指标降低
。


只引入ＥＤ策略时
，
可以观察到
一致性的性能提升
，
在ＢＬＥＵ和ＭＥＴＥＯＲ指标


上的提升尤为显著
。
同时引入ＥＤ和ＲＰ策略后
，
基线模型取得了最好的生成结


果
，
ＲＰ策略也正常发挥了作用
，
提升了段落生成的多样性
。


综上
，
通过区域树结构的剖析
、
引入方式和解码策略三个方面的消融实验
，


本节进
一步验证了所提的引入视觉树结构的图像段落描述模型的有效性
。


４
．４．４定性分析


本节通过展示区域树结构剖析结果以及不同模型生成的段落
，进行定性分析


和对比
。相关结果展示在图４
－５中
，每张输入图像对应
一个剖析得到区域树结构
、


三个由不同模型生成的段落文本
。


５５


北京邮电大学工学硕士学位论文


Ａｂａｂｙｅ
ｌｅｐｈａｎｔ
ｉｓｗａ
ｌｋ
ｉｎｇｏｎｔｈｅ
ｇ
ｒａｓｓ
．Ｔｈｅｂａｂｙ
ｉｓ
ｇ
ｒｅｙ
ｉｎ


ｖ
，二
ｃｏ
ｌｏｒ．Ｔｈｅｂａｂｙ
ｉｓ
ｌｏｏｋ
ｉｎｇｄ
ｒｅｃｔ
ｌｙａｔｔｈｅｃａｍｅｒａ
．Ｔｈｅｂａｂｙ
ｉｓ


〔
ｓｔａｎｄ
ｉｎｇ
ｉｎｆｒｏｎ
ｔｏｆｔｈｅｂａｂｙ
．


Ｏｕｒｓｗ／ｏＴｒｅｅ
：


Ａｂａｂｙｅ
ｌｅｐｈａｎ
ｔ
ｉｓｗａ
ｌｋ
ｉｎｇｏｎｔｈｅｇ
ｒａｓｓ
．Ｔｈｅｂａｂｙ
ｉｓｇ
ｒｅｙ
ｉｎ


ｃｏ
ｌｏｒ
．Ｔｈｅｂａｂｙｈａｓａ
ｌｏｎｇ
ｔｒｕｎｋ
．Ｔｈｅｂａｂｙｅ
ｌｅｐｈａｎｔｈａｓａ


ａ
ｓｍａ
ｌ
ｌｂａｂｙ
．Ｔｈｅ
ｌａｋｅ
ｉｓｃａ
ｌｍａｎｄｇ
ｒｅｅｎ
．Ｔｈｅｗａ
ｔｅｒ
ｉｓｃａ
ｌｍ
．


一Ｏｕｒｓ
：


Ａ
ｌａｒｇｅ
ｇ
ｒａｙｅ
ｌｅｐｈａｎ
ｔ
ｉｓｗａ
ｌｋ
ｉｎｇ
ｔｈｒｏｕｇｈａｆｉｅ
ｌｄｎｅａｒａｂｏｄｙ


ｏｆｗａ
ｔｅｒ
．Ｔｈｅｗａ
ｔｅｒ
ｉｓａｂｒｉｇｈ
ｔ
ｇ
ｒｅｅｎｃｏ
ｌｏｒａｎｄｔｈｅｅ
ｌｅｐｈａｎｔ


ｈａｓａ
ｌｏｎｇ
ｔｒｕｎｋ
．Ｔｈｅｅ
ｌｅｐｈａｎｔ
ｉｓｗａ
丨ｋ
ｉｎｇ
ｉｎｔｈｅ
ｇ
ｒａｓｓｎｅａｒ



＾？？
ｔｈｅｗａｔｅｒ
．Ｔｈｅｒｅ
ｉｓａｂｏｄｙｏｆｗａｔｅｒｎｅａｒｔｈｅｂｏｄｙｏｆｗａ
ｔｅｒ


ｂｅｈ
ｉｎｄｔｈｅｅ
ｌｅｐｈａｎｔａｎｄｔｈｅｒｅａｒｅｓｍａ
ｌ
ｌｒ
ｉｐｐ
ｌｅｓ
ｉｎｔｈｅｗａ
ｔｅｒ


．
…
Ｌ
．
＇
；＾
ａｒｏｕｎｄｔｈｅｅ
ｌｅｐｈａｎｔ
．Ｔｈｅｒｅａｒｅｓｍａ
ｌ
ｌｂ
ｉ
ｒｄｓｓ
ｉ
ｔｔ
ｉｎｇｏｎｔｈｅ


ｇ
ｒｏｕｎｄｎｅａ
ｒｔｈｅｓｍａ
ｌ
ｌｂｏｄｙｏｆｗａ
ｔｅｒ
．


Ｔｒａｎｓｆｏｒｍｅｒ
：


Ａｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓｒ
ｉｄ
ｉｎｇｏｎｔｈｅｓｔｒｅｅｔ
．Ｔｈｅｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓｂ
ｌａｃｋ


—棄
知泛續顯
，
ｉｎｃｏ
ｌｏｒ
．Ｔｈｅｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓ
ｉｎｍｏ
ｔ
ｉｏｎ
．Ｔｈｅｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓａ


ｄａｒｋ
ｇ
ｒａｙｃｏ
丨ｏｒ
．


〇ｕｒｓＷ／ｏＴｒｅｅ
：


：Ｈｆ
ｅ
＇Ａｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓｒ
ｉｄ
ｉｎｇｏｎｔｈｅｓｔｒｅｅｔ
．Ｔｈｅｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓｂ
ｌａｃｋ


ｉｎｃｏ
ｌｏｒ
．Ｔｈｅｍｏｔｏｒ
ｃｙｃ
ｌｅ
ｉｓ
ｉｎｍｏｔ
ｉｏｎ
．Ｔｈｅｒ
ｉｄｅｒ
丨ｓｗｅａｒ
ｉｎｇａ


Ｂ
ｈｅ
ｌｍｅｔ
．Ｔｈｅｈｅ
ｌｍｅｔｉｓｗｈ
ｉｔｅ
．Ｔｈｅｈｅ
ｌｍｅｔ
ｉｓｂ
ｌａｃｋ
．Ｔｈｅｂ
ｉｋｅ
ｉｓ


ｏｎｔｈｅｍｏｔｏｒｃｙｃ
ｌｅ
．Ｔｈｅｓｔｒｅｅ
ｔ
ｉｓｐａｖｅｄ
．Ｔｈｅｒｅ
ｉｓ
ｇ
ｒａｓｓｏｎｔｈｅ


ｓ
ｉｄｅｏｆｔｈｅｓｔｒｅｅｔ
．Ｔｈｅｒｅａｒｅｔｒｅｅｓ
ｉｎｔｈｅｄ
ｉｓｔａｎｃｅ
．


〇ｕｒｓ
：


Ａｒｏａｄｈａｓ
ｙｅ
ｌ
ｌｏｗ
ｌ
ｉｎｅｓ
丁ｈｅｒｅ
ｉｓａｍａｎｒ
ｉｄ
ｉｎｇａｍｏｔｏｒｃｙｃ
ｌｅ
．


Ｔｈｅｍｏｔｏｒｃｙｃ
ｌｅ
ｉｓｒ
ｉｄ
ｉｎｇｏｎａｐａｖｅｄｒｏａｄ
．Ｔｈｅｒｅａｒｅｔｒｅｅｓ
ｉｎ


一＾
？？
ｔｈｅｂａｃｋｇ
ｒｏｕｎｄ
．丁ｈｅｒｅ
ｉｓａｗｈ
ｉ
ｔｅｂｕ
ｉ
ｌｄ
ｉｎｇ
ｉ门ｔｈｅｄ
ｉｓｔａｎｃｅ
．


Ｔｈｅｒｅ
ｉｓａｎｏｔｈｅｒｔｒａｃｋ
ｉｎｆｒｏｎｔｏｆｔｈｅｒｏａｄ
．Ｔｈｅｒｅａｒｅｙｅ
ｌ
ｌｏｗ


ｌ
ｉｎｅｓｏｎｔｈｅｒｏａｄ
．Ｔｈｅｓｋｙ
ｉｓｂ
ｌｕｅａｎｄｔｈｅｒｅ
ｉｓｓｏｍｅｗｈ
ｉ
ｔｅ


ＨＨＢｉＷＢＢＢＷＨＳＨＭｉＨｌｆｃ
｜〇ｕｄｓ
ｊｎｔｈｅｓ
｜＜ｙ
－


广多？
Ｔｒａｎｓｆｏｒｍｅｒ
：


隱■ＳＴｗｏｃｏｍｐｕｔｅｒｓｃｒｅｅｎｓａ
ｒｅｓ
ｉｔｔ
ｉｎｇｏｎａｄｅｓｋ
．Ｔｈｅｄｅｓｋ
ｉｓ


ｂｒｏｗｎａｎｄｗｏｏｄｅｎ
．Ｔｈｅｄｅｓｋ
ｉｓｍａｄｅｏｆｗｏｏｄ
．Ｔｈｅ
ｒｅ
ｉｓａ



ｗｈ
ｉ
ｔｅｋｅｙｂｏａｒｄ
ｉｎｆｒｏｎｔｏｆｔｈｅｍｏｎ
ｉｔｏｒｓ
．


■
■Ｓ（Ｔ
巨目■


ｒＯｕｒｓｗ／ｏＴｒｅｅ
：


Ｔｗｏｃｏｍｐｕｔｅｒｓｃｒｅｅｎｓａｒｅｓ
ｉ
ｔｔ
ｉｎｇｏｎａｄｅｓｋ
．Ｔｈｅｄｅｓｋ
ｉｓ


ＭＨｃＡｍｆ
ｌｌｒ
ｉｌＨＩＨＩｂｒｏｗｎａｎｄｗｏｏｄｅｎ
．Ｔｈｅ
ｌａｐ
ｔｏｐｓａｒｅｓ
ｉ
ｔｔ
ｉｎｇｏｎｔｏｐｏｆａｗｈ
ｉｔｅ


Ｂ
ｋｅｙｂｏａｒｄ
．Ｔｈｅｒｅ
ｉｓａｗｈ
ｉｔｅｍｏｕｓｅｎｅｘｔｔｏｔｈｅｋｅｙｂｏａｒｄ
．


Ｔｈｅｒｅ
ｉｓａｋｅｙｂｏａｒｄｕｎｄｅｒｔｈｅｍｏｕｓｅｐａｄ
．Ｔｈｅｒｅａ
ｒｅｐａｐｅｒｓ


ｏｎｔｈｅｄｅｓｋ
．Ｔｈｅｒｅ
ｉｓａｗ
ｉｎｄｏｗｂｅｈ
ｉｎｄｔｈｅｄｅｓｋｃｈａ
ｉｒ
．Ｔｈｅｒｅ


ａｒｅｂ
ｌ
ｉｎｄｓｏｎｔｈｅｗ
ｉｎｄｏｗｂｅｈ
ｉｎｄｔｈｅｄｅｓｋ
．


〇ｕｒｓ
：


ＰｐＨｆ
ｃ
ｉＪ＾ＰＡｗｈ
ｉｔｅｃｏｍｐｕｔｅｒ
ｉｓｓ
ｉ
ｔｔ
ｉｎｇｏｎａｄｅｓｋ
．Ｔｈｅ
ｒｅ
ｉｓａ
ｌａｒｇｅｃｏｍｐｕ
ｔｅｒ


ｍｏｎ
ｉｔｏｒｔｈａｔ
ｉｓｔｕｒ
ｎｅｄｏｎ
．Ｔｈｅｒｅ
ｉｓａｗｈ
ｉ
ｔｅｋｅｙｂｏａｒｄｓ
ｉｔｔ
ｉｎｇｏｎ



ｔｈｅｄｅｓｋｂｅｈ
ｉｎｄｔｈｅｃｏｍｐｕ
ｔｅ
ｒ
．Ｔｈｅｒｅａｒｅｔｗｏｗ
ｉｎｄｏｗｓｏｎｔｈｅ


權ｗａ
ｌ
ｌｂｅｈ
ｉｎｄｔｈｅｃｏｍｐｕｔｅｒ
．Ｔｈｅｒｅ
ｉｓａｗ
ｉｎｄｏｗｂｅｈ
ｉｎｄｔｈｅｄｅｓｋ
．Ａ


ｗｉｎｄｏｗ
ｉｓｂｅｈ
ｉｎｄｔｈｅｄｅｓｋｗ
ｉ
ｔｈａｗ
ｉｎｄｏｗ
ｉｎ
ｉ
ｔ
．Ｔｈｅｒｅａｒｅｂ
ｌ
ｉｎｄｓ


Ｓｉｇｉｉｏｎｔｈｅｗ
ｉｎｄｏｗ
．


图
４
－５
区域树结构与模型生成段落的对比展示


可以看到
，
引入区域树结构后
，模型能够捕捉图像中更多的细节信息
，
从而


生成质量更好的段落描述
。
以图
４
－５中第
一幅图的生成结果为例
，
ｗ／ｏＴｒｅｅ模型


仅完成了图像中大象和湖的描述
，而在引入区域树后
，模型能进
一步提及处于图


像背景中停留在湖边的飞鸟
（
“
Ｔｈｅｒｅａｒｅｓｍａｌ
ｌｂｉｒｄｓｓｉｔｔｉｎｇｏｎｔｈｅｇｒｏｕｎｄｎｅａｒｔｈｅ


ｓｍａｌｌｂｏｄｙｏｆｗａｔ
ｅｒ．
”
）
。这得益于区域树结构对于相关子区域的划分
，
即区域树第


５６


第四章
引入视觉树结构的图像段落描述算法研究


二层首个节点
，
实现了对该区域单独的分组
。
同样的
，
在图
４
－５的第二幅图中
，


通过引入区域树结构
，模型进
一步提及了道路中的黄线
（
“ Ａｒｏａｄｈａｓ
ｙｅｌｌｏｗｌｉｎｅｓ．
”
）


和背景处的白色房屋
（
“
Ｔｈｅｒｅｉｓａｗｈｉｔｅｂｕｉｌｄｉｎｇ
ｉｎｔｈｅｄｉｓｔａｎｃｅ．
”
）
。


此外
，对图像区域边界框的划分是符合人类认知习惯的
。
以图
４
－５中第二幅


图的区域树结构为例
，区域集合首先被拆分为以上方区域为主的背景以及下方区


域为主的前景物体
。然后上方的背景被
“ 左右
” 划分
，
右节点主要涉及房子
。下


方的前景也被
“ 左右
” 划分为摩托车以及道路
。在更为复杂的第三幅图中
，
区域


树结构剖析的表现稍差
，但在首次划分时对
“ 左右
’ ’ 不同显示器的划分也是比较


准确的
。剖析质量下滑的主要原因是目标检测器输出的多个边界框过大
，互相重


叠严重
。尽管如此
，通过观察生成的段落
，当前的树结构剖析质量是可以接受的
，


最后
，
通过对比基线模型Ｔｒａｎｓｆｏｒｍｅｒ和ｗ／ｏＴｒｅｅ生成的段落
，
可以看到所


提出的延迟终止和重复惩罚的段落解码组合策略能有效提升段落生成质量
。描述


段落不仅在句子生成个数上得到了提升
，
也提及了更多图像中出现的对象
。


总的来说
，通过在编码端引入区域树结构信息
，模型能够有效提升描述段落


的准确性和丰富程度
。生成段落中仍存在局部不连贯和内容冗余的问题
，这是由


于本节提出的方法仍属于非层次结构模型
，
需要对解码组件进
一步改进
。


４
．５本章小结


本章开展了引入视觉树结构的图像段落描述算法的研究工作
。本章首先提出


了
一种用于构建图像区域树结构的建模方法。随后
，基于变压器网络框架
，本章


详细介绍了所提出的树结构增强的编码器网络
，以及基于概率分布衰减的段落解


码策略
。最终
，得到了
一种新颖的编码视觉树结构的图像段落描述模型
。在实验


部分
，本章通过定量分析实验
、消融实验对比以及定性展示剖析结构和生成段落
，


验证了引入视觉树结构的可行性与有效性
。


５７


北京邮电大学工学硕士学位论文


５８


第五章
总结与展望


第五章总结与展望


５
．
１工作总结


本文开展了基于树结构的图像段落描述研究
。图像段落描述任务旨在为图像


自动生成由多个句子组成的
，
内容多样且语义连贯的描述段落
。
目前
，主流研宄


存在两个问题亟待解决
：
１）模型缺乏对段落句子结构信息的建模和利用
；
２
）模


型缺乏对图像区域结构信息的建模和利用
。为此
，本文提出通过引入图文模态中


蕴含的树结构来解决上述问题
。


针对问题
１
，本文提出利用句子树结构对段落中句子间关系进行建模
，
开展


了基于文本树结构的图像段落描述算法研宄工作
。本文设计了
一种用于构建段落


句子树结构的层次建模方法
，使主题更相关的句子表示于同
一棵子树下
。将建模


得到的树结构作为监督信息
，本文进
一步提出了
一种新颖的树结构段落解码框架


Ｓ２ＴＤ
。
该框架将段落生成过程建模为
一棵自顶向下不断扩展的二叉树结构
，
从


图像全局特征开始
，父节点特征被逐步划分成左右子节点
。最终
，
叶节点代表的


图像局部特征被解码成句子组成输出的描述段落
。与传统方法相比
，提出的
Ｓ２ＴＤ


模型能够生成语义更连贯
、
内容更丰富的描述段落
，
同时生成过程具有良好的可


解释性
。本文通过定量和定性实验
，
验证了所提方法的可行性与有效性
。


针对问题２
，本文提出利用区域树结构对图像区域间关系进行建模
，开展了


引入视觉树结构的图像段落描述算法的研究工作
。本文设计了
一种图像区域树结


构的启发式构建方法
，能够将图像区域集合逐步分组为符合人类观察习惯的
“ 上


和下
” 或
“ 左与右
” 子部分
，
实现了对区域间关系结构的建模
。将建模得到的树


结构作为对多头自注意力机制的指导信息
，本文进
一步提出了
一种新颖的树结构


增强的编码器网络ＴＥＥ
。ＴＥＥ编码组件是对朴素变压器编码网络的改进
，能够基


于剖析得到的区域树结构捕捉更丰富的图像信息
。此外
，本文提出了
一套基于概


率分布衰减的段落解码策略
，用以改善解码器组件的段落生成质量
。与基线方法


相比
，
所提出的
ＴＥＥ组件和解码策略在不引入额外参数量的基础上
，
能够有效


建模图像区域间关系
，并提升描述段落的内容丰富程度和准确性
。本文通过定量


分析和定性对比
，
验证了所提方法的可行性与有效性
。


综上所述
，
本文研宄工作的主要贡献总结如下
：


１）首次在图像段落描述研宄中考虑引入树结构进行模态建模和模型改进
。


２
）提出了
一种段落句子树结构构建方法以及对应的树结构解码框架。


３）提出了
一种图像区域树结构构建方法以及对应的树结构编码组件。


５９


北京邮电大学工学硕士学位论文


５
．２未来工作展望


尽管本文对如何在图像段落描述模型中引入树结构开展了研究
，并取得了
一


定的成果
。
引入树结构的思路和方式仍值得进
一步探索和挖掘
：


１）如何实现图像观察和句子生成的显式对齐？


本文分别在文本侧和图像侧构造了文本树和视觉树
，用于提升段落生成质量。


然而
，文本树无法给出节点对应的图像区域分组
，视觉树无法实现节点与段落句


子的对齐
，这在
一定程度上限制了树结构跨模态的表征能力
。因此
，融合文本树


和视觉树从而实现图像观察与句子生成的显式对齐是
一个潜在的改进方向
。


２
）如何利用强化学习对树结构的建构进行学习或优化？


尽管本文提出了两种构造树结构的方法
，并有效应用于图像段落描述任务上
，


但本文采用的解决思路偏向于静态剖析和手工设计
，无法利用梯度反传或强化学


习等方法进行学习或优化
，不可避免的存在
一定的缺陷并引入部分噪声
。强化学


习作为
一种强有力的学习机制
，通过不断试错并从环境得到奖励反馈
。
因此
，能


否利用强化学习对树结构的建构进行优化是另
一个潜在的改进方向
。


除了本文开展的研究工作外
，图像段落描述任务仍有许多有价值且具有挑战


．性的方向值得研究
：


１）如何利用预训练模型解决图像段落描述问题？


近期人工智能研究的
一个重要趋势
，是利用预训练大模型泛化到下游问题并


予以解决
。潜在的研究点包括如何在图文多模态预训练阶段引入图像段落描述任


务
，
或在段落描述基准数据集上联合微调图像和语言预训练模型
。


２
）能否借助跨模态检索技术优化段落生成质量？


随着图文检索技术的成熟
，如果能够在生成段落前检索出与图像内容相关的


模板段落
，将有助于缓解长序列生成带来的困难
，辅助语言模型生成质量更高的


描述段落
，过程也更为可控。此外
，也可以在生成每个段落句子时
，进行图文联


合检索
，
即利用当前图像和已生成的句子检索下
一个模板句子
。


图像段落描述任务作为多模态人工智能的新兴研究方向之
一
，仍是
一个充满


未知且极具挑战性的任务
，
需要不断探索和大胆试错。
“ 道阻且长
，
行则将至
。
”


６０


参考文献


参考文献


［
１
］ＬｅＣｕｎＹ
，Ｂｅｎｇ
ｉｏＹ
，ＨｉｎｔｏｎＧ
．Ｄｅｅｐ
ｌｅａｍｉｎｇ［Ｊ］
，ｎａｔｕｒｅ
，２０１５
，
５２
１（７５５３）
：４３６
－４４４
．


［２
］ＢａｌｔｒｕｓａｉｔｉｓＴ
，Ａｈｕ
ｊ
ａＣ
，ＭｏｒｅｎｃｙＬ
，
ｅｔａｌ
．ＭｕｌｔｉｍｏｄａｌＭａｃｈｉｎｅＬｅａｒ
ｎｉｎｇ
：ＡＳｕｒｖｅｙ


ａｎｄＴａｘｏｎｏｍｙ［Ｊ］
．ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＰａｔｅｒ
ｎＡｎａｌｙｓｉｓａｎｄＭａｃｈｉｎｅ


Ｉｎｔｅｌｌｉｇｅｎｃｅ
，２０１９
，４１（２
）
：４２３
－４４３
．


［３
］
陈悦，郭宇
，谢圆琰，等
．基于图像描述算法的离线盲人视觉辅助系统［Ｊ
］
．
电


信科学
，２０２２
，３８（
１
）
：６
１
－７２
．


［４
］
杨润霞
，邵洁
，罗岩
，
白万荣
．基于编解码器的电力施工场景可控图像字幕


生
成
［Ｊ／ＯＬ
］
．
电
网
技
术
：
１
－
１０
［２０２２
－０４
－０４
］
．Ｄ０１
：
１０
．
１３３３５／ｊ
．
ｌ０００
－


３６７３．ｐｓｔ．２０２１
．２４００
．


［５
］
徐守坤
，倪楚涵
，吉晨晨，李宁
．基于
ＹＯＬＯｖ３
的施工场景安全帽佩戴的图


像描述［Ｊ
］
．计算机科学，２０２０
，４７（０８）
：２３３
－２４０
．


［６
］沈佳敏
，鲍秉坤
．基于深度学习的广告布局图片美学属性评价［Ｊ
］
．计算机技


术与发展
，２０２
１
，
３
１（０３）
：３９
￣４４
．


［７
］ＫｒａｕｓｅＪ
，
ＪｏｈｎｓｏｎＪ
，Ｋｒ
ｉｓｈｎａＲ
，
ｅｔａｌ
＿ＡＨｉｅｒａｒｃｈｉｃａｌＡｐｐｒｏａｃｈｆｏｒＧｅｎｅｒａｔｉｎｇ


Ｄｅｓｃｒｉｐ
ｔｉｖｅＩｍａｇｅＰａｒａｇｒａｐｈｓ
［Ａ
］
，／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎ


Ｃｏｍｐｕｔｅｒ＼ｌｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］５２０１７
：３３３７
－３３４５
．


［８
］ＥｌｌｉｏｔｔＤ
，ＫｅｌｌｅｒＦ．ＩｍａｇｅＤｅｓｃｒｉｐ
ｔｉｏｎＵｓｉｎｇＶｉｓｕａｌＤｅｐｅｎｄｅｎｃｙ


Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ
［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆ
ｔｈｅ２０１３ＣｏｎｆｅｒｅｎｃｅｏｎＥｍｐ
ｉｒｉｃａｌＭｅｔｈｏｄｓ


ｉｎＮａｔｕｒａｌＬａｎｇｕａｇｅＰｒｏｃｅｓｓｉｎｇ［Ｃ
］
，２０１３
：１２９２
－１３０２
．


［９
］ＫｕｌｋａｍｉＧ
，ＰｒｅｍｒａｊＶ
，ＯｒｄｏｎｅｚＶ
５ｅｔａｌ
．Ｂａｂｙｔａｌｋ：ＵｎｄｅｒｓｔａｎｄｉｎｇａｎｄＧｅｎｅｒａｔｉｎｇ


Ｓｉｍｐ
ｌｅＩｍａｇｅＤｅｓｃｒ
ｉｐ
ｔｉｏｎｓ［Ｊ］
，ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＰａｔｔｅｒ
ｎ
ＡｎａｌｙｓｉｓａｎｄＭａｃｈｉｎｅ


Ｉｎｔｅｌｌｉｇｅｎｃｅ
，２０１３
，３５（１２
）
：２８９１
－２９０３
．


［
１０
］ＫｕｚｎｅｔｓｏｖａＰ
，ＯｒｄｏｎｅｚＶ
，ＢｅｒｇＴＬ
，ｅｔａｌ
，Ｔｒｅｅｔａｌｋ：ＣｏｍｐｏｓｉｔｉｏｎａｎｄＣｏｍｐｒｅｓｓｉｏｎ


ｏｆＴｒｅｅｓｆｏｒＩｍａｇｅＤｅｓｃｒ
ｉｐ
ｔｉｏｎｓ［Ｊ］
，ＴｒａｎｓａｃｔｉｏｎｓｏｆｔｈｅＡｓｓｏｃｉａｔｉｏｎｆｏｒ


ＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ
，２０１４
，２
：３５
１
－３６２
．


［１
１
］ＭｉｔｃｈｅｌｌＭ
，ＨａｎＸ
５ＤｏｄｇｅＪ
，ｅｔａｌ
．Ｍｉｄｇｅ
：ＧｅｎｅｒａｔｉｎｇＩｍａｇｅＤｅｓｃｒ
ｉｐｔｉｏｎｓｆ
ｒｏｍ


ＣｏｍｐｕｔｅｒＶｉｓｉｏｎＤｅｔｅｃｔｉｏｎｓ［Ａ
］
，／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ１３ｔｈＣｏｎｆｅｒｅｎｃｅｏｆｔｈｅ


ＥｕｒｏｐｅａｎＣｈａｐ
ｔｅｒｏｆｔｈｅＡｓｓｏｃｉａｔｉｏｎｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ
．Ａｓｓｏｃｉａｔｉｏｎ


ｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ［Ｃ］，２０１２
：７４７
－７５６
．


［
１２
］ＹａｎｇＹ
，ＴｅｏＣＬ
，ＤａｕｍｅＩＩＩＨ
？ｅｔａｌ
．Ｃｏｒｐｕｓ
－ｇｕｉｄｅｄＳｅｎｔｅｎｃｅＧｅｎｅｒａｔｉｏｎｏｆ


ＮａｔｕｒａｌＩｍａｇｅｓ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＣｏｎｆｅｒｅｎｃｅｏｎＥｍｐ
ｉｒｉｃａｌＭｅｔｈｏｄｓｉｎ


６１


北京邮电大学工学硕士学位论文


ＮａｔｕｒａｌＬａｎｇｕａｇｅＰｒｏｃｅｓｓｉｎｇ
．ＡｓｓｏｃｉａｔｉｏｎｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ
［Ｃ
］
，２０１
１
：


４４４
－４５４
．


［
１３
］ＦａｒｈａｄｉＡ
，ＨｅｊｒａｔｉＭ
，ＳａｄｅｇｈｉＭＡ
，ｅｔａｌ
．ＥｖｅｒｙＰｉｃｔｕｒｅＴｅｌｌｓａＳｔｏｒｙ
：Ｇｅｎｅｒａｔｉｎｇ


ＳｅｎｔｅｎｃｅｓｆｒｏｍＩｍａｇｅｓ
［Ａ
］
．／／ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ［Ｃ
］
５２０１０
：


１５
－２９
．


［
１４
］ＨｏｄｏｓｈＭ
，ＹｏｕｎｇＰ
，ＨｏｃｋｅｎｍａｉｅｒＪ
．Ｆｒａｍｉｎｇ
ＩｍａｇｅＤｅｓｃｒ
ｉｐ
ｔｉｏｎａｓＡＲａｎｋｉｎｇ


Ｔａｓｋ：Ｄａｔａ
，ＭｏｄｅｌｓａｎｄＥｖａｌｕａｔｉｏｎＭｅｔｒｉｃｓ［Ｊ］
．Ｊｏｕｒ
ｎａｌｏｆＡｒｔｉｆ
ｉｃｉａｌＩｎｔｅｌｌｉｇｅｎｃｅ


Ｒｅｓｅａｒｃｈ
，２０１３
，４７
：８５３
－８９９
．


［
１５
］ＳｏｃｈｅｒＲ
，ＫａｒｐａｔｈｙＡ
，
ＬｅＱＶ
，
ｅｔａｌ
．ＧｒｏｕｎｄｅｄＣｏｍｐｏｓｉｔｉｏｎａｌＳｅｍａｎｔｉｃｓｆｏｒ


ＦｉｎｄｉｎｇａｎｄＤｅｓｃｒ
ｉｂｉｎｇＩｍａｇｅｓｗｉｔｈＳｅｎｔｅｎｃｅｓ［Ｊ
］
．ＴｒａｎｓａｃｔｉｏｎｓｏｆｔｈｅＡｓｓｏｃｉａｔｉｏｎ


ｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ
，２０１４
，２
：２０７
－２１８
．


［
１６
］ＧｏｎｇＹ
，ＷａｎｇＬ
，ＨｏｄｏｓｈＭ
，ｅｔａｌ
．Ｉｍｐｒｏｖｉｎｇ
Ｉｍａｇｅ
－ｓｅｎｔｅｎｃｅＥｍｂｅｄｄｉｎｇｓＵｓｉｎｇ


ＬａｒｇｅＷｅａｋｌｙＡｎｎｏｔａｔｅｄＰｈｏｔｏＣｏｌｌｅｃｔｉｏｎｓ
［Ａ
］
．／／ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎ


ＣｏｍｐｕｔｅｒＶｉｓｉｏｎ［Ｃ］５Ｃｈａｍ
：Ｓｐｒｉｎｇｅｒ
，２０１４：５２９
－５４５
．


［
１７
］ＯｒｄｏｎｅｚＶ
，ＫｕｌｋａｍｉＧ
，ＢｅｒｇＴＬ
．Ｉｍ２ｔｅｘｔ：Ｄｅｓｃｒ
ｉｂｉｎｇＩｍａｇｅｓＵｓｉｎｇ
１Ｍｉｌｌｉｏｎ


ＣａｐｔｉｏｎｅｄＰｈｏｔｏｇｒａｐｈｓ［Ａ
］
．／／ＡｄｖａｎｃｅｓｉｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎＰｒｏｃｅｓｓｉｎｇ


Ｓｙｓｔｅｍｓ
ｆＣ
］
，２０１
１
：１
１４３
－１
１５
１
．


［
１８
］ＶｉｎｙａｌｓＯ
，ＴｏｓｈｅｖＡ
，Ｂｅｎｇ
ｉｏＳ
，ｅｔａｌ
．ＳｈｏｗａｎｄＴｅｌｌ
：ＡＮｅｕｒａｌＩｍａｇｅＣａｐｔｉｏｎ


Ｇｅｎｅｒａｔｏｒ
［Ａ］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄ


ＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］
５２０１５
：３
１５６
－３
１６４．


［
１９
］ＸｕＫ
，ＢａＪ
，ＫｉｒｏｓＲ
，ｅｔａｌ
．Ｓｈｏｗ
，ＡｔｔｅｎｄａｎｄＴｅｌｌ
；ＮｅｕｒａｌＩｍａｇｅＣａｐ
ｔｉｏｎＧｅｎｅｒａｔｉｏｎ


ｗｉｔｈＶｉｓｕａｌＡｔｔｅｎｔｉｏｎ［Ａ］
，／／ＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＭａｃｈｉｎｅＬｅａｒ
ａｉｎｇ［Ｃ
］，


２０１５
：２０４８
－２０５７
．


［２０］ＬｕＪ
？ＸｉｏｎｇＣ
？ＰａｒｉｋｈＤ
，ｅｔａｌ
．ＫｎｏｗｉｎｇＷｈｅｎｔｏＬｏｏｋ
：Ａｄａｐ
ｔｉｖｅＡｔｔｅｎｔｉｏｎｖｉａＡ


ＶｉｓｕａｌＳｅｎｔｉｎｅｌｆｏｒＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅ


ｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ］
５２０１７
：３７５
－３８３
．


［２
１
］ＡｎｄｅｒｓｏｎＰ
，ＨｅＸ
，ＢｕｅｈｌｅｒＣ
３ｅｔａｌ
．Ｂｏｔｔｏｍ
－ｕｐａｎｄＴｏｐ
－ｄｏｗｎＡｔｔｅｎｔｉｏｎｆｏｒＩｍａｇｅ


Ｃａｐ
ｔｉｏｎｉｎｇａｎｄＶｉｓｕａｌＱｕｅｓｔｉｏｎＡｎｓｗｅｒｉｎｇ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ


ＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒ＼ｌｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ［Ｃ］
５２０１８
：６０７７
－６０８６
．


［２２
］ＲｅｎＳ
，ＨｅＫ
，ＧｉｒｓｈｉｃｋＲ
，ｅｔａｌ
．ＦａｓｔｅｒＲ
－ＣＮＮ
：ＴｏｗａｒｄｓＲｅａｌ
－ｔｉｍｅＯｂｊｅｃｔＤｅｔｅｃｔｉｏｎ


ｗｉｔｈＲｅｇ
ｉｏｎＰｒｏｐｏｓａｌＮｅｔｗｏｒｋｓ［Ａ
］
，／／ＡｄｖａｎｃｅｓｉｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎＰｒｏｃｅｓｓｉｎｇ


Ｓｙｓｔｅｍｓ［Ｃ］
５２０１５
：９１
－９９
．


［２３
］Ｐａｐ
ｉｎｅｎｉＫ
５ＲｏｕｋｏｓＳ
？ＷａｒｄＴ
，ｅｔａｌ
．ＢＬＥＵ
：ＡＭｅｔｈｏｄｆｏｒＡｕｔｏｍａｔｉｃＥｖａｌｕａｔｉｏｎ


ｏｆＭａｃｈｉｎｅＴｒａｎｓｌａｔｉｏｎ
［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ４０ｔｈＡｎｎｕａｌＭｅｅｔｉｎｇｏｎ


６２


参考文献


ＡｓｓｏｃｉａｔｉｏｎｆｏｒＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ
［Ｃ
］
５２００２
：３
１
１
－３１８
．


［２４
］ＶｅｄａｎｔａｍＲ
，ＬａｗｒｅｎｃｅＺｉｔｎｉｃｋＣ
５ＰａｒｉｋｈＤ
．ＣＩＤＥｒ：Ｃｏｎｓｅｎｓｕｓ
－ｂａｓｅｄＩｍａｇｅ


Ｄｅｓｃｒ
ｉｐ
ｔｉｏｎＥｖａｌｕａｔｉｏｎ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒ


ＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］，２０１５
：４５６６
－４５７５
．


［２５
］Ｂｅｎｇ
ｉｏＳ
，Ｖｉｎｙａｌｓ０
？ＪａｉｔｌｙＮ
，ｅｔａｌ
．ＳｃｈｅｄｕｌｅｄＳａｍｐ
ｌｉｎｇｆｏｒＳｅｑｕｅｎｃｅＰｒｅｄｉｃｔｉｏｎ


ｗｉｔｈＲｅｃｕｒｒｅｎｔＮｅｕｒａｌＮｅｔｗｏｒｋｓ
［Ａ
］
．／／ＡｄｖａｎｃｅｓｉｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎＰｒｏｃｅｓｓｉｎｇ


Ｓｙｓｔｅｍｓ［Ｃ］，２０１５
：
１
１７１
－１
１７９
．


［２６
］ＲｅｎｎｉｅＳＪ
，ＭａｒｃｈｅｒｅｔＥ
，ＭｒｏｕｅｈＹ
，ｅｔａｌ
．Ｓｅｌｆ
－ｃｒｉｔｉｃａｌＳｅｑｕｅｎｃｅＴｒａｉｎｉｎｇｆｏｒＩｍａｇｅ


Ｃａｐｔｉｏｎｉｎｇ［Ａ
］
，／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄ


Ｐａｔｔｅｒ
ｎＲｅｃｏｇｎｉｔｉｏｎ［Ｃ
］
５２０１７
：７００８
－７０２４
．


［２７
］ＶａｓｗａｎｉＡ
，ＳｈａｚｅｅｒＮ
，ＰａｒｍａｒＮ
，ｅｔａｌ
．Ａｔｅｎｔｉｏｎｉｓａｌｌ
ｙｏｕｎｅｅｄ
［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓ


ｏｆ
ｔｈｅ３
１ｓｔＩｎｔｅｒ
ｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎＰｒｏｃｅｓｓｉｎｇＳｙｓｔｅｍｓ［Ｃ
］
，


２０１７
：６０００
－６０１０
．


［２８
］ＨｅｒｄａｄｅＳ
，ＫａｐｐｅｌｅｒＡ
，ＢｏａｋｙｅＫ
？ｅｔａｌ
．Ｉｍａｇｅｃａｐ
ｔｉｏｎｉｎｇ
：ＴｒａｎｓｆｏｒｍｉｎｇＯｂｊｅｃｔｓ


ｉｎｔｏＷｏｒｄｓ［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ３３ｒｄＩｎｔｅｒ
ｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＮｅｕｒａｌ


ＩｎｆｏｒｍａｔｉｏｎＰｒｏｃｅｓｓｉｎｇＳｙｓｔｅｍｓ［Ｃ
］
５２０１９
：１
１
１３７
－１１１４７
．


［２９
］ＨｕａｎｇＬ
５ＷａｎｇＷ
３ＣｈｅｎＪ
，ｅｔａｌ
．ＡｔｔｅｎｔｉｏｎｏｎＡｔｔｅｎｔｉｏｎｆｏｒＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．


／／Ｐｒ
ｏｃｅｅｄｉｎｇｓｏｆ
ｔｈｅＩＥＥＥ／ＣＶＦＩｎｔｅｒｎａｔ
ｉｏｎａｌＣｏｎｆ
ｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒ＼ｌｓｉｏｎ［Ｃ
］
，


２０１９：４６３４
－４６４３
．


［３０
］Ｃｏｒ
ａｉａＭ
，ＳｔｅｆａｎｉｎｉＭ
？ＢａｒａｌｄｉＬ
，ｅｔａｌ
．Ｍｅｓｈｅｄ
－ｍｅｍｏｒｙＴｒａｎｓｆｏｒｍｅｒｆｏｒＩｍａｇｅ


Ｃａｐｔｉｏｎｉｎｇ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ／ＣＶＦＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ


ａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ］，２０２０
：１０５７８
－
１０５８７
．


［３
１
］ＺｈｏｕＬ
，Ｐａｌａｎｇ
ｉＨ
，ＺｈａｎｇＬ
，ｅｔａｌ
．ＵｎｉｆｉｅｄＶｉｓｉｏｎ
－
ｌａｎｇｕａｇｅＰｒｅ
－ｔｒａｉｎｉｎｇｆｏｒＩｍａｇｅ


ＣａｐｔｉｏｎｉｎｇａｎｄＶＱＡ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＡＡＡＩＣｏｎｆ
ｅｒｅｎｃｅｏｎＡｒｔｉｆ
ｉｃｉａｌ


Ｉｎｔｅｌｌｉｇｅｎｃｅ［Ｃ
］
５２０２０
：１３０４１
－１３０４９
．


［３２
］ＤｅｎｇＣ
，ＤｉｎｇＮ
？ＴａｎＭ
，ｅｔａｌ
．Ｌｅｎｇｔｈ
－ｃｏｎｔｒｏｌｌａｂｌｅＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／


ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
［Ｃ
］
，２０２０
：７１２
－７２９
．


［３３
］ＪｏｈｎｓｏｎＪ
３ＫａｒｐａｔｈｙＡ
，Ｆｅｉ
－ＦｅｉＬ
．Ｄｅｎｓｅｃａｐ
：ＦｕｌｌｙＣｏｎｖｏｌｕｔｉｏｎａｌＬｏｃａｌｉｚａｔｉｏｎ


ＮｅｔｗｏｒｋｓｆｏｒＤｅｎｓｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎ


ＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］
５２０１６
：４５６５
－４５７４．


［３４
］ＭａｏＹ
，ＺｈｏｕＣ
５ＷａｎｇＸ
，ｅｔａｌ
．ＳｈｏｗａｎｄＴｅｌｌＭｏｒｅ
：Ｔｏｐ
ｉｃ
－ｏｒ
ｉｅｎｔｅｄＭｕｌｔｉ
－ｓｅｎｔｅｎｃｅ


ＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ］
，／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆ
Ｈｉｅ２７ｔｈＩｎｔｅｒ
ｎａｔｉｏｎａｌＪｏｉｎｔＣｏｎｆｅｒｅｎｃｅｏｎ


ＡｒｔｉｆｉｃｉａｌＩｎｔｅｌｌｉｇｅｎｃｅ
［Ｃ］
，２０１８
：４２５８
－４２６４
．


［３５
］ＬｉａｎｇＸ
，ＨｕＺ
？ＺｈａｎｇＨ
，ｅｔａｌ
．ＲｅｃｕｒｒｅｎｔＴｏｐ
ｉｃ
－ＴｒａｎｓｉｔｉｏｎＧＡＮｆｏｒＶｉｓｕａｌ


６３


北京邮电大学工学硕士学位论文


ＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎ［Ａ
］
．／／ＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒ＼＾ｓｉｏｎ
［Ｃ
］
，


２０
１７
：３３８２
－３３９
１
．


［３６
］ＣｈａｔｔｅｉｊｅｅＭ
，ＳｃｈｗｉｎｇＡＧ
．ＤｉｖｅｒｓｅａｎｄＣｏｈｅｒｅｎｔＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎｆｒｏｍ


Ｉｍａｇｅｓ［Ａ
］
．／／ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
［Ｃ
］
，２０１８
：７４７
－７６３
．


［３
７
］
＂
ＷａｎｇＪ
，ＰａｎＹ
，ＹａｏＴ
，ｅｔａｌ
．ＣｏｎｖｏｌｕｔｉｏｎａｌＡｕｔｏ
－ｅｎｃｏｄｉｎｇｏｆＳｅｎｔｅｎｃｅＴｏｐ
ｉｃｓｆｏｒ


ＩｍａｇｅＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎ
［Ａ
］
．／／Ｉｎｔｅｒ
ｎａｔｉｏｎａｌＪｏｉｎｔＣｏｎｆｅｒｅｎｃｅｏｎＡｒｔｉｆｉｃｉａｌ


Ｉｎｔｅｌｌｉｇｅｎｃｅ［Ｃ］５２０１９
：９４０
－９４６
．


［３８
］ＷｕＳ
，
ＺｈａＺＪ
，ＷａｎｇＺ
３ｅｔａｌ
．ＤｅｎｓｅｌｙＳｕｐｅｒｖｉｓｅｄＨｉｅｒａｒｃｈｉｃａｌＰｏｌｉｃｙ
－ｖａｌｕｅ


ＮｅｔｗｏｒｋｆｏｒＩｍａｇｅＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎ
［Ａ
］
，／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２８ｔｈ


Ｉｎｔｅｒ
ｎａｔｉｏｎａｌＪｏｉｎｔＣｏｎｆｅｒｅｎｃｅｏｎＡｒｔｉｆ
ｉｃｉａｌＩｎｔｅｌｌｉｇｅｎｃｅ
ｆＣ
］
，２０１９
：９７５
－９８Ｌ


［３９
］李睿凡
，梁昊雨
，冯方向
，等
．全卷积神经结构的段落式图像描述算法［Ｊ
］
．北


京邮电大学学报，２０１９（６）
：７
．


［４０
］
ＬｉＲ
，ＬｉａｎｇＨ
，ＳｈｉＹ
，ｅｔａｌ
．Ｄｕａｌ
－ＣＮＮ
：ＡＣｏｎｖｏｌｕｔｉｏｎａｌＬａｎｇｕａｇｅＤｅｃｏｄｅｒｆｏｒ


ＰａｒａｇｒａｐｈＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ｊ
］
，Ｎｅｕｒｏｃｏｍｐｕｔｉｎｇ，２０２０
，３９６
：９２
－１０１
．


［４１
］ＣｈｅＷ
，ＦａｎＸ
，ＸｉｏｎｇＲ
，ｅｔａｌ
．ＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎＮｅｔｗｏｒｋｗｉｔｈＶｉｓｕａｌ


ＲｅｌａｔｉｏｎｓｈｉｐＤｅｔｅｃｔｉｏｎ［Ａ］
，／／ＡＣＭＭｕｌｔｉｍｅｄｉａ
［Ｃ
］
，２０１８
：１４３５
－
１４４３
．


［４２
］ＣｈｅＷ
３ＦａｎＸ
，ＸｉｏｎｇＲ
，ｅｔａｌ
．ＶｉｓｕａｌＲｅｌａｔｉｏｎｓｈｉｐＥｍｂｅｄｄｉｎｇＮｅｔｗｏｒｋｆｏｒＩｍａｇｅ


ＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎ
［Ｊ
］
，ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＭｕｌｔｉｍｅｄｉａ
，２０１９
：１
－
１
．


［４３
］ＺｈａＺ
，ＬｉｕＤ
，ＺｈａｎｇＨ
，ｅｔａｌ
．Ｃｏｎｔｅｘｔ
－ＡｗａｒｅＶｉｓｕａｌＰｏｌｉｃｙＮｅｔｗｏｒｋｆｏｒＦｉｎｅ
－


ＧｒａｉｎｅｄＩｍａｇｅＣａｐｔｉｏｎｉｎｇ［Ｊ
］
，ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＰａｔｔｅｒ
ｎＡｎａｌｙｓｉｓａｎｄＭａｃｈｉｎｅ


Ｉｎｔｅｌｌｉｇｅｎｃｅ
，２０１９
：１
－
１
．


［４４
］ＸｕＣ
，ＬｉＹ
，ＬｉＣ
？ｅｔａｌ
．ＩｎｔｅｒａｃｔｉｖｅＫｅｙ
－ＶａｌｕｅＭｅｍｏｒｙ
－ａｕｇｍｅｎｔｅｄＡｔｔｅｎｔｉｏｎｆｏｒ


ＩｍａｇｅＰａｒａｇｒａｐｈＣａｐ
ｔｉｏｎｉｎｇ［Ａ］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２８ｔｈＩｎｔｅｒ
ｎａｔｉｏｎａｌ


ＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔａｔｉｏｎａｌＬｉｎｇｕｉｓｔｉｃｓ
［Ｃ
］
５２０２０
：３
１３２
－３
１４２
．


［４５
］ＹａｎｇＸ
，ＧａｏＣ
，ＺｈａｎｇＨ
，ｅｔａｌ
．ＨｉｅｒａｒｃｈｉｃａｌＳｃｅｎｅＧｒａｐｈＥｎｃｏｄｅｒ
－Ｄｅｃｏｄｅｒｆｏｒ


ＩｍａｇｅＰａｒａｇｒａｐｈＣａｐ
ｔｉｏｎｉｎｇ［Ａ］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２８ｔｈＡＣＭＩｎｔｅｒ
ｎａｔｉｏｎａｌ


ＣｏｎｆｅｒｅｎｃｅｏｎＭｕｌｔｉｍｅｄｉａ［Ｃ
］
，２０２０
：４１８
１
－４１８９
．


［４６］Ｍｅｌａｓｋｙｒ
ｉａｚｉＬ
，ＲｕｓｈＡＭ
，ＨａｎＧ
，ｅｔａｌ
．ＴｒａｉｎｉｎｇｆｏｒＤｉｖｅｒｓｉｔｙ
ｉｎＩｍａｇｅＰａｒａｇｒａｐｈ


Ｃａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／Ｅｍｐ
ｉｒｉｃａｌＭｅｔｈｏｄｓｉｎＮａｔｕｒａｌＬａｎｇｕａｇｅＰｒｏｃｅｓｓｉｎｇ［Ｃ
］
？２０
１８
：


７５７
－７６
１
．


［４７
］ＷａｎｇＺ
，ＬｕｏＹ
，ＬｉＹ
，ｅｔａｌ
．ＬｏｏｋＤｅｅｐｅｒＳｅｅＲｉｃｈｅｒ
：Ｄｅｐｔｈ
－ａｗｍ
＇
ｅＩｍａｇｅＰａｒａｇｒａｐｈ


Ｃａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／ＡＣＭＭｕｌｔｉｍｅｄｉａ
［Ｃ］，２０１８
：６７２
－６８０
．


［４８
］ＬｕｏＹ
，ＨｕａｎｇＺ
，
ＺｈａｎｇＺ
，
ｅｔａｌ
．Ｃｕｒｉｏｓｉｔｙ
－ｄｒ
ｉｖｅｎＲｅｉｎｆｏｒｃｅｍｅｎｔＬｅａｒｎｉｎｇｆｏｒ


ＤｉｖｅｒｓｅＶｉｓｕａｌＰａｒａｇｒａｐｈＧｅｎｅｒａｔｉｏｎ［Ａ
］
，／／ＡＣＭＭｕｌｔｉｍｅｄｉａ［Ｃ
］
，２０１９
：２３４１
－


６４


参考文献


２３５０
．


［４９
］ＹａｎｇＬＣ
５ＹａｎｇＣＹ
，ＨｓｕＪＹ．ＯｂｊｅｃｔＲｅｌａｔｉｏｎＡｔｔｅｎｔｉｏｎｆｏｒＩｍａｇｅＰａｒａｇｒａｐｈ


Ｃａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＡＡＡＩＣｏｎｆｅｒｅｎｃｅｏｎＡｒｔｉｆｉｃｉａｌ


Ｉｎｔｅｌｌｉｇｅｎｃｅ
［Ｃ
］，２０２１
，
３５（４）
：３
１３６
－３
１４４
．


［５０
］ＨｏｎｇＲ
，ＬｉｕＤ
？ＭｏＸ
５ｅｔａｌ
．Ｌｅａｒｎｉｎｇ
ｔｏＣｏｍｐｏｓｅａｎｄＲｅａｓｏｎｗｉｔｈＬａｎｇｕａｇｅＴｒｅｅ


ＳｔｒｕｃｔｕｒｅｓｆｏｒＶｉｓｕａｌＧｒｏｕｎｄｉｎｇ［Ｊ］
＿ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＰａｔｅｒ
ｎＡｎａｌｙｓｉｓａｎｄ


ＭａｃｈｉｎｅＩｎｔｅｌｌｉｇｅｎｃｅ
，２０１９
．


［５ｌ
］ＬｉｕＤ
，ＺｈａｎｇＨ
，ＷｕＦ
，ｅｔａｌ
．Ｌｅａｒｎｉｎｇ
ｔｏＡｓｓｅｍｂｌｅＮｅｕｒａｌＭｏｄｕｌｅＴｒｅｅＮｅｔｗｏｒｋｓ


ｆｏｒＶｉｓｕａｌＧｒｏｕｎｄｉｎｇ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ／ＣＶＦＩｎｔｅｒ
ｎａｔｉｏｎａｌ


ＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
［Ｃ
］
５２０１９
：４６７３
－４６８２
．


［５２
］ＣａｏＱ？ＬｉａｎｇＸ
，ＬｉＢ
，ｅｔａｌ
．ＶｉｓｕａｌＱｕｅｓｔｉｏｎＲｅａｓｏｎｉｎｇｏｎＧｅｎｅｒａｌＤｅｐｅｎｄｅｎｃｙ


Ｔｒｅｅ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎ


Ｒｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］
，２０１８
：７２４９
－７２５７
．


［５３
］ＴａｎｇＫ
，ＺｈａｎｇＨ
，ＷｕＢ
，ｅｔａｌ
．Ｌｅａｒｎｉｎｇ
ｔｏＣｏｍｐｏｓｅＤｙｎａｍｉｃＴｒｅｅＳｔｒｕｃｔｕｒｅｓｆｏｒ


ＶｉｓｕａｌＣｏｎｔｅｘｔｓ
［Ａ
］
．／／Ｐｒ
ｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ／ＣＶＦＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒ


ＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］
？２０１９
：６６１９
－６６２８
．


［５４
］ＹａｏＴ
，
ＰａｎＹ
，
ＬｉＹ
，
ｅｔａｌ
．ＨｉｅｒａｒｃｈｙＰａｒｓｉｎｇｆｏｒＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ
］
＿／／


ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ／ＣＶＦＩｎｔｅｒ
ｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｃｍＣｏｍｐｕｔｅｒＶｉｓｉｏｎ［Ｃ
］
，


２０１９
：２６２１
－２６２９
．


［５５
］ＭａＺ
，ＹｕａｎＣ
，ＣｈｅｎｇＹ
，ｅｔａｌ
．Ｉｍａｇｅ
－ｔｏ
－
ｔｒｅｅ
：ＡＴｒｅｅ
－ｓｔｒｕｃｔｕｒｅｄＤｅｃｏｄｅｒｆｏｒＩｍａｇｅ


Ｃａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／２０１９ＩＥＥＥＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＭｕｌｔｉｍｅｄｉａａｎｄＥｘｐｏ
［Ｃ
］
，


２０１９
：１２９４
－１２９９
．


［５６
］ＷａｎｇＨ
？ＬｉｎＧ
，ＨｏｉＳＣＨ
，ｅｔａｌ
．Ｓｔｒｕｃｔｕｒｅ
－ａｗａｒｅＧｅｎｅｒａｔｉｏｎＮｅｔｗｏｒｋｆｏｒＲｅｃｉｐｅ


Ｇｅｎｅｒａｔｉｏｎｆ
ｒｏｍＩｍａｇｅｓ［Ａ
］
，／／ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ［Ｃ
］
，２０２０
：


３５９
－３７４
．


［５７
］ＬｅＣｕｎＹ
，ＢｏｓｅｒＢ
，ＤｅｎｋｅｒＪＳ
，ｅｔａｌ
．ＢａｃｋｐｒｏｐａｇａｔｉｏｎＡｐｐ
ｌｉｅｄｔｏＨａｎｄｗｒｉｔｔｅｎＺｉｐ


ＣｏｄｅＲｅｃｏｇｎｉｔｉｏｎ
［Ｊ］
，ＮｅｕｒａｌＣｏｍｐｕｔａｔｉｏｎ
，１９８９
，１
（４
）
：５４１
－５５
１
．


［５
８
］ＤｅｎｇＪ
，ＤｏｎｇＷ
，
ＳｏｃｈｅｒＲ
，
ｅｔａｌ
．ＩｍａｇｅＮｅｔ
：ＡＬａｒｇｅ
－ｓｃａｌｅＨｉｅｒａｒｃｈｉｃａｌＩｍａｇｅ


Ｄａｔａｂａｓｅ
［Ａ
］
．／／２００９ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｅｒｎ


Ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ
］
？２００９
：２４８
－２５５
．


［５９
］ＫｒｉｚｈｅｖｓｋｙＡ
，ＳｕｔｓｋｅｖｅｒＩ
，ＨｉｎｔｏｎＧＥ
．ＩｍａｇｅＮｅｔＣｌａｓｓｉｆｉｃａｔｉｏｎｗｉｔｈＤｅｅｐ


ＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｕｒａｌＮｅｔｗｏｒｋｓ［Ａ
］
．／／ＡｄｖａｎｃｅｓｉｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎＰｒｏｃｅｓｓｉｎｇ


Ｓｙｓｔｅｍｓ［Ｃ］
，２０１２
：８４
－９０
．


［６０
］ＳｉｍｏｎｙａｎＫ
，ＺｉｓｓｅｒｍａｎＡ
．ＶｅｒｙＤｅｅｐＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｔｗｏｒｋｓｆｏｒＬａｒｇｅ
－ｓｃａｌｅ


６５


北京邮电大学工学硕士学位论文


ＩｍａｇｅＲｅｃｏｇｎｉｔ
ｉｏｎ［Ｊ］
．ａｒＸｉｖ
ｐｒｅｐｒ
ｉｎｔａｒＸｉｖ
：１４０９
．
１５５６
，２０１４．


［６１
］ＳｚｅｇｅｄｙＣ
，ＬｉｕＷ
，ＪｉａＹ
，ｅｔａｌ
．ＧｏｉｎｇＤｅｅｐｅｒｗｉｔｂＣｏｎｖｏｌｕｔｉｏｎｓ［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓ


ｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］
５２０
１５
：１
－


９
．


［６２
］ＨｅＫ
，ＺｈａｎｇＸ
，ＲｅｎＳ
，
ｅｔａｌ
．ＤｅｅｐＲｅｓｉｄｕａｌＬｅａｒｎｉｎｇｆｏｒＩｍａｇｅＲｅｃｏｇｎｉｔｉｏｎ
［Ａ
］
．


／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎ


Ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ
］
，２０１６
：７７０
－７７８
．


［６３
］ＨｕＪ
，ＳｈｅｎＬ
５ＳｕｎＧ
．Ｓｑｕｅｅｚｅ
－ａｎｄ
－ｅｘｃｉｔａｔｉｏｎＮｅｔｗｏｒｋｓ［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ


ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ［Ｃ
］
，２０１８
：７１３２
－


７１４１
．


［６４
］ＸｉｅＳ
，ＧｉｒｓｈｉｃｋＲ
，ＤｏｌｌａｒＰ
，ｅｔａｌ
．ＡｇｇｒｅｇａｔｅｄＲｅｓｉｄｕａｌＴｒａｎｓｆｏｒｍａｔｉｏｎｓｆｏｒＤｅｅｐ


ＮｅｕｒａｌＮｅｔｗｏｒｋｓ
［Ａ
］
，／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ


ａｎｄＰａｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ］
，２０１７
：１４９２
－１５００．


［６５
］ＴａｎＭ
，ＬｅＱ
．Ｅｆ
ｌｆｉｃｉｅｎｔｎｅｔ
：ＲｅｔｈｉｎｋｉｎｇＭｏｄｅｌＳｃａｌｉｎｇｆｏｒＣｏｎｖｏｌｕｔｉｏｎａｌＮｅｕｒａｌ


Ｎｅｔｗｏｒｋｓ［Ａ
］
．／／Ｉｎｔｅｒ
ｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＭａｃｈｉｎｅＬｅａｍｉｎｇ［Ｃ
］
，２０
１９
：６１０５
－


６１
１４．


［６６
］ＧｏｏｄｆｅｌｌｏｗＩ
，Ｂｅｎｇ
ｉｏＹ
，ＣｏｕｒｖｉｌｌｅＡ
．Ｄｅｅｐ
ｌｅａｍｉｎｇ［Ｍ］
．ＭＩＴ
ｐｒｅｓｓ
，２０１６
．


［６７
］ＲｅｄｍｏｎＪ
，ＤｉｗａｌａＳ
３ＧｉｒｓｈｉｃｋＲ
，
ｅｔａｌ
．ＹｏｕＯｎｌｙＬｏｏｋＯｎｃｅ
：Ｕｎｉｆ
ｉｅｄ
，Ｒｅａｌ
－ｔ
ｉｍｅ


ＯｂｊｅｃｔＤｅｔｅｃｔｉｏｎ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒ＼＾ｓｉｏｎ


ａｎｄＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］
，２０１６
：７７９
－７８８
．


［６８
］ＨｅＫ
ｓＧｋｉｏｘａｒｉＧ
，ＤｏｌｌａｒＰ
，ｅｔａｌ
．ＭａｓｋＲ
－ＣＮＮ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥ


ＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
ｆＣ
］
，２０１７
：２９６１
－２９６９
．


［６９
］Ｋｒ
ｉｓｈｎａＲ
，ＺｈｕＹ
５ＧｒｏｔｈＯ
，ｅｔａｌ
．ＶｉｓｕａｌＧｅｎｏｍｅ
：ＣｏｎｎｅｃｔｉｎｇＬａｎｇｕａｇｅａｎｄＶｉｓｉｏｎ


ＵｓｉｎｇＣｒｏｗｄｓｏｕｒｃｅｄＤｅｎｓｅＩｍａｇｅＡｎｎｏｔａｔｉｏｎｓ［Ｊ
］
．Ｉｎｔｅｒ
ｎａｔｉｏｎａｌＪｏｕｒ
ｎａｌｏｆ


ＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
，２０１７
，１２３（
１）
：３２
－７３
．


［７０
］Ｂｅｎｇ
ｉｏＹ
，ＤｕｃｈａｒｍｅＲ
ｓＶｉｎｃｅｎｔＰ
，ｅｔａｌ
．ＡＮｅｕｒａｌＰｒｏｂａｂｉｌｉｓｔｉｃＬａｎｇｕａｇｅＭｏｄｅｌ
［Ｊ］
．


Ｊｏｕｒ
ｎａｌｏｆＭａｃｈｉｎｅＬｅａｒｎｉｎｇＲｅｓｅａｒｃｈ
，２００３
，３
：１
１３７
－
１
１５５
．


［７１
］ＨｏｃｈｒｅｉｔｅｒＳ
，ＳｃｈｍｉｄｈｕｂｅｒＪ．ＬｏｎｇＳｈｏｒ
ｔ
－ｔｅｒｍＭｅｍｏｒｙ［Ｊ］
．ＮｅｕｒａｌＣｏｍｐｕｔａｔｉｏｎ
，


１９９７
，
９（８）
：１７３５
－１７８０
．


［７２
］
ＢａＪＬ
，
ＫｉｒｏｓＪＲ
，
ＨｉｎｔｏｎＧＥ
．ＬａｙｅｒＮｏｒｍａｌｉｚａｔｉｏｎ
［Ｊ
］
．ａｒＸｉｖｐｒｅｐｒ
ｉｎｔ


ａｒＸｉｖ
：１６０７
．０６４５０
，２０１６
．


［７３
］ＬｉｎＴＹ
，ＭａｉｒｅＭ
，Ｂｅｌｏｎｇ
ｉｅＳ
，ｅｔａｌ
．Ｍｉｃｒｏｓｏｆ
ｔＣＯＣＯ
：ＣｏｍｍｏｎＯｂｊｅｃｔｓｉｎ


Ｃｏｎｔｅｘｔ
［Ａ
］
．／／ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ［Ｃ］
，２０１４
：７４０
－７５５
．


［７４
］ＢａｎｅｉｊｅｅＳ
，ＬａｖｉｅＡ
．ＭＥＴＥＯＲ
：ＡｎＡｕｔｏｍａｔｉｃＭｅｔｒｉｃｆｏｒＭＴＥｖａｌｕａｔｉｏｎｗｉｔｈ


６６


参考文献


ＩｍｐｒｏｖｅｄＣｏｒｒｅｌａｔｉｏｎｗｉｔｈＨｕｍａｎＪｕｄｇｍｅｎｔｓ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＡＣＬ


ＷｏｒｋｓｈｏｐｏｎＩｎｔｒ
ｉｎｓｉｃａｎｄＥｘｔｒｉｎｓｉｃＥｖａｌｕａｔｉｏｎＭｅａｓｕｒｅｓｆｏｒＭａｃｈｉｎｅＴｒａｎｓｌａｔｉｏｎ


ａｎｄ／ｏｒｓｕｍｍａｒｉｚａｔｉｏｎ
［Ｃ
］
５２００５
：６５
－７２
．


［７５
］ＤｅｖｌｉｎＪ
，ＣｈａｎｇＭＷ
？ＬｅｅＫ，ｅｔａｌ
．Ｂｅｒｔ
：Ｐｒｅ
－ｔｒａｉｎｉｎｇｏｆＤｅｅｐＢｉｄｉｒｅｃｔｉｏｎａｌ


ＴｒａｎｓｆｏｒｍｅｒｓｆｏｒＬａｎｇｕａｇｅＵｎｄｅｒｓｔａｎｄｉｎｇ［Ｊ
］
．ａｒＸｉｖｐｒｅｐｒ
ｉｎｔａｒＸｉｖ
：１８１０
．０４８０５
，


２０
１８
．


［７６
］ＲｅｉｍｅｒｓＮ
，ＧｕｒｅｖｙｃｈＩ
，ＲｅｉｍｅｒｓＮ
，ｅｔａｌ
．Ｓｅｎｔｅｎｃｅ
－ＢＥＲＴ：ＳｅｎｔｅｎｃｅＥｍｂｅｄｄｉｎｇｓ


ＵｓｉｎｇＳｉａｍｅｓｅＢＥＲＴ
－Ｎｅｔｗｏｒｋｓ
［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２０
１９Ｃｏｎｆｅｒｅｎｃｅｏｎ


Ｅｍｐ
ｉｒｉｃａｌＭｅｔｈｏｄｓｉｎＮａｔｕｒａｌＬａｎｇｕａｇｅＰｒｏｃｅｓｓｉｎｇ［Ｃ
］
？２０
１９
：６７
１
－６８８
．


［７７
］Ｓｒ
ｉｖａｓｔａｖａＲＫ
，ＧｒｅｆｆＫ
，ＳｃｈｍｉｄｈｕｂｅｒＪ．ＴｒａｉｎｉｎｇＶｅｒｙＤｅｅｐＮｅｔＡｖｏｒｋｓ［Ａ
］
．／／


Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２８ｔｈＩｎｔｅｒ
ｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎ


ＰｒｏｃｅｓｓｉｎｇＳｙｓｔｅｍｓ
［Ｃ
］，２０１５
：２３７７
－２３８５
．


［７８
］ＫｉｎｇｍａＤＰ
，ＢａＪ
．Ａｄａｍ
：Ａｍｅｔｈｏｄｆｏｒｓｔｏｃｈａｓｔｉｃｏｐ
ｔｉｍｉｚａｔｉｏｎ
［Ｊ］
．ａｒＸｉｖ
ｐｒｅｐｒｉｎｔ


ａｒＸｉｖ
：
１４１２
．６９８０
，２０１４．


［７９
］
ＶａｎｓＤ
，Ｂｏ
ｊａｒＯ
．ＳｅｑｕｅｎｃｅＬｅｎｇ
ｔｈｉｓａＤｏｍａｉｎ
：Ｌｅｎｇ
ｔｈ
－ｂａｓｅｄＯｖｅｒｆｉｔｔｉｎｇ
ｉｎ


ＴｒａｎｓｆｏｒｍｅｒＭｏｄｅｌｓ［Ａ
］
．／／Ｐｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅ２０２１ＣｏｎｆｅｒｅｎｃｅｏｎＥｍｐ
ｉｒｉｃａｌ


ＭｅｔｈｏｄｓｉｎＮａｔｕｒａｌＬａｎｇｕａｇｅＰｒｏｃｅｓｓｉｎｇ［Ｃ
］，２０２
１
：８２４６
－８２５７
．


［８０
］ＤｅｎｇＣ
５ＤｉｎｇＮ
，ＴａｎＭ
５ｅｔａｌ
．Ｌｅｎｇ
ｔｈ
－ｃｏｎｔｒｏｌｌａｂｌｅＩｍａｇｅＣａｐ
ｔｉｏｎｉｎｇ［Ａ
］
．／／


ＥｕｒｏｐｅａｎＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
［Ｃ
］，２０２０
：７１２
－７２９
．


［８１
］ＲｕｓｈＡＭ
．ＴｈｅＡｎｎｏｔａｔｅｄＴｒａｎｓｆｏｒｍｅｒ［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆＷｏｒｋｓｈｏｐｆｏｒＮＬＰ


ＯｐｅｎＳｏｕｒｃｅＳｏｆｔｗａｒｅ［Ｃ
］
，２０１８
：５２
－６０
．


［８２
］ＳｚｅｇｅｄｙＣ
，ＶａｎｈｏｕｃｋｅＶ
，ＩｏｆｆｅＳ
？ｅｔａｌ
．Ｒｅｔｈｉｎｋｉｎｇ
ｔｈｅＩｎｃｅｐ
ｔｉｏｎＡｒｃｈｉｔｅｃｔｕｒｅｆｏｒ


ＣｏｍｐｕｔｅｒＶｉｓｉｏｎ
［Ａ
］
．／／ＰｒｏｃｅｅｄｉｎｇｓｏｆｔｈｅＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ


ａｎｄＰａｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎ
［Ｃ
］５２０１６
：２８１８
－２８２６
．


６７


