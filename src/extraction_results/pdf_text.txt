
--- 第1页 ---
第１０期 电 子 学 报 Ｖｏｌ．４２ Ｎｏ．１０
２０１４年１０月 ＡＣＴＡＥＬＥＣＴＲＯＮＩＣＡＳＩＮＩＣＡ Ｏｃｔ． ２０１４
多视图有监督的 ＬＤＡ模型
李晓旭１，李睿凡２，３，冯方向２，曹 洁１，王小捷２，３
（１．兰州理工大学计算机与通信学院，甘肃兰州７３００５０；２．北京邮电大学计算机学院，北京１００８７６；
３．教育部信息网络工程研究中心，北京１００８７６）
摘 要： 本文主要关注多视图数据的分类问题．考虑到集成分类方法可组合多个弱分类器构成一个强分类器，
以及主题模型能学习复杂数据的语义表示，本文试图将集成学习思想引入主题模型中，以便同时学习多视图数据的分
类规则和预测性语义特征．具体地，结合概率主题模型ＬＤＡ模型和集成分类方法Ｓｏｆｔｍａｘ混合模型，提出了一个多视图
有监督的分类模型．基于变分ＥＭ方法，推导了该模型的参数估计算法．两个真实图像数据集上的实验结果表明了提
出模型有较好的分类性能．
关键词： 多视图分类；概率主题模型；变分期望最大化
中图分类号： ＴＰ１８１ 文献标识码： Ａ 文章编号： ０３７２２１１２（２０１４）１０２０４００５
电子学报ＵＲＬ：ｈｔｔｐ：／／ｗｗｗ．ｅｊｏｕｒｎａｌ．ｏｒｇ．ｃｎ ＤＯＩ：１０．３９６９／ｊ．ｉｓｓｎ．０３７２２１１２．２０１４．１０．２６
ＭｕｌｔｉｖｉｅｗＳｕｐｅｒｖｉｓｅｄＬａｔｅｎｔＤｉｒｉｃｈｌｅｔＡｌｌｏｃａｔｉｏｎ
ＬＩＸｉａｏｘｕ１，ＬＩＲｕｉｆａｎ２，３，ＦＥＮＧＦａｎｇｘｉａｎｇ２，ＣＡＯＪｉｅ１，ＷＡＮＧＸｉａｏｊｉｅ２，３
（１．ＣｏｌｌｅｇｅｏｆＣｏｍｐｕｔｅｒａｎｄＣｏｍｍｕｎｉｃａｔｉｏｎ，ＬａｎｚｈｏｕＵｎｉｖｅｒｓｉｔｙｏｆＴｅｃｈｎｏｌｏｇｙ，Ｌａｎｚｈｏｕ，Ｇａｎｓｕ７３００５０，Ｃｈｉｎａ；
２．ＳｃｈｏｏｌｏｆＣｏｍｐｕｔｅｒＳｃｉｅｎｃｅ，ＢｅｉｊｉｎｇＵｎｉｖｅｒｓｉｔｙｏｆＰｏｓｔｓａｎｄＴｅｌｅｃｏｍｍｕｎｉｃａｔｉｏｎｓ，Ｂｅｉｊｉｎｇ１００８７６，Ｃｈｉｎａ；
３．ＥｎｇｉｎｅｅｒｉｎｇＲｅｓｅａｒｃｈＣｅｎｔｅｒｏｆＩｎｆｏｒｍａｔｉｏｎＮｅｔｗｏｒｋｓ，ＭｉｎｉｓｔｒｙｏｆＥｄｕｃａｔｉｏｎ．Ｂｅｉｊｉｎｇ１００８７６，Ｃｈｉｎａ）
Ａｂｓｔｒａｃｔ： Ｉｎｔｈｅｐａｐｅｒ，ｗｅｍａｉｎｌｙｆｏｃｕｓｏｎｃｌａｓｓｉｆｉｔｉｏｎｏｎｍｕｌｔｉｖｉｅｗｄａｔａ．Ｃｏｎｓｉｄｅｒｉｎｇｔｈａｔｅｎｓｅｍｂｌｅｍｅｔｈｏｄｓｃａｎｃｏｍｂｉｎｅ
ｗｅａｋｃｌａｓｓｉｆｉｅｒｓｔｏｃｏｎｓｔｒｕｃｔａｓｔｒｏｎｇｃｌａｓｓｉｆｉｅｒ，ａｎｄｔｏｐｉｃｍｏｄｅｌｃａｎｌｅａｒｎｌａｔｅｎｔｒｅｐｒｅｓｅｎｔａｔｉｏｎｓｆｒｏｍｃｏｍｐｌｅｘｄａｔａ，ｗｅｔｒｙｔｏｉｎｔｒｏ
ｄｕｃｅｅｎｓｅｍｂｌｅｉｄｅａｔｏｔｏｐｉｃｍｏｄｅｌ，ｓｕｃｈｔｈａｔｐｒｅｄｉｃｔｉｖｅｌａｔｅｎｔｒｅｐｒｅｓｅｎｔａｔｉｏｎｃｏｕｌｄｂｅｏｂｔａｉｎｅｄａｎｄｍｕｌｔｉｖｉｅｗｃｌａｓｓｉｆｉｅｒｃｏｕｌｄｂｅ
ｌｅａｒｎｅｄ．ＷｅｐｒｏｐｏｓｅｍｕｌｔｉｖｉｅｗｓｕｐｅｒｖｉｓｅｄｌａｔｅｎｔＤｉｒｉｃｈｌｅｔａｌｌｏｃａｔｉｏｎ（ｍｕｌｔｉｖｉｅｗｓＬＤＡ）ｍｏｄｅｌｂｙｃｏｍｂｉｎｉｎｇｌａｔｅｎｔＤｉｒｉｃｈｌｅｔａｌｌｏ
ｃａｔｉｏｎｍｏｄｅｌａｎｄｔｈｅｍｉｘｔｕｒｅｏｆｓｏｆｔｍａｘｍｏｄｅｌｗｈｉｃｈｉｓａｎｅｎｓｅｍｂｌｅｃｌａｓｓｉｆｉｃａｔｉｏｎｍｏｄｅｌ．Ｍｏｒｅｏｖｅｒ，ｗｅｄｅｒｉｖｅａｐａｒａｍｅｔｅｒｅｓｔｉｍａ
ｔｉｏｎａｌｇｏｒｉｔｈｍｏｆｔｈｅｐｒｏｐｏｓｅｄｍｏｄｅｌｂａｓｅｄｏｎｖａｒｉａｔｉｏｎａｌｅｘｐｅｃｔａｔｉｏｎｍａｘｉｍｉｚａｔｉｏｎ（ＥＭ）ｐｒｏｃｅｄｕｒｅ．Ｔｈｅｅｘｐｅｒｉｍｅｎｔａｌｒｅｓｕｌｔｓｏｎ
ｔｗｏｒｅａｌｄａｔａｓｅｔｓｓｈｏｗｔｈｅｅｆｆｅｃｔｉｖｅｎｅｓｓｏｆｔｈｅｐｒｏｐｏｓｅｄｍｏｄｅｌ．
Ｋｅｙｗｏｒｄｓ： ｍｕｌｔｉｖｉｅｗｃｌａｓｓｉｆｉｃａｔｉｏｎ；ｐｒｏｂａｂｉｌｉｓｔｉｃｔｏｐｉｃｍｏｄｅｌ；ｖａｒｉａｔｉｏｎａｌｅｘｐｅｃｔａｔｉｏｎｍａｘｉｍｉｚａｔｉｏｎ
视图分类方法预测其类别．这种两阶段的多视图分类方
１ 引言
法，往往不能学到适合分类的特征表示．另一类方法是
在计算机视觉和机器学习中，很多问题都包含多视 将特征学习和分类器学习整合为一个模型，以便能学到
图数据，例如一段视频可分为声音、图像、文本字幕等数 适合分类的特征表示，如 ＭＭＨ［６］，ＭＣｓＬＤＡ［７］以及文献
据，一个物体可以分为颜色、形状等特征．目前，多视图 ［８］给出的多核学习方法．其中文献［８］的方法没有直接
数据的分类问题已被广泛关注，目的是希望利用多视图 从多视图数据中学习特征表示，而是通过学习多视图的
信息提高分类性能．传统的多视图分类方法包括特征水 核来融合多视图数据．总之，这两种中期融合方法，都是
平上的融合［１］，即初期融合方法，以及输出水平的融
从特征学习的角度来融合多视图信息．
合［２］，即后期融合方法．近期的研究逐渐开始关注中期
本文提出了一种一阶段的中期融合方法，该方法没
融合方法．在中期融合方法中，一类方法是先使用无监 有在特征学习部分而是在分类器学习部分融合多视图
督的特征学习方法学习多视图特征，如 ＣｏｒｒＬＤＡ［３］， 信息．其动机是，主题模型适合学习数据的语义特征，集
ＣＣＡ［４］以及Ｍｅｍｉｓｅｖｉｃ提出的方法［５］，然后使用一般的单
成分类方法能将多个弱分类器组合为一个强分类器，将
收稿日期：２０１３０５０２；修回日期：２０１３１００５；责任编辑：赵克
基金项目：国家自然科学基金（Ｎｏ．６１２６３０３１）；甘肃省自然科学基金（Ｎｏ．１３１０ＲＪＺＡ０３４）；中央高校基本科研业务费专项资金（Ｎｏ．２０１３ＲＣ０３０４）

--- 第2页 ---
第 １０ 期 李晓旭：多视图有监督的ＬＤＡ模型 ２０４１
其结合以便构建兼具二者优势的多视图分类方法．本 上的分类器生成类标．参数 ｙ记录了每个视图的权重，
文建立在概率主题模型 ＬＤＡ［９］和集成分类方法 Ｍｉｘｔｕｒｅ 值越大意味着越重要．
ｏｆＳｏｆｔｍａｘＭｏｄｅｌ（ＳＭＭ）［１０］上，通过令ＬＤＡ模型学习出的
语义特征作为ＳＭＭ模型的输入，提出了用于分类多视
图数据的概率主题模型．另外，两个模型的结合并不是
简单的联合，增加了参数优化中求解 ＳＭＭ模型参数的
困难．本文使用一些近似技巧，并基于变分期望最大化
（ＥＭ）方法，推导了提出模型的参数估计算法．两个真实
图像集上的实验结果表明了提出模型有较好的分类性
能．
２ ＭｖｓＬＤＡ模型
通过嵌入ＬＤＡ模型到 ＳＭＭ中，提出多视图有监督 值得指出的是，提出模型既可分类单视图数据，亦
的ＬＤＡ模型———ＭｕｌｔｉｖｉｅｗｓＬＤＡ（ＭＶｓＬＤＡ）模型．该模 可分类多视图数据，只需要将每个视图的特征表示成
型条件依赖视图数目 Ｈ和视图的主题数目Ｋ，ｈ∈｛１， 词袋表示形式．
ｈ
２，…，Ｈ｝，并假设带有类标的多视图数据（（Ｖ １ ，Ｖ ２ ，…， ３ 参数估计和预测
Ｖ），ｃ）的生成过程如下：
Ｈ
３１ 参数估计
（１）对于视图
使用最大似然估计优化提出模型的参数．考虑到
Ｖ＝｛ｖ，ｖ，…，ｖ ｝，ｈ∈｛１，２，…，Ｈ｝
ｈ ｈ１ ｈ２ ｈＭ
ｈ 潜变量上的后验概率 ｐ（Ｈ｜Ｅ）很难计算，因而采用变分
（ａ）抽取主题比例θ ～ｐ（α）．
ｈ ｄｉｒ ｈ 近似［１０］来获得近似的后验分布．给定一个数据（（Ｖ，
（ｂ）对于每个视图词汇 ｖ，ｍ∈｛１，２，…，Ｍ｝： １
ｈｍ ｈ Ｖ，…，Ｖ），ｃ），定义一个全分解的潜变量上的变分分
（ｉ）抽取主题分派 ｚ ｜θ ～ｐ （θ）． ２ Ｈ
ｈｍ ｈ ｍｕｌｔ ｈ
布：
（ｉｉ）抽取视图词汇 ｖ ｜ｚ ～ｐ （π ）．
ｈｍ ｈｍ ｍｕｌｔ ｚ ｈｍ Ｈ Ｍ ｈ
（２）对于类标 ｃ ｑ（Ｈ｜Λ）＝∏ｑ（θ ｜γ）∏ｑ（ｚ ｜ｆ）ｑ（ｓ｜λ）
ｈ ｈ ｈｍ ｈｍ
（ａ）抽取“视图”的 分派，ｓ｜ｙ～ｐ （ｙ）． ｈ＝１ ｍ＝１
ｍｕｌｔ （２）
（ｂ）
Ｍ
抽取类标 ｃ｜ｚ
ｈ
，ｓ～ｐ
ｓｏｆｔｍａｘ
（珋ｚ
ｈ
，ｓ，μ），其中珋ｚ
ｈ
＝
其中，Λ＝｛γ
１
，φ１ ，…，γ
Ｈ
，φＨ ，λ｝，γ
ｈ
是一个 Ｋ
ｈ
维的
１／Ｍ∑ ｍ ｈ ＝１ ｚ ｈｍ 为经验主题频次，Ｓｏｆｔｍａｘ函数为： Ｄｉｒｉｃｈｌｅｔ参数，φｍｈ 是一个Ｋ ｈ 维的多项式参数．给定模型
Ｈ ( ｅｘｐ（ηΤ ｈ 珋 ｃ ｚ ｈ ） )ｓｈ Ω＝｛α １ ，π １ ，…，α Ｈ ，π Ｈ ，ｙ，η｝和变分分布 ｑ，基于ＫＬ散
ｐ（ｃ｜珋ｚ，ｓ，η）＝∏ ∑ Ｃ ｅｘｐ（Τ珋ｚ） 度，可得到（（Ｖ １ ，Ｖ ２ ，…，Ｖ Ｈ ），ｃ）的似然下限：
ｈ＝１ ｌ＝１ ηｈｌｈ ｌｏｇｐ（Ｅ｜Ω）Ｅ［ｌｏｇｐ（Ｅ，Ｈ｜Ω）］－Ｅ［ｌｏｇｑ（Ｈ｜Λ）］
ｑ ｑ
该模型确定了一个潜变量和观测变量的联合分
＝Ｌ（Λ；Ω） （３）
布：
则优化目标由原来的最大化ｌｏｇｐ（Ｅ｜Ω）变为相对于变
ｐ（Ｅ，Ｈ｜Ω）
分参数Λ＝｛γ
１
，φ１ ，…，γ
Ｈ
，φＨ ，λ｝和模型参数Ω＝
＝∏
Ｈ
ｐ（θ ｜α）∏
Ｍ ｈ
ｐ（ｚ ｜θ）ｐ（ｖ ｜ｚ，π）
｛α
１
，π
１
，…，α
Ｈ
，π
Ｈ
，ｙ，η｝最大化 Ｌ（Λ；Ω）．
ｈ ｈ ｈｍ ｈ ｈｍ ｈｍ
ｈ＝１ ｍ＝１ （１）变分Ｅｓｔｅｐ
·ｐ（ｓ｜ｙ）ｐ（ｃ｜珋ｚ，ｓ，η） （１）
在Ｅｓｔｅｐ中，固定模型参数Ω，相对于变分参数Λ
其中，Ｅ＝（（Ｖ，Ｖ，…，Ｖ），ｃ），Ｈ＝｛θ，Ｚ，…，θ，
１ ２ Ｈ １ １ Ｈ 最大化Ｌ（Λ；Ω），可得到
Ｚ
Ｈ
，ｓ｝和Ω＝｛α
１
，π
１
，…，α
Ｈ
，π
Ｈ
，ｙ，η｝．其图模型表示
Ｍ
ｈ
见图１． γ
ｈｉ
＝α
ｈｉ
＋∑φｈｍｉ （４）
在上述生成过程中，步骤（１）描述了视图 Ｖ ＝ ｍ＝１
ｈ ( ( １ ))
｛ｖ，ｖ，…，ｖ ｝，ｈ∈｛１，２，…，Ｈ｝的生成过程，其中每 φｈｍｉ ∝π ｈｉｖ ｅｘｐ ψ （γ ｈｉ ）＋λ ｈ Ｍ ηｈｃｉ －（ｂΤ ｈφ ｏ ｈ ｌ ｍ ｄ）－１ｂ ｈｉ
ｈ１ ｈ２ ｈＭ ｈ ｍ ｈ
个视图的生成是无序的．该步骤目的是为了获得每个 （５）
视图的经验主题频次．步骤（２）建模了类标的生成过 其中，符号 “∝”代表“正比于”，并且
程，采用与ＳＭＭ相似的集成方法，为每个视图构建一个 Ｃ ( ( １ ) Ｍ ｈ ( Ｋ ｈ ( １ )))
分类器．首先，选择一个视图的分派，然后根据该视图 ｂ ｈｉ ＝∑ ｅｘｐ Ｍ ηｈｌｉ ∏ ∑φｈｆｉ ｅｘｐ Ｍ ηｈｌｊ
ｌ＝１ ｈ ｆ≠ｍ ｊ＝１ ｈ

--- 第3页 ---
２０４２ 电 子 学 报 ２０１４年
和φ ｏ ｈ ｌ ｍ ｄ是上一次被更新的值． ∑
ｍ
Ｍ ｄ
＝１
（φｄｈｍｉ １（ｆ＝ｉ）－φｄｈｍｆφｄｈｍｉ ）／Ｍ２
ｄｈ
．显然得不到η
λ ｈ∝
的封闭解，因而采用共轭梯度法来优化η．
ｅｘｐ ( ηΤ ｈ 珔 φｃｈ ＋ｌｎ（ｙ ｈ ）－ｌｎ ( ∑ Ｃ ∏ Ｍ ｈ ∑ Ｋ ｈ φｍｉ ｅｘｐ ( Ｍ １ ηｈｌｊ ))) 重复调用ＥＭ步骤，直到 Ｌ（Ｄ）＝∑ Ｄ Ｌ（Λ；Ω）收
ｌ＝１ｍ＝１ｊ＝１ ｈ ｄ
ｄ＝１
（６） 敛．
λ 是当前数据分派给第ｈ个视图分类器的概率，λ的 ３２ 预测分类
ｈ
值越大意味着该视图的特征分辨性越强． 从提出模型的生成过程看，类标的生成依赖每个视
迭代式（４），（５）和（６）直到数据的 ｌｏｇ似然（ｌｏｇｌｉｋｅ 图的主题频次珋ｚ和权重 ｙ．对于一个新数据，需要使用训
ｌｉｈｏｏｄ）方程（３）收敛． 练好的模型参数π计算每个视图的主题频次．这里通过
（２）Ｍｓｔｅｐ Ｅｓｅｔｐ计算 Ｅ
ｑ
［珋ｚ］＝珔 φ来近似珋ｚ．得到视图的主题频次珋ｚ
重复ＥｓｔｅｐＤ次，得到所有数据的近似后验分布， 后，利用训练好的模型参数η（即每个视图的分类规则）
从而简化了 Ｍｓｔｅｐ的计算．在 Ｍｓｔｅｐ中，相对于模型参 和视图的权重参数 ｙ，采用加权求和方式，最高值的决策
数Ω＝｛α
１
，π
１
，…，α
Ｈ
，π
Ｈ
，ｙ，η｝最大化 Ｌ（Ｄ）＝ 将被选择为最终的决策．具体计算公式如下：
∑ ｄ Ｄ ＝１ Ｌ（Λ ｄ ；Ω）．视图的
Ｄ
主题
Ｍ ｄ
和权重参数更新如下： Ｃ  ＝ａｒｇ ｃ∈｛ ｍ １，２ ａ ，… ｘ ，Ｃ｝ ∑ ｈ Ｈ ＝１ ｙ ｈ  ∑ Ｃ ｅｘ ｅ ｐ ｘ （η ｐ（η Τ ｈ 珋 ｃ Τ ｚ
ｈ
珋
ｌ
ｈ ｚ ）
ｈ
）
π ｈｉｊ∝∑ ｄ＝１ ∑ ｍ＝１ φｄｈｍｉ ｖｊ ｄｈｍ （７） ＝ａｒｇ ｍａｘ ∑ Ｈ ｙ ｌ＝ ｅ １ ｘｐ（ηΤ ｈｃ 珔 φｄｈ ） （１１）
Ｄ ｈ Ｃ
ｙ ｈ∝∑λ ｄｈ （８） ｃ∈｛１，２，…，Ｃ｝ｈ＝１ ∑ｅｘｐ（ηΤ ｈｌ 珔 φｄｈ ）
ｄ＝１ ｌ＝１
对于视图的分类规则η的优化，挑选 Ｌ中包含η 可见，最终的决策考虑了每个试图的决策和权重，
的项： 这和提出模型的生成过程是一致的，也符合人的一般
Ｄ Ｈ Ｃ 的思维方式．
Ｌ ［η］ ＝∑∑λ ｄｈ [ ηΤ ｈｃ 珔 φｄｈ －ｌｎ ( ∑Ｅ ｑ ［ｅｘｐ（ηΤ珋 ｈｌ ｚ ｄｈ ）］)]
ｄ＝１ｎ＝１ ｌ＝１ ４ 实验
关于 Ｅ
ｑ
［ｅｘｐ（ηΤ
ｈ
珋
ｌ
ｚ
ｄｈ
）］的计算，采用多变量 ｄｅｌｔａ方
１ ４１ 数据和预处理
法［１１］，Ｅｆ（Ｖ）ｆ（ＥＶ）＋ ｔｒ［２ｆ（ＥＶ）／ＶＶΤｃｏｖ（Ｖ）］．其
２ 为了评估提出模型的性能，选择了两个真实图像
中，ｆ（Ｖ）是一个 Ｋ维空间的函数．令 ｆ（珋ｚ）＝ｅｘｐ（ηΤ珋ｚ），则 数据集．一个是带有标注的场景分类数据集：ＬａｂｅｌＭｅ的
有 Ｅ ｑ ｆ（珋ｚ）ｅｘｐ（ηΤ ｈ 珔 φｌ ）
(
１＋
１
２ ηΤ ｈｌ ｃｏｖ（珋ｚ）ηｈｌ
)
．另外，为了防
子集［１２］．该数据集包含８类自然场景图像，共１６００个图
像．另一个是带有标注的事件分类数据集：８类的 ＵＩＵＣ
止过拟合，采用Ｌｏｇｉｓｔｉｃ回归［１０］等分类器的优化中常用的
Ｓｐｏｒｔ数据集［１３］，共１７９１个图像．图像和标注文本分别
方法，在目标函数中加入一个正则化项－τ‖η‖２，则Ｌ
［η］ 被作为两个不同的单视图特征．
近似为：
（１）对于图像视图，采用文献［７］中相似的方法．对
Ｄ Ｈ Ｃ
Ｌ ［η］ －∑∑λ ｄｈ ｌｎ ( ∑ｅｘｐ（ηΤ ｈ 珔 φｌｄｈ ） 于ＬａｂｅｌＭｅ数据集相关参数设置如下：设置网格的大小
ｄ＝１ｎ＝１ ｌ＝１ 为５×５，图像区块为 １６×１６，码书长度为 ２４０．对于
( １ ))
· １＋
２
ηΤ
ｈｌ
ｃｏｖ（珋ｚ
ｄｈ
）ηｈｌ ＵＩＵＣＳｐｏｒｔ的数据，所有图像一致地抽取 ２５００图像区
块，每个区块的大小为３２×３２，码书长度为２４０．
Ｄ Ｈ Ｈ Ｃ
＋∑∑λ ｄηｈ Τ ｈ 珔 φｃｄｈ －τ∑∑ηｈｌ ·ηｈｌ （９） （２）对于文本视图，使用所有不同的标注词构成标
ｄ＝１ｎ＝１ ｈ＝１ｌ＝１
Ｌ
［η］
相对于ηｈｃ 的导数为： 注文本的码书，则图像在每个标注词维度上的值，就是
该标注词的出现的频次．在 ＬａｂｅｌＭｅ数据上平均每个图
 η Ｌ ［η
ｈｃ
］ ∑
ｄ
Ｄ
＝１
λ ｄｈ ｃｃ ｄ 珔 φｄｈ －２τ·ηｈｃ －∑
ｄ
Ｄ
＝１
λ ｄｈ Ａ （１０） 像有６个标注词，对ＵＩＵＣＳｐｏｒｔ的数据上平均每个图像
有８个标注词．
其中Ａ ＝
最后，平分每个类别来生成训练和测试集．
( ( １ ) )
ｅｘｐ（ηΤ ｈ 珔 φｃｄｈ ）珔 φｄｈ １＋ ２ηΤ ｈｃ ｃｏｖ（珋ｚ ｄｈ ）ηｈｃ ＋ηΤ ｈｃ ｃｏｖ（珋ｚ ｄｈ ） ４２ 分类性能
λｄｈ
Ｃ ( １ )
∑ｅｘｐ（ηΤ ｈｌ 珔 φｄｈ ）１＋ ２ηΤ ｈｌ ｃｏｖ（珋ｚ ｄｈ ）ηｈｌ 为了评估提出模型的分类性能，选择如下几个方
ｌ＝１ 法进行比较：（１）ＭＣｓＬＤＡ，（２）ＳＢＭＬＲ［１４］，（３）ＳＶＭ
其中，珔 φｄｈｉ ＝∑ ｍ Ｍ ｄ ＝ ｈ １ 珔 φｄｈｍｉ ／Ｍ ｄｈ 并且 ｃｏｖ（珋ｚ ｄｈ ） ｆｉ ＝ ＰＯＬ［１５］，（４）ＳＶＭＲＢＦ［１５］，（５）ＦｕＬ［２］和（６）ＭＣａｓＬＤＡ．ＭＣ

--- 第4页 ---
第 １０ 期 李晓旭：多视图有监督的ＬＤＡ模型 ２０４３
ｓＬＤＡ是有监督的主题模型，该模型嵌入 ｓｏｆｔｍａｘ［１０］模型 对于方法（１）～（４），分别测试了在两个数据集的图
到ＬＤＡ模型中，并且在上述两个数据集上报告了较高的 像视图、文本视图以及将图像和文本特征平行拼接而
分类性能．ＳＢＭＬＲ是一个带有 Ｌａｐｌａｃｅ先验的 ｓｏｆｔｍａｘ分 构成的联合试图上的性能．对于方法（５）～（６）和本文的
类器，常常具有很好的泛化能力．对于两个 ＳＶＭ方法， 方法，测试了在图像和文本两个视图上的性能．对于
本文使用ｌｉｂｓｖｍ进行测试． ＭＣｓＬＤＡ模型和ＭＣａｓＬＤＡ模型，均匀的从２０到１００选
ＦｕＬ模型是先分别在图像和文本视图上构建单分 择５组主题数目，并选其最佳性能，见从表２可以看出，
类器，然后使用第三个分类器综合前面的结果．ＭＣａｓＬ 在ＬａｂｅｌＭｅ数据集上，当只使用图像视图的时候，单视
ＤＡ模型是可同时做图像分类和标注的概率主题模型， 图方法的最好性能是 ＳＶＭＲＢＦ的８１．１％．当只使用文
也可看做使用了文本和图像两个视图的分类模型． 本视图的时候，单视图方法的最好性能是 ＭＣｓＬＤＡ的
表１给出了提出模型 ＭｖｓＬＤＡ在文本和图像两个 ８９．０％．当使用图像和文本的联合试图时，四个单视图
视图数据上的性能．为了方便起见，在两个视图上设置 方法的最好性能是ＳＶＭＰＯＬ的８８．９％．另外，四个单视
相同的主题数目．实际上，可以设置不同的主题数目． 图方法在联合视图上的性能有时居然比在单视图上的
ＭｖｓＬＤＡ模型中的视图的权重参数 ｙ是二维数组，第一 性能还差一些．在多视图方法中，后期融合方法 ＦｕＬ的
维表示图像的权重，第二维表示文本的权重．实验结果 性能是８２．２％，中期融合方法 ＭＣａｓＬＤＡ的性能是７６．
表明：两个数据集上文本特征的权重比图像特征都较 ８％．而提出方法ＭｖｓＬＤＡ的性能是９２．２％．
高，及文本特征较为重要，即有更好的分辨性．提出模 在ＵＩＵＣＳｐｏｒｔ数据集上，提出模型的性能也有相似
型在 ＬａｂｅｌＭｅ数据上可达到 ９２．２％准确率，在 ＵＩＵＣ 的提升，见表３．总之，提出的模型在这两个数据集上有
Ｓｐｏｒｔ数据上可达到９９．０％的准确率． 较高的分类性能．
表１ 在ＵＩＵＣｓｐｏｒｔ和ＬａｂｅｌＭｅ数据集的５个随机训练和测试子集上ＭｖｓＬＤＡ模型的平均性能和视图的权重分派．ＡＡ表示平均性能，Ｗｅｉｇｈｔ表示
权重的分派．二元组的第一个元素表示图像视图的权重，第二个元素表示文本视图的权重
多视图 Ｋ１＝Ｋ２＝５ Ｋ１＝Ｋ２＝１０ Ｋ１＝Ｋ２＝２０ Ｋ１＝Ｋ２＝３０ Ｋ１＝Ｋ２＝４０
ＡＡＬａｂｅｌＭｅ ０．７９６ ０．８４３ ０．８８２ ０．９０５ ０．９２２
ＡＡＵＩＵＣ ０．８７６ ０．８８２ ０．９９０ ０．９８７ ０．９９０
ＷｅｉｇｈｔＬａｂｅｌＭｅ （０．５９，０．４１） （０．３３，０．６７） （０．２３，０．７７） （０．１２，０．８８） （０．２２，０．７８）
ＷｅｉｇｈｔＵＩＵＣ （０．０３，０．９７） （０．０１，０．９９） （０．００，１．００） （０．００，１．００） （０．００，１．００）
表２ 在ＬａｂｅｌＭｅ数据集的５个随机训练和测试子集上模型的平均性能比较．图像视图是指当图像特征作为一个单视图，文本视图指文本特征作
为单视图，联合特征指文本和图像的联合特征作为单视图，多视图指将文本和图像的分别作为两个不同的视图
视图类型 ＳＶＭＰＯＬ ＳＶＭＲＢＦ ＳＢＭＬＲ ＭＣｓＬＤＡ ＭｃａｓＬＤＡ ＦｕＬ ＭｖｓＬＤＡ
图像视图 ０．７７９ ０．８１１ ０．７４８ ０．７６６ Ｎ／Ａ Ｎ／Ａ ０．７６８
文本视图 ０．７８９ ０．８７９ ０．８６０ ０．８９０ Ｎ／Ａ Ｎ／Ａ ０．８９０
联合视图 ０．８８９ ０．８３７ ０．７７８ ０．７８９ Ｎ／Ａ Ｎ／Ａ ０．７８９
多视图 Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ ０．７６８ ０．８２２ ０．９２２
表３ 在ＵＩＵＣｓｐｏｒｔ数据集的５个随机训练和测试子集上模型的平均性能比较．图像视图是指当图像特征作为一个单视图，文本视图指文本特征
作为单视图，联合特征指文本和图像的联合特征作为单视图，多视图指将文本和图像的分别作为两个不同的视图
视图类型 ＳＶＭＰＯＬ ＳＶＭＲＢＦ ＳＢＭＬＲ ＭＣｓＬＤＡ ＭｃａｓＬＤＡ ＦｕＬ ＭｖｓＬＤＡ
图像视图 ０．６４７ ０．６９２ ０．６４３ ０．６４０ Ｎ／Ａ Ｎ／Ａ ０．６３９
文本视图 ０．９７６ ０．９７８ ０．９８０ ０．９８１ Ｎ／Ａ Ｎ／Ａ ０．９８３
联合视图 ０．４９３ ０．９３２ ０．９１６ ０．６６０ Ｎ／Ａ Ｎ／Ａ ０．６６２
多视图 Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ Ｎ／Ａ ０．６７０ ０．８４１ ０．９９０
４３ 结果分析 信息，而提出的模型却表现的比较好．原因在于，在上
对于上述实验结果，可总结为以下三点：（１）四个 述两个数据集中，文本特征的值相比图像特征的值较
单视图方法在联合视图上的性能有时低于在单视图上 小，然而又比较重要．两个视图的值较大的差距增加找
的性能，即使用联合视图的方法不能很好利用多视图 到这些分类器的最优解的难度，即便这些分类器的优

--- 第5页 ---
２０４４ 电 子 学 报 ２０１４年
化程序一般能够辨别不同的特征的重要性．特别在 ２００３．１２７－１３４．
ＳＢＭＬＲ方法中，Ｌ１约束的使用使得该方法更难辨别两 ［４］ＦｒａｗｌｅｙＷ Ｊ，ｅｔａｌ．Ｋｎｏｗｌｅｄｇｅｄｉｓｃｏｖｅｒｙｉｎｄａｔａｂａｓｅｓ：Ａｎ
个视图特征的重要性．而提出的模型属于中期融合方 ｏｖｅｒｖｉｅｗ［Ｊ］．ＡＩＭａｇａｚｉｎｅ，１９９２，１３（３）：５７．
法，通过构建集成分类器来融合多视图信息，避免上面 ［５］Ｍｅｍｉｓｅｖｉｃ，Ｒ．Ｏｎｍｕｌｔｉｖｉｅｗｆｅａｔｕｒｅｌｅａｒｎｉｎｇ［Ａ］．Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｆｔｈｅ２９ｔｈＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅｏｎＭａｃｈｉｎｅＬｅａｒｎｉｎｇ
提到的使用联合视图的问题．
（ＩＣＭＬ１２）［Ｃ］．ＮｅｗＹｏｒｋ，ＵＳＡ：Ｏｍｎｉｐｒｅｓｓ，２０１２．１６１－
（２）提出的模型表现的比后期融合方法 ＦｕＬ好，原
１６８．
因也许是：在 ＦｕＬ中，每个视图分类器的训练是独立
［６］ＣｈｅｎＮ，ｅｔａｌ．Ｐｒｅｄｉｃｔｉｖｅｓｕｂｓｐａｃｅｌｅａｒｎｉｎｇｆｏｒｍｕｌｔｉｖｉｅｗｄａｔａ：
的．相反，在提出的模型中，分类器的训练是交互的．另
Ａｌａｒｇｅｍａｒｇｉｎａｐｐｒｏａｃｈ［Ａ］．ＡｄｖａｎｃｅｓｉｎＮｅｕｒａｌＩｎｆｏｒｍａｔｉｏｎ
外，提出的模型能学习适合分类的预测特征，以致更容
ＰｒｏｃｅｓｓｉｎｇＳｙｓｔｅｍｓ［Ｃ］．Ｖａｎｃｏｕｖｅｒ：ＣｕｒｒａｎＡｓｓｏｃｉａｔｅｓ，２０１０．
易构建适合分类多视图数据的分类器．
３６１－３６９．
（３）提出的模型表现的比多视图中期融合方法
［７］ＷａｎｇＣ，ｅｔａｌ．Ｓｉｍｕｌｔａｎｅｏｕｓｉｍａｇｅｃｌａｓｓｉｆｉｃａｔｉｏｎａｎｄａｎｎｏｔａｔｉｏｎ
ＭＣａｓＬＤＡ好，是因为本文使用的两个数据集上文本特 ［Ａ］．ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎＲｅｃｏｇ
征值比较小，并且高频词对主题模型 ＭＣａｓＬＤＡ学习语 ｎｉｔｉｏｎ（ＣＶＰＲ０９）［Ｃ］．ＩＥＥＥ，２００９．１９０３－１９１０．
义特征的影响大，以致文本特征对语义特征学习有较 ［８］ＳｏｎｎｅｎｂｕｒｇＳ，ｅｔａｌ．Ｌａｒｇｅｓｃａｌｅｍｕｌｔｉｐｌｅｋｅｒｎｅｌｌｅａｒｎｉｎｇ［Ｊ］．
小的作用．而提出的模型集合了特征学习和集成分类 ＴｈｅＪｏｕｒｎａｌｏｆＭａｃｈｉｎｅＬｅａｒｎｉｎｇＲｅｓｅａｒｃｈ，２００６，７：１５３１－
器的学习，并选择在视图分类器的训练阶段利用多视 １５６５．
图信息，从而避免该问题． ［９］ＢｌｅｉＤＭ，ｅｔａｌ．Ｌａｔｅｎｔｄｉｒｉｃｈｌｅｔｌｅｔａｌｌｏｃａｔｉｏｎ［Ｊ］．ＴｈｅＪｏｕｒｎａｌ
ｏｆＭａｃｈｉｎｅＬｅａｒｎｉｎｇＲｅｓｅａｒｃｈ，２００３，３：９９３－１０２２．
５ 结论
［１０］ＢｉｓｈｏｐＣＭ，ｅｔａｌ．ＰａｔｔｅｒｎＲｅｃｏｇｎｉｔｉｏｎａｎｄＭａｃｈｉｎｅＬｅａｒｎｉｎｇ
本文提出了一个分类多视图数据的概率主题模型
［Ｍ］．ＳｐｒｉｎｇｅｒＮｅｗＹｏｒｋ，２００６．４６１－６７４．
［１１］ＢｒａｕｎＭ，ＭｃＡｕｌｉｆｆｅＪ．Ｖａｒｉａｔｉｏｎａｌｉｎｆｅｒｅｎｃｅｆｏｒｌａｒｇｅｓｃａｌｅ
ＭｖｓＬＤＡ，并基于变分ＥＭ推导了参数估计算法．两个真
ｍｏｄｅｌｓｏｆｄｉｓｃｒｅｔｅｃｈｏｉｃｅ［Ｊ］．ＪｏｕｒｎａｌｏｆｔｈｅＡｍｅｒｉｃａｎＳｔａｔｉｓ
实图像数据集上的实验结果表明了提出模型有较好的
ｔｉｃａｌＡｓｓｏｃｉａｔｉｏｎ，２０１０，１０５（４８９）：３２４－３３５．
分类性能，也表明了该模型充分利用了多视图信息．下
［１２］ＲｕｓｓｅｌｌＢＣ，ｅｔａｌ．Ｌａｂｅｌｍｅ：Ａｄａｔａｂａｓｅａｎｄｗｅｂｂａｓｅｄｔｏｏｌ
一步工作，将在本文算法的基础上，考虑如何确定主题
ｆｏｒｉｍａｇｅａｎｎｏｔａｔｉｏｎ［Ｊ］．ＩｎｔｅｒｎａｔｉｏｎａｌＪｏｕｒｎａｌｏｆＣｏｍｐｕｔｅｒ
数目，以及当给定一组特征时，如何确定特征的视图分
Ｖｉｓｉｏｎ，２００８，７７（１）：１５７－１７３．
组等问题．
［１３］ＬｉＬＪ，ＦｅｉＦｅｉＬ．Ｗｈａｔ，ｗｈｅｒｅａｎｄｗｈｏ？ｃｌａｓｓｉｆｙｉｎｇｅｖｅｎｔｓｂｙ
ｓｃｅｎｅａｎｄｏｂｊｅｃｔｒｅｃｏｇｎｉｔｉｏｎ［Ａ］．ＩＥＥＥ１１ｔｈＩｎｔｅｒｎａｔｉｏｎａｌ
参考文献
ＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎ（ＩＣＣＶ２００７）［Ｃ］．ＩＥＥＥ，
［１］ＷｕＬ，ｅｔａｌ．Ｍｕｌｔｉｍｏｄａｌｉｎｔｅｇｒａｔｉｏｎ—Ａｓｔａｔｉｓｔｉｃａｌｖｉｅｗ［Ｊ］． ２００７．１－８．
ＩＥＥＥＴｒａｎｓａｃｔｉｏｎｓｏｎＭｕｌｔｉｍｅｄｉａ，１９９９，１（４）：３３４－３４１． ［１４］ＣａｗｌｅｙＧＣ，ｅｔａｌ．Ｓｐａｒｓｅｍｕｌｔｉｎｏｍｉａｌｌｏｇｉｓｔｉｃｒｅｇｒｅｓｓｉｏｎｖｉａ
［２］ＷａｎｇＧ，ｅｔａｌ．Ｂｕｉｌｄｉｎｇｔｅｘｔｆｅａｔｕｒｅｓｆｏｒｏｂｊｅｃｔｉｍａｇｅｃｌａｓｓｉｆｉ ｂａｙｅｓｉａｎＬ１ｒｅｇｕｌａｒｉｓａｔｉｏｎ［Ａ］．Ａｄｖａｎｃｅｓｉｎｎｅｕｒａｌｉｎｆｏｒｍａｔｉｏｎ
ｃａｔｉｏｎ［Ａ］．ＩＥＥＥＣｏｎｆｅｒｅｎｃｅｏｎＣｏｍｐｕｔｅｒＶｉｓｉｏｎａｎｄＰａｔｔｅｒｎ ｐｒｏｃｅｓｓｉｎｇｓｙｓｔｅｍｓ［Ｃ］．ＣａｍｂｒｉｄｇｅＭＡＵＳＡ：ＭＩＴＰｒｅｓｓ，
Ｒｅｃｏｇｎｉｔｉｏｎ（ＣＶＰＲ０９）［Ｃ］．ＩＥＥＥ，２００９．１３６７－１３７４． ２００７．２０９－２１６．
［３］ＢｌｅｉＤＭａｎｄＪｏｒｄａｎＭＩ．Ｍｏｄｅｌｉｎｇａｎｎｏｔａｔｅｄｄａｔａ［Ａ］．Ｐｒｏｃ ［１５］ＣｈａｎｇＣＣ，ＬｉｎＣＪ．Ｌｉｂｓｖｍ：Ａｌｉｂｒａｒｙｆｏｒｓｕｐｐｏｒｔｖｅｃｔｏｒｍａ
ｏｆｔｈｅ２６ｔｈＡｎｎｕａｌＩｎｔｅｒｎａｔｉｏｎａｌＡＣＭ ＳＩＧＩＲＣｏｎｆｅｒｅｎｃｅｏｎ ｃｈｉｎｅｓ［Ｊ］．ＡＣＭ ＴｒａｎｓａｃｔｉｏｎｓｏｎＩｎｔｅｌｌｉｇｅｎｔＳｙｓｔｅｍｓａｎｄ
ＲｅｓｅａｒｃｈａｎｄＤｅｖｅｌｏｐｍｅｎｔｉｎＩｎｆｏｒｍａｉｏｎＲｅｔｒｉｅｖａｌ［Ｃ］．ＡＣＭ， Ｔｅｃｈｎｏｌｏｇｙ（ＴＩＳＴ），２０１１，２（３）：２７．
作者简介
李晓旭 女，１９８２年生于吉林白城．兰州理 李睿凡 男，１９７５年生于河北完县．北京邮
工大学计算机与通信学院讲师．研究方向为计 电大学计算机学院讲师．主要研究兴趣为多模
算机视觉、机器学习． 态智能信息处理．
Ｅｍａｉｌ：ｘｉａｏｘｕｌｉｌｕｔ＠ｇｍａｉｌ．ｃｏｍ Ｅｍａｉｌ：ｒｆｌｉ＠ｂｕｐｔ．ｅｄｕ．ｃｎ
